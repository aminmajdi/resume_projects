{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef846b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import ijson\n",
    "import pandas as pd\n",
    "import re, os\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f901f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_df= pd.read_csv('database/country_code.csv' ,sep = ',')\n",
    "country_code = country_code_df.values.tolist()\n",
    "\n",
    "domain_df= pd.read_csv('database/domain.csv' ,sep = '.')\n",
    "domain_code = domain_df.values.tolist()\n",
    "\n",
    "flags_df= pd.read_csv('database/flags_new.csv' ,sep = ',')\n",
    "flags = flags_df.values.tolist()\n",
    "\n",
    "language_code_df= pd.read_csv('database/language_code.csv' ,sep = ':')\n",
    "language_code = language_code_df.values.tolist()\n",
    "    \n",
    "cities_df= pd.read_csv('database/worldcities.csv' ,sep = ',')\n",
    "cities = cities_df.values.tolist()\n",
    "\n",
    "country_to_code = [row[1] for row in country_code]\n",
    "country_class = { name: k+1 for k,name in enumerate(country_to_code) }#create class for each country code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485d56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### all the functiones needed for this project\n",
    "def tokenize(s): return re.sub('([^A-Za-z0-9 ]+)', ' \\\\1 ', s).split()  # add space around anything not alphanum\n",
    "def sanify(s): return s.replace(':',';').replace('|','/')\n",
    "\n",
    "def get_key(dicti,val):\n",
    "    for key, value in dicti.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "def writeToVWFile(filename, examples):\n",
    "    with open(filename, 'w') as h:\n",
    "        for ex in examples:\n",
    "            h.write(ex.strip()+'\\n')\n",
    "def pop_2(tokens,n=2):# \n",
    "    pop_list =[]\n",
    "    for ii in tokens:\n",
    "        if len(ii)<=n:\n",
    "            pop_list.append(ii)\n",
    "    for ii in pop_list:\n",
    "        tokens.remove(ii)\n",
    "    return tokens\n",
    "    \n",
    "def check_flag(tokens):\n",
    "    labeled = False\n",
    "    label = None\n",
    "    #tokens = pop_2(tokens)\n",
    "    for token in tokens: #check for countries with one part\n",
    "        if token in flags_df.values:\n",
    "            index_row = [flags.index(row) for row in flags if token in row[0]]\n",
    "            if index_row:\n",
    "                label_char =flags[index_row[0]][1]\n",
    "                label_char =str(label_char).lower()\n",
    "                label = country_class[label_char]\n",
    "                labeled =True\n",
    "                break\n",
    "    return labeled , label\n",
    "\n",
    "def city_country_check(place):\n",
    "    is_labeled = False\n",
    "    label = None\n",
    "    place = pop_2(place)\n",
    "    for token in place: #check for countries with one part\n",
    "        if token in country_code_df.values:\n",
    "            index_row = [country_code.index(row) for row in country_code if token in row[0]]\n",
    "            label_char =country_code[index_row[0]][1]\n",
    "            label_char =str(label_char).lower()\n",
    "            label = country_class[label_char]\n",
    "            is_labeled= True\n",
    "            break\n",
    "    if not is_labeled:\n",
    "        for k in range(len(place)-1): #for cities like new york or mexico city\n",
    "            token ='%s %s' % (place[k],place[k+1])\n",
    "            token = str(token).lower()\n",
    "            #print(token)\n",
    "            if token in cities_df.values:\n",
    "                index_row = [cities.index(row) for row in cities if token in row]\n",
    "                label_char =cities[index_row[0]][5]\n",
    "                label_char =str(label_char).lower()\n",
    "                label = country_class[label_char]\n",
    "                is_labeled= True\n",
    "                break\n",
    "    if not is_labeled:\n",
    "        for token in place: #check for cities with one part\n",
    "            if token in cities_df.values:\n",
    "                index_row = [cities.index(row) for row in cities if token in row]\n",
    "                label_char=cities[index_row[0]][5]\n",
    "                label_char =str(label_char).lower()\n",
    "                label = country_class[label_char]\n",
    "                is_labeled= True\n",
    "                break\n",
    "    return is_labeled , label\n",
    "\n",
    "def operation(data):\n",
    "    examples = []\n",
    "    labels_list = []\n",
    "    for i in range(len(data)):\n",
    "        label = None\n",
    "        namespaces = {}\n",
    "        is_labeled= False\n",
    "        if data[i][\"place\"] != None:\n",
    "            #print(data[i][\"place\"])\n",
    "            label_char = data[i][\"place\"]['country_code']\n",
    "            label_char =str(label_char).lower()\n",
    "            namespaces['p'] = [label_char]\n",
    "            label = country_class[label_char]\n",
    "            is_labeled= True\n",
    "\n",
    "        if data[i][\"user\"][\"location\"] != \"\":\n",
    "            place= tokenize(data[i][\"user\"][\"location\"].strip())\n",
    "            place=pop_2(place)\n",
    "            text = []\n",
    "            text += place\n",
    "            #print(place)\n",
    "            namespaces['l'] = text\n",
    "            if not is_labeled:\n",
    "                is_labeled , label =city_country_check(place)\n",
    "\n",
    "        if data[i][\"user\"][\"name\"] != \"\" and not is_labeled:\n",
    "            user_name= tokenize(data[i][\"user\"][\"name\"].strip())\n",
    "            namespaces['n'] = user_name\n",
    "            if not is_labeled:\n",
    "                is_labeled , label = check_flag(user_name)\n",
    "            if not is_labeled:\n",
    "                is_labeled , label =city_country_check(user_name)\n",
    "\n",
    "        if data[i][\"user\"][\"screen_name\"] != \"\" and not is_labeled:\n",
    "            screen_name= tokenize(data[i][\"user\"][\"screen_name\"].strip())\n",
    "            namespaces['s'] = screen_name\n",
    "            if not is_labeled:\n",
    "                is_labeled , label = check_flag(screen_name)\n",
    "            if not is_labeled:\n",
    "                is_labeled , label =city_country_check(screen_name)\n",
    "\n",
    "        if data[i][\"user\"][\"description\"] != \"\" and not is_labeled:\n",
    "            description= tokenize(data[i][\"user\"][\"description\"].strip())\n",
    "            namespaces['d'] = description\n",
    "            if not is_labeled:\n",
    "                is_labeled , label = check_flag(description)\n",
    "            if not is_labeled:\n",
    "                is_labeled , label =city_country_check(description)\n",
    "\n",
    "        if data[i][\"full_text\"] != \"\":\n",
    "            full_text= tokenize(data[i][\"full_text\"].strip())\n",
    "            full_text = pop_2(full_text , 1)\n",
    "            namespaces['f'] = full_text\n",
    "            if not is_labeled:\n",
    "                is_labeled , label = check_flag(full_text)\n",
    "\n",
    "        if not is_labeled:\n",
    "            if 'url' in data[i][\"user\"][\"entities\"]:\n",
    "                if 'display_url' in data[i][\"user\"][\"entities\"]['url']['urls'][0]:\n",
    "                    if data[i][\"user\"][\"entities\"]['url']['urls'][0]['display_url'] != 'None':\n",
    "                        url = data[i][\"user\"][\"entities\"]['url']['urls'][0]['display_url']\n",
    "                        #print(url)\n",
    "                        x = re.search(\"(\\.[^c][^o]($|\\W))\", url)\n",
    "                        #print(x)\n",
    "                        if x!=None:\n",
    "                            x = re.search(\"(\\w\\w)\", x[0])\n",
    "                            if x!=None:\n",
    "                                if x[0] in country_code_df.values:\n",
    "                                    namespaces['m'] = x[0] \n",
    "        if data[i][\"lang\"] != \"\":\n",
    "            lang= tokenize(data[i][\"lang\"].strip())\n",
    "            #print(lang)\n",
    "            if lang[0] in language_code_df.values:\n",
    "                index_row = [language_code.index(row) for row in language_code if lang[0] in row]\n",
    "                #print(language_code[index_row[0]][0])\n",
    "                namespaces['g'] = [language_code[index_row[0]][0]]\n",
    "                \n",
    "        if label!=None:\n",
    "            labels_list.append(label)\n",
    "            ex = ''\n",
    "            for ns,words in namespaces.items():\n",
    "                ex += '%s %s' % (ns, ' '.join(map(sanify,words)))\n",
    "            examples += [ex]\n",
    "    return examples , labels_list\n",
    "\n",
    "def write_files(file_name,examples):\n",
    "    random.seed(9999)\n",
    "    random.shuffle(examples)\n",
    "    middle = int(len(examples)/2)\n",
    "    train_data = examples[:middle]\n",
    "    test_data = examples[middle:]\n",
    "    test_file_name = file_name+\".te\"\n",
    "    train_file_name = file_name+\".tr\"\n",
    "    with open(test_file_name, 'w') as h:\n",
    "        for ex in test_data:\n",
    "                h.write(ex.strip()+'\\n')\n",
    "    with open(train_file_name, 'w') as m:\n",
    "        for ex in train_data:\n",
    "                m.write(ex.strip()+'\\n')\n",
    "    return\n",
    "\n",
    "def take_top_n(labels_list,n):\n",
    "    res = Counter(labels_list)\n",
    "    items = list(res.items())\n",
    "    sorted_list = sorted(items,key=lambda x: (x[1],x[0]),reverse=True)\n",
    "    fir = sorted_list[:n-1]\n",
    "    rest = sorted_list[n-1:]\n",
    "    contry_code_list = [i[0] for i in fir]\n",
    "    new_country_class = { name: k+1 for k,name in enumerate(contry_code_list) }\n",
    "    return contry_code_list,new_country_class\n",
    "\n",
    "def create_new_label(labels_list,n):# to reduce the number of classe to n\n",
    "    contry_top_list,top_country_class=take_top_n(labels_list,n)\n",
    "    new_label_list =[]\n",
    "    for i in range(len(labels_list)):\n",
    "        label = labels_list[i]\n",
    "        if label in contry_top_list:\n",
    "            new_label = top_country_class[label]\n",
    "        else: \n",
    "            new_label = n\n",
    "        new_label_list.append(new_label)\n",
    "    return new_label_list\n",
    "\n",
    "def add_labels(examples , labels_list):\n",
    "    new_examples = []\n",
    "    for i in range(len(labels_list)):\n",
    "        ex = str(labels_list[i])\n",
    "        ex +=' |%s' % examples[i]\n",
    "        new_examples += [ex]\n",
    "    return new_examples\n",
    "\n",
    "def create_vw_file(json_file,n = 20):# write the file name without .json\n",
    "    with open(json_file+\".json\",\"r\") as f:\n",
    "        data=json.load(f)\n",
    "\n",
    "    examples1 , labels_list1 = operation(data)\n",
    "    new_label_list = create_new_label(labels_list1,n)\n",
    "    top_country_code_list = [get_key(country_class,val) for val in new_label_list]\n",
    "    top_country_list=[]\n",
    "    for token in top_country_code_list:\n",
    "            top_country_list.append = [country_code.index(row) for row in country_code if token in row[0]]\n",
    "    new_examples = add_labels(examples1 , new_label_list)\n",
    "    write_files(\"project/%s\" %json_file,new_examples)\n",
    "    return top_country_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_country_list = create_vw_file(\"ukrain_loc_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6cef9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = project/ukrain_loc.model\n",
      "Num weight bits = 27\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = project/ukrain_loc.tr.cache\n",
      "Reading datafile = project/ukrain_loc.tr\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0       11        1       52\n",
      "1.000000 1.000000            2            2.0       13       11       47\n",
      "0.750000 0.500000            4            4.0       20       20       66\n",
      "0.875000 1.000000            8            8.0        2       20       47\n",
      "0.875000 0.875000           16           16.0        2        2       27\n",
      "0.781250 0.687500           32           32.0       20       20       49\n",
      "0.734375 0.687500           64           64.0        1        1       44\n",
      "0.656250 0.578125          128          128.0       20        3       50\n",
      "0.531250 0.406250          256          256.0        1        1       56\n",
      "0.431641 0.332031          512          512.0       20        2       16\n",
      "0.360352 0.289062         1024         1024.0        4        4       22\n",
      "0.206030 0.206030         2048         2048.0        1        1       50 h\n",
      "0.193467 0.180905         4096         4096.0        4        4       52 h\n",
      "0.189698 0.185930         8192         8192.0        2        2       57 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1999\n",
      "passes used = 5\n",
      "weighted example sum = 9995.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.180905 h\n",
      "total feature number = 426020\n"
     ]
    }
   ],
   "source": [
    "!vw -k -c -b 27 --oaa 20 -d project/ukrain_loc.tr -f project/ukrain_loc.model --passes 20 --holdout_after 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b4f8881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\r\n",
      "Num weight bits = 27\r\n",
      "learning rate = 0.5\r\n",
      "initial_t = 0\r\n",
      "power_t = 0.5\r\n",
      "using no cache\r\n",
      "Reading datafile = project/ukrain_loc.te\r\n",
      "num sources = 1\r\n",
      "average  since         example        example  current  current  current\r\n",
      "loss     last          counter         weight    label  predict features\r\n",
      "0.000000 0.000000            1            1.0        2        2       44\r\n",
      "0.000000 0.000000            2            2.0        4        4       48\r\n",
      "0.000000 0.000000            4            4.0        6        6       38\r\n",
      "0.125000 0.250000            8            8.0       20       20       28\r\n",
      "0.312500 0.500000           16           16.0       16        2       32\r\n",
      "0.312500 0.312500           32           32.0        3        3       56\r\n",
      "0.250000 0.187500           64           64.0       16       16       36\r\n",
      "0.250000 0.250000          128          128.0       20       20       18\r\n",
      "0.203125 0.156250          256          256.0        5        1       51\r\n",
      "0.167969 0.132812          512          512.0        2        2       42\r\n",
      "0.184570 0.201172         1024         1024.0        1        1       80\r\n",
      "0.189453 0.194336         2048         2048.0        5        5       67\r\n",
      "\r\n",
      "finished run\r\n",
      "number of examples per pass = 2198\r\n",
      "passes used = 1\r\n",
      "weighted example sum = 2198.000000\r\n",
      "weighted label sum = 0.000000\r\n",
      "average loss = 0.189718\r\n",
      "total feature number = 94621\r\n"
     ]
    }
   ],
   "source": [
    "!vw -t -i project/ukrain_loc.model -d project/ukrain_loc.te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c623937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: pl \n",
      "final_regressor = project/ukrain_loc.model\n",
      "using dropout for neural network training\n",
      "using input passthrough for neural network training\n",
      "Num weight bits = 27\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = project/ukrain_loc.tr.cache\n",
      "Reading datafile = project/ukrain_loc.tr\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0       11        1       52\n",
      "1.000000 1.000000            2            2.0       13       11       47\n",
      "0.750000 0.500000            4            4.0       20       20       66\n",
      "0.875000 1.000000            8            8.0        2       20       47\n",
      "0.875000 0.875000           16           16.0        2        2       27\n",
      "0.781250 0.687500           32           32.0       20       20       49\n",
      "0.765625 0.750000           64           64.0        1        1       44\n",
      "0.648438 0.531250          128          128.0       20        3       50\n",
      "0.368907 0.368907          256          256.0        2        2       22 h\n",
      "0.366085 0.363263          512          512.0        4        4       43 h\n",
      "0.365316 0.364546         1024         1024.0        4        4       26 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 249\n",
      "passes used = 5\n",
      "weighted example sum = 1245.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.363263 h\n",
      "total feature number = 54210\n"
     ]
    }
   ],
   "source": [
    "!vw -k -c -b 27 --oaa 20 -d project/ukrain_loc.tr -f project/ukrain_loc.model --passes 20 --holdout_after 250 -q pl --nn 8 --inpass --dropout #-q ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207cd409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
