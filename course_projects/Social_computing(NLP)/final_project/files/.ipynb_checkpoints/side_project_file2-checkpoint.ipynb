{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0449e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import ijson\n",
    "import pandas as pd\n",
    "import re, os\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1a4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_df= pd.read_csv('database/country_code.csv' ,sep = ',')\n",
    "country_code = country_code_df.values.tolist()\n",
    "\n",
    "domain_df= pd.read_csv('database/domain.csv' ,sep = '.')\n",
    "domain_code = domain_df.values.tolist()\n",
    "\n",
    "flags_df= pd.read_csv('database/flags_new.csv' ,sep = ',')\n",
    "flags = flags_df.values.tolist()\n",
    "\n",
    "language_code_df= pd.read_csv('database/language_code.csv' ,sep = ':')\n",
    "language_code = language_code_df.values.tolist()\n",
    "    \n",
    "cities_df= pd.read_csv('database/worldcities.csv' ,sep = ',')\n",
    "cities = cities_df.values.tolist()\n",
    "\n",
    "country_to_code = [row[1] for row in country_code]\n",
    "country_class = { name: k+1 for k,name in enumerate(country_to_code) }#create class for each country code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51bc6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### all the functiones needed for this project\n",
    "def tokenize(s): return re.sub('([^A-Za-z0-9 ]+)', ' \\\\1 ', s).split()  # add space around anything not alphanum\n",
    "def sanify(s): return s.replace(':',';').replace('|','/')\n",
    "def writeToVWFile(filename, examples):\n",
    "    with open(filename, 'w') as h:\n",
    "        for ex in examples:\n",
    "            h.write(ex.strip()+'\\n')\n",
    "def pop_2(tokens,n=2):# \n",
    "    pop_list =[]\n",
    "    for ii in tokens:\n",
    "        if len(ii)<=n:\n",
    "            pop_list.append(ii)\n",
    "    for ii in pop_list:\n",
    "        tokens.remove(ii)\n",
    "    return tokens\n",
    "    \n",
    "def check_flag(tokens):\n",
    "    labeled = False\n",
    "    label = None\n",
    "    #tokens = pop_2(tokens)\n",
    "    for token in tokens: #check for countries with one part\n",
    "        if token in flags_df.values:\n",
    "            index_row = [flags.index(row) for row in flags if token in row[0]]\n",
    "            if index_row:\n",
    "                label_char =flags[index_row[0]][1]\n",
    "                label_char =str(label_char).lower()\n",
    "                label = country_class[label_char]\n",
    "                labeled =True\n",
    "                break\n",
    "    return labeled , label\n",
    "\n",
    "def city_country_check(place):\n",
    "    is_labeled = False\n",
    "    label = None\n",
    "    place = pop_2(place)\n",
    "    for token in place: #check for countries with one part\n",
    "        if token in country_code_df.values:\n",
    "            index_row = [country_code.index(row) for row in country_code if token in row[0]]\n",
    "            label_char =country_code[index_row[0]][1]\n",
    "            label_char =str(label_char).lower()\n",
    "            label = country_class[label_char]\n",
    "            is_labeled= True\n",
    "            break\n",
    "    if not is_labeled:\n",
    "        for k in range(len(place)-1): #for cities like new york or mexico city\n",
    "            token ='%s %s' % (place[k],place[k+1])\n",
    "            token = str(token).lower()\n",
    "            #print(token)\n",
    "            if token in cities_df.values:\n",
    "                index_row = [cities.index(row) for row in cities if token in row]\n",
    "                label_char =cities[index_row[0]][5]\n",
    "                label_char =str(label_char).lower()\n",
    "                label = country_class[label_char]\n",
    "                is_labeled= True\n",
    "                break\n",
    "    if not is_labeled:\n",
    "        for token in place: #check for cities with one part\n",
    "            if token in cities_df.values:\n",
    "                index_row = [cities.index(row) for row in cities if token in row]\n",
    "                label_char=cities[index_row[0]][5]\n",
    "                label_char =str(label_char).lower()\n",
    "                label = country_class[label_char]\n",
    "                is_labeled= True\n",
    "                break\n",
    "    return is_labeled , label\n",
    "\n",
    "def operation(data):\n",
    "    examples = []\n",
    "    labels_list = []\n",
    "    for i in range(len(data)):\n",
    "        label = None\n",
    "        namespaces = {}\n",
    "        is_labeled= False\n",
    "        if data[i][\"place\"] != None:\n",
    "            #print(data[i][\"place\"])\n",
    "            label_char = data[i][\"place\"]['country_code']\n",
    "            label_char =str(label_char).lower()\n",
    "            namespaces['p'] = [label_char]\n",
    "            label = country_class[label_char]\n",
    "            is_labeled= True\n",
    "\n",
    "        if data[i][\"user\"][\"location\"] != \"\":\n",
    "            place= tokenize(data[i][\"user\"][\"location\"].strip())\n",
    "            place=pop_2(place)\n",
    "            text = []\n",
    "            text += place\n",
    "            #print(place)\n",
    "            namespaces['l'] = text\n",
    "            if not is_labeled:\n",
    "                is_labeled , label =city_country_check(place)\n",
    "\n",
    "        if data[i][\"user\"][\"name\"] != \"\" and not is_labeled:\n",
    "            user_name= tokenize(data[i][\"user\"][\"name\"].strip())\n",
    "            namespaces['n'] = user_name\n",
    "            if not is_labeled:\n",
    "                is_labeled , label = check_flag(user_name)\n",
    "            if not is_labeled:\n",
    "                is_labeled , label =city_country_check(user_name)\n",
    "\n",
    "        if data[i][\"user\"][\"screen_name\"] != \"\" and not is_labeled:\n",
    "            screen_name= tokenize(data[i][\"user\"][\"screen_name\"].strip())\n",
    "            namespaces['s'] = screen_name\n",
    "            if not is_labeled:\n",
    "                is_labeled , label = check_flag(screen_name)\n",
    "            if not is_labeled:\n",
    "                is_labeled , label =city_country_check(screen_name)\n",
    "\n",
    "        if data[i][\"user\"][\"description\"] != \"\" and not is_labeled:\n",
    "            description= tokenize(data[i][\"user\"][\"description\"].strip())\n",
    "            namespaces['d'] = description\n",
    "            if not is_labeled:\n",
    "                is_labeled , label = check_flag(description)\n",
    "            if not is_labeled:\n",
    "                is_labeled , label =city_country_check(description)\n",
    "\n",
    "        if data[i][\"full_text\"] != \"\":\n",
    "            full_text= tokenize(data[i][\"full_text\"].strip())\n",
    "            full_text = pop_2(full_text , 1)\n",
    "            namespaces['f'] = full_text\n",
    "            if not is_labeled:\n",
    "                is_labeled , label = check_flag(full_text)\n",
    "\n",
    "        if not is_labeled:\n",
    "            if 'url' in data[i][\"user\"][\"entities\"]:\n",
    "                if 'display_url' in data[i][\"user\"][\"entities\"]['url']['urls'][0]:\n",
    "                    if data[i][\"user\"][\"entities\"]['url']['urls'][0]['display_url'] != 'None':\n",
    "                        url = data[i][\"user\"][\"entities\"]['url']['urls'][0]['display_url']\n",
    "                        #print(url)\n",
    "                        x = re.search(\"(\\.[^c][^o]($|\\W))\", url)\n",
    "                        #print(x)\n",
    "                        if x!=None:\n",
    "                            x = re.search(\"(\\w\\w)\", x[0])\n",
    "                            if x!=None:\n",
    "                                if x[0] in country_code_df.values:\n",
    "                                    namespaces['m'] = x[0] \n",
    "        if data[i][\"lang\"] != \"\":\n",
    "            lang= tokenize(data[i][\"lang\"].strip())\n",
    "            #print(lang)\n",
    "            if lang[0] in language_code_df.values:\n",
    "                index_row = [language_code.index(row) for row in language_code if lang[0] in row]\n",
    "                #print(language_code[index_row[0]][0])\n",
    "                namespaces['g'] = [language_code[index_row[0]][0]]\n",
    "                \n",
    "        if label!=None:\n",
    "            labels_list.append(label)\n",
    "            ex = ''\n",
    "            for ns,words in namespaces.items():\n",
    "                ex += '%s %s' % (ns, ' '.join(map(sanify,words)))\n",
    "            examples += [ex]\n",
    "    return examples , labels_list\n",
    "\n",
    "def write_files(file_name,examples):\n",
    "    random.seed(9999)\n",
    "    random.shuffle(examples)\n",
    "    middle = int(len(examples)/2)\n",
    "    train_data = examples[:middle]\n",
    "    test_data = examples[middle:]\n",
    "    test_file_name = file_name+\".te\"\n",
    "    train_file_name = file_name+\".tr\"\n",
    "    with open(test_file_name, 'w') as h:\n",
    "        for ex in test_data:\n",
    "                h.write(ex.strip()+'\\n')\n",
    "    with open(train_file_name, 'w') as m:\n",
    "        for ex in train_data:\n",
    "                m.write(ex.strip()+'\\n')\n",
    "    return\n",
    "\n",
    "def take_top_n(labels_list,n):\n",
    "    res = Counter(labels_list)\n",
    "    items = list(res.items())\n",
    "    sorted_list = sorted(items,key=lambda x: (x[1],x[0]),reverse=True)\n",
    "    fir = sorted_list[:n-1]\n",
    "    rest = sorted_list[n-1:]\n",
    "    contry_code_list = [i[0] for i in fir]\n",
    "    new_country_class = { name: k+1 for k,name in enumerate(contry_code_list) }\n",
    "    return contry_code_list,new_country_class\n",
    "\n",
    "def create_new_label(labels_list,n):# to reduce the number of classe to n\n",
    "    contry_top_list,top_country_class=take_top_n(labels_list,n)\n",
    "    new_label_list =[]\n",
    "    for i in range(len(labels_list)):\n",
    "        label = labels_list[i]\n",
    "        if label in contry_top_list:\n",
    "            new_label = top_country_class[label]\n",
    "        else: \n",
    "            new_label = n\n",
    "        new_label_list.append(new_label)\n",
    "    return new_label_list\n",
    "\n",
    "def add_labels(examples , labels_list):\n",
    "    new_examples = []\n",
    "    for i in range(len(labels_list)):\n",
    "        ex = str(labels_list[i])\n",
    "        ex +=' |%s' % examples[i]\n",
    "        new_examples += [ex]\n",
    "    return new_examples\n",
    "\n",
    "def create_vw_file(json_file,n = 20):# write the file name without .json\n",
    "    with open(json_file+\".json\",\"r\") as f:\n",
    "        data=json.load(f)\n",
    "\n",
    "    examples1 , labels_list1 = operation(data)\n",
    "    new_label_list = create_new_label(labels_list1,n)\n",
    "    new_examples = add_labels(examples1 , new_label_list)\n",
    "    write_files(\"project/%s\" %json_file,new_examples)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e53aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_vw_file(\"ukrain_loc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a911b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = project/easter_sample.model\n",
      "Num weight bits = 27\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = project/easter_sample.tr.cache\n",
      "Reading datafile = project/easter_sample.tr\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1       27\n",
      "0.500000 1.000000            2            2.0        6        1       26\n",
      "0.750000 1.000000            4            4.0       20        1       37\n",
      "0.750000 0.750000            8            8.0       10        1       37\n",
      "0.625000 0.500000           16           16.0        1        1       42\n",
      "0.656250 0.687500           32           32.0        2        1       50\n",
      "0.687500 0.718750           64           64.0        5        5       26\n",
      "0.617188 0.546875          128          128.0        4        7       26\n",
      "0.503906 0.390625          256          256.0        2        2       12\n",
      " unknown  unknown          512          512.0        2        2       12 h\n",
      " unknown  unknown         1024         1024.0        1        1       44 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 258\n",
      "passes used = 4\n",
      "weighted example sum = 1032.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = undefined (no holdout)\n",
      "total feature number = 34140\n"
     ]
    }
   ],
   "source": [
    "!vw -k -c -b 27 --oaa 20 -d project/ukrain_loc.tr -f project/ukrain_loc.model --passes 20 --holdout_after 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a21d7db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: pl \n",
      "final_regressor = project/easter_sample.model\n",
      "using dropout for neural network training\n",
      "using input passthrough for neural network training\n",
      "Num weight bits = 27\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = project/easter_sample.tr.cache\n",
      "Reading datafile = project/easter_sample.tr\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1       27\n",
      "0.500000 1.000000            2            2.0        6        1       26\n",
      "0.750000 1.000000            4            4.0       20        1       37\n",
      "0.750000 0.750000            8            8.0       10        1       37\n",
      "0.687500 0.625000           16           16.0        1        1       42\n",
      "0.718750 0.750000           32           32.0        2        1       50\n",
      "0.734375 0.750000           64           64.0        5        5       26\n",
      "0.625000 0.515625          128          128.0        4        7       26\n",
      "0.444444 0.444444          256          256.0       13       13       11 h\n",
      "0.444444 0.444444          512          512.0        7        7       30 h\n",
      "0.388889 0.333333         1024         1024.0        1        1       44 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 249\n",
      "passes used = 6\n",
      "weighted example sum = 1494.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.333333 h\n",
      "total feature number = 49326\n"
     ]
    }
   ],
   "source": [
    "!vw -k -c -b 27 --oaa 20 -d project/ukrain_loc.tr -f project/ukrain_loc.model --passes 20 --holdout_after 250 -q pl --nn 8 --inpass --dropout #-q ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c68ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
