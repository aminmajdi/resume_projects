{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f142d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from columnar import columnar\n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "#First update below varibales with your own information\n",
    "consumer_key = \"ohiltOxhFTpbdUDtV6thRMLPX\"\n",
    "consumer_secret = \"0ue4FsixVyktA39iFNs9mKEZrBpmc6OspbJvoej7JKF8jZDY9T\"\n",
    "access_token = \"1489250229127770113-sPD6f998qjObWdGOZsKUUImbT66pwH\"\n",
    "access_token_secret = \"6i5Beg9O4gGlnsP3Uxd0q3YJDeIvHmUChYbQMwxsKZ1AZ\"\n",
    "\n",
    "\n",
    "# Setting up Tweepy authorization\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a312ea4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 623\n",
      "Rate limit reached. Sleeping for: 799\n",
      "Rate limit reached. Sleeping for: 813\n",
      "Rate limit reached. Sleeping for: 808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1697\n"
     ]
    }
   ],
   "source": [
    "# Define the search term and the date_since date\n",
    "\n",
    "search_words = \"#easter -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets_2 = tweepy.Cursor(api.search_tweets,\n",
    "                       q=search_words).items(2000)\n",
    "tweets_list_2 = []\n",
    "counter = 0\n",
    "n_tweet= 0\n",
    "for tweet in tweets_2:\n",
    "    n_tweet+=1\n",
    "    tweet_id=tweet.id\n",
    "    tweet_ = api.get_status(tweet_id,tweet_mode=\"extended\")\n",
    "    #tweet_list = [tweet_.text, tweet_.favorite_count, tweet_.retweet_count]\n",
    "    #print(tweet_list)\n",
    "    #json_tweet = json.dumps(tweet_._json)\n",
    "    with open('easter.json', 'a') as f:\n",
    "        json.dump(tweet_._json, f, indent=2)\n",
    "    tweets_list_2.append([tweet_.id,tweet_.user.id,tweet_.user.location,tweet_.coordinates,tweet_.geo,tweet_.lang, tweet_.created_at,tweet_.favorite_count,tweet_.retweet_count,tweet_.place, tweet.text])\n",
    "    if counter <300: \n",
    "        word_list = tweet.text.split()\n",
    "        number_of_words = len(word_list)\n",
    "        if number_of_words> 5 :\n",
    "            counter +=1\n",
    "            with open('easter_sample.json', 'a') as f:\n",
    "                json.dump(tweet_._json, f, indent=2)\n",
    "print(n_tweet)\n",
    "# Pulling information from tweets iterable object\n",
    "#tweets_list = [[tweet.id, tweet.created_at, tweet.text] for tweet in tweets]\n",
    "\n",
    "#print tweets\n",
    "headers = ['id','user id',\"location\",\"coordinates\",\"geo\",\"language\", ' created_at','favorite_count','retweet_count','place','text']\n",
    "#table = columnar(tweets_list, headers, no_borders=True)\n",
    "df_1 = pd.DataFrame(tweets_list_2, columns = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf1bb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 454\n",
      "Rate limit reached. Sleeping for: 806\n",
      "Rate limit reached. Sleeping for: 814\n",
      "Rate limit reached. Sleeping for: 811\n",
      "Rate limit reached. Sleeping for: 813\n",
      "Rate limit reached. Sleeping for: 814\n",
      "Rate limit reached. Sleeping for: 813\n",
      "Rate limit reached. Sleeping for: 812\n",
      "Rate limit reached. Sleeping for: 818\n",
      "Rate limit reached. Sleeping for: 814\n",
      "Rate limit reached. Sleeping for: 811\n",
      "Rate limit reached. Sleeping for: 810\n",
      "Rate limit reached. Sleeping for: 813\n",
      "Rate limit reached. Sleeping for: 819\n",
      "Rate limit reached. Sleeping for: 816\n",
      "Rate limit reached. Sleeping for: 816\n",
      "Rate limit reached. Sleeping for: 814\n",
      "Rate limit reached. Sleeping for: 812\n",
      "Rate limit reached. Sleeping for: 816\n",
      "Rate limit reached. Sleeping for: 811\n",
      "Rate limit reached. Sleeping for: 817\n",
      "Rate limit reached. Sleeping for: 815\n",
      "Rate limit reached. Sleeping for: 787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-61ad6d28cdf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#table = columnar(tweets_list, headers, no_borders=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mdf_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_list_3\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the search term and the date_since date\n",
    "\n",
    "    search_words = \"#ukrainerussianwar OR #ukrainewar OR #warukraine OR #ukrainianarmy OR #militaryukraine -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets_3 = tweepy.Cursor(api.search_tweets,\n",
    "                       q=search_words).items(10000)\n",
    "    \n",
    "\n",
    "tweets_list_3 = []\n",
    "counter = 0\n",
    "n_tweet= 0\n",
    "for tweet in tweets_3:\n",
    "    n_tweet+=1\n",
    "    tweet_id=tweet.id\n",
    "    tweet_ = api.get_status(tweet_id,tweet_mode=\"extended\")\n",
    "    #tweet_list = [tweet_.text, tweet_.favorite_count, tweet_.retweet_count]\n",
    "    #print(tweet_list)\n",
    "    #json_tweet = json.dumps(tweet_._json)\n",
    "    with open('ukrain_loc.json', 'a') as f:\n",
    "        json.dump(tweet_._json, f, indent=2)\n",
    "    tweets_list_3.append([tweet_.id,tweet_.user.id,tweet_.user.location,tweet_.coordinates,tweet_.geo,tweet_.lang, tweet_.created_at,tweet_.favorite_count,tweet_.retweet_count,tweet_.place, tweet.text])\n",
    "    if counter <300: \n",
    "        word_list = tweet.text.split()\n",
    "        number_of_words = len(word_list)\n",
    "        if number_of_words> 5 :\n",
    "            counter +=1\n",
    "            with open('ukrain_loc_sample.json', 'a') as f:\n",
    "                json.dump(tweet_._json, f, indent=2)\n",
    "print(n_tweet)\n",
    "# Pulling information from tweets iterable object\n",
    "#tweets_list = [[tweet.id, tweet.created_at, tweet.text] for tweet in tweets]\n",
    "\n",
    "#print tweets\n",
    "headers = ['id','user id',\"location\",\"coordinates\",\"geo\",\"language\", ' created_at','favorite_count','retweet_count','place','text']\n",
    "#table = columnar(tweets_list, headers, no_borders=True)\n",
    "df_3 = pd.DataFrame(tweets_list_3 , columns = headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "100acd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n"
     ]
    }
   ],
   "source": [
    "test=df.iloc[:, 3]\n",
    "for i in test:\n",
    "    if i == \"None\"\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00880fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tweets_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9512871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream connection closed by Twitter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id              user id                created_at  \\\n",
      "0    1491244920937402371  1471492150848200712 2022-02-09 02:57:49+00:00   \n",
      "1    1491244920849702913  1445473858555842568 2022-02-09 02:57:49+00:00   \n",
      "2    1491244923512893444  1340367063559356416 2022-02-09 02:57:50+00:00   \n",
      "3    1491244925069176834  1487103493827870725 2022-02-09 02:57:50+00:00   \n",
      "4    1491244925169840129  1452575136075456513 2022-02-09 02:57:50+00:00   \n",
      "..                   ...                  ...                       ...   \n",
      "995  1491245619167764483  1459931094158135299 2022-02-09 03:00:36+00:00   \n",
      "996  1491245619658502144  1407067138217721858 2022-02-09 03:00:36+00:00   \n",
      "997  1491245619671105536  1465738256683655171 2022-02-09 03:00:36+00:00   \n",
      "998  1491245620233146370  1473949835594063872 2022-02-09 03:00:36+00:00   \n",
      "999  1491245620270858241            382785333 2022-02-09 03:00:36+00:00   \n",
      "\n",
      "     favorite_count  retweet_count place  \\\n",
      "0                 0              0  None   \n",
      "1                 0              0  None   \n",
      "2                 0              0  None   \n",
      "3                 0              0  None   \n",
      "4                 0              0  None   \n",
      "..              ...            ...   ...   \n",
      "995               0              0  None   \n",
      "996               0              0  None   \n",
      "997               0              0  None   \n",
      "998               0              0  None   \n",
      "999               0              0  None   \n",
      "\n",
      "                                                  text  \n",
      "0    RT @Gina52939786: I will send to 10 people 2.7...  \n",
      "1    RT @onlysenna_: NFTea &amp; Coffee ‚òï Episode 1...  \n",
      "2    RT @robot_concept: üéÅüî• C'EST REPARTI üî•üéÅ\\n\\n√Ä ga...  \n",
      "3    RT @klaraliron: This is the state of all thing...  \n",
      "4                  @DelCrxpto For #Eth , that‚Äôs cheap!  \n",
      "..                                                 ...  \n",
      "995  @PlayApex The greatest division of wealth of t...  \n",
      "996  Guys enter on discord¬†cryptohippo will have gi...  \n",
      "997  Nice project \\n@Karimraj9 \\n@biplob126 \\n@Rato...  \n",
      "998  RT @gkhosts: $30 | 420.000 IDR \\n\\nRT &amp; Li...  \n",
      "999  RT @gkhosts: $30 | 420.000 IDR \\n\\nRT &amp; Li...  \n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creating a StreamListener\n",
    "class MyStreamListener(tweepy.Stream):\n",
    "    \n",
    "\n",
    "    #override tweepy.StreamListener to add logic to on_status\n",
    "        \n",
    "    tweets = []\n",
    "    limit = 1000\n",
    "\n",
    "    def on_status(self, status):\n",
    "        self.tweets.append(status)\n",
    "        if len(self.tweets) == self.limit:\n",
    "            self.disconnect()      \n",
    "        \n",
    "# Creating a Stream\n",
    "myStreamListener = MyStreamListener(consumer_key,consumer_secret,access_token,access_token_secret)\n",
    "#myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener)        \n",
    "\n",
    "# Starting a Stream\n",
    "\n",
    "# we will use filter to stream all tweets containing the hashtag '#covid19' and the query 'apple'\n",
    "myStreamListener.filter(track=['#BTC , #ETH , -filter:retweets'])\n",
    "\n",
    "headers = ['id','user id', ' created_at','favorite_count','retweet_count','place','text']\n",
    "data = []\n",
    "counter = 0\n",
    "for tweet in myStreamListener.tweets:\n",
    "    with open('BTC_full_stream.json', 'a') as f:\n",
    "        json.dump(tweet._json, f, indent=2)\n",
    "    tweets_list.append([tweet.id,tweet.user.id, tweet.created_at,tweet.favorite_count,tweet.retweet_count,tweet.place, tweet.text])\n",
    "    if counter <300: \n",
    "        word_list = tweet.text.split()\n",
    "        number_of_words = len(word_list)\n",
    "        if number_of_words> 5 :\n",
    "            counter +=1\n",
    "            with open('BTC_sample_stream.json', 'a') as f:\n",
    "                json.dump(tweet._json, f, indent=2)\n",
    "    if not tweet.truncated:\n",
    "        data.append([tweet.id,tweet.user.id, tweet.created_at,tweet_.favorite_count,tweet_.retweet_count,tweet_.place, tweet.text])\n",
    "    else:\n",
    "        data.append([tweet.id,tweet.user.id, tweet.created_at,tweet_.favorite_count,tweet_.retweet_count,tweet_.place, tweet.extended_tweet['full_text']])\n",
    "\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "print(df)\n",
    "df.to_csv(\"tweets_list_stream.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95aae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
