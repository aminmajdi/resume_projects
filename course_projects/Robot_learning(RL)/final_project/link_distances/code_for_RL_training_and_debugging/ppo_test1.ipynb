{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [stable_baselines3 docs for PPO](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html)\n",
    "\n",
    "## [docs for configuring our custom environment to work with stable_baselines3](https://stable-baselines.readthedocs.io/en/master/guide/custom_env.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from robot_model import Model, Inverse_model\n",
    "import pygame as pg\n",
    "from environment_gym import HumanArmImitation\n",
    "# just including full class definition below so you can tweak it as needed\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PPO2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8e850f5c7dce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPPO2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_checker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmd_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_vec_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PPO2'"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO2\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.cmd_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/csrobot/.local/lib/python3.6/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_from_angle(thetas,L_list,base_pose):\n",
    "    pose=[base_pose]\n",
    "    x_old=base_pose[0]\n",
    "    y_old=base_pose[1]\n",
    "    theta=0\n",
    "    for i in range(len(thetas)):\n",
    "        theta+=thetas[i]\n",
    "        x=L_list[i]*np.cos(theta)\n",
    "        y=L_list[i]*np.sin(theta)\n",
    "        x_old+=x\n",
    "        y_old+=y\n",
    "        pose=np.append(pose,[[x_old,y_old]],axis=0)\n",
    "    return pose\n",
    "\n",
    "def animate(teacher_pose,learner_pose,r):\n",
    "    pg.init()\n",
    "\n",
    "    win_x = 1500\n",
    "    win_y = 1500\n",
    "    win = pg.display.set_mode((win_x, win_y))\n",
    "    clock = pg.time.Clock()\n",
    "    win.fill((0, 0, 0))\n",
    "    while True:\n",
    "        for i in range(len(teacher_pose)):\n",
    "            for event in pg.event.get():\n",
    "                if event.type == pg.QUIT:\n",
    "                    pg.quit()\n",
    "            clock.tick(r)\n",
    "            win.fill((0, 0, 0))\n",
    "\n",
    "            for j in range(len(teacher_pose[0])-1):\n",
    "                pg.draw.line(win,(0,255,255),teacher_pose[i,j,:],teacher_pose[i,j+1,:],5)\n",
    "                pg.draw.line(win,(255,0,0),learner_pose[i,j,:],learner_pose[i,j+1,:],5)\n",
    "            pg.display.update()\n",
    "    pg.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:From /home/csrobot/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/csrobot/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/csrobot/.local/lib/python3.6/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/csrobot/.local/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/csrobot/.local/lib/python3.6/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0ede9fc5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0ede9fc5f8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0ede9fc5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0ede9fc5f8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From /home/csrobot/.local/lib/python3.6/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0edc0bf2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0edc0bf2b0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0edc0bf2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0edc0bf2b0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From /home/csrobot/.local/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/csrobot/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/csrobot/.local/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/csrobot/.local/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "self.next: 3\n",
      "self.next: 6\n",
      "self.next: 9\n",
      "self.next: 12\n",
      "self.next: 15\n",
      "self.next: 18\n",
      "self.next: 21\n",
      "self.next: 24\n",
      "self.next: 27\n",
      "self.next: 30\n",
      "self.next: 33\n",
      "self.next: 36\n",
      "self.next: 39\n",
      "self.next: 42\n",
      "self.next: 45\n",
      "self.next: 48\n",
      "self.next: 51\n",
      "self.next: 54\n",
      "self.next: 57\n",
      "self.next: 60\n",
      "self.next: 63\n",
      "self.next: 66\n",
      "self.next: 69\n",
      "self.next: 72\n",
      "self.next: 75\n",
      "self.next: 78\n",
      "self.next: 81\n",
      "self.next: 84\n",
      "self.next: 87\n",
      "self.next: 90\n",
      "self.next: 93\n",
      "self.next: 96\n",
      "self.next: 99\n",
      "self.next: 102\n",
      "self.next: 105\n",
      "self.next: 108\n",
      "self.next: 111\n",
      "self.next: 114\n",
      "self.next: 117\n",
      "self.next: 120\n",
      "self.next: 123\n",
      "self.next: 126\n",
      "self.next: 129\n",
      "self.next: 132\n",
      "self.next: 135\n",
      "self.next: 138\n",
      "self.next: 141\n",
      "self.next: 144\n",
      "self.next: 147\n",
      "self.next: 150\n",
      "self.next: 153\n",
      "self.next: 156\n",
      "self.next: 159\n",
      "self.next: 162\n",
      "self.next: 165\n",
      "self.next: 168\n",
      "self.next: 171\n",
      "self.next: 174\n",
      "self.next: 177\n",
      "self.next: 180\n",
      "self.next: 183\n",
      "self.next: 186\n",
      "self.next: 189\n",
      "self.next: 192\n",
      "self.next: 195\n",
      "self.next: 198\n",
      "self.next: 201\n",
      "self.next: 204\n",
      "self.next: 207\n",
      "self.next: 210\n",
      "self.next: 213\n",
      "self.next: 216\n",
      "self.next: 219\n",
      "self.next: 222\n",
      "self.next: 225\n",
      "self.next: 228\n",
      "self.next: 231\n",
      "self.next: 234\n",
      "self.next: 237\n",
      "self.next: 240\n",
      "self.next: 243\n",
      "self.next: 246\n",
      "self.next: 249\n",
      "self.next: 252\n",
      "self.next: 255\n",
      "self.next: 258\n",
      "self.next: 261\n",
      "self.next: 264\n",
      "self.next: 267\n",
      "self.next: 270\n",
      "self.next: 273\n",
      "self.next: 276\n",
      "self.next: 279\n",
      "self.next: 282\n",
      "self.next: 285\n",
      "self.next: 288\n",
      "self.next: 291\n",
      "self.next: 294\n",
      "self.next: 297\n",
      "self.next: 300\n",
      "self.next: 303\n",
      "self.next: 306\n",
      "self.next: 309\n",
      "self.next: 312\n",
      "self.next: 315\n",
      "self.next: 318\n",
      "self.next: 321\n",
      "self.next: 324\n",
      "self.next: 327\n",
      "self.next: 330\n",
      "self.next: 333\n",
      "self.next: 336\n",
      "self.next: 339\n",
      "self.next: 342\n",
      "self.next: 345\n",
      "self.next: 348\n",
      "self.next: 351\n",
      "self.next: 354\n",
      "self.next: 357\n",
      "self.next: 360\n",
      "self.next: 363\n",
      "self.next: 366\n",
      "self.next: 369\n",
      "self.next: 372\n",
      "self.next: 375\n",
      "self.next: 378\n",
      "self.next: 381\n",
      "self.next: 384\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0028508147 |\n",
      "| clipfrac           | 0.03515625   |\n",
      "| explained_variance | -0.161       |\n",
      "| fps                | 9            |\n",
      "| n_updates          | 1            |\n",
      "| policy_entropy     | 8.515065     |\n",
      "| policy_loss        | -0.015333065 |\n",
      "| serial_timesteps   | 128          |\n",
      "| time_elapsed       | 9.54e-06     |\n",
      "| total_timesteps    | 128          |\n",
      "| value_loss         | 17.112074    |\n",
      "-------------------------------------\n",
      "self.next: 387\n",
      "self.next: 390\n",
      "self.next: 393\n",
      "self.next: 396\n",
      "self.next: 399\n",
      "self.next: 402\n",
      "self.next: 405\n",
      "self.next: 408\n",
      "self.next: 411\n",
      "self.next: 414\n",
      "self.next: 417\n",
      "self.next: 420\n",
      "self.next: 423\n",
      "self.next: 426\n",
      "self.next: 429\n",
      "self.next: 432\n",
      "self.next: 435\n",
      "self.next: 438\n",
      "self.next: 441\n",
      "self.next: 444\n",
      "self.next: 447\n",
      "self.next: 450\n",
      "self.next: 453\n",
      "self.next: 456\n",
      "self.next: 459\n",
      "self.next: 462\n",
      "self.next: 465\n",
      "self.next: 468\n",
      "self.next: 471\n",
      "self.next: 474\n",
      "self.next: 477\n",
      "self.next: 480\n",
      "self.next: 483\n",
      "self.next: 486\n",
      "self.next: 489\n",
      "self.next: 492\n",
      "self.next: 495\n",
      "self.next: 498\n",
      "self.next: 501\n",
      "self.next: 504\n",
      "self.next: 507\n",
      "self.next: 510\n",
      "self.next: 513\n",
      "self.next: 516\n",
      "self.next: 519\n",
      "self.next: 522\n",
      "self.next: 525\n",
      "self.next: 528\n",
      "self.next: 531\n",
      "self.next: 534\n",
      "self.next: 537\n",
      "self.next: 540\n",
      "self.next: 543\n",
      "self.next: 546\n",
      "self.next: 549\n",
      "self.next: 552\n",
      "self.next: 555\n",
      "self.next: 558\n",
      "self.next: 561\n",
      "self.next: 564\n",
      "self.next: 567\n",
      "self.next: 570\n",
      "self.next: 573\n",
      "self.next: 576\n",
      "self.next: 579\n",
      "self.next: 582\n",
      "self.next: 585\n",
      "self.next: 588\n",
      "self.next: 591\n",
      "self.next: 594\n",
      "self.next: 597\n",
      "self.next: 600\n",
      "self.next: 603\n",
      "self.next: 606\n",
      "self.next: 609\n",
      "self.next: 612\n",
      "self.next: 615\n",
      "self.next: 618\n",
      "self.next: 621\n",
      "self.next: 624\n",
      "self.next: 627\n",
      "self.next: 630\n",
      "self.next: 633\n",
      "self.next: 636\n",
      "self.next: 639\n",
      "self.next: 642\n",
      "self.next: 645\n",
      "self.next: 648\n",
      "self.next: 651\n",
      "self.next: 654\n",
      "self.next: 657\n",
      "self.next: 660\n",
      "self.next: 663\n",
      "self.next: 666\n",
      "self.next: 669\n",
      "self.next: 672\n",
      "self.next: 675\n",
      "self.next: 678\n",
      "self.next: 681\n",
      "self.next: 684\n",
      "self.next: 687\n",
      "self.next: 690\n",
      "self.next: 693\n",
      "self.next: 696\n",
      "self.next: 699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 702\n",
      "self.next: 705\n",
      "self.next: 708\n",
      "self.next: 711\n",
      "self.next: 714\n",
      "self.next: 717\n",
      "self.next: 720\n",
      "self.next: 723\n",
      "self.next: 726\n",
      "self.next: 729\n",
      "self.next: 732\n",
      "self.next: 735\n",
      "self.next: 738\n",
      "self.next: 741\n",
      "self.next: 744\n",
      "self.next: 747\n",
      "self.next: 750\n",
      "self.next: 753\n",
      "self.next: 756\n",
      "self.next: 759\n",
      "self.next: 762\n",
      "self.next: 765\n",
      "self.next: 768\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00085031404 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | -0.0315       |\n",
      "| fps                | 9             |\n",
      "| n_updates          | 2             |\n",
      "| policy_entropy     | 8.516488      |\n",
      "| policy_loss        | -0.0039227386 |\n",
      "| serial_timesteps   | 256           |\n",
      "| time_elapsed       | 13.9          |\n",
      "| total_timesteps    | 256           |\n",
      "| value_loss         | 19.323008     |\n",
      "--------------------------------------\n",
      "self.next: 771\n",
      "self.next: 774\n",
      "self.next: 777\n",
      "self.next: 780\n",
      "self.next: 783\n",
      "self.next: 786\n",
      "self.next: 789\n",
      "self.next: 792\n",
      "self.next: 795\n",
      "self.next: 798\n",
      "self.next: 801\n",
      "self.next: 804\n",
      "self.next: 807\n",
      "self.next: 810\n",
      "self.next: 813\n",
      "self.next: 816\n",
      "self.next: 819\n",
      "self.next: 822\n",
      "self.next: 825\n",
      "self.next: 3\n",
      "self.next: 6\n",
      "self.next: 9\n",
      "self.next: 12\n",
      "self.next: 15\n",
      "self.next: 18\n",
      "self.next: 21\n",
      "self.next: 24\n",
      "self.next: 27\n",
      "self.next: 30\n",
      "self.next: 33\n",
      "self.next: 36\n",
      "self.next: 39\n",
      "self.next: 42\n",
      "self.next: 45\n",
      "self.next: 48\n",
      "self.next: 51\n",
      "self.next: 54\n",
      "self.next: 57\n",
      "self.next: 60\n",
      "self.next: 63\n",
      "self.next: 66\n",
      "self.next: 69\n",
      "self.next: 72\n",
      "self.next: 75\n",
      "self.next: 78\n",
      "self.next: 81\n",
      "self.next: 84\n",
      "self.next: 87\n",
      "self.next: 90\n",
      "self.next: 93\n",
      "self.next: 96\n",
      "self.next: 99\n",
      "self.next: 102\n",
      "self.next: 105\n",
      "self.next: 108\n",
      "self.next: 111\n",
      "self.next: 114\n",
      "self.next: 117\n",
      "self.next: 120\n",
      "self.next: 123\n",
      "self.next: 126\n",
      "self.next: 129\n",
      "self.next: 132\n",
      "self.next: 135\n",
      "self.next: 138\n",
      "self.next: 141\n",
      "self.next: 144\n",
      "self.next: 147\n",
      "self.next: 150\n",
      "self.next: 153\n",
      "self.next: 156\n",
      "self.next: 159\n",
      "self.next: 162\n",
      "self.next: 165\n",
      "self.next: 168\n",
      "self.next: 171\n",
      "self.next: 174\n",
      "self.next: 177\n",
      "self.next: 180\n",
      "self.next: 183\n",
      "self.next: 186\n",
      "self.next: 189\n",
      "self.next: 192\n",
      "self.next: 195\n",
      "self.next: 198\n",
      "self.next: 201\n",
      "self.next: 204\n",
      "self.next: 207\n",
      "self.next: 210\n",
      "self.next: 213\n",
      "self.next: 216\n",
      "self.next: 219\n",
      "self.next: 222\n",
      "self.next: 225\n",
      "self.next: 228\n",
      "self.next: 231\n",
      "self.next: 234\n",
      "self.next: 237\n",
      "self.next: 240\n",
      "self.next: 243\n",
      "self.next: 246\n",
      "self.next: 249\n",
      "self.next: 252\n",
      "self.next: 255\n",
      "self.next: 258\n",
      "self.next: 261\n",
      "self.next: 264\n",
      "self.next: 267\n",
      "self.next: 270\n",
      "self.next: 273\n",
      "self.next: 276\n",
      "self.next: 279\n",
      "self.next: 282\n",
      "self.next: 285\n",
      "self.next: 288\n",
      "self.next: 291\n",
      "self.next: 294\n",
      "self.next: 297\n",
      "self.next: 300\n",
      "self.next: 303\n",
      "self.next: 306\n",
      "self.next: 309\n",
      "self.next: 312\n",
      "self.next: 315\n",
      "self.next: 318\n",
      "self.next: 321\n",
      "self.next: 324\n",
      "self.next: 327\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00091504236 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.175        |\n",
      "| fps                | 9             |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 8.517311      |\n",
      "| policy_loss        | -0.0048003746 |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 27.8          |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 15.489856     |\n",
      "--------------------------------------\n",
      "self.next: 330\n",
      "self.next: 333\n",
      "self.next: 336\n",
      "self.next: 339\n",
      "self.next: 342\n",
      "self.next: 345\n",
      "self.next: 348\n",
      "self.next: 351\n",
      "self.next: 354\n",
      "self.next: 357\n",
      "self.next: 360\n",
      "self.next: 363\n",
      "self.next: 366\n",
      "self.next: 369\n",
      "self.next: 372\n",
      "self.next: 375\n",
      "self.next: 378\n",
      "self.next: 381\n",
      "self.next: 384\n",
      "self.next: 387\n",
      "self.next: 390\n",
      "self.next: 393\n",
      "self.next: 396\n",
      "self.next: 399\n",
      "self.next: 402\n",
      "self.next: 405\n",
      "self.next: 408\n",
      "self.next: 411\n",
      "self.next: 414\n",
      "self.next: 417\n",
      "self.next: 420\n",
      "self.next: 423\n",
      "self.next: 426\n",
      "self.next: 429\n",
      "self.next: 432\n",
      "self.next: 435\n",
      "self.next: 438\n",
      "self.next: 441\n",
      "self.next: 444\n",
      "self.next: 447\n",
      "self.next: 450\n",
      "self.next: 453\n",
      "self.next: 456\n",
      "self.next: 459\n",
      "self.next: 462\n",
      "self.next: 465\n",
      "self.next: 468\n",
      "self.next: 471\n",
      "self.next: 474\n",
      "self.next: 477\n",
      "self.next: 480\n",
      "self.next: 483\n",
      "self.next: 486\n",
      "self.next: 489\n",
      "self.next: 492\n",
      "self.next: 495\n",
      "self.next: 498\n",
      "self.next: 501\n",
      "self.next: 504\n",
      "self.next: 507\n",
      "self.next: 510\n",
      "self.next: 513\n",
      "self.next: 516\n",
      "self.next: 519\n",
      "self.next: 522\n",
      "self.next: 525\n",
      "self.next: 528\n",
      "self.next: 531\n",
      "self.next: 534\n",
      "self.next: 537\n",
      "self.next: 540\n",
      "self.next: 543\n",
      "self.next: 546\n",
      "self.next: 549\n",
      "self.next: 552\n",
      "self.next: 555\n",
      "self.next: 558\n",
      "self.next: 561\n",
      "self.next: 564\n",
      "self.next: 567\n",
      "self.next: 570\n",
      "self.next: 573\n",
      "self.next: 576\n",
      "self.next: 579\n",
      "self.next: 582\n",
      "self.next: 585\n",
      "self.next: 588\n",
      "self.next: 591\n",
      "self.next: 594\n",
      "self.next: 597\n",
      "self.next: 600\n",
      "self.next: 603\n",
      "self.next: 606\n",
      "self.next: 609\n",
      "self.next: 612\n",
      "self.next: 615\n",
      "self.next: 618\n",
      "self.next: 621\n",
      "self.next: 624\n",
      "self.next: 627\n",
      "self.next: 630\n",
      "self.next: 633\n",
      "self.next: 636\n",
      "self.next: 639\n",
      "self.next: 642\n",
      "self.next: 645\n",
      "self.next: 648\n",
      "self.next: 651\n",
      "self.next: 654\n",
      "self.next: 657\n",
      "self.next: 660\n",
      "self.next: 663\n",
      "self.next: 666\n",
      "self.next: 669\n",
      "self.next: 672\n",
      "self.next: 675\n",
      "self.next: 678\n",
      "self.next: 681\n",
      "self.next: 684\n",
      "self.next: 687\n",
      "self.next: 690\n",
      "self.next: 693\n",
      "self.next: 696\n",
      "self.next: 699\n",
      "self.next: 702\n",
      "self.next: 705\n",
      "self.next: 708\n",
      "self.next: 711\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00036025286  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.00119        |\n",
      "| fps                | 9              |\n",
      "| n_updates          | 4              |\n",
      "| policy_entropy     | 8.51735        |\n",
      "| policy_loss        | -0.00010204839 |\n",
      "| serial_timesteps   | 512            |\n",
      "| time_elapsed       | 41.5           |\n",
      "| total_timesteps    | 512            |\n",
      "| value_loss         | 22.623621      |\n",
      "---------------------------------------\n",
      "self.next: 714\n",
      "self.next: 717\n",
      "self.next: 720\n",
      "self.next: 723\n",
      "self.next: 726\n",
      "self.next: 729\n",
      "self.next: 732\n",
      "self.next: 735\n",
      "self.next: 738\n",
      "self.next: 741\n",
      "self.next: 744\n",
      "self.next: 747\n",
      "self.next: 750\n",
      "self.next: 753\n",
      "self.next: 756\n",
      "self.next: 759\n",
      "self.next: 762\n",
      "self.next: 765\n",
      "self.next: 768\n",
      "self.next: 771\n",
      "self.next: 774\n",
      "self.next: 777\n",
      "self.next: 780\n",
      "self.next: 783\n",
      "self.next: 786\n",
      "self.next: 789\n",
      "self.next: 792\n",
      "self.next: 795\n",
      "self.next: 798\n",
      "self.next: 801\n",
      "self.next: 804\n",
      "self.next: 807\n",
      "self.next: 810\n",
      "self.next: 813\n",
      "self.next: 816\n",
      "self.next: 819\n",
      "self.next: 822\n",
      "self.next: 825\n",
      "self.next: 3\n",
      "self.next: 6\n",
      "self.next: 9\n",
      "self.next: 12\n",
      "self.next: 15\n",
      "self.next: 18\n",
      "self.next: 21\n",
      "self.next: 24\n",
      "self.next: 27\n",
      "self.next: 30\n",
      "self.next: 33\n",
      "self.next: 36\n",
      "self.next: 39\n",
      "self.next: 42\n",
      "self.next: 45\n",
      "self.next: 48\n",
      "self.next: 51\n",
      "self.next: 54\n",
      "self.next: 57\n",
      "self.next: 60\n",
      "self.next: 63\n",
      "self.next: 66\n",
      "self.next: 69\n",
      "self.next: 72\n",
      "self.next: 75\n",
      "self.next: 78\n",
      "self.next: 81\n",
      "self.next: 84\n",
      "self.next: 87\n",
      "self.next: 90\n",
      "self.next: 93\n",
      "self.next: 96\n",
      "self.next: 99\n",
      "self.next: 102\n",
      "self.next: 105\n",
      "self.next: 108\n",
      "self.next: 111\n",
      "self.next: 114\n",
      "self.next: 117\n",
      "self.next: 120\n",
      "self.next: 123\n",
      "self.next: 126\n",
      "self.next: 129\n",
      "self.next: 132\n",
      "self.next: 135\n",
      "self.next: 138\n",
      "self.next: 141\n",
      "self.next: 144\n",
      "self.next: 147\n",
      "self.next: 150\n",
      "self.next: 153\n",
      "self.next: 156\n",
      "self.next: 159\n",
      "self.next: 162\n",
      "self.next: 165\n",
      "self.next: 168\n",
      "self.next: 171\n",
      "self.next: 174\n",
      "self.next: 177\n",
      "self.next: 180\n",
      "self.next: 183\n",
      "self.next: 186\n",
      "self.next: 189\n",
      "self.next: 192\n",
      "self.next: 195\n",
      "self.next: 198\n",
      "self.next: 201\n",
      "self.next: 204\n",
      "self.next: 207\n",
      "self.next: 210\n",
      "self.next: 213\n",
      "self.next: 216\n",
      "self.next: 219\n",
      "self.next: 222\n",
      "self.next: 225\n",
      "self.next: 228\n",
      "self.next: 231\n",
      "self.next: 234\n",
      "self.next: 237\n",
      "self.next: 240\n",
      "self.next: 243\n",
      "self.next: 246\n",
      "self.next: 249\n",
      "self.next: 252\n",
      "self.next: 255\n",
      "self.next: 258\n",
      "self.next: 261\n",
      "self.next: 264\n",
      "self.next: 267\n",
      "self.next: 270\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00084410334 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0415       |\n",
      "| fps                | 9             |\n",
      "| n_updates          | 5             |\n",
      "| policy_entropy     | 8.518799      |\n",
      "| policy_loss        | -0.009966777  |\n",
      "| serial_timesteps   | 640           |\n",
      "| time_elapsed       | 55.4          |\n",
      "| total_timesteps    | 640           |\n",
      "| value_loss         | 18.784157     |\n",
      "--------------------------------------\n",
      "self.next: 273\n",
      "self.next: 276\n",
      "self.next: 279\n",
      "self.next: 282\n",
      "self.next: 285\n",
      "self.next: 288\n",
      "self.next: 291\n",
      "self.next: 294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 297\n",
      "self.next: 300\n",
      "self.next: 303\n",
      "self.next: 306\n",
      "self.next: 309\n",
      "self.next: 312\n",
      "self.next: 315\n",
      "self.next: 318\n",
      "self.next: 321\n",
      "self.next: 324\n",
      "self.next: 327\n",
      "self.next: 330\n",
      "self.next: 333\n",
      "self.next: 336\n",
      "self.next: 339\n",
      "self.next: 342\n",
      "self.next: 345\n",
      "self.next: 348\n",
      "self.next: 351\n",
      "self.next: 354\n",
      "self.next: 357\n",
      "self.next: 360\n",
      "self.next: 363\n",
      "self.next: 366\n",
      "self.next: 369\n",
      "self.next: 372\n",
      "self.next: 375\n",
      "self.next: 378\n",
      "self.next: 381\n",
      "self.next: 384\n",
      "self.next: 387\n",
      "self.next: 390\n",
      "self.next: 393\n",
      "self.next: 396\n",
      "self.next: 399\n",
      "self.next: 402\n",
      "self.next: 405\n",
      "self.next: 408\n",
      "self.next: 411\n",
      "self.next: 414\n",
      "self.next: 417\n",
      "self.next: 420\n",
      "self.next: 423\n",
      "self.next: 426\n",
      "self.next: 429\n",
      "self.next: 432\n",
      "self.next: 435\n",
      "self.next: 438\n",
      "self.next: 441\n",
      "self.next: 444\n",
      "self.next: 447\n",
      "self.next: 450\n",
      "self.next: 453\n",
      "self.next: 456\n",
      "self.next: 459\n",
      "self.next: 462\n",
      "self.next: 465\n",
      "self.next: 468\n",
      "self.next: 471\n",
      "self.next: 474\n",
      "self.next: 477\n",
      "self.next: 480\n",
      "self.next: 483\n",
      "self.next: 486\n",
      "self.next: 489\n",
      "self.next: 492\n",
      "self.next: 495\n",
      "self.next: 498\n",
      "self.next: 501\n",
      "self.next: 504\n",
      "self.next: 507\n",
      "self.next: 510\n",
      "self.next: 513\n",
      "self.next: 516\n",
      "self.next: 519\n",
      "self.next: 522\n",
      "self.next: 525\n",
      "self.next: 528\n",
      "self.next: 531\n",
      "self.next: 534\n",
      "self.next: 537\n",
      "self.next: 540\n",
      "self.next: 543\n",
      "self.next: 546\n",
      "self.next: 549\n",
      "self.next: 552\n",
      "self.next: 555\n",
      "self.next: 558\n",
      "self.next: 561\n",
      "self.next: 564\n",
      "self.next: 567\n",
      "self.next: 570\n",
      "self.next: 573\n",
      "self.next: 576\n",
      "self.next: 579\n",
      "self.next: 582\n",
      "self.next: 585\n",
      "self.next: 588\n",
      "self.next: 591\n",
      "self.next: 594\n",
      "self.next: 597\n",
      "self.next: 600\n",
      "self.next: 603\n",
      "self.next: 606\n",
      "self.next: 609\n",
      "self.next: 612\n",
      "self.next: 615\n",
      "self.next: 618\n",
      "self.next: 621\n",
      "self.next: 624\n",
      "self.next: 627\n",
      "self.next: 630\n",
      "self.next: 633\n",
      "self.next: 636\n",
      "self.next: 639\n",
      "self.next: 642\n",
      "self.next: 645\n",
      "self.next: 648\n",
      "self.next: 651\n",
      "self.next: 654\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0016840433  |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| explained_variance | 0.0338        |\n",
      "| fps                | 9             |\n",
      "| n_updates          | 6             |\n",
      "| policy_entropy     | 8.518591      |\n",
      "| policy_loss        | 0.00050244515 |\n",
      "| serial_timesteps   | 768           |\n",
      "| time_elapsed       | 69.2          |\n",
      "| total_timesteps    | 768           |\n",
      "| value_loss         | 24.595247     |\n",
      "--------------------------------------\n",
      "self.next: 657\n",
      "self.next: 660\n",
      "self.next: 663\n",
      "self.next: 666\n",
      "self.next: 669\n",
      "self.next: 672\n",
      "self.next: 675\n",
      "self.next: 678\n",
      "self.next: 681\n",
      "self.next: 684\n",
      "self.next: 687\n",
      "self.next: 690\n",
      "self.next: 693\n",
      "self.next: 696\n",
      "self.next: 699\n",
      "self.next: 702\n",
      "self.next: 705\n",
      "self.next: 708\n",
      "self.next: 711\n",
      "self.next: 714\n",
      "self.next: 717\n",
      "self.next: 720\n",
      "self.next: 723\n",
      "self.next: 726\n",
      "self.next: 729\n",
      "self.next: 732\n",
      "self.next: 735\n",
      "self.next: 738\n",
      "self.next: 741\n",
      "self.next: 744\n",
      "self.next: 747\n",
      "self.next: 750\n",
      "self.next: 753\n",
      "self.next: 756\n",
      "self.next: 759\n",
      "self.next: 762\n",
      "self.next: 765\n",
      "self.next: 768\n",
      "self.next: 771\n",
      "self.next: 774\n",
      "self.next: 777\n",
      "self.next: 780\n",
      "self.next: 783\n",
      "self.next: 786\n",
      "self.next: 789\n",
      "self.next: 792\n",
      "self.next: 795\n",
      "self.next: 798\n",
      "self.next: 801\n",
      "self.next: 804\n",
      "self.next: 807\n",
      "self.next: 810\n",
      "self.next: 813\n",
      "self.next: 816\n",
      "self.next: 819\n",
      "self.next: 822\n",
      "self.next: 825\n",
      "self.next: 3\n",
      "self.next: 6\n",
      "self.next: 9\n",
      "self.next: 12\n",
      "self.next: 15\n",
      "self.next: 18\n",
      "self.next: 21\n",
      "self.next: 24\n",
      "self.next: 27\n",
      "self.next: 30\n",
      "self.next: 33\n",
      "self.next: 36\n",
      "self.next: 39\n",
      "self.next: 42\n",
      "self.next: 45\n",
      "self.next: 48\n",
      "self.next: 51\n",
      "self.next: 54\n",
      "self.next: 57\n",
      "self.next: 60\n",
      "self.next: 63\n",
      "self.next: 66\n",
      "self.next: 69\n",
      "self.next: 72\n",
      "self.next: 75\n",
      "self.next: 78\n",
      "self.next: 81\n",
      "self.next: 84\n",
      "self.next: 87\n",
      "self.next: 90\n",
      "self.next: 93\n",
      "self.next: 96\n",
      "self.next: 99\n",
      "self.next: 102\n",
      "self.next: 105\n",
      "self.next: 108\n",
      "self.next: 111\n",
      "self.next: 114\n",
      "self.next: 117\n",
      "self.next: 120\n",
      "self.next: 123\n",
      "self.next: 126\n",
      "self.next: 129\n",
      "self.next: 132\n",
      "self.next: 135\n",
      "self.next: 138\n",
      "self.next: 141\n",
      "self.next: 144\n",
      "self.next: 147\n",
      "self.next: 150\n",
      "self.next: 153\n",
      "self.next: 156\n",
      "self.next: 159\n",
      "self.next: 162\n",
      "self.next: 165\n",
      "self.next: 168\n",
      "self.next: 171\n",
      "self.next: 174\n",
      "self.next: 177\n",
      "self.next: 180\n",
      "self.next: 183\n",
      "self.next: 186\n",
      "self.next: 189\n",
      "self.next: 192\n",
      "self.next: 195\n",
      "self.next: 198\n",
      "self.next: 201\n",
      "self.next: 204\n",
      "self.next: 207\n",
      "self.next: 210\n",
      "self.next: 213\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00037590988  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0471        |\n",
      "| fps                | 9              |\n",
      "| n_updates          | 7              |\n",
      "| policy_entropy     | 8.518082       |\n",
      "| policy_loss        | -0.00092824653 |\n",
      "| serial_timesteps   | 896            |\n",
      "| time_elapsed       | 83.1           |\n",
      "| total_timesteps    | 896            |\n",
      "| value_loss         | 19.014448      |\n",
      "---------------------------------------\n",
      "self.next: 216\n",
      "self.next: 219\n",
      "self.next: 222\n",
      "self.next: 225\n",
      "self.next: 228\n",
      "self.next: 231\n",
      "self.next: 234\n",
      "self.next: 237\n",
      "self.next: 240\n",
      "self.next: 243\n",
      "self.next: 246\n",
      "self.next: 249\n",
      "self.next: 252\n",
      "self.next: 255\n",
      "self.next: 258\n",
      "self.next: 261\n",
      "self.next: 264\n",
      "self.next: 267\n",
      "self.next: 270\n",
      "self.next: 273\n",
      "self.next: 276\n",
      "self.next: 279\n",
      "self.next: 282\n",
      "self.next: 285\n",
      "self.next: 288\n",
      "self.next: 291\n",
      "self.next: 294\n",
      "self.next: 297\n",
      "self.next: 300\n",
      "self.next: 303\n",
      "self.next: 306\n",
      "self.next: 309\n",
      "self.next: 312\n",
      "self.next: 315\n",
      "self.next: 318\n",
      "self.next: 321\n",
      "self.next: 324\n",
      "self.next: 327\n",
      "self.next: 330\n",
      "self.next: 333\n",
      "self.next: 336\n",
      "self.next: 339\n",
      "self.next: 342\n",
      "self.next: 345\n",
      "self.next: 348\n",
      "self.next: 351\n",
      "self.next: 354\n",
      "self.next: 357\n",
      "self.next: 360\n",
      "self.next: 363\n",
      "self.next: 366\n",
      "self.next: 369\n",
      "self.next: 372\n",
      "self.next: 375\n",
      "self.next: 378\n",
      "self.next: 381\n",
      "self.next: 384\n",
      "self.next: 387\n",
      "self.next: 390\n",
      "self.next: 393\n",
      "self.next: 396\n",
      "self.next: 399\n",
      "self.next: 402\n",
      "self.next: 405\n",
      "self.next: 408\n",
      "self.next: 411\n",
      "self.next: 414\n",
      "self.next: 417\n",
      "self.next: 420\n",
      "self.next: 423\n",
      "self.next: 426\n",
      "self.next: 429\n",
      "self.next: 432\n",
      "self.next: 435\n",
      "self.next: 438\n",
      "self.next: 441\n",
      "self.next: 444\n",
      "self.next: 447\n",
      "self.next: 450\n",
      "self.next: 453\n",
      "self.next: 456\n",
      "self.next: 459\n",
      "self.next: 462\n",
      "self.next: 465\n",
      "self.next: 468\n",
      "self.next: 471\n",
      "self.next: 474\n",
      "self.next: 477\n",
      "self.next: 480\n",
      "self.next: 483\n",
      "self.next: 486\n",
      "self.next: 489\n",
      "self.next: 492\n",
      "self.next: 495\n",
      "self.next: 498\n",
      "self.next: 501\n",
      "self.next: 504\n",
      "self.next: 507\n",
      "self.next: 510\n",
      "self.next: 513\n",
      "self.next: 516\n",
      "self.next: 519\n",
      "self.next: 522\n",
      "self.next: 525\n",
      "self.next: 528\n",
      "self.next: 531\n",
      "self.next: 534\n",
      "self.next: 537\n",
      "self.next: 540\n",
      "self.next: 543\n",
      "self.next: 546\n",
      "self.next: 549\n",
      "self.next: 552\n",
      "self.next: 555\n",
      "self.next: 558\n",
      "self.next: 561\n",
      "self.next: 564\n",
      "self.next: 567\n",
      "self.next: 570\n",
      "self.next: 573\n",
      "self.next: 576\n",
      "self.next: 579\n",
      "self.next: 582\n",
      "self.next: 585\n",
      "self.next: 588\n",
      "self.next: 591\n",
      "self.next: 594\n",
      "self.next: 597\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005646913  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0709        |\n",
      "| fps                | 9             |\n",
      "| n_updates          | 8             |\n",
      "| policy_entropy     | 8.5198555     |\n",
      "| policy_loss        | -0.0019168674 |\n",
      "| serial_timesteps   | 1024          |\n",
      "| time_elapsed       | 97            |\n",
      "| total_timesteps    | 1024          |\n",
      "| value_loss         | 12.451866     |\n",
      "--------------------------------------\n",
      "self.next: 600\n",
      "self.next: 603\n",
      "self.next: 606\n",
      "self.next: 609\n",
      "self.next: 612\n",
      "self.next: 615\n",
      "self.next: 618\n",
      "self.next: 621\n",
      "self.next: 624\n",
      "self.next: 627\n",
      "self.next: 630\n",
      "self.next: 633\n",
      "self.next: 636\n",
      "self.next: 639\n",
      "self.next: 642\n",
      "self.next: 645\n",
      "self.next: 648\n",
      "self.next: 651\n",
      "self.next: 654\n",
      "self.next: 657\n",
      "self.next: 660\n",
      "self.next: 663\n",
      "self.next: 666\n",
      "self.next: 669\n",
      "self.next: 672\n",
      "self.next: 675\n",
      "self.next: 678\n",
      "self.next: 681\n",
      "self.next: 684\n",
      "self.next: 687\n",
      "self.next: 690\n",
      "self.next: 693\n",
      "self.next: 696\n",
      "self.next: 699\n",
      "self.next: 702\n",
      "self.next: 705\n",
      "self.next: 708\n",
      "self.next: 711\n",
      "self.next: 714\n",
      "self.next: 717\n",
      "self.next: 720\n",
      "self.next: 723\n",
      "self.next: 726\n",
      "self.next: 729\n",
      "self.next: 732\n",
      "self.next: 735\n",
      "self.next: 738\n",
      "self.next: 741\n",
      "self.next: 744\n",
      "self.next: 747\n",
      "self.next: 750\n",
      "self.next: 753\n",
      "self.next: 756\n",
      "self.next: 759\n",
      "self.next: 762\n",
      "self.next: 765\n",
      "self.next: 768\n",
      "self.next: 771\n",
      "self.next: 774\n",
      "self.next: 777\n",
      "self.next: 780\n",
      "self.next: 783\n",
      "self.next: 786\n",
      "self.next: 789\n",
      "self.next: 792\n",
      "self.next: 795\n",
      "self.next: 798\n",
      "self.next: 801\n",
      "self.next: 804\n",
      "self.next: 807\n",
      "self.next: 810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 813\n",
      "self.next: 816\n",
      "self.next: 819\n",
      "self.next: 822\n",
      "self.next: 825\n",
      "self.next: 3\n",
      "self.next: 6\n",
      "self.next: 9\n",
      "self.next: 12\n",
      "self.next: 15\n",
      "self.next: 18\n",
      "self.next: 21\n",
      "self.next: 24\n",
      "self.next: 27\n",
      "self.next: 30\n",
      "self.next: 33\n",
      "self.next: 36\n",
      "self.next: 39\n",
      "self.next: 42\n",
      "self.next: 45\n",
      "self.next: 48\n",
      "self.next: 51\n",
      "self.next: 54\n",
      "self.next: 57\n",
      "self.next: 60\n",
      "self.next: 63\n",
      "self.next: 66\n",
      "self.next: 69\n",
      "self.next: 72\n",
      "self.next: 75\n",
      "self.next: 78\n",
      "self.next: 81\n",
      "self.next: 84\n",
      "self.next: 87\n",
      "self.next: 90\n",
      "self.next: 93\n",
      "self.next: 96\n",
      "self.next: 99\n",
      "self.next: 102\n",
      "self.next: 105\n",
      "self.next: 108\n",
      "self.next: 111\n",
      "self.next: 114\n",
      "self.next: 117\n",
      "self.next: 120\n",
      "self.next: 123\n",
      "self.next: 126\n",
      "self.next: 129\n",
      "self.next: 132\n",
      "self.next: 135\n",
      "self.next: 138\n",
      "self.next: 141\n",
      "self.next: 144\n",
      "self.next: 147\n",
      "self.next: 150\n",
      "self.next: 153\n",
      "self.next: 156\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0011408192 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.00313      |\n",
      "| fps                | 9            |\n",
      "| n_updates          | 9            |\n",
      "| policy_entropy     | 8.519538     |\n",
      "| policy_loss        | 0.001961148  |\n",
      "| serial_timesteps   | 1152         |\n",
      "| time_elapsed       | 111          |\n",
      "| total_timesteps    | 1152         |\n",
      "| value_loss         | 28.677105    |\n",
      "-------------------------------------\n",
      "self.next: 159\n",
      "self.next: 162\n",
      "self.next: 165\n",
      "self.next: 168\n",
      "self.next: 171\n",
      "self.next: 174\n",
      "self.next: 177\n",
      "self.next: 180\n",
      "self.next: 183\n",
      "self.next: 186\n",
      "self.next: 189\n",
      "self.next: 192\n",
      "self.next: 195\n",
      "self.next: 198\n",
      "self.next: 201\n",
      "self.next: 204\n",
      "self.next: 207\n",
      "self.next: 210\n",
      "self.next: 213\n",
      "self.next: 216\n",
      "self.next: 219\n",
      "self.next: 222\n",
      "self.next: 225\n",
      "self.next: 228\n",
      "self.next: 231\n",
      "self.next: 234\n",
      "self.next: 237\n",
      "self.next: 240\n",
      "self.next: 243\n",
      "self.next: 246\n",
      "self.next: 249\n",
      "self.next: 252\n",
      "self.next: 255\n",
      "self.next: 258\n",
      "self.next: 261\n",
      "self.next: 264\n",
      "self.next: 267\n",
      "self.next: 270\n",
      "self.next: 273\n",
      "self.next: 276\n",
      "self.next: 279\n",
      "self.next: 282\n",
      "self.next: 285\n",
      "self.next: 288\n",
      "self.next: 291\n",
      "self.next: 294\n",
      "self.next: 297\n",
      "self.next: 300\n",
      "self.next: 303\n",
      "self.next: 306\n",
      "self.next: 309\n",
      "self.next: 312\n",
      "self.next: 315\n",
      "self.next: 318\n",
      "self.next: 321\n",
      "self.next: 324\n",
      "self.next: 327\n",
      "self.next: 330\n",
      "self.next: 333\n",
      "self.next: 336\n",
      "self.next: 339\n",
      "self.next: 342\n",
      "self.next: 345\n",
      "self.next: 348\n",
      "self.next: 351\n",
      "self.next: 354\n",
      "self.next: 357\n",
      "self.next: 360\n",
      "self.next: 363\n",
      "self.next: 366\n",
      "self.next: 369\n",
      "self.next: 372\n",
      "self.next: 375\n",
      "self.next: 378\n",
      "self.next: 381\n",
      "self.next: 384\n",
      "self.next: 387\n",
      "self.next: 390\n",
      "self.next: 393\n",
      "self.next: 396\n",
      "self.next: 399\n",
      "self.next: 402\n",
      "self.next: 405\n",
      "self.next: 408\n",
      "self.next: 411\n",
      "self.next: 414\n",
      "self.next: 417\n",
      "self.next: 420\n",
      "self.next: 423\n",
      "self.next: 426\n",
      "self.next: 429\n",
      "self.next: 432\n",
      "self.next: 435\n",
      "self.next: 438\n",
      "self.next: 441\n",
      "self.next: 444\n",
      "self.next: 447\n",
      "self.next: 450\n",
      "self.next: 453\n",
      "self.next: 456\n",
      "self.next: 459\n",
      "self.next: 462\n",
      "self.next: 465\n",
      "self.next: 468\n",
      "self.next: 471\n",
      "self.next: 474\n",
      "self.next: 477\n",
      "self.next: 480\n",
      "self.next: 483\n",
      "self.next: 486\n",
      "self.next: 489\n",
      "self.next: 492\n",
      "self.next: 495\n",
      "self.next: 498\n",
      "self.next: 501\n",
      "self.next: 504\n",
      "self.next: 507\n",
      "self.next: 510\n",
      "self.next: 513\n",
      "self.next: 516\n",
      "self.next: 519\n",
      "self.next: 522\n",
      "self.next: 525\n",
      "self.next: 528\n",
      "self.next: 531\n",
      "self.next: 534\n",
      "self.next: 537\n",
      "self.next: 540\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004271164  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00773       |\n",
      "| fps                | 9             |\n",
      "| n_updates          | 10            |\n",
      "| policy_entropy     | 8.517075      |\n",
      "| policy_loss        | 0.00043288223 |\n",
      "| serial_timesteps   | 1280          |\n",
      "| time_elapsed       | 125           |\n",
      "| total_timesteps    | 1280          |\n",
      "| value_loss         | 11.982373     |\n",
      "--------------------------------------\n",
      "self.next: 543\n",
      "self.next: 546\n",
      "self.next: 549\n",
      "self.next: 552\n",
      "self.next: 555\n",
      "self.next: 558\n",
      "self.next: 561\n",
      "self.next: 564\n",
      "self.next: 567\n",
      "self.next: 570\n",
      "self.next: 573\n",
      "self.next: 576\n",
      "self.next: 579\n",
      "self.next: 582\n",
      "self.next: 585\n",
      "self.next: 588\n",
      "self.next: 591\n",
      "self.next: 594\n",
      "self.next: 597\n",
      "self.next: 600\n",
      "self.next: 603\n",
      "self.next: 606\n",
      "self.next: 609\n",
      "self.next: 612\n",
      "self.next: 615\n",
      "self.next: 618\n",
      "self.next: 621\n",
      "self.next: 624\n",
      "self.next: 627\n",
      "self.next: 630\n",
      "self.next: 633\n",
      "self.next: 636\n",
      "self.next: 639\n",
      "self.next: 642\n",
      "self.next: 645\n",
      "self.next: 648\n",
      "self.next: 651\n",
      "self.next: 654\n",
      "self.next: 657\n",
      "self.next: 660\n",
      "self.next: 663\n",
      "self.next: 666\n",
      "self.next: 669\n",
      "self.next: 672\n",
      "self.next: 675\n",
      "self.next: 678\n",
      "self.next: 681\n",
      "self.next: 684\n",
      "self.next: 687\n",
      "self.next: 690\n",
      "self.next: 693\n",
      "self.next: 696\n",
      "self.next: 699\n",
      "self.next: 702\n",
      "self.next: 705\n",
      "self.next: 708\n",
      "self.next: 711\n",
      "self.next: 714\n",
      "self.next: 717\n",
      "self.next: 720\n",
      "self.next: 723\n",
      "self.next: 726\n",
      "self.next: 729\n",
      "self.next: 732\n",
      "self.next: 735\n",
      "self.next: 738\n",
      "self.next: 741\n",
      "self.next: 744\n",
      "self.next: 747\n",
      "self.next: 750\n",
      "self.next: 753\n",
      "self.next: 756\n",
      "self.next: 759\n",
      "self.next: 762\n",
      "self.next: 765\n",
      "self.next: 768\n",
      "self.next: 771\n",
      "self.next: 774\n",
      "self.next: 777\n",
      "self.next: 780\n",
      "self.next: 783\n",
      "self.next: 786\n",
      "self.next: 789\n",
      "self.next: 792\n",
      "self.next: 795\n",
      "self.next: 798\n",
      "self.next: 801\n",
      "self.next: 804\n",
      "self.next: 807\n",
      "self.next: 810\n",
      "self.next: 813\n",
      "self.next: 816\n",
      "self.next: 819\n",
      "self.next: 822\n",
      "self.next: 825\n",
      "self.next: 3\n",
      "self.next: 6\n",
      "self.next: 9\n",
      "self.next: 12\n",
      "self.next: 15\n",
      "self.next: 18\n",
      "self.next: 21\n",
      "self.next: 24\n",
      "self.next: 27\n",
      "self.next: 30\n",
      "self.next: 33\n",
      "self.next: 36\n",
      "self.next: 39\n",
      "self.next: 42\n",
      "self.next: 45\n",
      "self.next: 48\n",
      "self.next: 51\n",
      "self.next: 54\n",
      "self.next: 57\n",
      "self.next: 60\n",
      "self.next: 63\n",
      "self.next: 66\n",
      "self.next: 69\n",
      "self.next: 72\n",
      "self.next: 75\n",
      "self.next: 78\n",
      "self.next: 81\n",
      "self.next: 84\n",
      "self.next: 87\n",
      "self.next: 90\n",
      "self.next: 93\n",
      "self.next: 96\n",
      "self.next: 99\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0011349117 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0302      |\n",
      "| fps                | 9            |\n",
      "| n_updates          | 11           |\n",
      "| policy_entropy     | 8.515655     |\n",
      "| policy_loss        | 0.00147233   |\n",
      "| serial_timesteps   | 1408         |\n",
      "| time_elapsed       | 138          |\n",
      "| total_timesteps    | 1408         |\n",
      "| value_loss         | 27.548811    |\n",
      "-------------------------------------\n",
      "self.next: 102\n",
      "self.next: 105\n",
      "self.next: 108\n",
      "self.next: 111\n",
      "self.next: 114\n",
      "self.next: 117\n",
      "self.next: 120\n",
      "self.next: 123\n",
      "self.next: 126\n",
      "self.next: 129\n",
      "self.next: 132\n",
      "self.next: 135\n",
      "self.next: 138\n",
      "self.next: 141\n",
      "self.next: 144\n",
      "self.next: 147\n",
      "self.next: 150\n",
      "self.next: 153\n",
      "self.next: 156\n",
      "self.next: 159\n",
      "self.next: 162\n",
      "self.next: 165\n",
      "self.next: 168\n",
      "self.next: 171\n",
      "self.next: 174\n",
      "self.next: 177\n",
      "self.next: 180\n",
      "self.next: 183\n",
      "self.next: 186\n",
      "self.next: 189\n",
      "self.next: 192\n",
      "self.next: 195\n",
      "self.next: 198\n",
      "self.next: 201\n",
      "self.next: 204\n",
      "self.next: 207\n",
      "self.next: 210\n",
      "self.next: 213\n",
      "self.next: 216\n",
      "self.next: 219\n",
      "self.next: 222\n",
      "self.next: 225\n",
      "self.next: 228\n",
      "self.next: 231\n",
      "self.next: 234\n",
      "self.next: 237\n",
      "self.next: 240\n",
      "self.next: 243\n",
      "self.next: 246\n",
      "self.next: 249\n",
      "self.next: 252\n",
      "self.next: 255\n",
      "self.next: 258\n",
      "self.next: 261\n",
      "self.next: 264\n",
      "self.next: 267\n",
      "self.next: 270\n",
      "self.next: 273\n",
      "self.next: 276\n",
      "self.next: 279\n",
      "self.next: 282\n",
      "self.next: 285\n",
      "self.next: 288\n",
      "self.next: 291\n",
      "self.next: 294\n",
      "self.next: 297\n",
      "self.next: 300\n",
      "self.next: 303\n",
      "self.next: 306\n",
      "self.next: 309\n",
      "self.next: 312\n",
      "self.next: 315\n",
      "self.next: 318\n",
      "self.next: 321\n",
      "self.next: 324\n",
      "self.next: 327\n",
      "self.next: 330\n",
      "self.next: 333\n",
      "self.next: 336\n",
      "self.next: 339\n",
      "self.next: 342\n",
      "self.next: 345\n",
      "self.next: 348\n",
      "self.next: 351\n",
      "self.next: 354\n",
      "self.next: 357\n",
      "self.next: 360\n",
      "self.next: 363\n",
      "self.next: 366\n",
      "self.next: 369\n",
      "self.next: 372\n",
      "self.next: 375\n",
      "self.next: 378\n",
      "self.next: 381\n",
      "self.next: 384\n",
      "self.next: 387\n",
      "self.next: 390\n",
      "self.next: 393\n",
      "self.next: 396\n",
      "self.next: 399\n",
      "self.next: 402\n",
      "self.next: 405\n",
      "self.next: 408\n",
      "self.next: 411\n",
      "self.next: 414\n",
      "self.next: 417\n",
      "self.next: 420\n",
      "self.next: 423\n",
      "self.next: 426\n",
      "self.next: 429\n",
      "self.next: 432\n",
      "self.next: 435\n",
      "self.next: 438\n",
      "self.next: 441\n",
      "self.next: 444\n",
      "self.next: 447\n",
      "self.next: 450\n",
      "self.next: 453\n",
      "self.next: 456\n",
      "self.next: 459\n",
      "self.next: 462\n",
      "self.next: 465\n",
      "self.next: 468\n",
      "self.next: 471\n",
      "self.next: 474\n",
      "self.next: 477\n",
      "self.next: 480\n",
      "self.next: 483\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003634555  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0165        |\n",
      "| fps                | 9             |\n",
      "| n_updates          | 12            |\n",
      "| policy_entropy     | 8.518761      |\n",
      "| policy_loss        | -0.0015816182 |\n",
      "| serial_timesteps   | 1536          |\n",
      "| time_elapsed       | 152           |\n",
      "| total_timesteps    | 1536          |\n",
      "| value_loss         | 28.465406     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 486\n",
      "self.next: 489\n",
      "self.next: 492\n",
      "self.next: 495\n",
      "self.next: 498\n",
      "self.next: 501\n",
      "self.next: 504\n",
      "self.next: 507\n",
      "self.next: 510\n",
      "self.next: 513\n",
      "self.next: 516\n",
      "self.next: 519\n",
      "self.next: 522\n",
      "self.next: 525\n",
      "self.next: 528\n",
      "self.next: 531\n",
      "self.next: 534\n",
      "self.next: 537\n",
      "self.next: 540\n",
      "self.next: 543\n",
      "self.next: 546\n",
      "self.next: 549\n",
      "self.next: 552\n",
      "self.next: 555\n",
      "self.next: 558\n",
      "self.next: 561\n",
      "self.next: 564\n",
      "self.next: 567\n",
      "self.next: 570\n",
      "self.next: 573\n",
      "self.next: 576\n",
      "self.next: 579\n",
      "self.next: 582\n",
      "self.next: 585\n",
      "self.next: 588\n",
      "self.next: 591\n",
      "self.next: 594\n",
      "self.next: 597\n",
      "self.next: 600\n",
      "self.next: 603\n",
      "self.next: 606\n",
      "self.next: 609\n",
      "self.next: 612\n",
      "self.next: 615\n",
      "self.next: 618\n",
      "self.next: 621\n",
      "self.next: 624\n",
      "self.next: 627\n",
      "self.next: 630\n",
      "self.next: 633\n",
      "self.next: 636\n",
      "self.next: 639\n",
      "self.next: 642\n",
      "self.next: 645\n",
      "self.next: 648\n",
      "self.next: 651\n",
      "self.next: 654\n",
      "self.next: 657\n",
      "self.next: 660\n",
      "self.next: 663\n",
      "self.next: 666\n",
      "self.next: 669\n",
      "self.next: 672\n",
      "self.next: 675\n",
      "self.next: 678\n",
      "self.next: 681\n",
      "self.next: 684\n",
      "self.next: 687\n",
      "self.next: 690\n",
      "self.next: 693\n",
      "self.next: 696\n",
      "self.next: 699\n",
      "self.next: 702\n",
      "self.next: 705\n",
      "self.next: 708\n",
      "self.next: 711\n",
      "self.next: 714\n",
      "self.next: 717\n",
      "self.next: 720\n",
      "self.next: 723\n",
      "self.next: 726\n",
      "self.next: 729\n",
      "self.next: 732\n",
      "self.next: 735\n",
      "self.next: 738\n",
      "self.next: 741\n",
      "self.next: 744\n",
      "self.next: 747\n",
      "self.next: 750\n",
      "self.next: 753\n",
      "self.next: 756\n",
      "self.next: 759\n",
      "self.next: 762\n",
      "self.next: 765\n",
      "self.next: 768\n",
      "self.next: 771\n",
      "self.next: 774\n",
      "self.next: 777\n",
      "self.next: 780\n",
      "self.next: 783\n",
      "self.next: 786\n",
      "self.next: 789\n",
      "self.next: 792\n",
      "self.next: 795\n",
      "self.next: 798\n",
      "self.next: 801\n",
      "self.next: 804\n",
      "self.next: 807\n",
      "self.next: 810\n",
      "self.next: 813\n",
      "self.next: 816\n",
      "self.next: 819\n",
      "self.next: 822\n",
      "self.next: 825\n",
      "self.next: 3\n",
      "self.next: 6\n",
      "self.next: 9\n",
      "self.next: 12\n",
      "self.next: 15\n",
      "self.next: 18\n",
      "self.next: 21\n",
      "self.next: 24\n",
      "self.next: 27\n",
      "self.next: 30\n",
      "self.next: 33\n",
      "self.next: 36\n",
      "self.next: 39\n",
      "self.next: 42\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011784774  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | -0.06         |\n",
      "| fps                | 9             |\n",
      "| n_updates          | 13            |\n",
      "| policy_entropy     | 8.5229        |\n",
      "| policy_loss        | -0.0019384392 |\n",
      "| serial_timesteps   | 1664          |\n",
      "| time_elapsed       | 166           |\n",
      "| total_timesteps    | 1664          |\n",
      "| value_loss         | 15.864912     |\n",
      "--------------------------------------\n",
      "self.next: 45\n",
      "self.next: 48\n",
      "self.next: 51\n",
      "self.next: 54\n",
      "self.next: 57\n",
      "self.next: 60\n",
      "self.next: 63\n",
      "self.next: 66\n",
      "self.next: 69\n",
      "self.next: 72\n",
      "self.next: 75\n",
      "self.next: 78\n",
      "self.next: 81\n",
      "self.next: 84\n",
      "self.next: 87\n",
      "self.next: 90\n",
      "self.next: 93\n",
      "self.next: 96\n",
      "self.next: 99\n",
      "self.next: 102\n",
      "self.next: 105\n",
      "self.next: 108\n",
      "self.next: 111\n",
      "self.next: 114\n",
      "self.next: 117\n",
      "self.next: 120\n",
      "self.next: 123\n",
      "self.next: 126\n",
      "self.next: 129\n",
      "self.next: 132\n",
      "self.next: 135\n",
      "self.next: 138\n",
      "self.next: 141\n",
      "self.next: 144\n",
      "self.next: 147\n",
      "self.next: 150\n",
      "self.next: 153\n",
      "self.next: 156\n",
      "self.next: 159\n",
      "self.next: 162\n",
      "self.next: 165\n",
      "self.next: 168\n",
      "self.next: 171\n",
      "self.next: 174\n",
      "self.next: 177\n",
      "self.next: 180\n",
      "self.next: 183\n",
      "self.next: 186\n",
      "self.next: 189\n",
      "self.next: 192\n",
      "self.next: 195\n",
      "self.next: 198\n",
      "self.next: 201\n",
      "self.next: 204\n",
      "self.next: 207\n",
      "self.next: 210\n",
      "self.next: 213\n",
      "self.next: 216\n",
      "self.next: 219\n",
      "self.next: 222\n",
      "self.next: 225\n",
      "self.next: 228\n",
      "self.next: 231\n",
      "self.next: 234\n",
      "self.next: 237\n",
      "self.next: 240\n",
      "self.next: 243\n",
      "self.next: 246\n",
      "self.next: 249\n",
      "self.next: 252\n",
      "self.next: 255\n",
      "self.next: 258\n",
      "self.next: 261\n",
      "self.next: 264\n",
      "self.next: 267\n",
      "self.next: 270\n",
      "self.next: 273\n",
      "self.next: 276\n",
      "self.next: 279\n",
      "self.next: 282\n",
      "self.next: 285\n",
      "self.next: 288\n",
      "self.next: 291\n",
      "self.next: 294\n",
      "self.next: 297\n",
      "self.next: 300\n",
      "self.next: 303\n",
      "self.next: 306\n",
      "self.next: 309\n",
      "self.next: 312\n",
      "self.next: 315\n",
      "self.next: 318\n",
      "self.next: 321\n",
      "self.next: 324\n",
      "self.next: 327\n",
      "self.next: 330\n",
      "self.next: 333\n",
      "self.next: 336\n",
      "self.next: 339\n",
      "self.next: 342\n",
      "self.next: 345\n",
      "self.next: 348\n",
      "self.next: 351\n",
      "self.next: 354\n",
      "self.next: 357\n",
      "self.next: 360\n",
      "self.next: 363\n",
      "self.next: 366\n",
      "self.next: 369\n",
      "self.next: 372\n",
      "self.next: 375\n",
      "self.next: 378\n",
      "self.next: 381\n",
      "self.next: 384\n",
      "self.next: 387\n",
      "self.next: 390\n",
      "self.next: 393\n",
      "self.next: 396\n",
      "self.next: 399\n",
      "self.next: 402\n",
      "self.next: 405\n",
      "self.next: 408\n",
      "self.next: 411\n",
      "self.next: 414\n",
      "self.next: 417\n",
      "self.next: 420\n",
      "self.next: 423\n",
      "self.next: 426\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001881914  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0371       |\n",
      "| fps                | 9             |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 8.526824      |\n",
      "| policy_loss        | -0.0018368245 |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 180           |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 10.608536     |\n",
      "--------------------------------------\n",
      "self.next: 429\n",
      "self.next: 432\n",
      "self.next: 435\n",
      "self.next: 438\n",
      "self.next: 441\n",
      "self.next: 444\n",
      "self.next: 447\n",
      "self.next: 450\n",
      "self.next: 453\n",
      "self.next: 456\n",
      "self.next: 459\n",
      "self.next: 462\n",
      "self.next: 465\n",
      "self.next: 468\n",
      "self.next: 471\n",
      "self.next: 474\n",
      "self.next: 477\n",
      "self.next: 480\n",
      "self.next: 483\n",
      "self.next: 486\n",
      "self.next: 489\n",
      "self.next: 492\n",
      "self.next: 495\n",
      "self.next: 498\n",
      "self.next: 501\n",
      "self.next: 504\n",
      "self.next: 507\n",
      "self.next: 510\n",
      "self.next: 513\n",
      "self.next: 516\n",
      "self.next: 519\n",
      "self.next: 522\n",
      "self.next: 525\n",
      "self.next: 528\n",
      "self.next: 531\n",
      "self.next: 534\n",
      "self.next: 537\n",
      "self.next: 540\n",
      "self.next: 543\n",
      "self.next: 546\n",
      "self.next: 549\n",
      "self.next: 552\n",
      "self.next: 555\n",
      "self.next: 558\n",
      "self.next: 561\n",
      "self.next: 564\n",
      "self.next: 567\n",
      "self.next: 570\n",
      "self.next: 573\n",
      "self.next: 576\n",
      "self.next: 579\n",
      "self.next: 582\n",
      "self.next: 585\n",
      "self.next: 588\n",
      "self.next: 591\n",
      "self.next: 594\n",
      "self.next: 597\n",
      "self.next: 600\n",
      "self.next: 603\n",
      "self.next: 606\n",
      "self.next: 609\n",
      "self.next: 612\n",
      "self.next: 615\n",
      "self.next: 618\n",
      "self.next: 621\n",
      "self.next: 624\n",
      "self.next: 627\n",
      "self.next: 630\n",
      "self.next: 633\n",
      "self.next: 636\n",
      "self.next: 639\n",
      "self.next: 642\n",
      "self.next: 645\n",
      "self.next: 648\n",
      "self.next: 651\n",
      "self.next: 654\n",
      "self.next: 657\n",
      "self.next: 660\n",
      "self.next: 663\n",
      "self.next: 666\n",
      "self.next: 669\n",
      "self.next: 672\n",
      "self.next: 675\n",
      "self.next: 678\n",
      "self.next: 681\n",
      "self.next: 684\n",
      "self.next: 687\n",
      "self.next: 690\n",
      "self.next: 693\n",
      "self.next: 696\n",
      "self.next: 699\n",
      "self.next: 702\n",
      "self.next: 705\n",
      "self.next: 708\n",
      "self.next: 711\n",
      "self.next: 714\n",
      "self.next: 717\n",
      "self.next: 720\n",
      "self.next: 723\n",
      "self.next: 726\n",
      "self.next: 729\n",
      "self.next: 732\n",
      "self.next: 735\n",
      "self.next: 738\n",
      "self.next: 741\n",
      "self.next: 744\n",
      "self.next: 747\n",
      "self.next: 750\n",
      "self.next: 753\n",
      "self.next: 756\n",
      "self.next: 759\n",
      "self.next: 762\n",
      "self.next: 765\n",
      "self.next: 768\n",
      "self.next: 771\n",
      "self.next: 774\n",
      "self.next: 777\n",
      "self.next: 780\n",
      "self.next: 783\n",
      "self.next: 786\n",
      "self.next: 789\n",
      "self.next: 792\n",
      "self.next: 795\n",
      "self.next: 798\n",
      "self.next: 801\n",
      "self.next: 804\n",
      "self.next: 807\n",
      "self.next: 810\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011587043  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0377        |\n",
      "| fps                | 9             |\n",
      "| n_updates          | 15            |\n",
      "| policy_entropy     | 8.532307      |\n",
      "| policy_loss        | -0.0051929746 |\n",
      "| serial_timesteps   | 1920          |\n",
      "| time_elapsed       | 194           |\n",
      "| total_timesteps    | 1920          |\n",
      "| value_loss         | 15.493913     |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the agent - should take a while\n",
    "env = HumanArmImitation('c2fixc')\n",
    "model = PPO2('MlpPolicy', env, verbose=1).learn(total_timesteps=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 3\n",
      "action [-0.00123015  0.00760531  0.0081427   0.00100603  0.00552579  0.006004  ]\n",
      "reward -0.0\n",
      "self.next: 6\n",
      "action [-0.06011808  0.24967365  0.18970402 -0.02032941  0.15008569  0.13161331]\n",
      "reward -0.6145515614871538\n",
      "self.next: 9\n",
      "action [-0.05947842  0.24559827  0.1911099  -0.02011051  0.14900358  0.13039309]\n",
      "reward -0.404954568548559\n",
      "self.next: 12\n",
      "action [-0.05977981  0.24616121  0.19153033 -0.02003562  0.14910123  0.13026184]\n",
      "reward -0.344561153449167\n",
      "self.next: 15\n",
      "action [-0.05998151  0.2466967   0.19034234 -0.02043619  0.1496797   0.13094264]\n",
      "reward -0.5066222993026812\n",
      "self.next: 18\n",
      "action [-0.06592935  0.25385576  0.19087075 -0.01886608  0.15170853  0.12901977]\n",
      "reward -0.9133333512533943\n",
      "self.next: 21\n",
      "action [-0.05863003  0.24596918  0.19104294 -0.02066679  0.14822353  0.13080898]\n",
      "reward -0.5357673413839287\n",
      "self.next: 24\n",
      "action [-0.06069123  0.24423555  0.19314662 -0.01979468  0.14951201  0.12932487]\n",
      "reward -0.49803201926841445\n",
      "self.next: 27\n",
      "action [-0.0616604   0.23939653  0.19429904 -0.01834311  0.14813124  0.12600622]\n",
      "reward -0.7471857349696869\n",
      "self.next: 30\n",
      "action [-0.06157475  0.24396111  0.19443561 -0.01878123  0.14922541  0.12781993]\n",
      "reward -0.5380342639056406\n",
      "self.next: 33\n",
      "action [-0.06105509  0.2489659   0.19343068 -0.01975494  0.15051569  0.13042802]\n",
      "reward -0.31172688642151664\n",
      "self.next: 36\n",
      "action [-0.06127231  0.24723874  0.19433591 -0.01955079  0.15067813  0.12992114]\n",
      "reward -0.33097087949974147\n",
      "self.next: 39\n",
      "action [-0.06284077  0.24789874  0.19399391 -0.01907979  0.15063694  0.12907876]\n",
      "reward -0.390177078512999\n",
      "self.next: 42\n",
      "action [-0.06405484  0.25322917  0.19362341 -0.0193222   0.15275945  0.1305818 ]\n",
      "reward -0.7345371346888316\n",
      "self.next: 45\n",
      "action [-0.06384394  0.24850139  0.19482818 -0.01880227  0.15109183  0.12870613]\n",
      "reward -0.3930835432227643\n",
      "self.next: 48\n",
      "action [-0.06172957  0.250209    0.19429955 -0.01969094  0.15104882  0.13078752]\n",
      "reward -0.4278555351956262\n",
      "self.next: 51\n",
      "action [-0.05825974  0.24798852  0.19292982 -0.02077239  0.14977457  0.13228145]\n",
      "reward -0.47590053727906795\n",
      "self.next: 54\n",
      "action [-0.06439015  0.25041693  0.19676435 -0.01869679  0.15218474  0.12913966]\n",
      "reward -0.33371611943953455\n",
      "self.next: 57\n",
      "action [-0.06190968  0.2539518   0.19520521 -0.01990489  0.152578    0.1321969 ]\n",
      "reward -0.6780460060946639\n",
      "self.next: 60\n",
      "action [-0.05677462  0.25017774  0.19181576 -0.02125933  0.14981784  0.1340676 ]\n",
      "reward -0.5274502854416014\n",
      "self.next: 63\n",
      "action [-0.06340658  0.24412052  0.1971823  -0.01803725  0.14991708  0.12665668]\n",
      "reward -0.5728667726781269\n",
      "self.next: 66\n",
      "action [-0.05983283  0.24831133  0.19555034 -0.02021726  0.15046425  0.13126716]\n",
      "reward -0.41351759846488556\n",
      "self.next: 69\n",
      "action [-0.06274552  0.2506278   0.19733833 -0.01904742  0.15183756  0.13007827]\n",
      "reward -0.4121918492128047\n",
      "self.next: 72\n",
      "action [-0.06038613  0.25391868  0.19590719 -0.01996136  0.15204926  0.13269234]\n",
      "reward -0.6354787613210556\n",
      "self.next: 75\n",
      "action [-0.0621951   0.24834651  0.19778769 -0.01898351  0.15191902  0.13004388]\n",
      "reward -0.4336579748478361\n",
      "self.next: 78\n",
      "action [-0.06099688  0.2529805   0.1969118  -0.02022341  0.15278882  0.13293824]\n",
      "reward -0.5057044472488292\n",
      "self.next: 81\n",
      "action [-0.06341857  0.24859281  0.19978589 -0.01865736  0.15226541  0.12931624]\n",
      "reward -0.44925913988807076\n",
      "self.next: 84\n",
      "action [-0.06367414  0.24954139  0.2012471  -0.01823907  0.15207149  0.1286762 ]\n",
      "reward -0.4741128746738626\n",
      "self.next: 87\n",
      "action [-0.0604809   0.25190645  0.19869827 -0.01969455  0.15157488  0.13198203]\n",
      "reward -0.3958783208885442\n",
      "self.next: 90\n",
      "action [-0.0626692   0.2518289   0.20043923 -0.0190308   0.1524992   0.13073415]\n",
      "reward -0.3852721013255954\n",
      "self.next: 93\n",
      "action [-0.05975752  0.2509937   0.19947693 -0.01987075  0.15159555  0.1322034 ]\n",
      "reward -0.38312190318460615\n",
      "self.next: 96\n",
      "action [-0.06477731  0.25281444  0.20196143 -0.01883894  0.15407123  0.13035157]\n",
      "reward -0.38414572445235723\n",
      "self.next: 99\n",
      "action [-0.06730052  0.25696382  0.20126414 -0.01843158  0.15523894  0.1302672 ]\n",
      "reward -0.535522825513\n",
      "self.next: 102\n",
      "action [-0.06536215  0.25282598  0.20230506 -0.01850479  0.15363632  0.12988439]\n",
      "reward -0.3451509234182992\n",
      "self.next: 105\n",
      "action [-0.06480287  0.2546443   0.20297521 -0.01875481  0.15404682  0.13073123]\n",
      "reward -0.2902146276972807\n",
      "self.next: 108\n",
      "action [-0.06243932  0.25240698  0.2027934  -0.01909906  0.15331733  0.13159499]\n",
      "reward -0.38625213862950036\n",
      "self.next: 111\n",
      "action [-0.06144102  0.24912417  0.20270206 -0.01917086  0.15225728  0.13106912]\n",
      "reward -0.4534931129106693\n",
      "self.next: 114\n",
      "action [-0.06445828  0.25087988  0.20301734 -0.01852397  0.15381233  0.13015914]\n",
      "reward -0.6570333486307222\n",
      "self.next: 117\n",
      "action [-0.06244926  0.25383952  0.20421694 -0.01860355  0.15373085  0.1315918 ]\n",
      "reward -0.41069350050912196\n",
      "self.next: 120\n",
      "action [-0.06328895  0.25453588  0.20447165 -0.0185671   0.15379453  0.13127863]\n",
      "reward -0.3219236786695225\n",
      "self.next: 123\n",
      "action [-0.06458785  0.2520139   0.20464426 -0.01810584  0.15352179  0.13000149]\n",
      "reward -0.433721557150955\n",
      "self.next: 126\n",
      "action [-0.06323881  0.24783139  0.20442158 -0.01835604  0.15191048  0.12928835]\n",
      "reward -0.3749127854065525\n",
      "self.next: 129\n",
      "action [-0.06584949  0.24989733  0.20727026 -0.01692131  0.15320298  0.12743801]\n",
      "reward -0.5713741127372418\n",
      "self.next: 132\n",
      "action [-0.06027246  0.25005698  0.20392263 -0.01868249  0.15190771  0.13177067]\n",
      "reward -0.3571146089540218\n",
      "self.next: 135\n",
      "action [-0.06716463  0.2571644   0.2053046  -0.01725394  0.15550695  0.13002363]\n",
      "reward -0.5514335942272429\n",
      "self.next: 138\n",
      "action [-0.06629218  0.24940771  0.20756425 -0.0161365   0.15285292  0.12665421]\n",
      "reward -0.5516073012744166\n",
      "self.next: 141\n",
      "action [-0.06579977  0.2573099   0.20508733 -0.01754493  0.15510495  0.13102952]\n",
      "reward -0.5019114887298796\n",
      "self.next: 144\n",
      "action [-0.06629448  0.2573759   0.20469746 -0.01736853  0.15505074  0.13074082]\n",
      "reward -0.5165843538137034\n",
      "self.next: 147\n",
      "action [-0.06630541  0.24858281  0.20659293 -0.01640446  0.15274303  0.12710184]\n",
      "reward -0.3913641526504741\n",
      "self.next: 150\n",
      "action [-0.0640455   0.2528973   0.20699874 -0.01742127  0.15357323  0.13019074]\n",
      "reward -0.26764971819977695\n",
      "self.next: 153\n",
      "action [-0.06229572  0.25308546  0.20612009 -0.01811247  0.15318243  0.13157904]\n",
      "reward -0.34649109822469565\n",
      "self.next: 156\n",
      "action [-0.06311896  0.25150993  0.20672482 -0.01749518  0.15299425  0.13043365]\n",
      "reward -0.2551857437841986\n",
      "self.next: 159\n",
      "action [-0.06543576  0.25083977  0.2080192  -0.01641537  0.1531799   0.1283973 ]\n",
      "reward -0.45141757197048615\n",
      "self.next: 162\n",
      "action [-0.06169658  0.250474    0.20748954 -0.01720668  0.15282159  0.13094291]\n",
      "reward -0.3639590873794296\n",
      "self.next: 165\n",
      "action [-0.06515143  0.2478462   0.20752299 -0.01661135  0.15251876  0.12808952]\n",
      "reward -0.3913584148423588\n",
      "self.next: 168\n",
      "action [-0.06376117  0.24436267  0.20661546 -0.01640163  0.15087661  0.12738009]\n",
      "reward -0.4600855579431234\n",
      "self.next: 171\n",
      "action [-0.05514441  0.24225189  0.20473352 -0.01804785  0.14793843  0.13083792]\n",
      "reward -0.6574275750147118\n",
      "self.next: 174\n",
      "action [-0.05840478  0.24759857  0.20714748 -0.01718275  0.15095715  0.13141808]\n",
      "reward -0.3989761063395748\n",
      "self.next: 177\n",
      "action [-0.06330387  0.24794765  0.20823616 -0.01633098  0.15172923  0.12874639]\n",
      "reward -0.36175060925026714\n",
      "self.next: 180\n",
      "action [-0.06204283  0.24847083  0.20840411 -0.01658239  0.15204285  0.1299671 ]\n",
      "reward -0.2732912222006895\n",
      "self.next: 183\n",
      "action [-0.06122522  0.24772078  0.20817716 -0.01655128  0.15156217  0.13026486]\n",
      "reward -0.3436793806270163\n",
      "self.next: 186\n",
      "action [-0.06110034  0.248887    0.20872729 -0.01639173  0.1520468   0.13057728]\n",
      "reward -0.4020711474669238\n",
      "self.next: 189\n",
      "action [-0.05877239  0.24496426  0.20795448 -0.01682075  0.15028603  0.13057697]\n",
      "reward -0.3235095764005131\n",
      "self.next: 192\n",
      "action [-0.05863256  0.24687964  0.20792569 -0.0165386   0.15045786  0.13100636]\n",
      "reward -0.31362630707923417\n",
      "self.next: 195\n",
      "action [-0.06263804  0.24673286  0.20946695 -0.01566832  0.151408    0.12869135]\n",
      "reward -0.31147781678755115\n",
      "self.next: 198\n",
      "action [-0.0550264   0.24562684  0.20396899 -0.01755697  0.14903694  0.13345852]\n",
      "reward -0.5967007772171968\n",
      "self.next: 201\n",
      "action [-0.06372847  0.24786896  0.20893718 -0.01469631  0.15125236  0.12801921]\n",
      "reward -0.38338995791123703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 204\n",
      "action [-0.05926842  0.24476911  0.20827352 -0.01572358  0.15001278  0.13009752]\n",
      "reward -0.36946259137323256\n",
      "self.next: 207\n",
      "action [-0.0580725   0.2413807   0.20893756 -0.01466052  0.14826652  0.12837875]\n",
      "reward -0.4428844497140372\n",
      "self.next: 210\n",
      "action [-0.05977244  0.24247399  0.20982514 -0.01469705  0.14958304  0.12858705]\n",
      "reward -0.31786621151299804\n",
      "self.next: 213\n",
      "action [-0.05644719  0.24226224  0.20857877 -0.01566959  0.14853536  0.13065362]\n",
      "reward -0.2846214367659046\n",
      "self.next: 216\n",
      "action [-0.05994974  0.24230821  0.20926106 -0.01501223  0.1490361   0.12861791]\n",
      "reward -0.32193062478125334\n",
      "self.next: 219\n",
      "action [-0.06014173  0.24141745  0.2102573  -0.01428538  0.14917913  0.12791869]\n",
      "reward -0.32298636133058617\n",
      "self.next: 222\n",
      "action [-0.05624788  0.23972109  0.20941474 -0.01478287  0.14814563  0.12977381]\n",
      "reward -0.3271876429015795\n",
      "self.next: 225\n",
      "action [-0.05840825  0.23427697  0.20841408 -0.01482197  0.14673407  0.12702309]\n",
      "reward -0.48268274275609535\n",
      "self.next: 228\n",
      "action [-0.05822398  0.239567    0.20760268 -0.01480321  0.14787853  0.12913404]\n",
      "reward -0.4734106180484259\n",
      "self.next: 231\n",
      "action [-0.05726305  0.24011342  0.20917276 -0.01441641  0.14753413  0.1292139 ]\n",
      "reward -0.4078994736403041\n",
      "self.next: 234\n",
      "action [-0.05386418  0.23706411  0.2087861  -0.01438913  0.14630337  0.13001212]\n",
      "reward -0.281881480423027\n",
      "self.next: 237\n",
      "action [-0.05627225  0.23392291  0.20957664 -0.01335409  0.14616574  0.12742332]\n",
      "reward -0.5613518607934351\n",
      "self.next: 240\n",
      "action [-0.05827039  0.23315331  0.20981927 -0.01336261  0.14580458  0.12594111]\n",
      "reward -0.4430643553916962\n",
      "self.next: 243\n",
      "action [-0.05476676  0.23526058  0.20954333 -0.01369079  0.14564937  0.12860414]\n",
      "reward -0.26129928416434034\n",
      "self.next: 246\n",
      "action [-0.05251362  0.2315132   0.20899817 -0.01403924  0.14430773  0.1286948 ]\n",
      "reward -0.36119762972164166\n",
      "self.next: 249\n",
      "action [-0.05478543  0.23358668  0.20937407 -0.01357193  0.14484574  0.12795189]\n",
      "reward -0.2729652311757502\n",
      "self.next: 252\n",
      "action [-0.05166529  0.23669803  0.20700629 -0.01386991  0.1446851   0.13103026]\n",
      "reward -0.4759690162352408\n",
      "self.next: 255\n",
      "action [-0.05208822  0.23397245  0.2094734  -0.01299057  0.14430192  0.12905082]\n",
      "reward -0.41221114206257004\n",
      "self.next: 258\n",
      "action [-0.05516526  0.23182751  0.20947486 -0.01278122  0.14414711  0.12701689]\n",
      "reward -0.35122626575807536\n",
      "self.next: 261\n",
      "action [-0.05516406  0.23327242  0.20929638 -0.01236967  0.14388064  0.12711534]\n",
      "reward -0.3298705128617763\n",
      "self.next: 264\n",
      "action [-0.05246866  0.22929904  0.2095975  -0.01275352  0.14280233  0.12746876]\n",
      "reward -0.25472846012262995\n",
      "self.next: 267\n",
      "action [-0.05279085  0.23444822  0.20740926 -0.01282605  0.14380115  0.12950958]\n",
      "reward -0.4492502706921576\n",
      "self.next: 270\n",
      "action [-0.04702962  0.22135392  0.20892957 -0.01235115  0.13915074  0.12644006]\n",
      "reward -0.5194219285699989\n",
      "self.next: 273\n",
      "action [-0.05352119  0.22987087  0.20981018 -0.01142724  0.14239854  0.12640768]\n",
      "reward -0.3890524284117859\n",
      "self.next: 276\n",
      "action [-0.04744183  0.22410327  0.20821074 -0.01194814  0.13993186  0.1279953 ]\n",
      "reward -0.3739622254546437\n",
      "self.next: 279\n",
      "action [-0.0501952   0.22830506  0.20643489 -0.01211038  0.14074992  0.12859967]\n",
      "reward -0.4578614167966164\n",
      "self.next: 282\n",
      "action [-0.05063665  0.22317265  0.20835452 -0.01128302  0.13963515  0.1258897 ]\n",
      "reward -0.3176952183719043\n",
      "self.next: 285\n",
      "action [-0.04741554  0.22221419  0.20842224 -0.01128046  0.1392468   0.12734482]\n",
      "reward -0.2891065211122306\n",
      "self.next: 288\n",
      "action [-0.0505455   0.22079226  0.20827784 -0.01096551  0.13882348  0.12518014]\n",
      "reward -0.3117057335944393\n",
      "self.next: 291\n",
      "action [-0.04375204  0.21789104  0.2068475  -0.01149694  0.13710722  0.12801853]\n",
      "reward -0.3529343230121127\n",
      "self.next: 294\n",
      "action [-0.04729506  0.21847804  0.20745529 -0.01052073  0.13723612  0.12595594]\n",
      "reward -0.31348460354049973\n",
      "self.next: 297\n",
      "action [-0.04579325  0.21786425  0.20781724 -0.01036209  0.13709809  0.12662394]\n",
      "reward -0.2971377948492169\n",
      "self.next: 300\n",
      "action [-0.04932622  0.21855034  0.20729871 -0.00948037  0.13703528  0.12456413]\n",
      "reward -0.38393261855049543\n",
      "self.next: 303\n",
      "action [-0.04342218  0.21456157  0.20715958 -0.00993994  0.13586737  0.1267071 ]\n",
      "reward -0.40696653843781533\n",
      "self.next: 306\n",
      "action [-0.04721043  0.21011336  0.20754737 -0.0089325   0.13389887  0.12192728]\n",
      "reward -0.5481456734831582\n",
      "self.next: 309\n",
      "action [-0.04146486  0.21344928  0.20613284 -0.01009461  0.13448693  0.12743351]\n",
      "reward -0.3245779738503034\n",
      "self.next: 312\n",
      "action [-0.03844501  0.21535523  0.20241031 -0.00990566  0.13343005  0.1298196 ]\n",
      "reward -0.5314167113236722\n",
      "self.next: 315\n",
      "action [-0.04245784  0.20988801  0.20528787 -0.00933814  0.13282682  0.12557948]\n",
      "reward -0.371371385992708\n",
      "self.next: 318\n",
      "action [-0.04033185  0.2088845   0.20506251 -0.00904521  0.13226554  0.12630987]\n",
      "reward -0.3657640398520295\n",
      "self.next: 321\n",
      "action [-0.04041795  0.2085418   0.20462903 -0.00907566  0.13203777  0.12635738]\n",
      "reward -0.3214093794232087\n",
      "self.next: 324\n",
      "action [-0.03221341  0.20049036  0.2013563  -0.00953046  0.12758084  0.12713766]\n",
      "reward -0.42462400933765515\n",
      "self.next: 327\n",
      "action [-0.0356064   0.20384349  0.20301788 -0.00866652  0.12915114  0.12690042]\n",
      "reward -0.42645854727165716\n",
      "self.next: 330\n",
      "action [-0.03842563  0.20250879  0.20438981 -0.00785618  0.12969491  0.12491773]\n",
      "reward -0.30237482635595886\n",
      "self.next: 333\n",
      "action [-0.03691269  0.20022258  0.20400074 -0.00758438  0.12870601  0.1248697 ]\n",
      "reward -0.3025388684132561\n",
      "self.next: 336\n",
      "action [-0.03818072  0.20030683  0.20381548 -0.00715378  0.12853433  0.12410755]\n",
      "reward -0.35364746071024533\n",
      "self.next: 339\n",
      "action [-0.03577155  0.19869503  0.20309855 -0.00693925  0.12765019  0.12484521]\n",
      "reward -0.3371720541853968\n",
      "self.next: 342\n",
      "action [-0.03222202  0.19590415  0.2020861  -0.00693361  0.12598132  0.12568358]\n",
      "reward -0.36856891807346387\n",
      "self.next: 345\n",
      "action [-0.03907488  0.19773915  0.20195358 -0.00566296  0.12619048  0.121899  ]\n",
      "reward -0.5183765856305141\n",
      "self.next: 348\n",
      "action [-0.03764591  0.19277674  0.20191649 -0.00596945  0.1251592   0.1213634 ]\n",
      "reward -0.3743024134820836\n",
      "self.next: 351\n",
      "action [-0.03198056  0.19215196  0.20122494 -0.00587276  0.12426148  0.12451585]\n",
      "reward -0.3636026722652579\n",
      "self.next: 354\n",
      "action [-0.0298357   0.18939827  0.20099701 -0.00545856  0.1232368   0.12450325]\n",
      "reward -0.3437303744515589\n",
      "self.next: 357\n",
      "action [-0.03147424  0.18667229  0.20087458 -0.00500738  0.12219931  0.12242432]\n",
      "reward -0.3472470902610348\n",
      "self.next: 360\n",
      "action [-0.03564592  0.18872708  0.19914484 -0.00387697  0.12157305  0.12004896]\n",
      "reward -0.5329535145442327\n",
      "self.next: 363\n",
      "action [-0.02992778  0.18687199  0.19915442 -0.00411178  0.12057951  0.12281329]\n",
      "reward -0.522153276751142\n",
      "self.next: 366\n",
      "action [-0.02877359  0.1818762   0.19895479 -0.00448642  0.11921352  0.12204295]\n",
      "reward -0.41108349456121596\n",
      "self.next: 369\n",
      "action [-0.02355969  0.1815535   0.19648144 -0.00400491  0.11765615  0.12463708]\n",
      "reward -0.4839889051788927\n",
      "self.next: 372\n",
      "action [-0.02047231  0.17705902  0.19588006 -0.00397553  0.11634772  0.12481035]\n",
      "reward -0.4328511086068327\n",
      "self.next: 375\n",
      "action [-0.02332346  0.17551138  0.19680737 -0.00315443  0.11613567  0.12270863]\n",
      "reward -0.42673377771715626\n",
      "self.next: 378\n",
      "action [-0.02169821  0.17484117  0.19552784 -0.00236053  0.11471953  0.12282334]\n",
      "reward -0.5788635260267943\n",
      "self.next: 381\n",
      "action [-0.01840566  0.16892362  0.19435088 -0.00292451  0.11271381  0.12281515]\n",
      "reward -0.4510466954277334\n",
      "self.next: 384\n",
      "action [-0.01767412  0.1693022   0.19346347 -0.00288362  0.11271534  0.12374562]\n",
      "reward -0.40794762842914445\n",
      "self.next: 387\n",
      "action [-0.01780761  0.16786155  0.19343294 -0.00176341  0.11181837  0.12266152]\n",
      "reward -0.4460867167582408\n",
      "self.next: 390\n",
      "action [-0.02016788  0.16779576  0.19273002 -0.00103007  0.11104438  0.12106581]\n",
      "reward -0.5294231025835328\n",
      "self.next: 393\n",
      "action [-0.01248093  0.1555229   0.1926386  -0.00110753  0.10683055  0.11989486]\n",
      "reward -0.7593873368065397\n",
      "self.next: 396\n",
      "action [-0.01772002  0.16090491  0.19240895 -0.00065651  0.10889032  0.11990767]\n",
      "reward -0.41648292139442894\n",
      "self.next: 399\n",
      "action [-0.01488494  0.15806255  0.19152774 -0.00039922  0.10768086  0.12051132]\n",
      "reward -0.3939723798300474\n",
      "self.next: 402\n",
      "action [-0.01435979  0.15619455  0.19089015  0.00024834  0.10642464  0.119699  ]\n",
      "reward -0.4623176123329271\n",
      "self.next: 405\n",
      "action [-0.01329727  0.15355586  0.1900458   0.00076895  0.1049883   0.11914649]\n",
      "reward -0.4700444448390232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 408\n",
      "action [-0.012165    0.1521747   0.1891787   0.00102794  0.1038889   0.11913265]\n",
      "reward -0.5758256205294354\n",
      "self.next: 411\n",
      "action [-0.01081562  0.1473237   0.18935125  0.00152509  0.10251958  0.11806772]\n",
      "reward -0.5298958027763685\n",
      "self.next: 414\n",
      "action [-0.00570461  0.1401262   0.18855356  0.00281421  0.09947837  0.11711638]\n",
      "reward -0.6361648713744179\n",
      "self.next: 417\n",
      "action [-0.00677291  0.14338264  0.18640386  0.00250361  0.09983397  0.11872038]\n",
      "reward -0.5022699679349248\n",
      "self.next: 420\n",
      "action [-0.00551252  0.13959691  0.18591659  0.00347844  0.09808224  0.11747617]\n",
      "reward -0.5604552446448099\n",
      "self.next: 423\n",
      "action [0.00182356 0.13395151 0.18268873 0.004277   0.09456886 0.11859362]\n",
      "reward -0.738544392997738\n",
      "self.next: 426\n",
      "action [-0.00178406  0.13345079  0.18410958  0.0047881   0.09526296  0.11698602]\n",
      "reward -0.5398279950398852\n",
      "self.next: 429\n",
      "action [-0.00864947  0.13521555  0.18284348  0.00522769  0.09480422  0.11344951]\n",
      "reward -0.7134732245658263\n",
      "self.next: 432\n",
      "action [-0.00159952  0.13439317  0.17978352  0.00584085  0.09404897  0.11755874]\n",
      "reward -0.5827958506521346\n",
      "self.next: 435\n",
      "action [0.00090946 0.12448877 0.18163505 0.00617939 0.09092498 0.11492189]\n",
      "reward -0.6603496017349358\n",
      "self.next: 438\n",
      "action [0.00683205 0.12148739 0.17905502 0.0070746  0.08890384 0.11687003]\n",
      "reward -0.682914543685648\n",
      "self.next: 441\n",
      "action [0.00448528 0.12048849 0.17899416 0.00750088 0.08862357 0.1153912 ]\n",
      "reward -0.6242151739663018\n",
      "self.next: 444\n",
      "action [0.00383419 0.11876525 0.17773677 0.00875073 0.08699468 0.11351343]\n",
      "reward -0.7020308518427258\n",
      "self.next: 447\n",
      "action [0.01121139 0.11191032 0.17583992 0.00878967 0.08463745 0.11552113]\n",
      "reward -0.6404528101520163\n",
      "self.next: 450\n",
      "action [0.01216142 0.10791411 0.17581043 0.00953787 0.08348611 0.11445644]\n",
      "reward -0.5854571336838645\n",
      "self.next: 453\n",
      "action [0.01084237 0.10750096 0.17484292 0.01007095 0.08222486 0.11332122]\n",
      "reward -0.7016991362255961\n",
      "self.next: 456\n",
      "action [0.01256879 0.10477591 0.174056   0.01105552 0.08086052 0.11286844]\n",
      "reward -0.6642853319709383\n",
      "self.next: 459\n",
      "action [0.01482968 0.09970026 0.17303051 0.01160254 0.07850023 0.1119638 ]\n",
      "reward -0.7710057254466842\n",
      "self.next: 462\n",
      "action [0.01549473 0.09848519 0.17194656 0.0120422  0.077704   0.1119329 ]\n",
      "reward -0.7216836008399161\n",
      "self.next: 465\n",
      "action [0.0208431  0.0938943  0.16954046 0.01279877 0.075047   0.11284271]\n",
      "reward -0.7761224425304909\n",
      "self.next: 468\n",
      "action [0.01691121 0.09353337 0.16997297 0.01363842 0.07422899 0.1099375 ]\n",
      "reward -0.8748421718637904\n",
      "self.next: 471\n",
      "action [0.01953504 0.09002806 0.16914015 0.01421446 0.07312975 0.11014026]\n",
      "reward -0.7618375978464674\n",
      "self.next: 474\n",
      "action [0.02503107 0.08428717 0.16669579 0.01446488 0.07031976 0.11112144]\n",
      "reward -0.8400812701566093\n",
      "self.next: 477\n",
      "action [0.02445624 0.08262035 0.16570391 0.01522021 0.06885102 0.10976499]\n",
      "reward -0.8349078394887461\n",
      "self.next: 480\n",
      "action [0.02157875 0.08205616 0.16562957 0.01567647 0.06824283 0.10756858]\n",
      "reward -0.7994378585273386\n",
      "self.next: 483\n",
      "action [0.02280062 0.08407665 0.1622836  0.01543789 0.06802419 0.10965043]\n",
      "reward -0.6875378729688683\n",
      "self.next: 486\n",
      "action [0.02662028 0.07699769 0.16266976 0.01663022 0.06559553 0.10850029]\n",
      "reward -0.7162598895391198\n",
      "self.next: 489\n",
      "action [0.02913827 0.0696007  0.16353935 0.01691936 0.06357986 0.10693077]\n",
      "reward -0.9368222078988756\n",
      "self.next: 492\n",
      "action [0.03063457 0.07088683 0.16046971 0.01753423 0.06242045 0.10817228]\n",
      "reward -0.7277054712822335\n",
      "self.next: 495\n",
      "action [0.0313125  0.0690213  0.15995902 0.01773873 0.0619862  0.10811594]\n",
      "reward -0.6045621467544318\n",
      "self.next: 498\n",
      "action [0.02975195 0.06813532 0.15937278 0.01807849 0.06078536 0.10645235]\n",
      "reward -0.6338024993789925\n",
      "self.next: 501\n",
      "action [0.03470464 0.06778903 0.15599355 0.01790194 0.06062733 0.11001095]\n",
      "reward -0.49573977530694907\n",
      "self.next: 504\n",
      "action [0.03340675 0.06263945 0.15870363 0.01877374 0.05905076 0.10643476]\n",
      "reward -0.5736344464339234\n",
      "self.next: 507\n",
      "action [0.03803064 0.05848105 0.15555708 0.01909627 0.05629351 0.10723072]\n",
      "reward -0.6643704005320853\n",
      "self.next: 510\n",
      "action [0.03377591 0.05874175 0.15671949 0.0192595  0.05636269 0.10476039]\n",
      "reward -0.5848600724406716\n",
      "self.next: 513\n",
      "action [0.03805863 0.04913703 0.15757619 0.01957962 0.05444003 0.10349459]\n",
      "reward -0.735414227473477\n",
      "self.next: 516\n",
      "action [0.03713498 0.05513288 0.15478073 0.01985536 0.05461424 0.10532383]\n",
      "reward -0.5079246389191242\n",
      "self.next: 519\n",
      "action [0.03545786 0.05391305 0.15499067 0.02024925 0.05365874 0.1028472 ]\n",
      "reward -0.8374145358250181\n",
      "self.next: 522\n",
      "action [0.03740783 0.05353934 0.15297967 0.01985636 0.05306838 0.10494   ]\n",
      "reward -0.48115318582240185\n",
      "self.next: 525\n",
      "action [0.03789165 0.05070128 0.15317452 0.019995   0.05239141 0.10431503]\n",
      "reward -0.4757536688487629\n",
      "self.next: 528\n",
      "action [0.03974745 0.04913764 0.15184343 0.02034152 0.05142154 0.10456996]\n",
      "reward -0.47919424262396504\n",
      "self.next: 531\n",
      "action [0.03787114 0.04896396 0.15122263 0.02054637 0.05021306 0.10283986]\n",
      "reward -0.4969416062068855\n",
      "self.next: 534\n",
      "action [0.0405217  0.04993602 0.14852425 0.02024478 0.05064967 0.10564099]\n",
      "reward -0.47826311333676763\n",
      "self.next: 537\n",
      "action [0.04037134 0.04270455 0.15070307 0.02066079 0.04855417 0.10231245]\n",
      "reward -0.46471971518731753\n",
      "self.next: 540\n",
      "action [0.04048064 0.04286759 0.14931448 0.02067253 0.04796995 0.10238733]\n",
      "reward -0.40723039720727755\n",
      "self.next: 543\n",
      "action [0.0437158  0.04101432 0.14766319 0.02083431 0.04716773 0.10354453]\n",
      "reward -0.530941754113325\n",
      "self.next: 546\n",
      "action [0.04028502 0.0415661  0.14772594 0.02048264 0.04663917 0.10183034]\n",
      "reward -0.4202745986405039\n",
      "self.next: 549\n",
      "action [0.04226781 0.04110932 0.14611575 0.02085354 0.04600172 0.10257601]\n",
      "reward -0.3503072396932902\n",
      "self.next: 552\n",
      "action [0.04185674 0.03827761 0.14670731 0.02068742 0.04532805 0.10156808]\n",
      "reward -0.3706922009709286\n",
      "self.next: 555\n",
      "action [0.04151544 0.03826303 0.14576395 0.02062664 0.04488141 0.10127791]\n",
      "reward -0.3417286345694165\n",
      "self.next: 558\n",
      "action [0.04408479 0.03065601 0.14615998 0.02076469 0.04277155 0.09992644]\n",
      "reward -0.7879770796141682\n",
      "self.next: 561\n",
      "action [0.04627227 0.0338     0.14274916 0.02069413 0.04267202 0.10264459]\n",
      "reward -0.5135663075455872\n",
      "self.next: 564\n",
      "action [0.04404351 0.03437166 0.14193097 0.02113464 0.04213135 0.10099354]\n",
      "reward -0.33568103733381527\n",
      "self.next: 567\n",
      "action [0.04247557 0.03328927 0.142311   0.02088566 0.04107144 0.09937692]\n",
      "reward -0.4844344102057089\n",
      "self.next: 570\n",
      "action [0.03831716 0.0350254  0.1428811  0.02019118 0.0415903  0.09757536]\n",
      "reward -0.5464037057623305\n",
      "self.next: 573\n",
      "action [0.0431765  0.02651174 0.14245513 0.02081006 0.03922471 0.09735193]\n",
      "reward -0.6902135805145776\n",
      "self.next: 576\n",
      "action [0.04591799 0.02853905 0.1402392  0.02097335 0.03968411 0.10014236]\n",
      "reward -0.3921471184502092\n",
      "self.next: 579\n",
      "action [0.04494548 0.02624722 0.1414944  0.02032705 0.03960551 0.09947248]\n",
      "reward -0.5427035419337344\n",
      "self.next: 582\n",
      "action [0.04545592 0.02700713 0.13948904 0.02081708 0.03882438 0.0992795 ]\n",
      "reward -0.3494636887435238\n",
      "self.next: 585\n",
      "action [0.04567851 0.02264444 0.13981627 0.02094674 0.03741273 0.09736044]\n",
      "reward -0.6431519850216844\n",
      "self.next: 588\n",
      "action [0.04264471 0.02834274 0.13858695 0.02021903 0.03829085 0.09818494]\n",
      "reward -0.4509588742782126\n",
      "self.next: 591\n",
      "action [0.0439318  0.02174338 0.13910167 0.0201306  0.03648217 0.09642915]\n",
      "reward -0.6711644792492886\n",
      "self.next: 594\n",
      "action [0.04297801 0.02518808 0.1370081  0.02008864 0.03675656 0.09723639]\n",
      "reward -0.4261663996851349\n",
      "self.next: 597\n",
      "action [0.04524668 0.02762101 0.13434862 0.01989631 0.03742191 0.10012828]\n",
      "reward -0.6883101030331379\n",
      "self.next: 600\n",
      "action [0.04581532 0.02245185 0.13555484 0.02013219 0.03610243 0.09841527]\n",
      "reward -0.3734438081395376\n",
      "self.next: 603\n",
      "action [0.0461669  0.02098208 0.13514483 0.0199805  0.03562814 0.09816089]\n",
      "reward -0.3677331603082531\n",
      "self.next: 606\n",
      "action [0.04614086 0.02094401 0.13464975 0.01997485 0.03544165 0.09816287]\n",
      "reward -0.37110566101402476\n",
      "self.next: 609\n",
      "action [0.04495315 0.0204972  0.13454981 0.02004418 0.03505222 0.09692443]\n",
      "reward -0.3537224358824014\n",
      "self.next: 612\n",
      "action [0.04552752 0.01539884 0.13413128 0.02012899 0.03272402 0.09472933]\n",
      "reward -0.5316725709408192\n",
      "self.next: 615\n",
      "action [0.04508502 0.01667794 0.133942   0.01945304 0.0333951  0.09608606]\n",
      "reward -0.5466263034933481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 618\n",
      "action [0.04864914 0.01787567 0.13073261 0.0194939  0.03364941 0.09908612]\n",
      "reward -0.4284104408660607\n",
      "self.next: 621\n",
      "action [0.04445127 0.02187867 0.13078    0.0191345  0.0345305  0.09786787]\n",
      "reward -0.7025108220004053\n",
      "self.next: 624\n",
      "action [0.04528097 0.01549819 0.13131964 0.01931435 0.03265042 0.09579107]\n",
      "reward -0.33351985088980846\n",
      "self.next: 627\n",
      "action [0.04748496 0.01449967 0.13035703 0.01894862 0.03278831 0.09740334]\n",
      "reward -0.5140354720673252\n",
      "self.next: 630\n",
      "action [0.04439712 0.01704356 0.12970401 0.01871791 0.03199457 0.09570304]\n",
      "reward -0.49998778209866035\n",
      "self.next: 633\n",
      "action [0.04468151 0.01312648 0.1300699  0.01866175 0.03124319 0.09463111]\n",
      "reward -0.38333218714895934\n",
      "self.next: 636\n",
      "action [0.04627069 0.01198976 0.12872331 0.01867067 0.0303987  0.09500178]\n",
      "reward -0.37863760492638204\n",
      "self.next: 639\n",
      "action [0.04530881 0.01224042 0.12844956 0.0184624  0.03040503 0.09454104]\n",
      "reward -0.3240644885578349\n",
      "self.next: 642\n",
      "action [0.04584398 0.00999633 0.12837026 0.01815527 0.02989107 0.09429762]\n",
      "reward -0.4536392093185375\n",
      "self.next: 645\n",
      "action [0.04505716 0.01159786 0.12751538 0.01801582 0.02979232 0.09413724]\n",
      "reward -0.32220374981906313\n",
      "self.next: 648\n",
      "action [0.04288726 0.00669032 0.12811898 0.01765428 0.02787556 0.0903724 ]\n",
      "reward -0.7429925965643848\n",
      "self.next: 651\n",
      "action [0.04537756 0.00833251 0.12671295 0.01762606 0.02864037 0.09340371]\n",
      "reward -0.45278558143707137\n",
      "self.next: 654\n",
      "action [0.04500588 0.00963405 0.12569356 0.01752007 0.02846985 0.09335395]\n",
      "reward -0.3741748129960929\n",
      "self.next: 657\n",
      "action [0.04444923 0.00898647 0.12531419 0.01710391 0.02791497 0.09279712]\n",
      "reward -0.46430212739286225\n",
      "self.next: 660\n",
      "action [0.04500864 0.00991247 0.12417479 0.01700744 0.02827957 0.09373299]\n",
      "reward -0.4501023869783983\n",
      "self.next: 663\n",
      "action [0.04396972 0.00874416 0.12461272 0.01665183 0.02850233 0.09304406]\n",
      "reward -0.4298472219886411\n",
      "self.next: 666\n",
      "action [0.04157841 0.01457064 0.12335593 0.01597955 0.02890014 0.09324463]\n",
      "reward -0.8329010413717456\n",
      "self.next: 669\n",
      "action [0.04387032 0.01390494 0.12150478 0.01615048 0.02871376 0.09458632]\n",
      "reward -0.8934171813474298\n",
      "self.next: 672\n",
      "action [0.04363614 0.00730473 0.12249061 0.01599291 0.02697467 0.09212336]\n",
      "reward -0.3467750204936352\n",
      "self.next: 675\n",
      "action [0.04599321 0.00554737 0.12032357 0.01622142 0.02580245 0.09289172]\n",
      "reward -0.44260463100968295\n",
      "self.next: 678\n",
      "action [0.04306802 0.00653316 0.12203161 0.01563773 0.02669831 0.09164164]\n",
      "reward -0.3499646259784738\n",
      "self.next: 681\n",
      "action [0.04402229 0.00609359 0.12054643 0.01580114 0.02616132 0.09178174]\n",
      "reward -0.45929189166677187\n",
      "self.next: 684\n",
      "action [0.04243257 0.00664161 0.12052084 0.0152329  0.02630999 0.09116083]\n",
      "reward -0.4099890498225076\n",
      "self.next: 687\n",
      "action [0.04420239 0.00861842 0.11921322 0.01483553 0.0270007  0.09393788]\n",
      "reward -0.700828205265554\n",
      "self.next: 690\n",
      "action [0.04177194 0.00500502 0.12033737 0.01467723 0.02601524 0.09047919]\n",
      "reward -0.37035055766158\n",
      "self.next: 693\n",
      "action [0.04096186 0.00529234 0.1200435  0.01427392 0.02583855 0.09014505]\n",
      "reward -0.4425942391452048\n",
      "self.next: 696\n",
      "action [0.0415649  0.0042832  0.11904193 0.01423709 0.02546832 0.09024204]\n",
      "reward -0.3821544270435\n",
      "self.next: 699\n",
      "action [0.03959507 0.00145254 0.11986678 0.01364511 0.02439626 0.08786231]\n",
      "reward -0.7569823040499666\n",
      "self.next: 702\n",
      "action [0.03725061 0.00628114 0.11891667 0.01329949 0.02515174 0.08759734]\n",
      "reward -0.7044519119295584\n",
      "self.next: 705\n",
      "action [ 0.04057452 -0.00255508  0.11792992  0.01359338  0.02301435  0.08673669]\n",
      "reward -0.8076391351101909\n",
      "self.next: 708\n",
      "action [0.03951761 0.00385945 0.11752893 0.01321222 0.02461592 0.08867017]\n",
      "reward -0.4823204781571945\n",
      "self.next: 711\n",
      "action [0.0374359  0.00396787 0.11757753 0.01271738 0.02461126 0.08727676]\n",
      "reward -0.581002120241524\n",
      "self.next: 714\n",
      "action [0.0369314  0.00022886 0.11721968 0.0122926  0.02325536 0.08539224]\n",
      "reward -0.7479065756255366\n",
      "self.next: 717\n",
      "action [0.03928931 0.00198745 0.11583752 0.01238027 0.02414804 0.08830185]\n",
      "reward -0.419066051494937\n",
      "self.next: 720\n",
      "action [0.03758722 0.00252585 0.11598536 0.01215426 0.02451031 0.08704096]\n",
      "reward -0.5641095390871324\n",
      "self.next: 723\n",
      "action [0.04012291 0.00310868 0.11452954 0.01192515 0.02458475 0.0897174 ]\n",
      "reward -0.6519077489849185\n",
      "self.next: 726\n",
      "action [0.03902266 0.00116715 0.11432209 0.01167443 0.02348353 0.08781933]\n",
      "reward -0.44773295733604623\n",
      "self.next: 729\n",
      "action [0.03690519 0.00192341 0.11464754 0.01129007 0.02341856 0.08628911]\n",
      "reward -0.649707315212668\n",
      "self.next: 732\n",
      "action [0.03861847 0.00232763 0.11300132 0.01140865 0.02341983 0.08771499]\n",
      "reward -0.6401326270095269\n",
      "self.next: 735\n",
      "action [0.03857648 0.00023247 0.11311588 0.01108019 0.02304438 0.08723027]\n",
      "reward -0.5095406426419281\n",
      "self.next: 738\n",
      "action [0.03755505 0.00065458 0.11278092 0.0108473  0.02270141 0.08638557]\n",
      "reward -0.6167279524331637\n",
      "self.next: 741\n",
      "action [ 0.03892764 -0.00131393  0.11103129  0.01088078  0.02195558  0.08645439]\n",
      "reward -0.5794964483118485\n",
      "self.next: 744\n",
      "action [ 0.03652181 -0.00028313  0.11278832  0.01021411  0.02329186  0.08591089]\n",
      "reward -0.4615034379449549\n",
      "self.next: 747\n",
      "action [0.03560278 0.00399407 0.11217846 0.00992824 0.02392428 0.08641274]\n",
      "reward -0.9492799850791567\n",
      "self.next: 750\n",
      "action [0.03393454 0.00031532 0.11280784 0.00927211 0.02334501 0.08430833]\n",
      "reward -0.53977219447317\n",
      "self.next: 753\n",
      "action [ 0.03725623 -0.00083979  0.10991558  0.0094647   0.0220431   0.0861523 ]\n",
      "reward -0.5825969275228273\n",
      "self.next: 756\n",
      "action [ 0.03588143 -0.0018615   0.1101554   0.00940614  0.02192845  0.08434719]\n",
      "reward -0.5515456888518129\n",
      "self.next: 759\n",
      "action [ 0.03443697 -0.0007265   0.11056988  0.00887914  0.02221663  0.08389294]\n",
      "reward -0.6018774019872296\n",
      "self.next: 762\n",
      "action [0.03638858 0.00229727 0.1084075  0.00880641 0.0230193  0.08645616]\n",
      "reward -0.8788650026612408\n",
      "self.next: 765\n",
      "action [ 0.03497529 -0.00256881  0.10904817  0.00850477  0.02150378  0.08360731]\n",
      "reward -0.5921799682497739\n",
      "self.next: 768\n",
      "action [ 0.03431573 -0.00212036  0.10897171  0.00809585  0.02154218  0.08340374]\n",
      "reward -0.599389204473836\n",
      "self.next: 771\n",
      "action [ 0.03453979 -0.00256832  0.10835493  0.00797223  0.02120883  0.08327791]\n",
      "reward -0.6433051305241135\n",
      "self.next: 774\n",
      "action [ 0.03622441 -0.00441038  0.10632986  0.00772077  0.01997412  0.08380017]\n",
      "reward -0.8818710197777965\n",
      "self.next: 777\n",
      "action [ 0.03473169 -0.00386022  0.10719511  0.00751599  0.02075486  0.08297165]\n",
      "reward -0.6676720059281088\n",
      "self.next: 780\n",
      "action [ 0.0331527  -0.00331118  0.10776746  0.00728061  0.02091459  0.08180133]\n",
      "reward -0.671931776150058\n",
      "self.next: 783\n",
      "action [ 0.03413785 -0.00448591  0.10675465  0.00711537  0.0205097   0.08218761]\n",
      "reward -0.6929751340971355\n",
      "self.next: 786\n",
      "action [ 0.03165956 -0.00343544  0.10760429  0.00668128  0.02087742  0.08046264]\n",
      "reward -0.767911431789922\n",
      "self.next: 789\n",
      "action [ 0.03087112 -0.00257467  0.10773747  0.00616837  0.02110159  0.08039771]\n",
      "reward -0.7691774587544749\n",
      "self.next: 792\n",
      "action [ 0.03274347 -0.00410493  0.10576962  0.00635844  0.0201522   0.08095952]\n",
      "reward -0.7913606372344616\n",
      "self.next: 795\n",
      "action [ 0.03115538 -0.0044892   0.10677317  0.00587806  0.02070753  0.07996307]\n",
      "reward -0.7261585798933697\n",
      "self.next: 798\n",
      "action [ 0.0323483  -0.00546985  0.10483695  0.00588197  0.0197453   0.0801778 ]\n",
      "reward -0.8105569325244697\n",
      "self.next: 801\n",
      "action [ 0.03231204 -0.00441738  0.10459495  0.00539544  0.0199312   0.08081136]\n",
      "reward -0.846881284778386\n",
      "self.next: 804\n",
      "action [ 0.0309975  -0.00453842  0.10489537  0.00535257  0.01979336  0.07923219]\n",
      "reward -0.8689300246610572\n",
      "self.next: 807\n",
      "action [ 0.03346295 -0.00701316  0.10184237  0.00545279  0.01834304  0.07996356]\n",
      "reward -0.9269561662576\n",
      "self.next: 810\n",
      "action [ 0.03008412 -0.00447663  0.1042897   0.00470646  0.01974188  0.07851408]\n",
      "reward -0.9779059123796959\n",
      "self.next: 813\n",
      "action [ 0.03141989 -0.009366    0.10226729  0.00488021  0.01756618  0.07747249]\n",
      "reward -1.042481741338593\n",
      "self.next: 816\n",
      "action [ 0.02919082 -0.00429004  0.10430147  0.00418384  0.01983293  0.07806932]\n",
      "reward -0.8772743157860042\n",
      "self.next: 819\n",
      "action [ 0.02649002 -0.00635048  0.10524936  0.0037808   0.01911185  0.07500031]\n",
      "reward -1.0238131573942197\n",
      "self.next: 822\n",
      "action [ 0.0280917  -0.00523612  0.10443486  0.00340413  0.01963515  0.07715891]\n",
      "reward -0.9913442669380588\n",
      "self.next: 825\n",
      "action [ 0.02658871 -0.00438699  0.10471082  0.00315295  0.01981801  0.07596549]\n",
      "reward -1.0553490851720768\n",
      "Goal reached! reward= -1.0553490851720768\n"
     ]
    }
   ],
   "source": [
    "# Test the trained agent\n",
    "rews = []\n",
    "states__ = np.empty((0,2,2,6))\n",
    "tot_rew = 0\n",
    "obs = env.reset()\n",
    "n_eps = 500\n",
    "for step in range(n_eps):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    #action=Inverse_model(obs[0,0,:],obs[0,1,:],env.ddthetas[step],env.L_list)\n",
    "    #print(\"Step {}\".format(step + 1))\n",
    "    #print(\"Action: \", action)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(\"action\",action)\n",
    "    #print(\"action'\",action_)\n",
    "    print(\"reward\",reward)\n",
    "    \n",
    "    states__=np.append(states__,[obs],axis=0)\n",
    "    #tot_rew+=reward\n",
    "    rews.append(reward)\n",
    "    #print('obs=', obs, 'reward=', reward, 'done=', done)\n",
    "    env.render(mode='console')\n",
    "    if done:\n",
    "        # Note that the VecEnv resets automatically\n",
    "        # when a done signal is encountered\n",
    "        print(\"Goal reached!\", \"reward=\", reward)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-26dfb9cc7ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mteacher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteacher_pose\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlearner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlearner_pose\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0manimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-da840f0356e5>\u001b[0m in \u001b[0;36manimate\u001b[0;34m(teacher_pose, learner_pose, r)\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mwin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_pose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "teacher=np.empty((0,7,2))#7 = number of points (L+1)\n",
    "learner=np.empty((0,7,2))\n",
    "for i in range(len(states__)):\n",
    "    teacher_theta=states__[i,0,0,:]\n",
    "    learner_theta=states__[i,1,0,:]\n",
    "    teacher_pose=position_from_angle(teacher_theta,env.L_list,[1000,500])\n",
    "    learner_pose=position_from_angle(learner_theta,env.L_list,[500,500])\n",
    "    teacher=np.append(teacher,[teacher_pose],axis=0)\n",
    "    learner=np.append(learner,[learner_pose],axis=0)\n",
    "animate(teacher,learner,30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.020659949845488 9.545177933762826\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.min(env.ddthetas),np.max(env.ddthetas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "self.next: 1\n",
      "self.next: 2\n",
      "self.next: 3\n",
      "self.next: 4\n",
      "self.next: 5\n",
      "self.next: 6\n",
      "self.next: 7\n",
      "self.next: 8\n",
      "self.next: 9\n",
      "self.next: 10\n",
      "self.next: 11\n",
      "self.next: 12\n",
      "self.next: 13\n",
      "self.next: 14\n",
      "self.next: 15\n",
      "self.next: 16\n",
      "self.next: 17\n",
      "self.next: 18\n",
      "self.next: 19\n",
      "self.next: 20\n",
      "self.next: 21\n",
      "self.next: 22\n",
      "self.next: 23\n",
      "self.next: 24\n",
      "self.next: 25\n",
      "self.next: 26\n",
      "self.next: 27\n",
      "self.next: 28\n",
      "self.next: 29\n",
      "self.next: 30\n",
      "self.next: 31\n",
      "self.next: 32\n",
      "self.next: 33\n",
      "self.next: 34\n",
      "self.next: 35\n",
      "self.next: 36\n",
      "self.next: 37\n",
      "self.next: 38\n",
      "self.next: 39\n",
      "self.next: 40\n",
      "self.next: 41\n",
      "self.next: 42\n",
      "self.next: 43\n",
      "self.next: 44\n",
      "self.next: 45\n",
      "self.next: 46\n",
      "self.next: 47\n",
      "self.next: 48\n",
      "self.next: 49\n",
      "self.next: 50\n",
      "self.next: 51\n",
      "self.next: 52\n",
      "self.next: 53\n",
      "self.next: 54\n",
      "self.next: 55\n",
      "self.next: 56\n",
      "self.next: 57\n",
      "self.next: 58\n",
      "self.next: 59\n",
      "self.next: 60\n",
      "self.next: 61\n",
      "self.next: 62\n",
      "self.next: 63\n",
      "self.next: 64\n",
      "self.next: 65\n",
      "self.next: 66\n",
      "self.next: 67\n",
      "self.next: 68\n",
      "self.next: 69\n",
      "self.next: 70\n",
      "self.next: 71\n",
      "self.next: 72\n",
      "self.next: 73\n",
      "self.next: 74\n",
      "self.next: 75\n",
      "self.next: 76\n",
      "self.next: 77\n",
      "self.next: 78\n",
      "self.next: 79\n",
      "self.next: 80\n",
      "self.next: 81\n",
      "self.next: 82\n",
      "self.next: 83\n",
      "self.next: 84\n",
      "self.next: 85\n",
      "self.next: 86\n",
      "self.next: 87\n",
      "self.next: 88\n",
      "self.next: 89\n",
      "self.next: 90\n",
      "self.next: 91\n",
      "self.next: 92\n",
      "self.next: 93\n",
      "self.next: 94\n",
      "self.next: 95\n",
      "self.next: 96\n",
      "self.next: 97\n",
      "self.next: 98\n",
      "self.next: 99\n",
      "self.next: 100\n",
      "self.next: 101\n",
      "self.next: 102\n",
      "self.next: 103\n",
      "self.next: 104\n",
      "self.next: 105\n",
      "self.next: 106\n",
      "self.next: 107\n",
      "self.next: 108\n",
      "self.next: 109\n",
      "self.next: 110\n",
      "self.next: 111\n",
      "self.next: 112\n",
      "self.next: 113\n",
      "self.next: 114\n",
      "self.next: 115\n",
      "self.next: 116\n",
      "self.next: 117\n",
      "self.next: 118\n",
      "self.next: 119\n",
      "self.next: 120\n",
      "self.next: 121\n",
      "self.next: 122\n",
      "self.next: 123\n",
      "self.next: 124\n",
      "self.next: 125\n",
      "self.next: 126\n",
      "self.next: 127\n",
      "self.next: 128\n",
      "self.next: 129\n",
      "self.next: 130\n",
      "self.next: 131\n",
      "self.next: 132\n",
      "self.next: 133\n",
      "self.next: 134\n",
      "self.next: 135\n",
      "self.next: 136\n",
      "self.next: 137\n",
      "self.next: 138\n",
      "self.next: 139\n",
      "self.next: 140\n",
      "self.next: 141\n",
      "self.next: 142\n",
      "self.next: 143\n",
      "self.next: 144\n",
      "self.next: 145\n",
      "self.next: 146\n",
      "self.next: 147\n",
      "self.next: 148\n",
      "self.next: 149\n",
      "self.next: 150\n",
      "self.next: 151\n",
      "self.next: 152\n",
      "self.next: 153\n",
      "self.next: 154\n",
      "self.next: 155\n",
      "self.next: 156\n",
      "self.next: 157\n",
      "self.next: 158\n",
      "self.next: 159\n",
      "self.next: 160\n",
      "self.next: 161\n",
      "self.next: 162\n",
      "self.next: 163\n",
      "self.next: 164\n",
      "self.next: 165\n",
      "self.next: 166\n",
      "self.next: 167\n",
      "self.next: 168\n",
      "self.next: 169\n",
      "self.next: 170\n",
      "self.next: 171\n",
      "self.next: 172\n",
      "self.next: 173\n",
      "self.next: 174\n",
      "self.next: 175\n",
      "self.next: 176\n",
      "self.next: 177\n",
      "self.next: 178\n",
      "self.next: 179\n",
      "self.next: 180\n",
      "self.next: 181\n",
      "self.next: 182\n",
      "self.next: 183\n",
      "self.next: 184\n",
      "self.next: 185\n",
      "self.next: 186\n",
      "self.next: 187\n",
      "self.next: 188\n",
      "self.next: 189\n",
      "self.next: 190\n",
      "self.next: 191\n",
      "self.next: 192\n",
      "self.next: 193\n",
      "self.next: 194\n",
      "self.next: 195\n",
      "self.next: 196\n",
      "self.next: 197\n",
      "self.next: 198\n",
      "self.next: 199\n",
      "self.next: 200\n",
      "self.next: 201\n",
      "self.next: 202\n",
      "self.next: 203\n",
      "self.next: 204\n",
      "self.next: 205\n",
      "self.next: 206\n",
      "self.next: 207\n",
      "self.next: 208\n",
      "self.next: 209\n",
      "self.next: 210\n",
      "self.next: 211\n",
      "self.next: 212\n",
      "self.next: 213\n",
      "self.next: 214\n",
      "self.next: 215\n",
      "self.next: 216\n",
      "self.next: 217\n",
      "self.next: 218\n",
      "self.next: 219\n",
      "self.next: 220\n",
      "self.next: 221\n",
      "self.next: 222\n",
      "self.next: 223\n",
      "self.next: 224\n",
      "self.next: 225\n",
      "self.next: 226\n",
      "self.next: 227\n",
      "self.next: 228\n",
      "self.next: 229\n",
      "self.next: 230\n",
      "self.next: 231\n",
      "self.next: 232\n",
      "self.next: 233\n",
      "self.next: 234\n",
      "self.next: 235\n",
      "self.next: 236\n",
      "self.next: 237\n",
      "self.next: 238\n",
      "self.next: 239\n",
      "self.next: 240\n",
      "self.next: 241\n",
      "self.next: 242\n",
      "self.next: 243\n",
      "self.next: 244\n",
      "self.next: 245\n",
      "self.next: 246\n",
      "self.next: 247\n",
      "self.next: 248\n",
      "self.next: 249\n",
      "self.next: 250\n",
      "self.next: 251\n",
      "self.next: 252\n",
      "self.next: 253\n",
      "self.next: 254\n",
      "self.next: 255\n",
      "self.next: 256\n",
      "self.next: 257\n",
      "self.next: 258\n",
      "self.next: 259\n",
      "self.next: 260\n",
      "self.next: 261\n",
      "self.next: 262\n",
      "self.next: 263\n",
      "self.next: 264\n",
      "self.next: 265\n",
      "self.next: 266\n",
      "self.next: 267\n",
      "self.next: 268\n",
      "self.next: 269\n",
      "self.next: 270\n",
      "self.next: 271\n",
      "self.next: 272\n",
      "self.next: 273\n",
      "self.next: 274\n",
      "self.next: 275\n",
      "self.next: 276\n",
      "self.next: 277\n",
      "self.next: 278\n",
      "self.next: 279\n",
      "self.next: 280\n",
      "self.next: 281\n",
      "self.next: 282\n",
      "self.next: 283\n",
      "self.next: 284\n",
      "self.next: 285\n",
      "self.next: 286\n",
      "self.next: 287\n",
      "self.next: 288\n",
      "self.next: 289\n",
      "self.next: 290\n",
      "self.next: 291\n",
      "self.next: 292\n",
      "self.next: 293\n",
      "self.next: 294\n",
      "self.next: 295\n",
      "self.next: 296\n",
      "self.next: 297\n",
      "self.next: 298\n",
      "self.next: 299\n",
      "self.next: 300\n",
      "self.next: 301\n",
      "self.next: 302\n",
      "self.next: 303\n",
      "self.next: 304\n",
      "self.next: 305\n",
      "self.next: 306\n",
      "self.next: 307\n",
      "self.next: 308\n",
      "self.next: 309\n",
      "self.next: 310\n",
      "self.next: 311\n",
      "self.next: 312\n",
      "self.next: 313\n",
      "self.next: 314\n",
      "self.next: 315\n",
      "self.next: 316\n",
      "self.next: 317\n",
      "self.next: 318\n",
      "self.next: 319\n",
      "self.next: 320\n",
      "self.next: 321\n",
      "self.next: 322\n",
      "self.next: 323\n",
      "self.next: 324\n",
      "self.next: 325\n",
      "self.next: 326\n",
      "self.next: 327\n",
      "self.next: 328\n",
      "self.next: 329\n",
      "self.next: 330\n",
      "self.next: 331\n",
      "self.next: 332\n",
      "self.next: 333\n",
      "self.next: 334\n",
      "self.next: 335\n",
      "self.next: 336\n",
      "self.next: 337\n",
      "self.next: 338\n",
      "self.next: 339\n",
      "self.next: 340\n",
      "self.next: 341\n",
      "self.next: 342\n",
      "self.next: 343\n",
      "self.next: 344\n",
      "self.next: 345\n",
      "self.next: 346\n",
      "self.next: 347\n",
      "self.next: 348\n",
      "self.next: 349\n",
      "self.next: 350\n",
      "self.next: 351\n",
      "self.next: 352\n",
      "self.next: 353\n",
      "self.next: 354\n",
      "self.next: 355\n",
      "self.next: 356\n",
      "self.next: 357\n",
      "self.next: 358\n",
      "self.next: 359\n",
      "self.next: 360\n",
      "self.next: 361\n",
      "self.next: 362\n",
      "self.next: 363\n",
      "self.next: 364\n",
      "self.next: 365\n",
      "self.next: 366\n",
      "self.next: 367\n",
      "self.next: 368\n",
      "self.next: 369\n",
      "self.next: 370\n",
      "self.next: 371\n",
      "self.next: 372\n",
      "self.next: 373\n",
      "self.next: 374\n",
      "self.next: 375\n",
      "self.next: 376\n",
      "self.next: 377\n",
      "self.next: 378\n",
      "self.next: 379\n",
      "self.next: 380\n",
      "self.next: 381\n",
      "self.next: 382\n",
      "self.next: 383\n",
      "self.next: 384\n",
      "self.next: 385\n",
      "self.next: 386\n",
      "self.next: 387\n",
      "self.next: 388\n",
      "self.next: 389\n",
      "self.next: 390\n",
      "self.next: 391\n",
      "self.next: 392\n",
      "self.next: 393\n",
      "self.next: 394\n",
      "self.next: 395\n",
      "self.next: 396\n",
      "self.next: 397\n",
      "self.next: 398\n",
      "self.next: 399\n",
      "self.next: 400\n",
      "self.next: 401\n",
      "self.next: 402\n",
      "self.next: 403\n",
      "self.next: 404\n",
      "self.next: 405\n",
      "self.next: 406\n",
      "self.next: 407\n",
      "self.next: 408\n",
      "self.next: 409\n",
      "self.next: 410\n",
      "self.next: 411\n",
      "self.next: 412\n",
      "self.next: 413\n",
      "self.next: 414\n",
      "self.next: 415\n",
      "self.next: 416\n",
      "self.next: 417\n",
      "self.next: 418\n",
      "self.next: 419\n",
      "self.next: 420\n",
      "self.next: 421\n",
      "self.next: 422\n",
      "self.next: 423\n",
      "self.next: 424\n",
      "self.next: 425\n",
      "self.next: 426\n",
      "self.next: 427\n",
      "self.next: 428\n",
      "self.next: 429\n",
      "self.next: 430\n",
      "self.next: 431\n",
      "self.next: 432\n",
      "self.next: 433\n",
      "self.next: 434\n",
      "self.next: 435\n",
      "self.next: 436\n",
      "self.next: 437\n",
      "self.next: 438\n",
      "self.next: 439\n",
      "self.next: 440\n",
      "self.next: 441\n",
      "self.next: 442\n",
      "self.next: 443\n",
      "self.next: 444\n",
      "self.next: 445\n",
      "self.next: 446\n",
      "self.next: 447\n",
      "self.next: 448\n",
      "self.next: 449\n",
      "self.next: 450\n",
      "self.next: 451\n",
      "self.next: 452\n",
      "self.next: 453\n",
      "self.next: 454\n",
      "self.next: 455\n",
      "self.next: 456\n",
      "self.next: 457\n",
      "self.next: 458\n",
      "self.next: 459\n",
      "self.next: 460\n",
      "self.next: 461\n",
      "self.next: 462\n",
      "self.next: 463\n",
      "self.next: 464\n",
      "self.next: 465\n",
      "self.next: 466\n",
      "self.next: 467\n",
      "self.next: 468\n",
      "self.next: 469\n",
      "self.next: 470\n",
      "self.next: 471\n",
      "self.next: 472\n",
      "self.next: 473\n",
      "self.next: 474\n",
      "self.next: 475\n",
      "self.next: 476\n",
      "self.next: 477\n",
      "self.next: 478\n",
      "self.next: 479\n",
      "self.next: 480\n",
      "self.next: 481\n",
      "self.next: 482\n",
      "self.next: 483\n",
      "self.next: 484\n",
      "self.next: 485\n",
      "self.next: 486\n",
      "self.next: 487\n",
      "self.next: 488\n",
      "self.next: 489\n",
      "self.next: 490\n",
      "self.next: 491\n",
      "self.next: 492\n",
      "self.next: 493\n",
      "self.next: 494\n",
      "self.next: 495\n",
      "self.next: 496\n",
      "self.next: 497\n",
      "self.next: 498\n",
      "self.next: 499\n",
      "self.next: 500\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 9         |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.55     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -1.81e+08 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 5.92e+14  |\n",
      "-------------------------------------\n",
      "self.next: 501\n",
      "self.next: 502\n",
      "self.next: 503\n",
      "self.next: 504\n",
      "self.next: 505\n",
      "self.next: 506\n",
      "self.next: 507\n",
      "self.next: 508\n",
      "self.next: 509\n",
      "self.next: 510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 511\n",
      "self.next: 512\n",
      "self.next: 513\n",
      "self.next: 514\n",
      "self.next: 515\n",
      "self.next: 516\n",
      "self.next: 517\n",
      "self.next: 518\n",
      "self.next: 519\n",
      "self.next: 520\n",
      "self.next: 521\n",
      "self.next: 522\n",
      "self.next: 523\n",
      "self.next: 524\n",
      "self.next: 525\n",
      "self.next: 526\n",
      "self.next: 527\n",
      "self.next: 528\n",
      "self.next: 529\n",
      "self.next: 530\n",
      "self.next: 531\n",
      "self.next: 532\n",
      "self.next: 533\n",
      "self.next: 534\n",
      "self.next: 535\n",
      "self.next: 536\n",
      "self.next: 537\n",
      "self.next: 538\n",
      "self.next: 539\n",
      "self.next: 540\n",
      "self.next: 541\n",
      "self.next: 542\n",
      "self.next: 543\n",
      "self.next: 544\n",
      "self.next: 545\n",
      "self.next: 546\n",
      "self.next: 547\n",
      "self.next: 548\n",
      "self.next: 549\n",
      "self.next: 550\n",
      "self.next: 551\n",
      "self.next: 552\n",
      "self.next: 553\n",
      "self.next: 554\n",
      "self.next: 555\n",
      "self.next: 556\n",
      "self.next: 557\n",
      "self.next: 558\n",
      "self.next: 559\n",
      "self.next: 560\n",
      "self.next: 561\n",
      "self.next: 562\n",
      "self.next: 563\n",
      "self.next: 564\n",
      "self.next: 565\n",
      "self.next: 566\n",
      "self.next: 567\n",
      "self.next: 568\n",
      "self.next: 569\n",
      "self.next: 570\n",
      "self.next: 571\n",
      "self.next: 572\n",
      "self.next: 573\n",
      "self.next: 574\n",
      "self.next: 575\n",
      "self.next: 576\n",
      "self.next: 577\n",
      "self.next: 578\n",
      "self.next: 579\n",
      "self.next: 580\n",
      "self.next: 581\n",
      "self.next: 582\n",
      "self.next: 583\n",
      "self.next: 584\n",
      "self.next: 585\n",
      "self.next: 586\n",
      "self.next: 587\n",
      "self.next: 588\n",
      "self.next: 589\n",
      "self.next: 590\n",
      "self.next: 591\n",
      "self.next: 592\n",
      "self.next: 593\n",
      "self.next: 594\n",
      "self.next: 595\n",
      "self.next: 596\n",
      "self.next: 597\n",
      "self.next: 598\n",
      "self.next: 599\n",
      "self.next: 600\n",
      "self.next: 601\n",
      "self.next: 602\n",
      "self.next: 603\n",
      "self.next: 604\n",
      "self.next: 605\n",
      "self.next: 606\n",
      "self.next: 607\n",
      "self.next: 608\n",
      "self.next: 609\n",
      "self.next: 610\n",
      "self.next: 611\n",
      "self.next: 612\n",
      "self.next: 613\n",
      "self.next: 614\n",
      "self.next: 615\n",
      "self.next: 616\n",
      "self.next: 617\n",
      "self.next: 618\n",
      "self.next: 619\n",
      "self.next: 620\n",
      "self.next: 621\n",
      "self.next: 622\n",
      "self.next: 623\n",
      "self.next: 624\n",
      "self.next: 625\n",
      "self.next: 626\n",
      "self.next: 627\n",
      "self.next: 628\n",
      "self.next: 629\n",
      "self.next: 630\n",
      "self.next: 631\n",
      "self.next: 632\n",
      "self.next: 633\n",
      "self.next: 634\n",
      "self.next: 635\n",
      "self.next: 636\n",
      "self.next: 637\n",
      "self.next: 638\n",
      "self.next: 639\n",
      "self.next: 640\n",
      "self.next: 641\n",
      "self.next: 642\n",
      "self.next: 643\n",
      "self.next: 644\n",
      "self.next: 645\n",
      "self.next: 646\n",
      "self.next: 647\n",
      "self.next: 648\n",
      "self.next: 649\n",
      "self.next: 650\n",
      "self.next: 651\n",
      "self.next: 652\n",
      "self.next: 653\n",
      "self.next: 654\n",
      "self.next: 655\n",
      "self.next: 656\n",
      "self.next: 657\n",
      "self.next: 658\n",
      "self.next: 659\n",
      "self.next: 660\n",
      "self.next: 661\n",
      "self.next: 662\n",
      "self.next: 663\n",
      "self.next: 664\n",
      "self.next: 665\n",
      "self.next: 666\n",
      "self.next: 667\n",
      "self.next: 668\n",
      "self.next: 669\n",
      "self.next: 670\n",
      "self.next: 671\n",
      "self.next: 672\n",
      "self.next: 673\n",
      "self.next: 674\n",
      "self.next: 675\n",
      "self.next: 676\n",
      "self.next: 677\n",
      "self.next: 678\n",
      "self.next: 679\n",
      "self.next: 680\n",
      "self.next: 681\n",
      "self.next: 682\n",
      "self.next: 683\n",
      "self.next: 684\n",
      "self.next: 685\n",
      "self.next: 686\n",
      "self.next: 687\n",
      "self.next: 688\n",
      "self.next: 689\n",
      "self.next: 690\n",
      "self.next: 691\n",
      "self.next: 692\n",
      "self.next: 693\n",
      "self.next: 694\n",
      "self.next: 695\n",
      "self.next: 696\n",
      "self.next: 697\n",
      "self.next: 698\n",
      "self.next: 699\n",
      "self.next: 700\n",
      "self.next: 701\n",
      "self.next: 702\n",
      "self.next: 703\n",
      "self.next: 704\n",
      "self.next: 705\n",
      "self.next: 706\n",
      "self.next: 707\n",
      "self.next: 708\n",
      "self.next: 709\n",
      "self.next: 710\n",
      "self.next: 711\n",
      "self.next: 712\n",
      "self.next: 713\n",
      "self.next: 714\n",
      "self.next: 715\n",
      "self.next: 716\n",
      "self.next: 717\n",
      "self.next: 718\n",
      "self.next: 719\n",
      "self.next: 720\n",
      "self.next: 721\n",
      "self.next: 722\n",
      "self.next: 723\n",
      "self.next: 724\n",
      "self.next: 725\n",
      "self.next: 726\n",
      "self.next: 727\n",
      "self.next: 728\n",
      "self.next: 729\n",
      "self.next: 730\n",
      "self.next: 731\n",
      "self.next: 732\n",
      "self.next: 733\n",
      "self.next: 734\n",
      "self.next: 735\n",
      "self.next: 736\n",
      "self.next: 737\n",
      "self.next: 738\n",
      "self.next: 739\n",
      "self.next: 740\n",
      "self.next: 741\n",
      "self.next: 742\n",
      "self.next: 743\n",
      "self.next: 744\n",
      "self.next: 745\n",
      "self.next: 746\n",
      "self.next: 747\n",
      "self.next: 748\n",
      "self.next: 749\n",
      "self.next: 750\n",
      "self.next: 751\n",
      "self.next: 752\n",
      "self.next: 753\n",
      "self.next: 754\n",
      "self.next: 755\n",
      "self.next: 756\n",
      "self.next: 757\n",
      "self.next: 758\n",
      "self.next: 759\n",
      "self.next: 760\n",
      "self.next: 761\n",
      "self.next: 762\n",
      "self.next: 763\n",
      "self.next: 764\n",
      "self.next: 765\n",
      "self.next: 766\n",
      "self.next: 767\n",
      "self.next: 768\n",
      "self.next: 769\n",
      "self.next: 770\n",
      "self.next: 771\n",
      "self.next: 772\n",
      "self.next: 773\n",
      "self.next: 774\n",
      "self.next: 775\n",
      "self.next: 776\n",
      "self.next: 777\n",
      "self.next: 778\n",
      "self.next: 779\n",
      "self.next: 780\n",
      "self.next: 781\n",
      "self.next: 782\n",
      "self.next: 783\n",
      "self.next: 784\n",
      "self.next: 785\n",
      "self.next: 786\n",
      "self.next: 787\n",
      "self.next: 788\n",
      "self.next: 789\n",
      "self.next: 790\n",
      "self.next: 791\n",
      "self.next: 792\n",
      "self.next: 793\n",
      "self.next: 794\n",
      "self.next: 795\n",
      "self.next: 796\n",
      "self.next: 797\n",
      "self.next: 798\n",
      "self.next: 799\n",
      "self.next: 800\n",
      "self.next: 801\n",
      "self.next: 802\n",
      "self.next: 803\n",
      "self.next: 804\n",
      "self.next: 805\n",
      "self.next: 806\n",
      "self.next: 807\n",
      "self.next: 808\n",
      "self.next: 809\n",
      "self.next: 810\n",
      "self.next: 811\n",
      "self.next: 812\n",
      "self.next: 813\n",
      "self.next: 814\n",
      "self.next: 815\n",
      "self.next: 816\n",
      "self.next: 817\n",
      "self.next: 818\n",
      "self.next: 819\n",
      "self.next: 820\n",
      "self.next: 821\n",
      "self.next: 822\n",
      "self.next: 823\n",
      "self.next: 824\n",
      "self.next: 825\n",
      "self.next: 826\n",
      "self.next: 827\n",
      "self.next: 1\n",
      "self.next: 2\n",
      "self.next: 3\n",
      "self.next: 4\n",
      "self.next: 5\n",
      "self.next: 6\n",
      "self.next: 7\n",
      "self.next: 8\n",
      "self.next: 9\n",
      "self.next: 10\n",
      "self.next: 11\n",
      "self.next: 12\n",
      "self.next: 13\n",
      "self.next: 14\n",
      "self.next: 15\n",
      "self.next: 16\n",
      "self.next: 17\n",
      "self.next: 18\n",
      "self.next: 19\n",
      "self.next: 20\n",
      "self.next: 21\n",
      "self.next: 22\n",
      "self.next: 23\n",
      "self.next: 24\n",
      "self.next: 25\n",
      "self.next: 26\n",
      "self.next: 27\n",
      "self.next: 28\n",
      "self.next: 29\n",
      "self.next: 30\n",
      "self.next: 31\n",
      "self.next: 32\n",
      "self.next: 33\n",
      "self.next: 34\n",
      "self.next: 35\n",
      "self.next: 36\n",
      "self.next: 37\n",
      "self.next: 38\n",
      "self.next: 39\n",
      "self.next: 40\n",
      "self.next: 41\n",
      "self.next: 42\n",
      "self.next: 43\n",
      "self.next: 44\n",
      "self.next: 45\n",
      "self.next: 46\n",
      "self.next: 47\n",
      "self.next: 48\n",
      "self.next: 49\n",
      "self.next: 50\n",
      "self.next: 51\n",
      "self.next: 52\n",
      "self.next: 53\n",
      "self.next: 54\n",
      "self.next: 55\n",
      "self.next: 56\n",
      "self.next: 57\n",
      "self.next: 58\n",
      "self.next: 59\n",
      "self.next: 60\n",
      "self.next: 61\n",
      "self.next: 62\n",
      "self.next: 63\n",
      "self.next: 64\n",
      "self.next: 65\n",
      "self.next: 66\n",
      "self.next: 67\n",
      "self.next: 68\n",
      "self.next: 69\n",
      "self.next: 70\n",
      "self.next: 71\n",
      "self.next: 72\n",
      "self.next: 73\n",
      "self.next: 74\n",
      "self.next: 75\n",
      "self.next: 76\n",
      "self.next: 77\n",
      "self.next: 78\n",
      "self.next: 79\n",
      "self.next: 80\n",
      "self.next: 81\n",
      "self.next: 82\n",
      "self.next: 83\n",
      "self.next: 84\n",
      "self.next: 85\n",
      "self.next: 86\n",
      "self.next: 87\n",
      "self.next: 88\n",
      "self.next: 89\n",
      "self.next: 90\n",
      "self.next: 91\n",
      "self.next: 92\n",
      "self.next: 93\n",
      "self.next: 94\n",
      "self.next: 95\n",
      "self.next: 96\n",
      "self.next: 97\n",
      "self.next: 98\n",
      "self.next: 99\n",
      "self.next: 100\n",
      "self.next: 101\n",
      "self.next: 102\n",
      "self.next: 103\n",
      "self.next: 104\n",
      "self.next: 105\n",
      "self.next: 106\n",
      "self.next: 107\n",
      "self.next: 108\n",
      "self.next: 109\n",
      "self.next: 110\n",
      "self.next: 111\n",
      "self.next: 112\n",
      "self.next: 113\n",
      "self.next: 114\n",
      "self.next: 115\n",
      "self.next: 116\n",
      "self.next: 117\n",
      "self.next: 118\n",
      "self.next: 119\n",
      "self.next: 120\n",
      "self.next: 121\n",
      "self.next: 122\n",
      "self.next: 123\n",
      "self.next: 124\n",
      "self.next: 125\n",
      "self.next: 126\n",
      "self.next: 127\n",
      "self.next: 128\n",
      "self.next: 129\n",
      "self.next: 130\n",
      "self.next: 131\n",
      "self.next: 132\n",
      "self.next: 133\n",
      "self.next: 134\n",
      "self.next: 135\n",
      "self.next: 136\n",
      "self.next: 137\n",
      "self.next: 138\n",
      "self.next: 139\n",
      "self.next: 140\n",
      "self.next: 141\n",
      "self.next: 142\n",
      "self.next: 143\n",
      "self.next: 144\n",
      "self.next: 145\n",
      "self.next: 146\n",
      "self.next: 147\n",
      "self.next: 148\n",
      "self.next: 149\n",
      "self.next: 150\n",
      "self.next: 151\n",
      "self.next: 152\n",
      "self.next: 153\n",
      "self.next: 154\n",
      "self.next: 155\n",
      "self.next: 156\n",
      "self.next: 157\n",
      "self.next: 158\n",
      "self.next: 159\n",
      "self.next: 160\n",
      "self.next: 161\n",
      "self.next: 162\n",
      "self.next: 163\n",
      "self.next: 164\n",
      "self.next: 165\n",
      "self.next: 166\n",
      "self.next: 167\n",
      "self.next: 168\n",
      "self.next: 169\n",
      "self.next: 170\n",
      "self.next: 171\n",
      "self.next: 172\n",
      "self.next: 173\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 827       |\n",
      "|    ep_rew_mean        | -5.23e+09 |\n",
      "| time/                 |           |\n",
      "|    fps                | 9         |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.54     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -1.95e+08 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 5.08e+14  |\n",
      "-------------------------------------\n",
      "self.next: 174\n",
      "self.next: 175\n",
      "self.next: 176\n",
      "self.next: 177\n",
      "self.next: 178\n",
      "self.next: 179\n",
      "self.next: 180\n",
      "self.next: 181\n",
      "self.next: 182\n",
      "self.next: 183\n",
      "self.next: 184\n",
      "self.next: 185\n",
      "self.next: 186\n",
      "self.next: 187\n",
      "self.next: 188\n",
      "self.next: 189\n",
      "self.next: 190\n",
      "self.next: 191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 192\n",
      "self.next: 193\n",
      "self.next: 194\n",
      "self.next: 195\n",
      "self.next: 196\n",
      "self.next: 197\n",
      "self.next: 198\n",
      "self.next: 199\n",
      "self.next: 200\n",
      "self.next: 201\n",
      "self.next: 202\n",
      "self.next: 203\n",
      "self.next: 204\n",
      "self.next: 205\n",
      "self.next: 206\n",
      "self.next: 207\n",
      "self.next: 208\n",
      "self.next: 209\n",
      "self.next: 210\n",
      "self.next: 211\n",
      "self.next: 212\n",
      "self.next: 213\n",
      "self.next: 214\n",
      "self.next: 215\n",
      "self.next: 216\n",
      "self.next: 217\n",
      "self.next: 218\n",
      "self.next: 219\n",
      "self.next: 220\n",
      "self.next: 221\n",
      "self.next: 222\n",
      "self.next: 223\n",
      "self.next: 224\n",
      "self.next: 225\n",
      "self.next: 226\n",
      "self.next: 227\n",
      "self.next: 228\n",
      "self.next: 229\n",
      "self.next: 230\n",
      "self.next: 231\n",
      "self.next: 232\n",
      "self.next: 233\n",
      "self.next: 234\n",
      "self.next: 235\n",
      "self.next: 236\n",
      "self.next: 237\n",
      "self.next: 238\n",
      "self.next: 239\n",
      "self.next: 240\n",
      "self.next: 241\n",
      "self.next: 242\n",
      "self.next: 243\n",
      "self.next: 244\n",
      "self.next: 245\n",
      "self.next: 246\n",
      "self.next: 247\n",
      "self.next: 248\n",
      "self.next: 249\n",
      "self.next: 250\n",
      "self.next: 251\n",
      "self.next: 252\n",
      "self.next: 253\n",
      "self.next: 254\n",
      "self.next: 255\n",
      "self.next: 256\n",
      "self.next: 257\n",
      "self.next: 258\n",
      "self.next: 259\n",
      "self.next: 260\n",
      "self.next: 261\n",
      "self.next: 262\n",
      "self.next: 263\n",
      "self.next: 264\n",
      "self.next: 265\n",
      "self.next: 266\n",
      "self.next: 267\n",
      "self.next: 268\n",
      "self.next: 269\n",
      "self.next: 270\n",
      "self.next: 271\n",
      "self.next: 272\n",
      "self.next: 273\n",
      "self.next: 274\n",
      "self.next: 275\n",
      "self.next: 276\n",
      "self.next: 277\n",
      "self.next: 278\n",
      "self.next: 279\n",
      "self.next: 280\n",
      "self.next: 281\n",
      "self.next: 282\n",
      "self.next: 283\n",
      "self.next: 284\n",
      "self.next: 285\n",
      "self.next: 286\n",
      "self.next: 287\n",
      "self.next: 288\n",
      "self.next: 289\n",
      "self.next: 290\n",
      "self.next: 291\n",
      "self.next: 292\n",
      "self.next: 293\n",
      "self.next: 294\n",
      "self.next: 295\n",
      "self.next: 296\n",
      "self.next: 297\n",
      "self.next: 298\n",
      "self.next: 299\n",
      "self.next: 300\n",
      "self.next: 301\n",
      "self.next: 302\n",
      "self.next: 303\n",
      "self.next: 304\n",
      "self.next: 305\n",
      "self.next: 306\n",
      "self.next: 307\n",
      "self.next: 308\n",
      "self.next: 309\n",
      "self.next: 310\n",
      "self.next: 311\n",
      "self.next: 312\n",
      "self.next: 313\n",
      "self.next: 314\n",
      "self.next: 315\n",
      "self.next: 316\n",
      "self.next: 317\n",
      "self.next: 318\n",
      "self.next: 319\n",
      "self.next: 320\n",
      "self.next: 321\n",
      "self.next: 322\n",
      "self.next: 323\n",
      "self.next: 324\n",
      "self.next: 325\n",
      "self.next: 326\n",
      "self.next: 327\n",
      "self.next: 328\n",
      "self.next: 329\n",
      "self.next: 330\n",
      "self.next: 331\n",
      "self.next: 332\n",
      "self.next: 333\n",
      "self.next: 334\n",
      "self.next: 335\n",
      "self.next: 336\n",
      "self.next: 337\n",
      "self.next: 338\n",
      "self.next: 339\n",
      "self.next: 340\n",
      "self.next: 341\n",
      "self.next: 342\n",
      "self.next: 343\n",
      "self.next: 344\n",
      "self.next: 345\n",
      "self.next: 346\n",
      "self.next: 347\n",
      "self.next: 348\n",
      "self.next: 349\n",
      "self.next: 350\n",
      "self.next: 351\n",
      "self.next: 352\n",
      "self.next: 353\n",
      "self.next: 354\n",
      "self.next: 355\n",
      "self.next: 356\n",
      "self.next: 357\n",
      "self.next: 358\n",
      "self.next: 359\n",
      "self.next: 360\n",
      "self.next: 361\n",
      "self.next: 362\n",
      "self.next: 363\n",
      "self.next: 364\n",
      "self.next: 365\n",
      "self.next: 366\n",
      "self.next: 367\n",
      "self.next: 368\n",
      "self.next: 369\n",
      "self.next: 370\n",
      "self.next: 371\n",
      "self.next: 372\n",
      "self.next: 373\n",
      "self.next: 374\n",
      "self.next: 375\n",
      "self.next: 376\n",
      "self.next: 377\n",
      "self.next: 378\n",
      "self.next: 379\n",
      "self.next: 380\n",
      "self.next: 381\n",
      "self.next: 382\n",
      "self.next: 383\n",
      "self.next: 384\n",
      "self.next: 385\n",
      "self.next: 386\n",
      "self.next: 387\n",
      "self.next: 388\n",
      "self.next: 389\n",
      "self.next: 390\n",
      "self.next: 391\n",
      "self.next: 392\n",
      "self.next: 393\n",
      "self.next: 394\n",
      "self.next: 395\n",
      "self.next: 396\n",
      "self.next: 397\n",
      "self.next: 398\n",
      "self.next: 399\n",
      "self.next: 400\n",
      "self.next: 401\n",
      "self.next: 402\n",
      "self.next: 403\n",
      "self.next: 404\n",
      "self.next: 405\n",
      "self.next: 406\n",
      "self.next: 407\n",
      "self.next: 408\n",
      "self.next: 409\n",
      "self.next: 410\n",
      "self.next: 411\n",
      "self.next: 412\n",
      "self.next: 413\n",
      "self.next: 414\n",
      "self.next: 415\n",
      "self.next: 416\n",
      "self.next: 417\n",
      "self.next: 418\n",
      "self.next: 419\n",
      "self.next: 420\n",
      "self.next: 421\n",
      "self.next: 422\n",
      "self.next: 423\n",
      "self.next: 424\n",
      "self.next: 425\n",
      "self.next: 426\n",
      "self.next: 427\n",
      "self.next: 428\n",
      "self.next: 429\n",
      "self.next: 430\n",
      "self.next: 431\n",
      "self.next: 432\n",
      "self.next: 433\n",
      "self.next: 434\n",
      "self.next: 435\n",
      "self.next: 436\n",
      "self.next: 437\n",
      "self.next: 438\n",
      "self.next: 439\n",
      "self.next: 440\n",
      "self.next: 441\n",
      "self.next: 442\n",
      "self.next: 443\n",
      "self.next: 444\n",
      "self.next: 445\n",
      "self.next: 446\n",
      "self.next: 447\n",
      "self.next: 448\n",
      "self.next: 449\n",
      "self.next: 450\n",
      "self.next: 451\n",
      "self.next: 452\n",
      "self.next: 453\n",
      "self.next: 454\n",
      "self.next: 455\n",
      "self.next: 456\n",
      "self.next: 457\n",
      "self.next: 458\n",
      "self.next: 459\n",
      "self.next: 460\n",
      "self.next: 461\n",
      "self.next: 462\n",
      "self.next: 463\n",
      "self.next: 464\n",
      "self.next: 465\n",
      "self.next: 466\n",
      "self.next: 467\n",
      "self.next: 468\n",
      "self.next: 469\n",
      "self.next: 470\n",
      "self.next: 471\n",
      "self.next: 472\n",
      "self.next: 473\n",
      "self.next: 474\n",
      "self.next: 475\n",
      "self.next: 476\n",
      "self.next: 477\n",
      "self.next: 478\n",
      "self.next: 479\n",
      "self.next: 480\n",
      "self.next: 481\n",
      "self.next: 482\n",
      "self.next: 483\n",
      "self.next: 484\n",
      "self.next: 485\n",
      "self.next: 486\n",
      "self.next: 487\n",
      "self.next: 488\n",
      "self.next: 489\n",
      "self.next: 490\n",
      "self.next: 491\n",
      "self.next: 492\n",
      "self.next: 493\n",
      "self.next: 494\n",
      "self.next: 495\n",
      "self.next: 496\n",
      "self.next: 497\n",
      "self.next: 498\n",
      "self.next: 499\n",
      "self.next: 500\n",
      "self.next: 501\n",
      "self.next: 502\n",
      "self.next: 503\n",
      "self.next: 504\n",
      "self.next: 505\n",
      "self.next: 506\n",
      "self.next: 507\n",
      "self.next: 508\n",
      "self.next: 509\n",
      "self.next: 510\n",
      "self.next: 511\n",
      "self.next: 512\n",
      "self.next: 513\n",
      "self.next: 514\n",
      "self.next: 515\n",
      "self.next: 516\n",
      "self.next: 517\n",
      "self.next: 518\n",
      "self.next: 519\n",
      "self.next: 520\n",
      "self.next: 521\n",
      "self.next: 522\n",
      "self.next: 523\n",
      "self.next: 524\n",
      "self.next: 525\n",
      "self.next: 526\n",
      "self.next: 527\n",
      "self.next: 528\n",
      "self.next: 529\n",
      "self.next: 530\n",
      "self.next: 531\n",
      "self.next: 532\n",
      "self.next: 533\n",
      "self.next: 534\n",
      "self.next: 535\n",
      "self.next: 536\n",
      "self.next: 537\n",
      "self.next: 538\n",
      "self.next: 539\n",
      "self.next: 540\n",
      "self.next: 541\n",
      "self.next: 542\n",
      "self.next: 543\n",
      "self.next: 544\n",
      "self.next: 545\n",
      "self.next: 546\n",
      "self.next: 547\n",
      "self.next: 548\n",
      "self.next: 549\n",
      "self.next: 550\n",
      "self.next: 551\n",
      "self.next: 552\n",
      "self.next: 553\n",
      "self.next: 554\n",
      "self.next: 555\n",
      "self.next: 556\n",
      "self.next: 557\n",
      "self.next: 558\n",
      "self.next: 559\n",
      "self.next: 560\n",
      "self.next: 561\n",
      "self.next: 562\n",
      "self.next: 563\n",
      "self.next: 564\n",
      "self.next: 565\n",
      "self.next: 566\n",
      "self.next: 567\n",
      "self.next: 568\n",
      "self.next: 569\n",
      "self.next: 570\n",
      "self.next: 571\n",
      "self.next: 572\n",
      "self.next: 573\n",
      "self.next: 574\n",
      "self.next: 575\n",
      "self.next: 576\n",
      "self.next: 577\n",
      "self.next: 578\n",
      "self.next: 579\n",
      "self.next: 580\n",
      "self.next: 581\n",
      "self.next: 582\n",
      "self.next: 583\n",
      "self.next: 584\n",
      "self.next: 585\n",
      "self.next: 586\n",
      "self.next: 587\n",
      "self.next: 588\n",
      "self.next: 589\n",
      "self.next: 590\n",
      "self.next: 591\n",
      "self.next: 592\n",
      "self.next: 593\n",
      "self.next: 594\n",
      "self.next: 595\n",
      "self.next: 596\n",
      "self.next: 597\n",
      "self.next: 598\n",
      "self.next: 599\n",
      "self.next: 600\n",
      "self.next: 601\n",
      "self.next: 602\n",
      "self.next: 603\n",
      "self.next: 604\n",
      "self.next: 605\n",
      "self.next: 606\n",
      "self.next: 607\n",
      "self.next: 608\n",
      "self.next: 609\n",
      "self.next: 610\n",
      "self.next: 611\n",
      "self.next: 612\n",
      "self.next: 613\n",
      "self.next: 614\n",
      "self.next: 615\n",
      "self.next: 616\n",
      "self.next: 617\n",
      "self.next: 618\n",
      "self.next: 619\n",
      "self.next: 620\n",
      "self.next: 621\n",
      "self.next: 622\n",
      "self.next: 623\n",
      "self.next: 624\n",
      "self.next: 625\n",
      "self.next: 626\n",
      "self.next: 627\n",
      "self.next: 628\n",
      "self.next: 629\n",
      "self.next: 630\n",
      "self.next: 631\n",
      "self.next: 632\n",
      "self.next: 633\n",
      "self.next: 634\n",
      "self.next: 635\n",
      "self.next: 636\n",
      "self.next: 637\n",
      "self.next: 638\n",
      "self.next: 639\n",
      "self.next: 640\n",
      "self.next: 641\n",
      "self.next: 642\n",
      "self.next: 643\n",
      "self.next: 644\n",
      "self.next: 645\n",
      "self.next: 646\n",
      "self.next: 647\n",
      "self.next: 648\n",
      "self.next: 649\n",
      "self.next: 650\n",
      "self.next: 651\n",
      "self.next: 652\n",
      "self.next: 653\n",
      "self.next: 654\n",
      "self.next: 655\n",
      "self.next: 656\n",
      "self.next: 657\n",
      "self.next: 658\n",
      "self.next: 659\n",
      "self.next: 660\n",
      "self.next: 661\n",
      "self.next: 662\n",
      "self.next: 663\n",
      "self.next: 664\n",
      "self.next: 665\n",
      "self.next: 666\n",
      "self.next: 667\n",
      "self.next: 668\n",
      "self.next: 669\n",
      "self.next: 670\n",
      "self.next: 671\n",
      "self.next: 672\n",
      "self.next: 673\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 827       |\n",
      "|    ep_rew_mean        | -5.23e+09 |\n",
      "| time/                 |           |\n",
      "|    fps                | 9         |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.58     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -2.09e+08 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.52e+14  |\n",
      "-------------------------------------\n",
      "self.next: 674\n",
      "self.next: 675\n",
      "self.next: 676\n",
      "self.next: 677\n",
      "self.next: 678\n",
      "self.next: 679\n",
      "self.next: 680\n",
      "self.next: 681\n",
      "self.next: 682\n",
      "self.next: 683\n",
      "self.next: 684\n",
      "self.next: 685\n",
      "self.next: 686\n",
      "self.next: 687\n",
      "self.next: 688\n",
      "self.next: 689\n",
      "self.next: 690\n",
      "self.next: 691\n",
      "self.next: 692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 693\n",
      "self.next: 694\n",
      "self.next: 695\n",
      "self.next: 696\n",
      "self.next: 697\n",
      "self.next: 698\n",
      "self.next: 699\n",
      "self.next: 700\n",
      "self.next: 701\n",
      "self.next: 702\n",
      "self.next: 703\n",
      "self.next: 704\n",
      "self.next: 705\n",
      "self.next: 706\n",
      "self.next: 707\n",
      "self.next: 708\n",
      "self.next: 709\n",
      "self.next: 710\n",
      "self.next: 711\n",
      "self.next: 712\n",
      "self.next: 713\n",
      "self.next: 714\n",
      "self.next: 715\n",
      "self.next: 716\n",
      "self.next: 717\n",
      "self.next: 718\n",
      "self.next: 719\n",
      "self.next: 720\n",
      "self.next: 721\n",
      "self.next: 722\n",
      "self.next: 723\n",
      "self.next: 724\n",
      "self.next: 725\n",
      "self.next: 726\n",
      "self.next: 727\n",
      "self.next: 728\n",
      "self.next: 729\n",
      "self.next: 730\n",
      "self.next: 731\n",
      "self.next: 732\n",
      "self.next: 733\n",
      "self.next: 734\n",
      "self.next: 735\n",
      "self.next: 736\n",
      "self.next: 737\n",
      "self.next: 738\n",
      "self.next: 739\n",
      "self.next: 740\n",
      "self.next: 741\n",
      "self.next: 742\n",
      "self.next: 743\n",
      "self.next: 744\n",
      "self.next: 745\n",
      "self.next: 746\n",
      "self.next: 747\n",
      "self.next: 748\n",
      "self.next: 749\n",
      "self.next: 750\n",
      "self.next: 751\n",
      "self.next: 752\n",
      "self.next: 753\n",
      "self.next: 754\n",
      "self.next: 755\n",
      "self.next: 756\n",
      "self.next: 757\n",
      "self.next: 758\n",
      "self.next: 759\n",
      "self.next: 760\n",
      "self.next: 761\n",
      "self.next: 762\n",
      "self.next: 763\n",
      "self.next: 764\n",
      "self.next: 765\n",
      "self.next: 766\n",
      "self.next: 767\n",
      "self.next: 768\n",
      "self.next: 769\n",
      "self.next: 770\n",
      "self.next: 771\n",
      "self.next: 772\n",
      "self.next: 773\n",
      "self.next: 774\n",
      "self.next: 775\n",
      "self.next: 776\n",
      "self.next: 777\n",
      "self.next: 778\n",
      "self.next: 779\n",
      "self.next: 780\n",
      "self.next: 781\n",
      "self.next: 782\n",
      "self.next: 783\n",
      "self.next: 784\n",
      "self.next: 785\n",
      "self.next: 786\n",
      "self.next: 787\n",
      "self.next: 788\n",
      "self.next: 789\n",
      "self.next: 790\n",
      "self.next: 791\n",
      "self.next: 792\n",
      "self.next: 793\n",
      "self.next: 794\n",
      "self.next: 795\n",
      "self.next: 796\n",
      "self.next: 797\n",
      "self.next: 798\n",
      "self.next: 799\n",
      "self.next: 800\n",
      "self.next: 801\n",
      "self.next: 802\n",
      "self.next: 803\n",
      "self.next: 804\n",
      "self.next: 805\n",
      "self.next: 806\n",
      "self.next: 807\n",
      "self.next: 808\n",
      "self.next: 809\n",
      "self.next: 810\n",
      "self.next: 811\n",
      "self.next: 812\n",
      "self.next: 813\n",
      "self.next: 814\n",
      "self.next: 815\n",
      "self.next: 816\n",
      "self.next: 817\n",
      "self.next: 818\n",
      "self.next: 819\n",
      "self.next: 820\n",
      "self.next: 821\n",
      "self.next: 822\n",
      "self.next: 823\n",
      "self.next: 824\n",
      "self.next: 825\n",
      "self.next: 826\n",
      "self.next: 827\n",
      "self.next: 1\n",
      "self.next: 2\n",
      "self.next: 3\n",
      "self.next: 4\n",
      "self.next: 5\n",
      "self.next: 6\n",
      "self.next: 7\n",
      "self.next: 8\n",
      "self.next: 9\n",
      "self.next: 10\n",
      "self.next: 11\n",
      "self.next: 12\n",
      "self.next: 13\n",
      "self.next: 14\n",
      "self.next: 15\n",
      "self.next: 16\n",
      "self.next: 17\n",
      "self.next: 18\n",
      "self.next: 19\n",
      "self.next: 20\n",
      "self.next: 21\n",
      "self.next: 22\n",
      "self.next: 23\n",
      "self.next: 24\n",
      "self.next: 25\n",
      "self.next: 26\n",
      "self.next: 27\n",
      "self.next: 28\n",
      "self.next: 29\n",
      "self.next: 30\n",
      "self.next: 31\n",
      "self.next: 32\n",
      "self.next: 33\n",
      "self.next: 34\n",
      "self.next: 35\n",
      "self.next: 36\n",
      "self.next: 37\n",
      "self.next: 38\n",
      "self.next: 39\n",
      "self.next: 40\n",
      "self.next: 41\n",
      "self.next: 42\n",
      "self.next: 43\n",
      "self.next: 44\n",
      "self.next: 45\n",
      "self.next: 46\n",
      "self.next: 47\n",
      "self.next: 48\n",
      "self.next: 49\n",
      "self.next: 50\n",
      "self.next: 51\n",
      "self.next: 52\n",
      "self.next: 53\n",
      "self.next: 54\n",
      "self.next: 55\n",
      "self.next: 56\n",
      "self.next: 57\n",
      "self.next: 58\n",
      "self.next: 59\n",
      "self.next: 60\n",
      "self.next: 61\n",
      "self.next: 62\n",
      "self.next: 63\n",
      "self.next: 64\n",
      "self.next: 65\n",
      "self.next: 66\n",
      "self.next: 67\n",
      "self.next: 68\n",
      "self.next: 69\n",
      "self.next: 70\n",
      "self.next: 71\n",
      "self.next: 72\n",
      "self.next: 73\n",
      "self.next: 74\n",
      "self.next: 75\n",
      "self.next: 76\n",
      "self.next: 77\n",
      "self.next: 78\n",
      "self.next: 79\n",
      "self.next: 80\n",
      "self.next: 81\n",
      "self.next: 82\n",
      "self.next: 83\n",
      "self.next: 84\n",
      "self.next: 85\n",
      "self.next: 86\n",
      "self.next: 87\n",
      "self.next: 88\n",
      "self.next: 89\n",
      "self.next: 90\n",
      "self.next: 91\n",
      "self.next: 92\n",
      "self.next: 93\n",
      "self.next: 94\n",
      "self.next: 95\n",
      "self.next: 96\n",
      "self.next: 97\n",
      "self.next: 98\n",
      "self.next: 99\n",
      "self.next: 100\n",
      "self.next: 101\n",
      "self.next: 102\n",
      "self.next: 103\n",
      "self.next: 104\n",
      "self.next: 105\n",
      "self.next: 106\n",
      "self.next: 107\n",
      "self.next: 108\n",
      "self.next: 109\n",
      "self.next: 110\n",
      "self.next: 111\n",
      "self.next: 112\n",
      "self.next: 113\n",
      "self.next: 114\n",
      "self.next: 115\n",
      "self.next: 116\n",
      "self.next: 117\n",
      "self.next: 118\n",
      "self.next: 119\n",
      "self.next: 120\n",
      "self.next: 121\n",
      "self.next: 122\n",
      "self.next: 123\n",
      "self.next: 124\n",
      "self.next: 125\n",
      "self.next: 126\n",
      "self.next: 127\n",
      "self.next: 128\n",
      "self.next: 129\n",
      "self.next: 130\n",
      "self.next: 131\n",
      "self.next: 132\n",
      "self.next: 133\n",
      "self.next: 134\n",
      "self.next: 135\n",
      "self.next: 136\n",
      "self.next: 137\n",
      "self.next: 138\n",
      "self.next: 139\n",
      "self.next: 140\n",
      "self.next: 141\n",
      "self.next: 142\n",
      "self.next: 143\n",
      "self.next: 144\n",
      "self.next: 145\n",
      "self.next: 146\n",
      "self.next: 147\n",
      "self.next: 148\n",
      "self.next: 149\n",
      "self.next: 150\n",
      "self.next: 151\n",
      "self.next: 152\n",
      "self.next: 153\n",
      "self.next: 154\n",
      "self.next: 155\n",
      "self.next: 156\n",
      "self.next: 157\n",
      "self.next: 158\n",
      "self.next: 159\n",
      "self.next: 160\n",
      "self.next: 161\n",
      "self.next: 162\n",
      "self.next: 163\n",
      "self.next: 164\n",
      "self.next: 165\n",
      "self.next: 166\n",
      "self.next: 167\n",
      "self.next: 168\n",
      "self.next: 169\n",
      "self.next: 170\n",
      "self.next: 171\n",
      "self.next: 172\n",
      "self.next: 173\n",
      "self.next: 174\n",
      "self.next: 175\n",
      "self.next: 176\n",
      "self.next: 177\n",
      "self.next: 178\n",
      "self.next: 179\n",
      "self.next: 180\n",
      "self.next: 181\n",
      "self.next: 182\n",
      "self.next: 183\n",
      "self.next: 184\n",
      "self.next: 185\n",
      "self.next: 186\n",
      "self.next: 187\n",
      "self.next: 188\n",
      "self.next: 189\n",
      "self.next: 190\n",
      "self.next: 191\n",
      "self.next: 192\n",
      "self.next: 193\n",
      "self.next: 194\n",
      "self.next: 195\n",
      "self.next: 196\n",
      "self.next: 197\n",
      "self.next: 198\n",
      "self.next: 199\n",
      "self.next: 200\n",
      "self.next: 201\n",
      "self.next: 202\n",
      "self.next: 203\n",
      "self.next: 204\n",
      "self.next: 205\n",
      "self.next: 206\n",
      "self.next: 207\n",
      "self.next: 208\n",
      "self.next: 209\n",
      "self.next: 210\n",
      "self.next: 211\n",
      "self.next: 212\n",
      "self.next: 213\n",
      "self.next: 214\n",
      "self.next: 215\n",
      "self.next: 216\n",
      "self.next: 217\n",
      "self.next: 218\n",
      "self.next: 219\n",
      "self.next: 220\n",
      "self.next: 221\n",
      "self.next: 222\n",
      "self.next: 223\n",
      "self.next: 224\n",
      "self.next: 225\n",
      "self.next: 226\n",
      "self.next: 227\n",
      "self.next: 228\n",
      "self.next: 229\n",
      "self.next: 230\n",
      "self.next: 231\n",
      "self.next: 232\n",
      "self.next: 233\n",
      "self.next: 234\n",
      "self.next: 235\n",
      "self.next: 236\n",
      "self.next: 237\n",
      "self.next: 238\n",
      "self.next: 239\n",
      "self.next: 240\n",
      "self.next: 241\n",
      "self.next: 242\n",
      "self.next: 243\n",
      "self.next: 244\n",
      "self.next: 245\n",
      "self.next: 246\n",
      "self.next: 247\n",
      "self.next: 248\n",
      "self.next: 249\n",
      "self.next: 250\n",
      "self.next: 251\n",
      "self.next: 252\n",
      "self.next: 253\n",
      "self.next: 254\n",
      "self.next: 255\n",
      "self.next: 256\n",
      "self.next: 257\n",
      "self.next: 258\n",
      "self.next: 259\n",
      "self.next: 260\n",
      "self.next: 261\n",
      "self.next: 262\n",
      "self.next: 263\n",
      "self.next: 264\n",
      "self.next: 265\n",
      "self.next: 266\n",
      "self.next: 267\n",
      "self.next: 268\n",
      "self.next: 269\n",
      "self.next: 270\n",
      "self.next: 271\n",
      "self.next: 272\n",
      "self.next: 273\n",
      "self.next: 274\n",
      "self.next: 275\n",
      "self.next: 276\n",
      "self.next: 277\n",
      "self.next: 278\n",
      "self.next: 279\n",
      "self.next: 280\n",
      "self.next: 281\n",
      "self.next: 282\n",
      "self.next: 283\n",
      "self.next: 284\n",
      "self.next: 285\n",
      "self.next: 286\n",
      "self.next: 287\n",
      "self.next: 288\n",
      "self.next: 289\n",
      "self.next: 290\n",
      "self.next: 291\n",
      "self.next: 292\n",
      "self.next: 293\n",
      "self.next: 294\n",
      "self.next: 295\n",
      "self.next: 296\n",
      "self.next: 297\n",
      "self.next: 298\n",
      "self.next: 299\n",
      "self.next: 300\n",
      "self.next: 301\n",
      "self.next: 302\n",
      "self.next: 303\n",
      "self.next: 304\n",
      "self.next: 305\n",
      "self.next: 306\n",
      "self.next: 307\n",
      "self.next: 308\n",
      "self.next: 309\n",
      "self.next: 310\n",
      "self.next: 311\n",
      "self.next: 312\n",
      "self.next: 313\n",
      "self.next: 314\n",
      "self.next: 315\n",
      "self.next: 316\n",
      "self.next: 317\n",
      "self.next: 318\n",
      "self.next: 319\n",
      "self.next: 320\n",
      "self.next: 321\n",
      "self.next: 322\n",
      "self.next: 323\n",
      "self.next: 324\n",
      "self.next: 325\n",
      "self.next: 326\n",
      "self.next: 327\n",
      "self.next: 328\n",
      "self.next: 329\n",
      "self.next: 330\n",
      "self.next: 331\n",
      "self.next: 332\n",
      "self.next: 333\n",
      "self.next: 334\n",
      "self.next: 335\n",
      "self.next: 336\n",
      "self.next: 337\n",
      "self.next: 338\n",
      "self.next: 339\n",
      "self.next: 340\n",
      "self.next: 341\n",
      "self.next: 342\n",
      "self.next: 343\n",
      "self.next: 344\n",
      "self.next: 345\n",
      "self.next: 346\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 827       |\n",
      "|    ep_rew_mean        | -5.23e+09 |\n",
      "| time/                 |           |\n",
      "|    fps                | 9         |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 222       |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.58     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -1.53e+08 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.43e+14  |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = HumanArmImitation('c2fixc')\n",
    "obs = env.reset()\n",
    "model = A2C('MlpPolicy', env, verbose=1).learn(2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Action:  [ 1.7707559   0.3006327  -1.5334713   1.5306907   4.467866   -0.64549166]\n",
      "self.next: 1\n",
      "obs= [[[ 2.68405764 -2.21274003 -0.22694922  0.70287207 -2.02217656\n",
      "    0.07690119]\n",
      "  [-0.03689182 -0.03266726  0.19883455 -0.18866474 -0.04250188\n",
      "    0.23757462]]\n",
      "\n",
      " [[ 2.68405764 -2.21274003 -0.22694922  0.70287207 -2.02217656\n",
      "    0.07690119]\n",
      "  [ 0.06275782  0.0148315  -0.12944074  0.05397229  0.10238338\n",
      "   -0.22398047]]] reward= -1652257.563136571 done= False\n",
      "Step 2\n",
      "Action:  [ 1.7697058  0.3008991 -1.5331622  1.5298084  4.466284  -0.6457371]\n",
      "self.next: 2\n",
      "obs= [[[ 2.68036846 -2.21600676 -0.20706577  0.68400559 -2.02642674\n",
      "    0.10065866]\n",
      "  [ 0.04477334 -0.03309095  0.03601677  0.03122596  0.02511049\n",
      "   -0.1322755 ]]\n",
      "\n",
      " [[ 2.69033343 -2.21125688 -0.2398933   0.70826929 -2.01193822\n",
      "    0.05450315]\n",
      "  [ 0.06437943  0.01410079 -0.12993282  0.05426402  0.10134899\n",
      "   -0.22379785]]] reward= -3313617.2075508586 done= False\n",
      "Step 3\n",
      "Action:  [ 1.7713336   0.3008461  -1.5341965   1.531405    4.4697285  -0.64582556]\n",
      "self.next: 3\n",
      "obs= [[[ 2.6848458  -2.21931585 -0.20346409  0.68712819 -2.0239157\n",
      "    0.08743111]\n",
      "  [-0.00837401  0.05821464 -0.22470043  0.15268546  0.0211272\n",
      "   -0.04947311]]\n",
      "\n",
      " [[ 2.69677137 -2.2098468  -0.25288658  0.7136957  -2.00180332\n",
      "    0.03212336]\n",
      "  [ 0.06599053  0.01338224 -0.13043648  0.05456219  0.10031946\n",
      "   -0.22362566]]] reward= -2474992.3901414257 done= False\n",
      "Step 4\n",
      "Action:  [ 1.7714273   0.30089107 -1.5341681   1.5314599   4.469882   -0.6458351 ]\n",
      "self.next: 4\n",
      "obs= [[[ 2.68400840e+00 -2.21349439e+00 -2.25934135e-01  7.02396732e-01\n",
      "   -2.02180298e+00  8.24837963e-02]\n",
      "  [-4.19597423e-03 -2.85908664e-02  3.33068938e-02 -1.71887142e-03\n",
      "   -6.28998676e-04  2.01613507e-02]]\n",
      "\n",
      " [[ 2.70337042e+00 -2.20850858e+00 -2.65930229e-01  7.19151915e-01\n",
      "   -1.99177137e+00  9.76079751e-03]\n",
      "  [ 6.75907118e-02  1.26761669e-02 -1.30951746e-01  5.48668427e-02\n",
      "    9.92948138e-02 -2.23463709e-01]]] reward= -3821186.734712618 done= False\n",
      "Step 5\n",
      "Action:  [ 1.7714937   0.30103305 -1.5344543   1.5316173   4.4703174  -0.64599574]\n",
      "self.next: 5\n",
      "obs= [[[ 2.6835888  -2.21635347 -0.22260345  0.70222485 -2.02186587\n",
      "    0.08449993]\n",
      "  [-0.04751741 -0.03360363  0.07897183 -0.07618797 -0.02410462\n",
      "    0.02562182]]\n",
      "\n",
      " [[ 2.71012949 -2.20724096 -0.2790254   0.7246386  -1.98184189\n",
      "   -0.01258557]\n",
      "  [ 0.06917955  0.01198292 -0.13147865  0.05517801  0.09827506\n",
      "   -0.22331177]]] reward= -1563807.251760292 done= False\n",
      "Step 6\n",
      "Action:  [ 1.7715389   0.30113268 -1.5345316   1.5317343   4.4703884  -0.64601374]\n",
      "self.next: 6\n",
      "obs= [[[ 2.67883706 -2.21971384 -0.21470626  0.69460605 -2.02427634\n",
      "    0.08706211]\n",
      "  [ 0.05587646  0.03563716 -0.09078489 -0.05811024  0.11078186\n",
      "   -0.02756331]]\n",
      "\n",
      " [[ 2.71704745 -2.20604267 -0.29217327  0.7301564  -1.97201439\n",
      "   -0.03491675]\n",
      "  [ 0.0707566   0.01130287 -0.1320172   0.05549569  0.09726024\n",
      "   -0.22316961]]] reward= -2258708.7644565734 done= False\n",
      "Step 7\n",
      "Action:  [ 1.7722517   0.30122805 -1.5348998   1.5323288   4.471602   -0.64602697]\n",
      "self.next: 7\n",
      "obs= [[[ 2.6844247  -2.21615012 -0.22378475  0.68879502 -2.01319815\n",
      "    0.08430578]\n",
      "  [-0.03786413  0.01672511  0.0213461  -0.0813081  -0.08023415\n",
      "    0.21223015]]\n",
      "\n",
      " [[ 2.72412311 -2.20491238 -0.30537499  0.73570597 -1.96228836\n",
      "   -0.05723371]\n",
      "  [ 0.0723214   0.01063639 -0.13256742  0.05581991  0.0962504\n",
      "   -0.22303701]]] reward= -1954563.226506263 done= False\n",
      "Step 8\n",
      "Action:  [ 1.7718      0.3013632  -1.5348539   1.5320516   4.471222   -0.64621794]\n",
      "self.next: 8\n",
      "obs= [[[ 2.68063829 -2.21447761 -0.22165014  0.68066421 -2.02122157\n",
      "    0.1055288 ]\n",
      "  [-0.04499684  0.00334445  0.04071759 -0.07645938 -0.03294372\n",
      "   -0.04105181]]\n",
      "\n",
      " [[ 2.73135525 -2.20384874 -0.31863173  0.74128796 -1.95266332\n",
      "   -0.07953741]\n",
      "  [ 0.07387348  0.00998389 -0.1331293   0.05615065  0.09524558\n",
      "   -0.22291372]]] reward= -2346284.343429357 done= False\n",
      "Step 9\n",
      "Action:  [ 1.772485    0.30137086 -1.5352713   1.5327739   4.472454   -0.6461807 ]\n",
      "self.next: 9\n",
      "obs= [[[ 2.67613861 -2.21414317 -0.21757838  0.67301828 -2.02451594\n",
      "    0.10142362]\n",
      "  [ 0.04852058 -0.0069786  -0.04223766 -0.0603461   0.11359627\n",
      "   -0.0418414 ]]\n",
      "\n",
      " [[ 2.7387426  -2.20285035 -0.33194466  0.74690302 -1.94313876\n",
      "   -0.10182879]\n",
      "  [ 0.07541234  0.00934579 -0.13370283  0.05648789  0.09424586\n",
      "   -0.2227995 ]]] reward= -2501264.8620749237 done= False\n",
      "Step 10\n",
      "Action:  [ 1.7729586   0.30140743 -1.5355133   1.5331317   4.4732885  -0.64619404]\n",
      "self.next: 10\n",
      "obs= [[[ 2.68099066 -2.21484103 -0.22180215  0.66698367 -2.01315631\n",
      "    0.09723948]\n",
      "  [ 0.00530694  0.0925226  -0.27502753  0.02352908 -0.00976747\n",
      "    0.26774606]]\n",
      "\n",
      " [[ 2.74628383 -2.20191577 -0.34531494  0.75255181 -1.93371418\n",
      "   -0.12410874]\n",
      "  [ 0.07693746  0.00872252 -0.13428798  0.0568316   0.09325132\n",
      "   -0.22269409]]] reward= -1512603.596535997 done= False\n",
      "Step 11\n",
      "Action:  [ 1.7726054   0.30155024 -1.5353172   1.5328202   4.472807   -0.6463087 ]\n",
      "self.next: 11\n",
      "obs= [[[ 2.68152136 -2.20558877 -0.2493049   0.66933657 -2.01413306\n",
      "    0.12401408]\n",
      "  [-0.02416898 -0.14522421  0.30237301 -0.04256524 -0.09390172\n",
      "   -0.12836003]]\n",
      "\n",
      " [[ 2.75397758 -2.20104352 -0.35874374  0.75823497 -1.92438905\n",
      "   -0.14637814]\n",
      "  [ 0.07844829  0.00811453 -0.1348847   0.05718174  0.09226205\n",
      "   -0.22259722]]] reward= -4434163.616865739 done= False\n",
      "Step 12\n",
      "Action:  [ 1.7728467   0.30141994 -1.5357099   1.5333025   4.4735193  -0.6462889 ]\n",
      "self.next: 12\n",
      "obs= [[[ 2.67910446e+00 -2.22011119e+00 -2.19067602e-01  6.65080051e-01\n",
      "   -2.02352323e+00  1.11178079e-01]\n",
      "  [ 2.01689999e-03  1.23337523e-01 -2.58700054e-01 -1.86549436e-02\n",
      "    9.57559623e-02  4.56343489e-02]]\n",
      "\n",
      " [[ 2.76182241e+00 -2.20023207e+00 -3.72232212e-01  7.63953147e-01\n",
      "   -1.91516284e+00 -1.68637866e-01]\n",
      "  [ 7.99442827e-02  7.52229825e-03 -1.35492935e-01  5.75382608e-02\n",
      "    9.12781478e-02 -2.22508643e-01]]] reward= -3232177.2767452085 done= False\n",
      "Step 13\n",
      "Action:  [ 1.77351    0.301675  -1.5359015  1.5337367  4.4744215 -0.6463195]\n",
      "self.next: 13\n",
      "obs= [[[ 2.67930615 -2.20777743 -0.24493761  0.66321456 -2.01394763\n",
      "    0.11574151]\n",
      "  [ 0.08282721 -0.03895954  0.08964488 -0.2587314   0.12685123\n",
      "    0.04496354]]\n",
      "\n",
      " [[ 2.76981683 -2.19947984 -0.38578151  0.76970697 -1.90603503\n",
      "   -0.19088873]\n",
      "  [ 0.08142486  0.0069463  -0.13611261  0.05790108  0.09029974\n",
      "   -0.22242808]]] reward= -2837485.9259088226 done= False\n",
      "Step 14\n",
      "Action:  [ 1.7734206   0.30174595 -1.5360109   1.5337228   4.4742756  -0.6463468 ]\n",
      "self.next: 14\n",
      "obs= [[[ 2.68758887 -2.21167339 -0.23597312  0.63734142 -2.00126251\n",
      "    0.12023787]\n",
      "  [ 0.00428555  0.00744117 -0.01179641 -0.13648177  0.02759103\n",
      "    0.16962817]]\n",
      "\n",
      " [[ 2.77795932 -2.19878521 -0.39939277  0.77549708 -1.89700505\n",
      "   -0.21313154]\n",
      "  [ 0.08288943  0.00638702 -0.13674361  0.05827012  0.08932696\n",
      "   -0.22235525]]] reward= -4664138.330957497 done= False\n",
      "Step 15\n",
      "Action:  [ 1.773744   0.3018583 -1.5363827  1.53411    4.475488  -0.6465893]\n",
      "self.next: 15\n",
      "obs= [[[ 2.68801743 -2.21092927 -0.23715276  0.62369324 -1.99850341\n",
      "    0.13720068]\n",
      "  [-0.03184756 -0.02617498 -0.11668508  0.3715539  -0.19237729\n",
      "    0.23298635]]\n",
      "\n",
      " [[ 2.78624826 -2.19814651 -0.41306713  0.78132409 -1.88807236\n",
      "   -0.23536706]\n",
      "  [ 0.08433737  0.00584497 -0.13738585  0.05864529  0.08835993\n",
      "   -0.22228988]]] reward= -2396404.512516341 done= False\n",
      "Step 16\n",
      "Action:  [ 1.7737563   0.30162498 -1.5364938   1.5342062   4.4763417  -0.6467511 ]\n",
      "self.next: 16\n",
      "obs= [[[ 2.68483267e+00 -2.21354677e+00 -2.48821269e-01  6.60848629e-01\n",
      "   -2.01774114e+00  1.60499320e-01]\n",
      "  [ 2.29606377e-03  5.01287880e-02 -5.27623689e-02 -1.32351482e-01\n",
      "    7.57206338e-02  2.25230355e-02]]\n",
      "\n",
      " [[ 2.79468200e+00 -2.19756201e+00 -4.26805712e-01  7.87188623e-01\n",
      "   -1.87923636e+00 -2.57596051e-01]\n",
      "  [ 8.57680578e-02  5.32066721e-03 -1.38039164e-01  5.90264701e-02\n",
      "    8.73988130e-02 -2.22231686e-01]]] reward= -6948148.581108704 done= False\n",
      "Step 17\n",
      "Action:  [ 1.7742509   0.30194446 -1.5366516   1.5346409   4.4762063  -0.64652765]\n",
      "self.next: 17\n",
      "obs= [[[ 2.68506228e+00 -2.20853389e+00 -2.54097506e-01  6.47613481e-01\n",
      "   -2.01016907e+00  1.62751623e-01]\n",
      "  [-2.59019924e-03 -5.58413721e-02  5.80055438e-02  1.32930381e-01\n",
      "   -7.62947717e-02 -1.12355801e-01]]\n",
      "\n",
      " [[ 2.80325881e+00 -2.19702994e+00 -4.40609629e-01  7.93091270e-01\n",
      "   -1.87049648e+00 -2.79819219e-01]\n",
      "  [ 8.71808539e-02  4.81462787e-03 -1.38703411e-01  5.94135430e-02\n",
      "    8.64437682e-02 -2.22180385e-01]]] reward= -2335570.572688276 done= False\n",
      "Step 18\n",
      "Action:  [ 1.7748573   0.30182227 -1.5372901   1.535361    4.4782705  -0.64677   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 18\n",
      "obs= [[[ 2.68480326 -2.21411803 -0.24829695  0.66090652 -2.01779855\n",
      "    0.15151604]\n",
      "  [-0.01276077  0.05882717 -0.0073968  -0.18232091  0.14309484\n",
      "   -0.15629956]]\n",
      "\n",
      " [[ 2.81197689 -2.19654848 -0.45447997  0.79903262 -1.86185211\n",
      "   -0.30203726]\n",
      "  [ 0.0885751   0.00432738 -0.13937841  0.05980637  0.08549497\n",
      "   -0.22213569]]] reward= -2089365.4691859414 done= False\n",
      "Step 19\n",
      "Action:  [ 1.7746251   0.30200896 -1.5368583   1.5350869   4.4766383  -0.64643186]\n",
      "self.next: 19\n",
      "obs= [[[ 2.68352718 -2.20823531 -0.24903663  0.64267443 -2.00348907\n",
      "    0.13588609]\n",
      "  [ 0.00956096 -0.03771868 -0.01082308  0.04964439 -0.06818256\n",
      "    0.19823502]]\n",
      "\n",
      " [[ 2.8208344  -2.19611574 -0.46841781  0.80501326 -1.85330261\n",
      "   -0.32425083]\n",
      "  [ 0.08995013  0.00385945 -0.14006395  0.0602048   0.08455258\n",
      "   -0.22209731]]] reward= -3259147.1644503935 done= False\n",
      "Step 20\n",
      "Action:  [ 1.7750496   0.30209497 -1.5375652   1.5355545   4.478956   -0.6470031 ]\n",
      "self.next: 20\n",
      "obs= [[[ 2.68448328 -2.21200718 -0.25011894  0.64763887 -2.01030732\n",
      "    0.15570959]\n",
      "  [ 0.01045253 -0.01318853  0.00299809 -0.00439356  0.11114363\n",
      "   -0.40056094]]\n",
      "\n",
      " [[ 2.82982941 -2.1957298  -0.48242421  0.81103374 -1.84484735\n",
      "   -0.34646056]\n",
      "  [ 0.09130525  0.00341138 -0.14075981  0.06060868  0.08361681\n",
      "   -0.22206497]]] reward= -2366658.337761634 done= False\n",
      "Step 21\n",
      "Action:  [ 1.7752883   0.30191943 -1.5373325   1.5358495   4.4781647  -0.6464527 ]\n",
      "self.next: 21\n",
      "obs= [[[ 2.68552853 -2.21332603 -0.24981913  0.64719951 -1.99919296\n",
      "    0.11565349]\n",
      "  [ 0.07824947  0.03615224 -0.07591961 -0.1751958   0.13871922\n",
      "    0.10190055]]\n",
      "\n",
      " [[ 2.83895994 -2.19538866 -0.49650019  0.81709461 -1.83648567\n",
      "   -0.36866706]\n",
      "  [ 0.0926398   0.00298368 -0.14146574  0.06101782  0.08268784\n",
      "   -0.22203837]]] reward= -2718688.6694677956 done= False\n",
      "Step 22\n",
      "Action:  [ 1.7754722   0.30229452 -1.5377105   1.5359361   4.4791136  -0.6468615 ]\n",
      "self.next: 22\n",
      "obs= [[[ 2.69335348e+00 -2.20971081e+00 -2.57411091e-01  6.29679931e-01\n",
      "   -1.98532104e+00  1.25843550e-01]\n",
      "  [-6.30483948e-03 -6.14594140e-02  6.72577207e-02 -3.38731738e-03\n",
      "    2.49019385e-03 -4.82131975e-02]]\n",
      "\n",
      " [[ 2.84822392e+00 -2.19509029e+00 -5.10646759e-01  8.23196392e-01\n",
      "   -1.82821689e+00 -3.90870892e-01]\n",
      "  [ 9.39530745e-02  2.57689144e-03 -1.42181460e-01  6.14320412e-02\n",
      "    8.17658785e-02 -2.22017222e-01]]] reward= -3253627.733538189 done= False\n",
      "Step 23\n",
      "Action:  [ 1.7760475  0.3022345 -1.5383343  1.5366435  4.481006  -0.6470872]\n",
      "self.next: 23\n",
      "obs= [[[ 2.69272299e+00 -2.21585675e+00 -2.50685319e-01  6.29341199e-01\n",
      "   -1.98507202e+00  1.21022230e-01]\n",
      "  [-4.92388805e-02  2.52391421e-03 -1.69979149e-01  3.54877176e-01\n",
      "    8.11464588e-02 -4.52580394e-01]]\n",
      "\n",
      " [[ 2.85761923e+00 -2.19483260e+00 -5.24864905e-01  8.29339596e-01\n",
      "   -1.82004030e+00 -4.13072614e-01]\n",
      "  [ 9.52443802e-02  2.19152422e-03 -1.42906680e-01  6.18511410e-02\n",
      "    8.08511244e-02 -2.22001252e-01]]] reward= -1658998.592104948 done= False\n",
      "Step 24\n",
      "Action:  [ 1.7759544  0.301881  -1.5378442  1.5365635  4.480069  -0.6466522]\n",
      "self.next: 24\n",
      "obs= [[[ 2.68779911e+00 -2.21560436e+00 -2.67683234e-01  6.64828917e-01\n",
      "   -1.97695737e+00  7.57641906e-02]\n",
      "  [ 3.87382512e-02 -1.85914590e-02  1.54305493e-01 -3.69667650e-01\n",
      "    9.14643614e-02  2.19943917e-01]]\n",
      "\n",
      " [[ 2.86714366e+00 -2.19461345e+00 -5.39155573e-01  8.35524710e-01\n",
      "   -1.81195518e+00 -4.35272740e-01]\n",
      "  [ 9.65130235e-02  1.82808751e-03 -1.43641074e-01  6.22749093e-02\n",
      "    7.99437899e-02 -2.21990174e-01]]] reward= -6352074.825683278 done= False\n",
      "Step 25\n",
      "Action:  [ 1.7752169  0.302501  -1.5377108  1.5358589  4.4786205 -0.646906 ]\n",
      "self.next: 25\n",
      "obs= [[[ 2.69167293e+00 -2.21746350e+00 -2.52252685e-01  6.27862152e-01\n",
      "   -1.96781094e+00  9.77585824e-02]\n",
      "  [-2.43923651e-02  4.94423764e-03 -1.18238555e-01  1.97962870e-01\n",
      "    4.92212074e-02 -3.68217408e-01]]\n",
      "\n",
      " [[ 2.87679497e+00 -2.19443064e+00 -5.53519681e-01  8.41752201e-01\n",
      "   -1.80396081e+00 -4.57471757e-01]\n",
      "  [ 9.77583112e-02  1.48707746e-03 -1.44384293e-01  6.27031249e-02\n",
      "    7.90440877e-02 -2.21983712e-01]]] reward= -5664011.644535072 done= False\n",
      "Step 26\n",
      "Action:  [ 1.7768563   0.30220243 -1.5387594   1.5375248   4.4824214  -0.64700514]\n",
      "self.next: 26\n",
      "obs= [[[ 2.68923369e+00 -2.21696908e+00 -2.64076540e-01  6.47658439e-01\n",
      "   -1.96288882e+00  6.09368416e-02]\n",
      "  [ 9.49951897e-04  2.75792729e-02 -2.89322326e-02 -6.43746579e-04\n",
      "   -2.61355676e-03 -2.20901901e-02]]\n",
      "\n",
      " [[ 2.88657080e+00 -2.19428193e+00 -5.67958110e-01  8.48022513e-01\n",
      "   -1.79605640e+00 -4.79670128e-01]\n",
      "  [ 9.89795564e-02  1.16897344e-03 -1.45135967e-01  6.31355578e-02\n",
      "    7.81522321e-02 -2.21981594e-01]]] reward= -3362060.47552567 done= False\n",
      "Step 27\n",
      "Action:  [ 1.7771819  0.3025594 -1.5393217  1.5378703  4.483715  -0.6474087]\n",
      "self.next: 27\n",
      "obs= [[[ 2.68932869e+00 -2.21421115e+00 -2.66969764e-01  6.47594064e-01\n",
      "   -1.96315017e+00  5.87278226e-02]\n",
      "  [ 3.09691058e-02 -4.53238766e-02  1.54193217e-01 -2.06240540e-01\n",
      "    6.92110420e-02  7.60736707e-02]]\n",
      "\n",
      " [[ 2.89646875e+00 -2.19416504e+00 -5.82471707e-01  8.54336069e-01\n",
      "   -1.78824117e+00 -5.01868287e-01]\n",
      "  [ 1.00176078e-01  8.74237744e-04 -1.45895703e-01  6.35719680e-02\n",
      "    7.72684372e-02 -2.21983553e-01]]] reward= -1868289.014984533 done= False\n",
      "Step 28\n",
      "Action:  [ 1.7767346   0.30263758 -1.5390054   1.5374464   4.4824862  -0.6472944 ]\n",
      "self.next: 28\n",
      "obs= [[[ 2.69242560e+00 -2.21874354e+00 -2.51550442e-01  6.26970010e-01\n",
      "   -1.95622907e+00  6.63351897e-02]\n",
      "  [-3.61940713e-02 -2.94750685e-02 -1.10312088e-01  2.40097852e-01\n",
      "   -1.16118419e-01  5.93937717e-02]]\n",
      "\n",
      " [[ 2.90648636e+00 -2.19407761e+00 -5.97061277e-01  8.60693266e-01\n",
      "   -1.78051433e+00 -5.24066643e-01]\n",
      "  [ 1.01347207e-01  6.03310855e-04 -1.46663080e-01  6.40121076e-02\n",
      "    7.63929158e-02 -2.21989327e-01]]] reward= -4043559.4388534254 done= False\n",
      "Step 29\n",
      "Action:  [ 1.777687    0.30256814 -1.5398166   1.5384208   4.4854703  -0.6476768 ]\n",
      "self.next: 29\n",
      "obs= [[[ 2.68880619e+00 -2.22169105e+00 -2.62581651e-01  6.50979796e-01\n",
      "   -1.96784091e+00  7.22745668e-02]\n",
      "  [ 1.46171817e-03 -1.33952551e-02  1.15935511e-02 -3.54300340e-04\n",
      "    1.06301385e-01 -1.69399593e-01]]\n",
      "\n",
      " [[ 2.91662108e+00 -2.19401728e+00 -6.11727585e-01  8.67094477e-01\n",
      "   -1.77287504e+00 -5.46265575e-01]\n",
      "  [ 1.02492287e-01  3.56609541e-04 -1.47437662e-01  6.44557226e-02\n",
      "    7.55258792e-02 -2.21998663e-01]]] reward= -5022513.137903613 done= False\n",
      "Step 30\n",
      "Action:  [ 1.7776854   0.30261448 -1.5396242   1.5384138   4.4845157  -0.6473498 ]\n",
      "self.next: 30\n",
      "obs= [[[ 2.68895236e+00 -2.22303057e+00 -2.61422296e-01  6.50944365e-01\n",
      "   -1.95721077e+00  5.53346075e-02]\n",
      "  [ 1.17381940e-03  1.24150435e-02 -1.16396606e-02 -8.33282338e-03\n",
      "    1.33296247e-03 -5.36895368e-02]]\n",
      "\n",
      " [[ 2.92687031e+00 -2.19398162e+00 -6.26471351e-01  8.73540049e-01\n",
      "   -1.76532245e+00 -5.68465442e-01]\n",
      "  [ 1.03610679e-01  1.34523852e-04 -1.48218985e-01  6.49025521e-02\n",
      "    7.46675339e-02 -2.22011314e-01]]] reward= -1657343.161201195 done= False\n",
      "Step 31\n",
      "Action:  [ 1.7780572   0.30277377 -1.5400667   1.5388377   4.4857483  -0.6476015 ]\n",
      "self.next: 31\n",
      "obs= [[[ 2.68906975e+00 -2.22178907e+00 -2.62586262e-01  6.50111083e-01\n",
      "   -1.95707747e+00  4.99656538e-02]\n",
      "  [ 8.32476495e-02 -3.91336609e-03  9.39499540e-02 -2.99773632e-01\n",
      "    1.79053116e-01 -4.73482647e-03]]\n",
      "\n",
      " [[ 2.93723138e+00 -2.19396817e+00 -6.41293250e-01  8.80030304e-01\n",
      "   -1.75785570e+00 -5.90666573e-01]\n",
      "  [ 1.04701761e-01 -6.25850277e-05 -1.49006570e-01  6.53523307e-02\n",
      "    7.38180825e-02 -2.22027041e-01]]] reward= -1906394.9637658307 done= False\n",
      "Step 32\n",
      "Action:  [ 1.7774643   0.30285516 -1.5394838   1.5382315   4.4836674  -0.6472847 ]\n",
      "self.next: 32\n",
      "obs= [[[ 2.69739451e+00 -2.22218040e+00 -2.53191266e-01  6.20133720e-01\n",
      "   -1.93917216e+00  4.94921712e-02]\n",
      "  [-9.09347581e-02  2.70724410e-02  6.52563806e-02 -7.62633182e-03\n",
      "   -1.48322123e-01  1.15954732e-01]]\n",
      "\n",
      " [[ 2.94770155e+00 -2.19397443e+00 -6.56193907e-01  8.86565537e-01\n",
      "   -1.75047389e+00 -6.12869277e-01]\n",
      "  [ 1.05764936e-01 -2.34387981e-04 -1.49799916e-01  6.58047889e-02\n",
      "    7.29777204e-02 -2.22045617e-01]]] reward= -5821345.102456976 done= False\n",
      "Step 33\n",
      "Action:  [ 1.778105   0.3029667 -1.5403043  1.5390111  4.4863253 -0.6478204]\n",
      "self.next: 33\n",
      "obs= [[[ 2.68830104e+00 -2.21947316e+00 -2.46665628e-01  6.19371087e-01\n",
      "   -1.95400437e+00  6.10876444e-02]\n",
      "  [ 4.88048347e-02 -3.52181957e-03 -4.40135116e-02 -6.67275257e-02\n",
      "    6.20966803e-02  3.20077617e-02]]\n",
      "\n",
      " [[ 2.95827805e+00 -2.19399787e+00 -6.71173898e-01  8.93146016e-01\n",
      "   -1.74317612e+00 -6.35073839e-01]\n",
      "  [ 1.06799631e-01 -3.80589660e-04 -1.50598506e-01  6.62596549e-02\n",
      "    7.21466371e-02 -2.22066820e-01]]] reward= -2619788.3124441183 done= False\n",
      "Step 34\n",
      "Action:  [ 1.7786362   0.30297664 -1.540532    1.5394415   4.4870434  -0.6477418 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 34\n",
      "obs= [[[ 2.69318152e+00 -2.21982534e+00 -2.51066979e-01  6.12698334e-01\n",
      "   -1.94779471e+00  6.42884206e-02]\n",
      "  [-1.76813023e-03 -1.96320991e-02  1.91674753e-02  2.53636547e-03\n",
      "   -7.49431816e-04 -3.22662840e-02]]\n",
      "\n",
      " [[ 2.96895801e+00 -2.19403593e+00 -6.86233749e-01  8.99771981e-01\n",
      "   -1.73596145e+00 -6.57280521e-01]\n",
      "  [ 1.07805300e-01 -5.00931433e-04 -1.51401807e-01  6.67166554e-02\n",
      "    7.13250119e-02 -2.22090441e-01]]] reward= -1962452.5591606507 done= False\n",
      "Step 35\n",
      "Action:  [ 1.7789156   0.30299318 -1.5408258   1.5397819   4.487894   -0.64784676]\n",
      "self.next: 35\n",
      "obs= [[[ 2.69300471e+00 -2.22178855e+00 -2.49150232e-01  6.12951971e-01\n",
      "   -1.94786965e+00  6.10617922e-02]\n",
      "  [-6.30977345e-02 -1.53403205e-02  1.22935580e-01 -4.77702205e-02\n",
      "   -1.06087101e-01  1.39761814e-01]]\n",
      "\n",
      " [[ 2.97973854e+00 -2.19408602e+00 -7.01373930e-01  9.06443647e-01\n",
      "   -1.72882895e+00 -6.79489565e-01]\n",
      "  [ 1.08781427e-01 -5.95192499e-04 -1.52209270e-01  6.71755164e-02\n",
      "    7.05130153e-02 -2.22116279e-01]]] reward= -1719811.4743767132 done= False\n",
      "Step 36\n",
      "Action:  [ 1.7786089   0.30311972 -1.5407226   1.539558    4.48744    -0.6479252 ]\n",
      "self.next: 36\n",
      "obs= [[[ 2.68669493e+00 -2.22332258e+00 -2.36856674e-01  6.08174949e-01\n",
      "   -1.95847836e+00  7.50379735e-02]\n",
      "  [-4.69462345e-02  4.40584913e-02  3.23271275e-03 -7.42970016e-02\n",
      "   -3.68985711e-02  1.19498045e-01]]\n",
      "\n",
      " [[ 2.99061668e+00 -2.19414554e+00 -7.16594857e-01  9.13161199e-01\n",
      "   -1.72177765e+00 -7.01701193e-01]\n",
      "  [ 1.09727531e-01 -6.63192074e-04 -1.53020334e-01  6.76359645e-02\n",
      "    6.97108066e-02 -2.22144146e-01]]] reward= -2453477.625361191 done= False\n",
      "Step 37\n",
      "Action:  [ 1.7788858   0.30319557 -1.5408365   1.5398227   4.487779   -0.64789265]\n",
      "self.next: 37\n",
      "obs= [[[ 2.68200031e+00 -2.21891674e+00 -2.36533403e-01  6.00745249e-01\n",
      "   -1.96216822e+00  8.69877780e-02]\n",
      "  [ 2.48275342e-02  7.03324472e-02 -9.68709551e-02 -2.08169542e-01\n",
      "    2.07463543e-01 -1.34009223e-01]]\n",
      "\n",
      " [[ 3.00158944e+00 -2.19421186e+00 -7.31896890e-01  9.19924795e-01\n",
      "   -1.71480657e+00 -7.23915607e-01]\n",
      "  [ 1.10643162e-01 -7.04791212e-04 -1.53834429e-01  6.80977289e-02\n",
      "    6.89185338e-02 -2.22173863e-01]]] reward= -2407829.162580034 done= False\n",
      "Step 38\n",
      "Action:  [ 1.7788342   0.30314043 -1.5404611   1.5397278   4.4865346  -0.64744616]\n",
      "self.next: 38\n",
      "obs= [[[ 2.68448306e+00 -2.21188349e+00 -2.46220498e-01  5.79928294e-01\n",
      "   -1.94142186e+00  7.35868557e-02]\n",
      "  [ 7.96614465e-02  1.16285460e-02  8.56914314e-02 -3.11580576e-01\n",
      "    1.85987063e-01 -6.03157803e-02]]\n",
      "\n",
      " [[ 3.01265375e+00 -2.19428234e+00 -7.47280333e-01  9.26734568e-01\n",
      "   -1.70791472e+00 -7.46132994e-01]\n",
      "  [ 1.11527909e-01 -7.19893842e-04 -1.54650971e-01  6.85605415e-02\n",
      "    6.81363317e-02 -2.22205263e-01]]] reward= -3228246.635459492 done= False\n",
      "Step 39\n",
      "Action:  [ 1.7788786   0.30323496 -1.540648    1.5398306   4.486867   -0.64756256]\n",
      "self.next: 39\n",
      "obs= [[[ 2.69244921e+00 -2.21072064e+00 -2.37651355e-01  5.48770237e-01\n",
      "   -1.92282316e+00  6.75552777e-02]\n",
      "  [-5.26794942e-02  3.28044059e-02 -1.93804718e-01  2.10473008e-01\n",
      "   -1.06772040e-01  1.17508194e-01]]\n",
      "\n",
      " [[ 3.02380654e+00 -2.19435433e+00 -7.62745430e-01  9.33590622e-01\n",
      "   -1.70110108e+00 -7.68353520e-01]\n",
      "  [ 1.12381400e-01 -7.08447439e-04 -1.55469373e-01  6.90241384e-02\n",
      "    6.73643229e-02 -2.22238188e-01]]] reward= -6175051.401167625 done= False\n",
      "Step 40\n",
      "Action:  [ 1.7800143   0.30326644 -1.5417836   1.5409852   4.49092    -0.64827543]\n",
      "self.next: 40\n",
      "obs= [[[ 2.68718126e+00 -2.20744020e+00 -2.57031827e-01  5.69817538e-01\n",
      "   -1.93350036e+00  7.93060972e-02]\n",
      "  [ 1.98140532e-03 -2.51920220e-02  6.24600100e-02 -3.88788023e-02\n",
      "   -3.20599212e-03  5.81976012e-02]]\n",
      "\n",
      " [[ 3.03504468e+00 -2.19442517e+00 -7.78292367e-01  9.40493036e-01\n",
      "   -1.69436465e+00 -7.90577339e-01]\n",
      "  [ 1.13203302e-01 -6.70444494e-04 -1.56289041e-01  6.94882614e-02\n",
      "    6.66026159e-02 -2.22272493e-01]]] reward= -5074332.987056217 done= False\n",
      "Step 41\n",
      "Action:  [ 1.7798786  0.3033511 -1.5416902  1.5408815  4.490212  -0.6481322]\n",
      "self.next: 41\n",
      "obs= [[[ 2.68737940e+00 -2.20995940e+00 -2.50785826e-01  5.65929657e-01\n",
      "   -1.93382096e+00  8.51258573e-02]\n",
      "  [ 2.20656679e-03 -5.02615078e-02  5.05950170e-02 -5.31774883e-03\n",
      "   -4.76081823e-02  5.44276943e-02]]\n",
      "\n",
      " [[ 3.04636501e+00 -2.19449221e+00 -7.93921271e-01  9.47441862e-01\n",
      "   -1.68770439e+00 -8.12804588e-01]\n",
      "  [ 1.13993324e-01 -6.05922984e-04 -1.57109377e-01  6.99526578e-02\n",
      "    6.58513036e-02 -2.22308044e-01]]] reward= -2185214.510486706 done= False\n",
      "Step 42\n",
      "Action:  [ 1.7801734  0.3033878 -1.541957   1.5411978  4.4910326 -0.6482313]\n",
      "self.next: 42\n",
      "obs= [[[ 2.68760005e+00 -2.21498555e+00 -2.45726324e-01  5.65397882e-01\n",
      "   -1.93858178e+00  9.05686267e-02]\n",
      "  [-5.05599721e-02  3.35967164e-02  1.46921815e-02 -6.54747562e-02\n",
      "   -4.08577049e-02  1.76555740e-01]]\n",
      "\n",
      " [[ 3.05776435e+00 -2.19455281e+00 -8.09632209e-01  9.54437128e-01\n",
      "   -1.68111926e+00 -8.35035393e-01]\n",
      "  [ 1.14751216e-01 -5.14966447e-04 -1.57929781e-01  7.04170826e-02\n",
      "    6.51104651e-02 -2.22344715e-01]]] reward= -1946696.9943637585 done= False\n",
      "Step 43\n",
      "Action:  [ 1.7799345   0.30351484 -1.5417545   1.541003    4.4903264  -0.6481871 ]\n",
      "self.next: 43\n",
      "obs= [[[ 2.68254406e+00 -2.21162588e+00 -2.44257106e-01  5.58850407e-01\n",
      "   -1.94266755e+00  1.08224201e-01]\n",
      "  [ 4.97644368e-02 -5.23425741e-02  1.30881976e-03  7.13096984e-02\n",
      "    3.75508272e-02 -2.08035524e-01]]\n",
      "\n",
      " [[ 3.06923947e+00 -2.19460430e+00 -8.25425187e-01  9.61478836e-01\n",
      "   -1.67460821e+00 -8.57269864e-01]\n",
      "  [ 1.15476773e-01 -3.97704122e-04 -1.58749654e-01  7.08812984e-02\n",
      "    6.43801638e-02 -2.22382391e-01]]] reward= -2415781.4181391704 done= False\n",
      "Step 44\n",
      "Action:  [ 1.7807477   0.3033475  -1.5422673   1.5417881   4.4919667  -0.64814436]\n",
      "self.next: 44\n",
      "obs= [[[ 2.68752050e+00 -2.21686013e+00 -2.44126224e-01  5.65981377e-01\n",
      "   -1.93891247e+00  8.74206484e-02]\n",
      "  [ 4.35211781e-02 -6.20806471e-03 -3.72386960e-02 -6.99897256e-02\n",
      "    1.21133647e-01  2.25752502e-02]]\n",
      "\n",
      " [[ 3.08078715e+00 -2.19464407e+00 -8.41300153e-01  9.68566966e-01\n",
      "   -1.66817020e+00 -8.79508103e-01]\n",
      "  [ 1.16169832e-01 -2.54311156e-04 -1.59568398e-01  7.13450775e-02\n",
      "    6.36604483e-02 -2.22420969e-01]]] reward= -2403635.2031012764 done= False\n",
      "Step 45\n",
      "Action:  [ 1.7806071   0.30352432 -1.5421733   1.541642    4.4915366  -0.64816725]\n",
      "self.next: 45\n",
      "obs= [[[ 2.69187262e+00 -2.21748094e+00 -2.47850094e-01  5.58982404e-01\n",
      "   -1.92679910e+00  8.96781734e-02]\n",
      "  [-5.79041665e-02  5.31670428e-02 -3.37863072e-02 -3.27207479e-02\n",
      "    1.22923750e-02 -2.76222908e-02]]\n",
      "\n",
      " [[ 3.09240413e+00 -2.19466951e+00 -8.57256992e-01  9.75701474e-01\n",
      "   -1.66180415e+00 -9.01750200e-01]\n",
      "  [ 1.16830275e-01 -8.50073597e-05 -1.60385418e-01  7.18082008e-02\n",
      "    6.29513515e-02 -2.22460351e-01]]] reward= -2251307.309208829 done= False\n",
      "Step 46\n",
      "Action:  [ 1.7807698  0.3035928 -1.5423664  1.5418878  4.492037  -0.6482455]\n",
      "self.next: 46\n",
      "obs= [[[ 2.68608220e+00 -2.21216424e+00 -2.51228724e-01  5.55710329e-01\n",
      "   -1.92556986e+00  8.69159443e-02]\n",
      "  [ 2.42732341e-02 -1.59210328e-02  7.54275871e-02 -1.53409042e-01\n",
      "    7.03042829e-02 -8.30581339e-02]]\n",
      "\n",
      " [[ 3.10408716e+00 -2.19467801e+00 -8.73295534e-01  9.82882294e-01\n",
      "   -1.65550902e+00 -9.23996235e-01]\n",
      "  [ 1.17458027e-01  1.09942502e-04 -1.61200127e-01  7.22704599e-02\n",
      "    6.22528913e-02 -2.22500450e-01]]] reward= -2396538.4259995525 done= False\n",
      "Step 47\n",
      "Action:  [ 1.7807815   0.30361322 -1.542358    1.5419221   4.4918256  -0.64815116]\n",
      "self.next: 47\n",
      "obs= [[[ 2.68850953e+00 -2.21375634e+00 -2.43685966e-01  5.40369425e-01\n",
      "   -1.91853944e+00  7.86101309e-02]\n",
      "  [ 3.35190895e-02 -6.62558162e-02 -1.20026237e-02  1.86434054e-01\n",
      "   -7.91536269e-02  1.31749781e-01]]\n",
      "\n",
      " [[ 3.11583296e+00 -2.19466701e+00 -8.89415547e-01  9.90109340e-01\n",
      "   -1.64928373e+00 -9.46246280e-01]\n",
      "  [ 1.18053059e-01  3.30229856e-04 -1.62011941e-01  7.27316571e-02\n",
      "    6.15650703e-02 -2.22541186e-01]]] reward= -3750166.6152464533 done= False\n",
      "Step 48\n",
      "Action:  [ 1.7815922   0.30364352 -1.5432045   1.5427014   4.4948006  -0.6487118 ]\n",
      "self.next: 48\n",
      "obs= [[[ 2.69186143e+00 -2.22038192e+00 -2.44886228e-01  5.59012831e-01\n",
      "   -1.92645480e+00  9.17851091e-02]\n",
      "  [ 3.42863750e-03  1.05632628e-01 -1.50596826e-01 -1.01965485e-01\n",
      "    1.44308809e-01 -2.16548483e-01]]\n",
      "\n",
      " [[ 3.12763827e+00 -2.19463399e+00 -9.05616741e-01  9.97382506e-01\n",
      "   -1.64312722e+00 -9.68500399e-01]\n",
      "  [ 1.18615382e-01  5.75503424e-04 -1.62820288e-01  7.31916059e-02\n",
      "    6.08878771e-02 -2.22582487e-01]]] reward= -4044681.920779034 done= False\n",
      "Step 49\n",
      "Action:  [ 1.7811279   0.303664   -1.5424622   1.5422976   4.4921093  -0.64803654]\n",
      "self.next: 49\n",
      "obs= [[[ 2.69220430e+00 -2.20981866e+00 -2.59945911e-01  5.48816282e-01\n",
      "   -1.91202392e+00  7.01302608e-02]\n",
      "  [-4.49465330e-03 -6.68159399e-02  7.22557928e-02 -3.69894715e-03\n",
      "   -3.69027155e-03  1.09731072e-01]]\n",
      "\n",
      " [[ 3.13949980e+00 -2.19457644e+00 -9.21898770e-01  1.00470167e+00\n",
      "   -1.63703843e+00 -9.90758647e-01]\n",
      "  [ 1.19145052e-01  8.45369858e-04 -1.63624603e-01  7.36501309e-02\n",
      "    6.02212843e-02 -2.22624283e-01]]] reward= -3161544.8480731575 done= False\n",
      "Step 50\n",
      "Action:  [ 1.7814811   0.30376804 -1.5430926   1.542658    4.4941382  -0.6485714 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 50\n",
      "obs= [[[ 2.69175483e+00 -2.21650025e+00 -2.52720331e-01  5.48446387e-01\n",
      "   -1.91239294e+00  8.11033679e-02]\n",
      "  [ 2.14615490e-02 -2.01758097e-03  1.52735600e-01 -3.80477830e-01\n",
      "    1.48237372e-01  2.40234624e-02]]\n",
      "\n",
      " [[ 3.15141431e+00 -2.19449190e+00 -9.38261230e-01  1.01206668e+00\n",
      "   -1.63101630e+00 -1.01302108e+00]\n",
      "  [ 1.19642166e-01  1.13939591e-03 -1.64424332e-01  7.41070688e-02\n",
      "    5.95652529e-02 -2.22666514e-01]]] reward= -2341164.607845788 done= False\n",
      "Step 51\n",
      "Action:  [ 1.7805364   0.30383754 -1.5421395   1.5418016   4.4907675  -0.64798635]\n",
      "self.next: 51\n",
      "obs= [[[ 2.69390099e+00 -2.21670201e+00 -2.37446771e-01  5.10398604e-01\n",
      "   -1.89756921e+00  8.35057142e-02]\n",
      "  [ 3.61240128e-03 -3.66609823e-02  3.42069670e-02 -8.69044768e-03\n",
      "   -4.04181350e-02  1.37205794e-01]]\n",
      "\n",
      " [[ 3.16337853e+00 -2.19437796e+00 -9.54703663e-01  1.01947739e+00\n",
      "   -1.62505978e+00 -1.03528773e+00]\n",
      "  [ 1.20106860e-01  1.45710868e-03 -1.65218933e-01  7.45622677e-02\n",
      "    5.89197287e-02 -2.22709120e-01]]] reward= -5809168.385482386 done= False\n",
      "Step 52\n",
      "Action:  [ 1.781943    0.30390352 -1.5434934   1.5431678   4.495292   -0.6487137 ]\n",
      "self.next: 52\n",
      "obs= [[[ 2.69426223e+00 -2.22036811e+00 -2.34026075e-01  5.09529560e-01\n",
      "   -1.90161102e+00  9.72262936e-02]\n",
      "  [ 5.41960595e-05 -2.17952501e-02  2.19049832e-02 -7.18481213e-04\n",
      "    4.73448745e-04 -3.05806528e-02]]\n",
      "\n",
      " [[ 3.17538921e+00 -2.19423225e+00 -9.71225557e-01  1.02693361e+00\n",
      "   -1.61916781e+00 -1.05755864e+00]\n",
      "  [ 1.20539312e-01  1.79799787e-03 -1.66007879e-01  7.50155886e-02\n",
      "    5.82846472e-02 -2.22752047e-01]]] reward= -2019741.2997167087 done= False\n",
      "Step 53\n",
      "Action:  [ 1.7822173   0.3038907  -1.5436459   1.5434562   4.4956803  -0.64864945]\n",
      "self.next: 53\n",
      "obs= [[[ 2.69426765e+00 -2.22254763e+00 -2.31835576e-01  5.09457711e-01\n",
      "   -1.90156368e+00  9.41682283e-02]\n",
      "  [ 2.27811473e-02  4.86521818e-02 -2.80883546e-02 -1.12567518e-01\n",
      "    2.03881536e-02  7.02703768e-02]]\n",
      "\n",
      " [[ 3.18744314e+00 -2.19405245e+00 -9.87826344e-01  1.03443517e+00\n",
      "   -1.61333934e+00 -1.07983384e+00]\n",
      "  [ 1.20939737e-01  2.16151687e-03 -1.66790653e-01  7.54669033e-02\n",
      "    5.76599302e-02 -2.22795240e-01]]] reward= -2032785.0660173385 done= False\n",
      "Step 54\n",
      "Action:  [ 1.7821279   0.30402336 -1.5435553   1.5434066   4.495256   -0.64861214]\n",
      "self.next: 54\n",
      "obs= [[[ 2.69654576e+00 -2.21768242e+00 -2.34644412e-01  4.98200960e-01\n",
      "   -1.89952486e+00  1.01195266e-01]\n",
      "  [ 7.45011258e-03 -6.77484225e-02 -1.15000856e-01  1.75767722e-01\n",
      "    4.39432042e-02 -9.49103362e-02]]\n",
      "\n",
      " [[ 3.19953712e+00 -2.19383630e+00 -1.00450541e+00  1.04198186e+00\n",
      "   -1.60757335e+00 -1.10211337e+00]\n",
      "  [ 1.21308387e-01  2.54708469e-03 -1.67566755e-01  7.59160956e-02\n",
      "    5.70454895e-02 -2.22838644e-01]]] reward= -3480507.0275847237 done= False\n",
      "Step 55\n",
      "Action:  [ 1.7827989   0.30386057 -1.5440619   1.5440222   4.4971404  -0.64876926]\n",
      "self.next: 55\n",
      "obs= [[[ 2.69729077e+00 -2.22445726e+00 -2.46144497e-01  5.15777732e-01\n",
      "   -1.89513054e+00  9.17042323e-02]\n",
      "  [-1.75460349e-02 -1.44110987e-02 -8.73655983e-03  1.05195787e-01\n",
      "   -6.46701833e-02  5.07510922e-02]]\n",
      "\n",
      " [[ 3.21166795e+00 -2.19358159e+00 -1.02126209e+00  1.04957347e+00\n",
      "   -1.60186880e+00 -1.12439723e+00]\n",
      "  [ 1.21645548e-01  2.95408709e-03 -1.68335699e-01  7.63630610e-02\n",
      "    5.64412271e-02 -2.22882208e-01]]] reward= -4842695.222823017 done= False\n",
      "Step 56\n",
      "Action:  [ 1.7828001  0.3040267 -1.5442038  1.5440909  4.497366  -0.6489143]\n",
      "self.next: 56\n",
      "obs= [[[ 2.69553617 -2.22589837 -0.24701815  0.52629731 -1.90159756\n",
      "    0.09677934]\n",
      "  [ 0.00942368 -0.05340965  0.08446477 -0.04188429 -0.04317969\n",
      "   -0.00339341]]\n",
      "\n",
      " [[ 3.22383251 -2.19328618 -1.03809566  1.05720978 -1.59622468\n",
      "   -1.14668545]\n",
      "  [ 0.12195154  0.00338188 -0.16909701  0.07680771  0.05584704\n",
      "   -0.22292587]]] reward= -2585054.093914914 done= False\n",
      "Step 57\n",
      "Action:  [ 1.7826968   0.30406764 -1.5441037   1.5440284   4.496842   -0.6487866 ]\n",
      "self.next: 57\n",
      "obs= [[[ 2.69647854 -2.23123933 -0.23857168  0.52210888 -1.90591553\n",
      "    0.09644   ]\n",
      "  [ 0.03720045  0.0851567  -0.2656099   0.08136383  0.21692298\n",
      "   -0.35370588]]\n",
      "\n",
      " [[ 3.23602766 -2.19294799 -1.05500536  1.06489055 -1.59063997\n",
      "   -1.16897804]\n",
      "  [ 0.12222672  0.00382978 -0.16985024  0.07724995  0.0552628\n",
      "   -0.22296958]]] reward= -2827050.320456215 done= False\n",
      "Step 58\n",
      "Action:  [ 1.7826717   0.30391476 -1.543674    1.543997    4.4956107  -0.6483063 ]\n",
      "self.next: 58\n",
      "obs= [[[ 2.70019858 -2.22272366 -0.26513267  0.53024526 -1.88422323\n",
      "    0.06106941]\n",
      "  [-0.04473889 -0.0144859   0.02025636  0.10704202 -0.16694334\n",
      "    0.19932655]]\n",
      "\n",
      " [[ 3.24825034 -2.19256502 -1.07199038  1.07261554 -1.58511369\n",
      "   -1.191275  ]\n",
      "  [ 0.12247147  0.0042971  -0.17059494  0.07768971  0.0546884\n",
      "   -0.22301327]]] reward= -3237724.857668052 done= False\n",
      "Step 59\n",
      "Action:  [ 1.783008   0.3042046 -1.5444845  1.5443949  4.4980984 -0.649091 ]\n",
      "self.next: 59\n",
      "obs= [[[ 2.69572470e+00 -2.22417225e+00 -2.63107030e-01  5.40949467e-01\n",
      "   -1.90091756e+00  8.10020685e-02]\n",
      "  [-4.34309257e-02  1.16501128e-01 -2.55777423e-01  1.19776291e-01\n",
      "   -5.70199587e-04  4.30254785e-02]]\n",
      "\n",
      " [[ 3.26049748e+00 -2.19213531e+00 -1.08904988e+00  1.08038451e+00\n",
      "   -1.57964485e+00 -1.21357633e+00]\n",
      "  [ 1.22686193e-01  4.78309417e-03 -1.71330699e-01  7.81269368e-02\n",
      "    5.41236961e-02 -2.23056865e-01]]] reward= -2616890.5283815274 done= False\n",
      "Step 60\n",
      "Action:  [ 1.7832024   0.30420545 -1.5444058   1.5445824   4.4978333  -0.6488807 ]\n",
      "self.next: 60\n",
      "obs= [[[ 2.6913816  -2.21252214 -0.28868477  0.5529271  -1.90097458\n",
      "    0.08530462]\n",
      "  [ 0.03457378 -0.08614946  0.22743501 -0.24764213  0.02157723\n",
      "    0.1634217 ]]\n",
      "\n",
      " [[ 3.2727661  -2.191657   -1.10618295  1.08819721 -1.57423248\n",
      "   -1.23588201]\n",
      "  [ 0.12287134  0.00528701 -0.17205709  0.07856157  0.05356857\n",
      "   -0.2231003 ]]] reward= -3800657.283537754 done= False\n",
      "Step 61\n",
      "Action:  [ 1.7822868   0.30427116 -1.5437809   1.5437535   4.495476   -0.6486273 ]\n",
      "self.next: 61\n",
      "obs= [[[ 2.69483898e+00 -2.22113709e+00 -2.65941272e-01  5.28162883e-01\n",
      "   -1.89881686e+00  1.01646787e-01]\n",
      "  [ 1.41200537e-02 -2.35594163e-03 -1.88990001e-01  1.71935967e-01\n",
      "    6.25401887e-03 -2.31463691e-04]]\n",
      "\n",
      " [[ 3.28505324e+00 -2.19112830e+00 -1.12338865e+00  1.09605336e+00\n",
      "   -1.56887563e+00 -1.25819204e+00]\n",
      "  [ 1.23027368e-01  5.80807302e-03 -1.72773738e-01  7.89935636e-02\n",
      "    5.30228715e-02 -2.23143478e-01]]] reward= -5039503.493871481 done= False\n",
      "Step 62\n",
      "Action:  [ 1.7837257  0.3042072 -1.5448753  1.5450985  4.4992867 -0.6490372]\n",
      "self.next: 62\n",
      "obs= [[[ 2.69625099 -2.22137268 -0.28484027  0.54535648 -1.89819146\n",
      "    0.10162364]\n",
      "  [-0.0552172   0.0278674   0.02585204 -0.06074344 -0.04659746\n",
      "    0.17651346]]\n",
      "\n",
      " [[ 3.29735597 -2.19054749 -1.14066603  1.10395272 -1.56357334\n",
      "   -1.28050639]\n",
      "  [ 0.12315477  0.00634547 -0.17348025  0.07942288  0.05248647\n",
      "   -0.22318632]]] reward= -4501523.665974914 done= False\n",
      "Step 63\n",
      "Action:  [ 1.7830495  0.3043816 -1.5444179  1.5445368  4.4975405 -0.6489087]\n",
      "self.next: 63\n",
      "obs= [[[ 2.69072927 -2.21858594 -0.28225507  0.53928213 -1.9028512\n",
      "    0.11927499]\n",
      "  [ 0.06248141 -0.01276025 -0.01468688 -0.11120299  0.13817777\n",
      "   -0.14380219]]\n",
      "\n",
      " [[ 3.30967145 -2.18991294 -1.15801405  1.11189501 -1.55832469\n",
      "   -1.30282502]\n",
      "  [ 0.12325406  0.00689839 -0.17417627  0.07984949  0.05195921\n",
      "   -0.22322871]]] reward= -2774163.9933612696 done= False\n",
      "Step 64\n",
      "Action:  [ 1.7832975   0.30426723 -1.5444248   1.5447634   4.497427   -0.6486318 ]\n",
      "self.next: 64\n",
      "obs= [[[ 2.69697741 -2.21986197 -0.28372376  0.52816184 -1.88903343\n",
      "    0.10489477]\n",
      "  [ 0.02360977  0.06931237 -0.09341885 -0.21723011  0.200061\n",
      "    0.00752972]]\n",
      "\n",
      " [[ 3.32199686 -2.1892231  -1.17543168  1.11987996 -1.55312877\n",
      "   -1.32514789]\n",
      "  [ 0.12332577  0.00746597 -0.17486145  0.08027338  0.05144096\n",
      "   -0.22327054]]] reward= -3250862.023143128 done= False\n",
      "Step 65\n",
      "Action:  [ 1.7829949   0.30439797 -1.544143    1.5445149   4.4964457  -0.6485341 ]\n",
      "self.next: 65\n",
      "obs= [[[ 2.69933838 -2.21293073 -0.29306564  0.50643883 -1.86902733\n",
      "    0.10564774]\n",
      "  [-0.0137507   0.05627841 -0.04232637 -0.1387594   0.1843329\n",
      "   -0.19480845]]\n",
      "\n",
      " [[ 3.33432943 -2.1884765  -1.19291783  1.1279073  -1.54798468\n",
      "   -1.34747495]\n",
      "  [ 0.12337045  0.00804736 -0.17553546  0.08069451  0.05093157\n",
      "   -0.22331169]]] reward= -3236583.927288601 done= False\n",
      "Step 66\n",
      "Action:  [ 1.783299   0.3043476 -1.5443939  1.5448519  4.4971547 -0.6485427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 66\n",
      "obs= [[[ 2.69796331 -2.20730289 -0.29729828  0.49256289 -1.85059404\n",
      "    0.08616689]\n",
      "  [-0.04864538 -0.02368886  0.07051942 -0.06332259  0.01879615\n",
      "   -0.00337875]]\n",
      "\n",
      " [[ 3.34666648 -2.18767177 -1.21047137  1.13597675 -1.54289152\n",
      "   -1.36980612]\n",
      "  [ 0.12338868  0.00864166 -0.17619796  0.08111288  0.0504309\n",
      "   -0.22335201]]] reward= -2713143.656724659 done= False\n",
      "Step 67\n",
      "Action:  [ 1.7837483   0.30445462 -1.5449834   1.5453058   4.4990616  -0.64896876]\n",
      "self.next: 67\n",
      "obs= [[[ 2.69309878 -2.20967177 -0.29024634  0.48623063 -1.84871442\n",
      "    0.08582902]\n",
      "  [-0.02286507  0.05125267 -0.06192423 -0.10395656  0.0719754\n",
      "    0.00937784]]\n",
      "\n",
      " [[ 3.35900534 -2.1868076  -1.22809117  1.14408803 -1.53784843\n",
      "   -1.39214132]\n",
      "  [ 0.12338105  0.00924799 -0.17684866  0.08152847  0.04993881\n",
      "   -0.22339134]]] reward= -2866408.082512261 done= False\n",
      "Step 68\n",
      "Action:  [ 1.7838396   0.30452675 -1.5449854   1.5454282   4.4989924  -0.64891464]\n",
      "self.next: 68\n",
      "obs= [[[ 2.69081227 -2.20454651 -0.29643876  0.47583497 -1.84151688\n",
      "    0.0867668 ]\n",
      "  [-0.01361088  0.05298625 -0.04119618 -0.13604247  0.13774249\n",
      "    0.00359328]]\n",
      "\n",
      " [[ 3.37134345 -2.1858828  -1.24577603  1.15224088 -1.53285455\n",
      "   -1.41448045]\n",
      "  [ 0.12334817  0.0098654  -0.17748726  0.08194128  0.04945514\n",
      "   -0.22342953]]] reward= -2895558.4015676705 done= False\n",
      "Step 69\n",
      "Action:  [ 1.7837934   0.30455452 -1.5449165   1.5454098   4.498698   -0.6488418 ]\n",
      "self.next: 69\n",
      "obs= [[[ 2.68945118 -2.19924788 -0.30055838  0.46223072 -1.82774263\n",
      "    0.08712613]\n",
      "  [-0.01080955 -0.08396335 -0.05265752  0.158225    0.10477995\n",
      "   -0.23722284]]\n",
      "\n",
      " [[ 3.38367827 -2.18489626 -1.26352476  1.16043501 -1.52790903\n",
      "   -1.4368234 ]\n",
      "  [ 0.12329067  0.01049298 -0.17811348  0.08235131  0.04897978\n",
      "   -0.22346637]]] reward= -2558400.2554769 done= False\n",
      "Step 70\n",
      "Action:  [ 1.7844621   0.30437207 -1.5454704   1.5460286   4.5006905  -0.64902425]\n",
      "self.next: 70\n",
      "obs= [[[ 2.68837022 -2.20764422 -0.30582413  0.47805322 -1.81726464\n",
      "    0.06340385]\n",
      "  [ 0.0458809  -0.00785464 -0.03718596 -0.07620334  0.18737839\n",
      "   -0.15075564]]\n",
      "\n",
      " [[ 3.39600733 -2.18384697 -1.28133611  1.16867014 -1.52301105\n",
      "   -1.45917004]\n",
      "  [ 0.1232092   0.01112976 -0.17872705  0.08275854  0.04851258\n",
      "   -0.22350168]]] reward= -4736765.020101819 done= False\n",
      "Step 71\n",
      "Action:  [ 1.7842735   0.30452517 -1.5452957   1.5459055   4.4997954  -0.64888155]\n",
      "self.next: 71\n",
      "obs= [[[ 2.69295831 -2.20842968 -0.30954273  0.47043289 -1.7985268\n",
      "    0.04832828]\n",
      "  [-0.08914539 -0.01146023  0.13302287 -0.01421181 -0.1768269\n",
      "    0.03024126]]\n",
      "\n",
      " [[ 3.40832825 -2.18273399 -1.29920881  1.17694599 -1.5181598\n",
      "   -1.48152021]\n",
      "  [ 0.12310441  0.01177477 -0.1793277   0.08316298  0.04805342\n",
      "   -0.22353523]]] reward= -2737367.53844059 done= False\n",
      "Step 72\n",
      "Action:  [ 1.7844268   0.30467543 -1.5456884   1.5461205   4.5010405  -0.6492704 ]\n",
      "self.next: 72\n",
      "obs= [[[ 2.68404378e+00 -2.20957570e+00 -2.96240439e-01  4.69011708e-01\n",
      "   -1.81620949e+00  5.13524080e-02]\n",
      "  [ 3.14381273e-02 -7.21639829e-04 -6.14524535e-02 -4.56831284e-02\n",
      "    1.22789887e-01  9.19244753e-02]]\n",
      "\n",
      " [[ 3.42063870e+00 -2.18155651e+00 -1.31714158e+00  1.18526229e+00\n",
      "   -1.51335445e+00 -1.50387373e+00]\n",
      "  [ 1.22976979e-01  1.24270319e-02 -1.79915187e-01  8.35646167e-02\n",
      "    4.76021660e-02 -2.23566779e-01]]] reward= -4057628.558140213 done= False\n",
      "Step 73\n",
      "Action:  [ 1.7846208   0.3046967  -1.5456823   1.5462906   4.50102    -0.64916676]\n",
      "self.next: 73\n",
      "obs= [[[ 2.68718759 -2.20964787 -0.30238568  0.4644434  -1.8039305\n",
      "    0.06054486]\n",
      "  [ 0.04554123 -0.00689526 -0.0401034  -0.07745471  0.13891233\n",
      "    0.05062073]]\n",
      "\n",
      " [[ 3.43293639 -2.18031381 -1.3351331   1.19361875 -1.50859424\n",
      "   -1.52623041]\n",
      "  [ 0.1228276   0.01308554 -0.18048928  0.08396345  0.04715871\n",
      "   -0.22359608]]] reward= -3359314.1776401745 done= False\n",
      "Step 74\n",
      "Action:  [ 1.7846818   0.30471626 -1.5457262   1.5463772   4.5010586  -0.6491355 ]\n",
      "self.next: 74\n",
      "obs= [[[ 2.69174171 -2.21033739 -0.30639602  0.45669792 -1.79003927\n",
      "    0.06560693]\n",
      "  [ 0.0686991  -0.07245003  0.1894736  -0.28648884  0.05627806\n",
      "    0.2199402 ]]\n",
      "\n",
      " [[ 3.44521915 -2.17900526 -1.35318203  1.2020151  -1.50387837\n",
      "   -1.54859002]\n",
      "  [ 0.12265699  0.01374929 -0.18104974  0.08435947  0.04672293\n",
      "   -0.22362285]]] reward= -3285296.3371316115 done= False\n",
      "Step 75\n",
      "Action:  [ 1.7840806   0.30482474 -1.5453193   1.5458772   4.49959    -0.6490233 ]\n",
      "self.next: 75\n",
      "obs= [[[ 2.69861162 -2.2175824  -0.28744866  0.42804904 -1.78441146\n",
      "    0.08760095]\n",
      "  [ 0.01691869  0.06783616 -0.23402986  0.08896223  0.10536813\n",
      "   -0.10480896]]\n",
      "\n",
      " [[ 3.45748485 -2.17763033 -1.371287    1.21045105 -1.49920607\n",
      "   -1.5709523 ]\n",
      "  [ 0.12246586  0.01441723 -0.18159636  0.08475266  0.04629472\n",
      "   -0.22364681]]] reward= -5226795.549308423 done= False\n",
      "Step 76\n",
      "Action:  [ 1.7852434  0.3047148 -1.5461309  1.5469589  4.502366  -0.6492335]\n",
      "self.next: 76\n",
      "obs= [[[ 2.70030349 -2.21079878 -0.31085165  0.43694526 -1.77387465\n",
      "    0.07712005]\n",
      "  [ 0.04135747 -0.01807761  0.01079819 -0.11610913  0.13371329\n",
      "   -0.06028386]]\n",
      "\n",
      " [[ 3.46973144 -2.1761886  -1.38944664  1.21892631 -1.4945766\n",
      "   -1.59331698]\n",
      "  [ 0.12225496  0.01508834 -0.18212893  0.08514302  0.04587398\n",
      "   -0.22366763]]] reward= -3795714.2212592247 done= False\n",
      "Step 77\n",
      "Action:  [ 1.7849408   0.30477813 -1.5459459   1.5467114   4.5015225  -0.64911675]\n",
      "self.next: 77\n",
      "obs= [[[ 2.70443924 -2.21260654 -0.30977183  0.42533435 -1.76050332\n",
      "    0.07109167]\n",
      "  [-0.05921801  0.03510171 -0.01080292 -0.01980122 -0.1009276\n",
      "    0.23414325]]\n",
      "\n",
      " [[ 3.48195693 -2.17467977 -1.40765953  1.22744061 -1.48998921\n",
      "   -1.61568375]\n",
      "  [ 0.12202504  0.01576154 -0.18264725  0.08553051  0.04546062\n",
      "   -0.22368499]]] reward= -2929800.412457337 done= False\n",
      "Step 78\n",
      "Action:  [ 1.7850311   0.30494523 -1.5461736   1.5468557   4.5023804  -0.64944315]\n",
      "self.next: 78\n",
      "obs= [[[ 2.69851744 -2.20909637 -0.31085212  0.42335423 -1.77059608\n",
      "    0.09450599]\n",
      "  [ 0.03542915 -0.02878693  0.02740957 -0.11701103  0.13334055\n",
      "    0.13929952]]\n",
      "\n",
      " [[ 3.49415944 -2.17310362 -1.42592426  1.23599367 -1.48544314\n",
      "   -1.63805224]\n",
      "  [ 0.12177688  0.01643577 -0.18315114  0.08591513  0.04505455\n",
      "   -0.22369854]]] reward= -3389726.6321132374 done= False\n",
      "Step 79\n",
      "Action:  [ 1.7849956  0.3049036 -1.5460327  1.5468142  4.5017934 -0.6492293]\n",
      "self.next: 79\n",
      "obs= [[[ 2.70206035e+00 -2.21197506e+00 -3.08111166e-01  4.11653125e-01\n",
      "   -1.75726202e+00  1.08435944e-01]\n",
      "  [ 1.97929170e-03  2.94252381e-03 -4.95809419e-03 -2.40421359e-03\n",
      "    3.53340276e-04 -1.42057191e-01]]\n",
      "\n",
      " [[ 3.50633713e+00 -2.17146004e+00 -1.44423937e+00  1.24458518e+00\n",
      "   -1.48093769e+00 -1.66042210e+00]\n",
      "  [ 1.21511263e-01  1.71099487e-02 -1.83640416e-01  8.62968365e-02\n",
      "    4.46556903e-02 -2.23707909e-01]]] reward= -4106662.6427478096 done= False\n",
      "Step 80\n",
      "Action:  [ 1.7854904   0.30484205 -1.5464468   1.5473096   4.5030518  -0.6493107 ]\n",
      "self.next: 80\n",
      "obs= [[[ 2.70225828 -2.21168081 -0.30860698  0.4114127  -1.75722669\n",
      "    0.09423023]\n",
      "  [ 0.04192012 -0.00982201 -0.03069703 -0.08446062  0.19045981\n",
      "   -0.08818305]]\n",
      "\n",
      " [[ 3.51848825 -2.16974904 -1.46260341  1.25321486 -1.47647212\n",
      "   -1.68279289]\n",
      "  [ 0.121229    0.01778297 -0.18411491  0.0866756   0.04426397\n",
      "   -0.22371271]]] reward= -3030258.9921157416 done= False\n",
      "Step 81\n",
      "Action:  [ 1.7853081  0.3048752 -1.5462162  1.5471591  4.5022273 -0.6491402]\n",
      "self.next: 81\n",
      "obs= [[[ 2.70645029 -2.21266301 -0.31167668  0.40296664 -1.73818071\n",
      "    0.08541192]\n",
      "  [ 0.01787527 -0.10807395  0.24260603 -0.18211579  0.03074767\n",
      "   -0.0169593 ]]\n",
      "\n",
      " [[ 3.53061115 -2.16797075 -1.4810149   1.26188242 -1.47204572\n",
      "   -1.70516416]\n",
      "  [ 0.12093092  0.01845373 -0.18457447  0.08705136  0.04387931\n",
      "   -0.22371254]]] reward= -3359652.626805243 done= False\n",
      "Step 82\n",
      "Action:  [ 1.7851678   0.30494243 -1.5462447   1.5470626   4.502205   -0.6492132 ]\n",
      "self.next: 82\n",
      "obs= [[[ 2.70823782 -2.22347041 -0.28741608  0.38475506 -1.73510594\n",
      "    0.08371599]\n",
      "  [-0.00490647  0.03908922 -0.18742233  0.12347823  0.09618276\n",
      "   -0.13569776]]\n",
      "\n",
      " [[ 3.54270424 -2.16612537 -1.49947235  1.27058756 -1.46765779\n",
      "   -1.72753541]\n",
      "  [ 0.12061786  0.0191211  -0.18501895  0.08742409  0.04350167\n",
      "   -0.22370697]]] reward= -4669307.668770972 done= False\n",
      "Step 83\n",
      "Action:  [ 1.7859546   0.30490208 -1.5467763   1.547819    4.5040917  -0.64940166]\n",
      "self.next: 83\n",
      "obs= [[[ 2.70774717 -2.21956149 -0.30615831  0.39710289 -1.72548767\n",
      "    0.07014621]\n",
      "  [-0.09935684  0.0333051  -0.00455059 -0.00603498 -0.19808478\n",
      "    0.49581941]]\n",
      "\n",
      " [[ 3.55476603 -2.16421326 -1.51797425  1.27932997 -1.46330762\n",
      "   -1.74990611]\n",
      "  [ 0.12029068  0.01978397 -0.18544822  0.08779372  0.04313098\n",
      "   -0.22369557]]] reward= -4291225.396009486 done= False\n",
      "Step 84\n",
      "Action:  [ 1.7850341  0.3051967 -1.5462196  1.5470676  4.5024376 -0.6495141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 84\n",
      "obs= [[[ 2.69781149 -2.21623098 -0.30661337  0.39649939 -1.74529615\n",
      "    0.11972816]\n",
      "  [ 0.01585851 -0.05144362  0.07129608 -0.03674338  0.1736679\n",
      "   -0.2328522 ]]\n",
      "\n",
      " [[ 3.5667951  -2.16223487 -1.53651907  1.28810934 -1.45899453\n",
      "   -1.77227567]\n",
      "  [ 0.11995027  0.02044118 -0.18586215  0.08816019  0.0427672\n",
      "   -0.22367788]]] reward= -4960608.542736698 done= False\n",
      "Step 85\n",
      "Action:  [ 1.7855629   0.30490643 -1.5464233   1.5474969   4.502726   -0.64911515]\n",
      "self.next: 85\n",
      "obs= [[[ 2.69939734e+00 -2.22137534e+00 -2.99483758e-01  3.92825049e-01\n",
      "   -1.72792936e+00  9.64429348e-02]\n",
      "  [-9.38290731e-04 -6.48915285e-02  6.58130962e-02 -3.82306929e-03\n",
      "    8.03721957e-03 -4.09606587e-02]]\n",
      "\n",
      " [[ 3.57879013e+00 -2.16019075e+00 -1.55510528e+00  1.29692536e+00\n",
      "   -1.45471781e+00 -1.79464346e+00]\n",
      "  [ 1.19597524e-01  2.10915876e-02 -1.86260635e-01  8.85234163e-02\n",
      "    4.24102983e-02 -2.23653430e-01]]] reward= -3920115.803610058 done= False\n",
      "Step 86\n",
      "Action:  [ 1.7860264   0.30503118 -1.5469522   1.5479567   4.504439   -0.64948195]\n",
      "self.next: 86\n",
      "obs= [[[ 2.69930351 -2.22786449 -0.29290245  0.39244274 -1.72712563\n",
      "    0.09234687]\n",
      "  [-0.08045065  0.10321462  0.00974127 -0.27090235  0.12572158\n",
      "    0.22570308]]\n",
      "\n",
      " [[ 3.59074988 -2.15808159 -1.57373135  1.3057777  -1.45047678\n",
      "   -1.8170088 ]\n",
      "  [ 0.11923336  0.02173405 -0.18664358  0.08888332  0.04206023\n",
      "   -0.22362174]]] reward= -2968951.24618384 done= False\n",
      "Step 87\n",
      "Action:  [ 1.7849529   0.30524084 -1.545958    1.5470781   4.501064   -0.64905846]\n",
      "self.next: 87\n",
      "obs= [[[ 2.69125845 -2.21754303 -0.29192832  0.36535251 -1.71455348\n",
      "    0.11491718]\n",
      "  [-0.02659492 -0.04722456  0.07697913 -0.08803223  0.08711716\n",
      "   -0.06908641]]\n",
      "\n",
      " [[ 3.60267321 -2.15590819 -1.59239571  1.31466603 -1.44627075\n",
      "   -1.83937097]\n",
      "  [ 0.11885872  0.02236739 -0.1870109   0.08923981  0.04171696\n",
      "   -0.2235823 ]]] reward= -4370551.077657369 done= False\n",
      "Step 88\n",
      "Action:  [ 1.78585    0.3050869 -1.5467414  1.5478601  4.503618  -0.6492949]\n",
      "self.next: 88\n",
      "obs= [[[ 2.68859895 -2.22226548 -0.28423041  0.35654928 -1.70584176\n",
      "    0.10800854]\n",
      "  [ 0.072085    0.06373453 -0.1421953  -0.17853112  0.34158416\n",
      "   -0.18327694]]\n",
      "\n",
      " [[ 3.61455909 -2.15367145 -1.6110968   1.32359001 -1.44209906\n",
      "   -1.8617292 ]\n",
      "  [ 0.11847455  0.02299046 -0.18736252  0.08959277  0.04138048\n",
      "   -0.22353462]]] reward= -3151256.3049822864 done= False\n",
      "Step 89\n",
      "Action:  [ 1.785469    0.30507734 -1.5462056   1.5475739   4.5017185  -0.6488562 ]\n",
      "self.next: 89\n",
      "obs= [[[ 2.69580745 -2.21589203 -0.29844994  0.33869617 -1.67168334\n",
      "    0.08968084]\n",
      "  [-0.05199791  0.15016335 -0.31601174  0.08435858  0.02566413\n",
      "    0.280585  ]]\n",
      "\n",
      " [[ 3.62640654 -2.1513724  -1.62983305  1.33254929 -1.43796101\n",
      "   -1.88408267]\n",
      "  [ 0.11808185  0.0236021  -0.18769841  0.08994211  0.04105076\n",
      "   -0.22347818]]] reward= -4434738.650883231 done= False\n",
      "Step 90\n",
      "Action:  [ 1.7860396   0.30528954 -1.5468942   1.5481708   4.504268   -0.6495314 ]\n",
      "self.next: 90\n",
      "obs= [[[ 2.69060766 -2.2008757  -0.33005111  0.34713203 -1.66911693\n",
      "    0.11773934]\n",
      "  [ 0.0302028  -0.01863233 -0.01192243 -0.08127853  0.23637687\n",
      "   -0.24137917]]\n",
      "\n",
      " [[ 3.63821473 -2.14901219 -1.64860289  1.3415435  -1.43385593\n",
      "   -1.90643048]\n",
      "  [ 0.11768159  0.02420113 -0.18801851  0.0902877   0.04072779\n",
      "   -0.22341244]]] reward= -6035141.9664461 done= False\n",
      "Step 91\n",
      "Action:  [ 1.7858287   0.30507973 -1.5466131   1.5479466   4.5029936  -0.64905626]\n",
      "self.next: 91\n",
      "obs= [[[ 2.69362794e+00 -2.20273893e+00 -3.31243356e-01  3.39004177e-01\n",
      "   -1.64547924e+00  9.36014251e-02]\n",
      "  [ 8.25154115e-05 -1.16118456e-02  1.19624566e-02 -3.48862090e-03\n",
      "    2.47384341e-03  5.90540612e-02]]\n",
      "\n",
      " [[ 3.64998288e+00 -2.14659208e+00 -1.66740474e+00  1.35057227e+00\n",
      "   -1.42978315e+00 -1.92877173e+00]\n",
      "  [ 1.17274807e-01  2.47864077e-02 -1.88322819e-01  9.06293959e-02\n",
      "    4.04115619e-02 -2.23336879e-01]]] reward= -3623713.383927681 done= False\n",
      "Step 92\n",
      "Action:  [ 1.7863988   0.30525142 -1.5472887   1.5485055   4.505244   -0.64958054]\n",
      "self.next: 92\n",
      "obs= [[[ 2.69363619 -2.20390011 -0.33004711  0.33865532 -1.64523186\n",
      "    0.09950683]\n",
      "  [ 0.00548495  0.03241449 -0.00825369 -0.0759049   0.04720103\n",
      "   -0.0217012 ]]\n",
      "\n",
      " [[ 3.66171037 -2.14411344 -1.68623702  1.35963521 -1.425742\n",
      "   -1.95110541]\n",
      "  [ 0.11686252  0.02535677 -0.18861133  0.09096707  0.04010206\n",
      "   -0.22325096]]] reward= -3292948.597740548 done= False\n",
      "Step 93\n",
      "Action:  [ 1.7862962   0.30527246 -1.547151    1.5484577   4.5046406  -0.6494277 ]\n",
      "self.next: 93\n",
      "obs= [[[ 2.69418469 -2.20065866 -0.33087248  0.33106483 -1.64051176\n",
      "    0.09733671]\n",
      "  [ 0.03056006  0.01710145 -0.07766315 -0.00650429  0.03858088\n",
      "    0.12073577]]\n",
      "\n",
      " [[ 3.67339662 -2.14157776 -1.70509815  1.36873192 -1.42173179\n",
      "   -1.97343051]\n",
      "  [ 0.11644579  0.02591106 -0.18888407  0.09130058  0.03979928\n",
      "   -0.22315414]]] reward= -3325625.2413697666 done= False\n",
      "Step 94\n",
      "Action:  [ 1.7865196  0.3053281 -1.547365   1.5486894  4.5054145 -0.6495918]\n",
      "self.next: 94\n",
      "obs= [[[ 2.69724069e+00 -2.19894852e+00 -3.38638794e-01  3.30414396e-01\n",
      "   -1.63665367e+00  1.09410289e-01]\n",
      "  [-8.85681671e-04 -2.94260239e-02  3.00078284e-02  6.00025694e-04\n",
      "    1.24470181e-03  2.32835222e-02]]\n",
      "\n",
      " [[ 3.68504120e+00 -2.13898665e+00 -1.72398656e+00  1.37786198e+00\n",
      "   -1.41775186e+00 -1.99574592e+00]\n",
      "  [ 1.16025679e-01  2.64481533e-02 -1.89141068e-01  9.16297454e-02\n",
      "    3.95032242e-02 -2.23045883e-01]]] reward= -3849023.3213380054 done= False\n",
      "Step 95\n",
      "Action:  [ 1.7865535   0.30530235 -1.5474122   1.5487219   4.505519   -0.64957345]\n",
      "self.next: 95\n",
      "obs= [[[ 2.69715213 -2.20189112 -0.33563801  0.3304744  -1.6365292\n",
      "    0.11173864]\n",
      "  [ 0.00904662 -0.18924603  0.35191207 -0.07398151 -0.04537238\n",
      "   -0.04051874]]\n",
      "\n",
      " [[ 3.69664376 -2.13634184 -1.74290067  1.38702495 -1.41380154\n",
      "   -2.01805051]\n",
      "  [ 0.11560327  0.02696692 -0.18938239  0.09195441  0.03921388\n",
      "   -0.22292565]]] reward= -3350534.9447831437 done= False\n",
      "Step 96\n",
      "Action:  [ 1.7862363   0.30526447 -1.5471932   1.5484117   4.504774   -0.64943933]\n",
      "self.next: 96\n",
      "obs= [[[ 2.69805679 -2.22081573 -0.3004468   0.32307625 -1.64106644\n",
      "    0.10768677]\n",
      "  [-0.01515374 -0.00906918 -0.12556602  0.22760203 -0.12522148\n",
      "    0.21221952]]\n",
      "\n",
      " [[ 3.70820409 -2.13364515 -1.76183891  1.39622039 -1.40988015\n",
      "   -2.04034308]\n",
      "  [ 0.11517966  0.02746626 -0.18960813  0.09227441  0.03893126\n",
      "   -0.22279289]]] reward= -5302187.251281484 done= False\n",
      "Step 97\n",
      "Action:  [ 1.7870218   0.30536425 -1.547846    1.5491956   4.507171   -0.6499025 ]\n",
      "self.next: 97\n",
      "obs= [[[ 2.69654141 -2.22172264 -0.31300341  0.34583645 -1.65358858\n",
      "    0.12890872]\n",
      "  [-0.02975753  0.07437411 -0.04565778 -0.17275251  0.22315784\n",
      "   -0.10376574]]\n",
      "\n",
      " [[ 3.71972206 -2.13089852 -1.78079972  1.40544783 -1.40598703\n",
      "   -2.06262237]\n",
      "  [ 0.11475596  0.02794508 -0.18981838  0.09258954  0.03865536\n",
      "   -0.2226471 ]]] reward= -5480124.65213286 done= False\n",
      "Step 98\n",
      "Action:  [ 1.7860215   0.30536187 -1.5467798   1.5483639   4.5031137  -0.64904964]\n",
      "self.next: 98\n",
      "obs= [[[ 2.69356566e+00 -2.21428523e+00 -3.17569184e-01  3.28561198e-01\n",
      "   -1.63127280e+00  1.18532145e-01]\n",
      "  [ 5.77537291e-02 -9.12960621e-02  3.17463228e-02 -1.70866779e-03\n",
      "    1.16110426e-01 -2.19079077e-02]]\n",
      "\n",
      " [[ 3.73119765e+00 -2.12810401e+00 -1.79978156e+00  1.41470679e+00\n",
      "   -1.40212149e+00 -2.08488708e+00]\n",
      "  [ 1.14333289e-01  2.84023096e-02 -1.90013284e-01  9.28996147e-02\n",
      "    3.83861645e-02 -2.22487736e-01]]] reward= -3784924.0105861328 done= False\n",
      "Step 99\n",
      "Action:  [ 1.7868252   0.30534333 -1.5475974   1.5490644   4.505953   -0.6495299 ]\n",
      "self.next: 99\n",
      "obs= [[[ 2.69934103e+00 -2.22341484e+00 -3.14394552e-01  3.28390331e-01\n",
      "   -1.61966176e+00  1.16341354e-01]\n",
      "  [-5.11404829e-02  4.69888209e-02  5.56855824e-03 -5.15124674e-02\n",
      "    3.33532043e-03  1.43254008e-01]]\n",
      "\n",
      " [[ 3.74263098e+00 -2.12526378e+00 -1.81878289e+00  1.42399675e+00\n",
      "   -1.39828287e+00 -2.10713585e+00]\n",
      "  [ 1.13912778e-01  2.88369162e-02 -1.90192986e-01  9.32044384e-02\n",
      "    3.81236849e-02 -2.22314293e-01]]] reward= -4637359.769961162 done= False\n",
      "Step 100\n",
      "Action:  [ 1.7866068   0.30549964 -1.5474464   1.5489496   4.505377   -0.64954007]\n",
      "self.next: 100\n",
      "obs= [[[ 2.69422699e+00 -2.21871596e+00 -3.13837696e-01  3.23239085e-01\n",
      "   -1.61932823e+00  1.30666755e-01]\n",
      "  [ 6.59078002e-02 -6.71345743e-02  1.54650345e-03 -1.59443828e-03\n",
      "    5.93769229e-02  3.13489302e-02]]\n",
      "\n",
      " [[ 3.75402226e+00 -2.12238009e+00 -1.83780219e+00  1.43331719e+00\n",
      "   -1.39447050e+00 -2.12936728e+00]\n",
      "  [ 1.13495564e-01  2.92478869e-02 -1.90357669e-01  9.35038021e-02\n",
      "    3.78679134e-02 -2.22126272e-01]]] reward= -3755397.3741890183 done= False\n",
      "Step 101\n",
      "Action:  [ 1.7870032   0.3054217  -1.547769    1.5492932   4.506431   -0.64961165]\n",
      "self.next: 101\n",
      "obs= [[[ 2.70081777 -2.22542941 -0.31368305  0.32307964 -1.61339053\n",
      "    0.13380165]\n",
      "  [-0.03345015  0.08856756 -0.05554631 -0.12717352  0.07203558\n",
      "    0.00594021]]\n",
      "\n",
      " [[ 3.76537182 -2.1194553  -1.85683795  1.44266757 -1.39068371\n",
      "   -2.15157991]\n",
      "  [ 0.11308279  0.02963424 -0.19050754  0.09379749  0.03761884\n",
      "   -0.22192319]]] reward= -4265639.57753953 done= False\n",
      "Step 102\n",
      "Action:  [ 1.7865472   0.3055135  -1.5473211   1.5489697   4.5047417  -0.64933705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 102\n",
      "obs= [[[ 2.69747275e+00 -2.21657266e+00 -3.19237676e-01  3.10362289e-01\n",
      "   -1.60618698e+00  1.34395668e-01]\n",
      "  [-3.02397323e-03 -2.88313865e-02  3.26883475e-02 -1.95216665e-03\n",
      "    2.21132373e-03  1.94112151e-02]]\n",
      "\n",
      " [[ 3.77668010e+00 -2.11649188e+00 -1.87588871e+00  1.45204732e+00\n",
      "   -1.38692183e+00 -2.17377223e+00]\n",
      "  [ 1.12675593e-01  2.99950429e-02 -1.90642826e-01  9.40852937e-02\n",
      "    3.73764687e-02 -2.21704564e-01]]] reward= -3375806.2427756377 done= False\n",
      "Step 103\n",
      "Action:  [ 1.7869645   0.30548155 -1.5477449   1.5493208   4.506263   -0.6495846 ]\n",
      "self.next: 103\n",
      "obs= [[[ 2.69717035e+00 -2.21945580e+00 -3.15968841e-01  3.10167073e-01\n",
      "   -1.60596584e+00  1.36336790e-01]\n",
      "  [ 2.31947499e-02 -3.76917207e-03 -4.95528441e-02 -1.08849891e-02\n",
      "    2.50737004e-01 -3.77750172e-01]]\n",
      "\n",
      " [[ 3.78794765e+00 -2.11349237e+00 -1.89495299e+00  1.46145585e+00\n",
      "   -1.38318418e+00 -2.19594268e+00]\n",
      "  [ 1.12275124e-01  3.03293821e-02 -1.90763786e-01  9.43669795e-02\n",
      "    3.71407758e-02 -2.21469958e-01]]] reward= -3689706.7569044507 done= False\n",
      "Step 104\n",
      "Action:  [ 1.7863839   0.30531478 -1.5470392   1.54884     4.5038066  -0.6489799 ]\n",
      "self.next: 104\n",
      "obs= [[[ 2.69948983e+00 -2.21983271e+00 -3.20924126e-01  3.09078574e-01\n",
      "   -1.58089214e+00  9.85617726e-02]\n",
      "  [ 3.61826196e-03 -1.07687208e-02  3.72159576e-02 -7.59020726e-02\n",
      "   -8.02829133e-03  1.32381218e-01]]\n",
      "\n",
      " [[ 3.79917517e+00 -2.11045943e+00 -1.91402937e+00  1.47089255e+00\n",
      "   -1.37947010e+00 -2.21808968e+00]\n",
      "  [ 1.11882521e-01  3.06363992e-02 -1.90870700e-01  9.46423226e-02\n",
      "    3.69117502e-02 -2.21218938e-01]]] reward= -4532464.064667728 done= False\n",
      "Step 105\n",
      "Action:  [ 1.786919    0.30559647 -1.54773     1.54938     4.506066   -0.64957196]\n",
      "self.next: 105\n",
      "obs= [[[ 2.69985166 -2.22090959 -0.31720253  0.30148837 -1.58169497\n",
      "    0.11179989]\n",
      "  [ 0.04031652 -0.00533821 -0.03548158 -0.0421365   0.15135289\n",
      "   -0.05268087]]\n",
      "\n",
      " [[ 3.81036342 -2.10739579 -1.93311644  1.48035678 -1.37577893\n",
      "   -2.24021157]\n",
      "  [ 0.11149892  0.03091528 -0.19096388  0.09491109  0.03668937\n",
      "   -0.2209511 ]]] reward= -3802196.309659308 done= False\n",
      "Step 106\n",
      "Action:  [ 1.7869656  0.3055229 -1.5476764  1.5494374  4.5058    -0.6494076]\n",
      "self.next: 106\n",
      "obs= [[[ 2.70388331 -2.22144341 -0.32075069  0.29727472 -1.56655968\n",
      "    0.10653181]\n",
      "  [-0.0609015   0.03871845  0.02252761 -0.0839973  -0.07415661\n",
      "    0.19808055]]\n",
      "\n",
      " [[ 3.82151331 -2.10430427 -1.95221283  1.48984789 -1.37210999\n",
      "   -2.26230668]\n",
      "  [ 0.11112545  0.03116525 -0.19104365  0.09517305  0.03647362\n",
      "   -0.22066605]]] reward= -4648946.5700609265 done= False\n",
      "Step 107\n",
      "Action:  [ 1.7868043   0.30568466 -1.5476383   1.5493556   4.5057144  -0.64954364]\n",
      "self.next: 107\n",
      "obs= [[[ 2.69779316 -2.21757156 -0.31849793  0.28887499 -1.57397534\n",
      "    0.12633986]\n",
      "  [ 0.01401946  0.02137746 -0.0648377  -0.05948248  0.19417101\n",
      "   -0.14193626]]\n",
      "\n",
      " [[ 3.83262586 -2.10118774 -1.97131719  1.49936519 -1.36846263\n",
      "   -2.28437329]\n",
      "  [ 0.11076321  0.0313856  -0.19111038  0.09542796  0.03626448\n",
      "   -0.22036345]]] reward= -4153287.136310195 done= False\n",
      "Step 108\n",
      "Action:  [ 1.7867924  0.3055339 -1.5474709  1.5493497  4.5050106 -0.6492203]\n",
      "self.next: 108\n",
      "obs= [[[ 2.6991951  -2.21543382 -0.3249817   0.28292674 -1.55455824\n",
      "    0.11214624]\n",
      "  [ 0.04188345  0.05164796 -0.05962418 -0.16605724  0.24229511\n",
      "   -0.02793748]]\n",
      "\n",
      " [[ 3.84370218 -2.09804918 -1.99042823  1.50890799 -1.36483618\n",
      "   -2.30640963]\n",
      "  [ 0.11041332  0.03157566 -0.19116444  0.09567558  0.03606189\n",
      "   -0.22004296]]] reward= -4598051.859029683 done= False\n",
      "Step 109\n",
      "Action:  [ 1.78662     0.30563104 -1.5473253   1.5492674   4.5043893  -0.64914024]\n",
      "self.next: 109\n",
      "obs= [[[ 2.70338345 -2.21026902 -0.33094411  0.26632102 -1.53032873\n",
      "    0.10935249]\n",
      "  [-0.02744165  0.09794093 -0.07484148 -0.16192048  0.27740879\n",
      "   -0.28617541]]\n",
      "\n",
      " [[ 3.85474351 -2.09489162 -2.00954467  1.51847555 -1.36122999\n",
      "   -2.32841393]\n",
      "  [ 0.11007685  0.03173483 -0.19120623  0.09591568  0.03586585\n",
      "   -0.21970428]]] reward= -5373311.022912122 done= False\n",
      "Step 110\n",
      "Action:  [ 1.7861918  0.3055496 -1.5468779  1.5489312  4.502792  -0.648783 ]\n",
      "self.next: 110\n",
      "obs= [[[ 2.70063928e+00 -2.20047493e+00 -3.38428263e-01  2.50128968e-01\n",
      "   -1.50258785e+00  8.07349481e-02]\n",
      "  [ 6.90472526e-02 -1.11218339e-01  3.58892057e-02  1.26563493e-01\n",
      "   -1.22603237e-02 -2.12874413e-03]]\n",
      "\n",
      " [[ 3.86575119e+00 -2.09171813e+00 -2.02866530e+00  1.52806712e+00\n",
      "   -1.35764341e+00 -2.35038436e+00]\n",
      "  [ 1.09754863e-01  3.18625461e-02 -1.91236196e-01  9.61479970e-02\n",
      "    3.56762908e-02 -2.19347153e-01]]] reward= -4352028.592218875 done= False\n",
      "Step 111\n",
      "Action:  [ 1.7875115   0.30558363 -1.5482529   1.5500408   4.5077186  -0.64971375]\n",
      "self.next: 111\n",
      "obs= [[[ 2.70754401 -2.21159676 -0.33483934  0.26278532 -1.50381389\n",
      "    0.08052207]\n",
      "  [-0.06944223  0.10869305 -0.19169172 -0.04814724  0.1534028\n",
      "    0.23147616]]\n",
      "\n",
      " [[ 3.87672668 -2.08853188 -2.04778892  1.53768192 -1.35407578\n",
      "   -2.37231907]\n",
      "  [ 0.10944839  0.03195833 -0.19125477  0.0963723   0.03549318\n",
      "   -0.21897134]]] reward= -5144689.256426748 done= False\n",
      "Step 112\n",
      "Action:  [ 1.7866797   0.30578607 -1.5474309   1.549475    4.5047913  -0.6493032 ]\n",
      "self.next: 112\n",
      "obs= [[[ 2.70059979 -2.20072746 -0.35400851  0.25797059 -1.48847361\n",
      "    0.10366969]\n",
      "  [-0.04065677  0.00759134  0.2244126  -0.31399325  0.06417998\n",
      "   -0.06741734]]\n",
      "\n",
      " [[ 3.88767152 -2.08533605 -2.06691439  1.54731915 -1.35052646\n",
      "   -2.3942162 ]\n",
      "  [ 0.10915845  0.03202176 -0.19126242  0.09658835  0.03531648\n",
      "   -0.21857664]]] reward= -7008734.67676695 done= False\n",
      "Step 113\n",
      "Action:  [ 1.786282    0.30573824 -1.5471141   1.5490843   4.5034366  -0.6489767 ]\n",
      "self.next: 113\n",
      "obs= [[[ 2.69653411 -2.19996832 -0.33156725  0.22657127 -1.48205561\n",
      "    0.09692796]\n",
      "  [-0.02038029 -0.00746342 -0.19373345  0.34085    -0.11621405\n",
      "   -0.04144045]]\n",
      "\n",
      " [[ 3.89858736 -2.08213387 -2.08604063  1.55697798 -1.34699481\n",
      "   -2.41607387]\n",
      "  [ 0.10888601  0.03205245 -0.19125963  0.09679589  0.03514611\n",
      "   -0.21816288]]] reward= -5520676.203858723 done= False\n",
      "Step 114\n",
      "Action:  [ 1.7874953   0.30557793 -1.5481746   1.5501184   4.507624   -0.6497026 ]\n",
      "self.next: 114\n",
      "obs= [[[ 2.69449608 -2.20071466 -0.3509406   0.26065627 -1.49367701\n",
      "    0.09278391]\n",
      "  [ 0.05723959 -0.07431286  0.01867202  0.03507842  0.12572841\n",
      "   -0.12210121]]\n",
      "\n",
      " [[ 3.90947597 -2.07892862 -2.1051666   1.56665757 -1.3434802\n",
      "   -2.43789016]\n",
      "  [ 0.10863201  0.03205012 -0.1912469   0.09699468  0.03498204\n",
      "   -0.21772993]]] reward= -6314410.987252196 done= False\n",
      "Step 115\n",
      "Action:  [ 1.7872221   0.30563673 -1.5479151   1.549925    4.506296   -0.64937395]\n",
      "self.next: 115\n",
      "obs= [[[ 2.70022004e+00 -2.20814595e+00 -3.49073397e-01  2.64164110e-01\n",
      "   -1.48110417e+00  8.05737900e-02]\n",
      "  [ 3.53221501e-03 -7.13835553e-03 -2.90448795e-05  5.57080080e-03\n",
      "   -5.68828052e-02  2.28975660e-01]]\n",
      "\n",
      " [[ 3.92033917e+00 -2.07572361e+00 -2.12429129e+00  1.57635704e+00\n",
      "   -1.33998200e+00 -2.45966315e+00]\n",
      "  [ 1.08397373e-01  3.20145234e-02 -1.91224748e-01  9.71844856e-02\n",
      "    3.48241862e-02 -2.17277702e-01]]] reward= -5147880.2052569585 done= False\n",
      "Step 116\n",
      "Action:  [ 1.7872186   0.30583188 -1.5480036   1.5500122   4.5066195  -0.64958596]\n",
      "self.next: 116\n",
      "obs= [[[ 2.70057326 -2.20885979 -0.3490763   0.26472119 -1.48679245\n",
      "    0.10347136]\n",
      "  [-0.06982777  0.02057072  0.04853181 -0.03736869 -0.06678844\n",
      "    0.1750463 ]]\n",
      "\n",
      " [[ 3.9311789  -2.07252216 -2.14341376  1.58607549 -1.33649958\n",
      "   -2.48139092]\n",
      "  [ 0.10818295  0.03194549 -0.19119369  0.09736506  0.0346725\n",
      "   -0.21680613]]] reward= -4460945.077346651 done= False\n",
      "Step 117\n",
      "Action:  [ 1.7870119   0.30585167 -1.5478053   1.5498493   4.5058885  -0.64945334]\n",
      "self.next: 117\n",
      "obs= [[[ 2.69359048e+00 -2.20680271e+00 -3.44223121e-01  2.60984322e-01\n",
      "   -1.49347130e+00  1.20975986e-01]\n",
      "  [ 3.00773132e-03 -5.93684124e-02  5.73035619e-02 -1.87506961e-03\n",
      "    4.95074401e-02 -1.08180426e-01]]\n",
      "\n",
      " [[ 3.94199720e+00 -2.06932761e+00 -2.16253313e+00  1.59581199e+00\n",
      "   -1.33303233e+00 -2.50307153e+00]\n",
      "  [ 1.07989579e-01  3.18429280e-02 -1.91154262e-01  9.75361670e-02\n",
      "    3.45269043e-02 -2.16315187e-01]]] reward= -4222930.923682865 done= False\n",
      "Step 118\n",
      "Action:  [ 1.7871766   0.30571303 -1.5478815   1.5499659   4.506074   -0.6493294 ]\n",
      "self.next: 118\n",
      "obs= [[[ 2.69389126 -2.21273956 -0.33849276  0.26079681 -1.48852055\n",
      "    0.11015794]\n",
      "  [-0.04178564  0.07197081 -0.03303085 -0.11611657  0.06694934\n",
      "    0.05695071]]\n",
      "\n",
      " [[ 3.95279616 -2.06614332 -2.18164856  1.60556561 -1.32957964\n",
      "   -2.52470305]\n",
      "  [ 0.10781803  0.03170679 -0.19110701  0.09769756  0.03438733\n",
      "   -0.21580489]]] reward= -4275802.240793243 done= False\n",
      "Step 119\n",
      "Action:  [ 1.7868855   0.30586913 -1.547613    1.5498307   4.5049987  -0.6492087 ]\n",
      "self.next: 119\n",
      "obs= [[[ 2.68971269 -2.20554248 -0.34179585  0.24918516 -1.48182562\n",
      "    0.11585301]\n",
      "  [ 0.01353223 -0.21527372  0.32969808  0.05569404 -0.18030529\n",
      "    0.14844038]]\n",
      "\n",
      " [[ 3.96357796 -2.06297264 -2.20075926  1.61533537 -1.32614091\n",
      "   -2.54628354]\n",
      "  [ 0.10766904  0.03153709 -0.19105247  0.09784901  0.03425372\n",
      "   -0.21527529]]] reward= -4104606.3595977193 done= False\n",
      "Step 120\n",
      "Action:  [ 1.7871903   0.305798   -1.5480263   1.5499774   4.5067897  -0.64956814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 120\n",
      "obs= [[[ 2.69106592e+00 -2.22706985e+00 -3.08826042e-01  2.54754562e-01\n",
      "   -1.49985615e+00  1.30697053e-01]\n",
      "  [ 1.78335885e-03 -2.80803412e-02  2.34093828e-02 -3.77692079e-02\n",
      "    9.69290528e-02  1.13616790e-01]]\n",
      "\n",
      " [[ 3.97434486e+00 -2.05981893e+00 -2.21986451e+00  1.62512027e+00\n",
      "   -1.32271553e+00 -2.56781107e+00]\n",
      "  [ 1.07543298e-01  3.13339470e-02 -1.90991194e-01  9.79902761e-02\n",
      "    3.41259800e-02 -2.14726473e-01]]] reward= -6897205.447383708 done= False\n",
      "Step 121\n",
      "Action:  [ 1.7872057   0.30586866 -1.5479041   1.5501207   4.5060487  -0.64935905]\n",
      "self.next: 121\n",
      "obs= [[[ 2.69124425 -2.22987788 -0.3064851   0.25097764 -1.49016324\n",
      "    0.14205873]\n",
      "  [-0.05590773  0.14331239 -0.26117787  0.00929833  0.3216762\n",
      "   -0.28555427]]\n",
      "\n",
      " [[ 3.98509919 -2.05668554 -2.23896363  1.63491929 -1.31930294\n",
      "   -2.58928372]\n",
      "  [ 0.10744143  0.0310975  -0.19092373  0.09812112  0.03400405\n",
      "   -0.21415856]]] reward= -5663519.836757751 done= False\n",
      "Step 122\n",
      "Action:  [ 1.7862787   0.3057339  -1.5468798   1.5494094   4.502427   -0.64861363]\n",
      "self.next: 122\n",
      "obs= [[[ 2.68565348e+00 -2.21554664e+00 -3.32602891e-01  2.51907473e-01\n",
      "   -1.45799562e+00  1.13503305e-01]\n",
      "  [ 3.12424834e-03 -1.32594852e-01  2.76813386e-01 -1.13100217e-01\n",
      "   -3.41291083e-02  2.20874578e-01]]\n",
      "\n",
      " [[ 3.99584334e+00 -2.05357579e+00 -2.25805600e+00  1.64473141e+00\n",
      "   -1.31590253e+00 -2.61069957e+00]\n",
      "  [ 1.07364011e-01  3.08279676e-02 -1.90850620e-01  9.82413042e-02\n",
      "    3.38878497e-02 -2.13571711e-01]]] reward= -7418646.181480592 done= False\n",
      "Step 123\n",
      "Action:  [ 1.7869377   0.3059445  -1.5477527   1.5499355   4.5055346  -0.64932394]\n",
      "self.next: 123\n",
      "obs= [[[ 2.6859659  -2.22880613 -0.30492155  0.24059745 -1.46140853\n",
      "    0.13559076]\n",
      "  [-0.04128361  0.08962901  0.01010494 -0.25232887  0.1464142\n",
      "    0.10396627]]\n",
      "\n",
      " [[ 4.00657974 -2.05049299 -2.27714106  1.65455554 -1.31251375\n",
      "   -2.63205674]\n",
      "  [ 0.10731157  0.03052563 -0.1907724   0.0983506   0.03377731\n",
      "   -0.21296612]]] reward= -7084506.524608139 done= False\n",
      "Step 124\n",
      "Action:  [ 1.7865397  0.3060052 -1.5472667  1.5497216  4.503564  -0.6489168]\n",
      "self.next: 124\n",
      "obs= [[[ 2.68183754 -2.21984323 -0.30391106  0.21536456 -1.44676711\n",
      "    0.14598739]\n",
      "  [-0.03443506  0.05256589 -0.0183886  -0.12185132  0.1832002\n",
      "   -0.20752242]]\n",
      "\n",
      " [[ 4.0173109  -2.04744043 -2.2962183   1.6643906  -1.30913602\n",
      "   -2.65335336]\n",
      "  [ 0.10728458  0.03019084 -0.1906896   0.09844876  0.03367236\n",
      "   -0.21234203]]] reward= -4906751.367652455 done= False\n",
      "Step 125\n",
      "Action:  [ 1.786633    0.30584222 -1.5472955   1.5497701   4.5036793  -0.648806  ]\n",
      "self.next: 125\n",
      "obs= [[[ 2.67839404 -2.21458664 -0.30574992  0.20317943 -1.42844709\n",
      "    0.12523515]\n",
      "  [-0.01453835  0.03673219 -0.22953815  0.23946765  0.07308337\n",
      "   -0.35536967]]\n",
      "\n",
      " [[ 4.02803935 -2.04442134 -2.31528726  1.67423547 -1.30576878\n",
      "   -2.67458756]\n",
      "  [ 0.10728344  0.02982398 -0.19060272  0.09853555  0.03357293\n",
      "   -0.21169969]]] reward= -4716846.937624302 done= False\n",
      "Step 126\n",
      "Action:  [ 1.7868567   0.30567947 -1.5474643   1.5499599   4.5046096  -0.6489659 ]\n",
      "self.next: 126\n",
      "obs= [[[ 2.6769402  -2.21091342 -0.32870373  0.2271262  -1.42113875\n",
      "    0.08969818]\n",
      "  [ 0.0787874  -0.11729129  0.2130169  -0.13834982 -0.03329232\n",
      "    0.11668731]]\n",
      "\n",
      " [[ 4.0387677  -2.04143894 -2.33434753  1.68408903 -1.30241149\n",
      "   -2.69575753]\n",
      "  [ 0.1073085   0.02942551 -0.19051229  0.09861075  0.03347896\n",
      "   -0.21103941]]] reward= -7239384.305899014 done= False\n",
      "Step 127\n",
      "Action:  [ 1.7871199   0.30598348 -1.5478886   1.5502398   4.5057464  -0.6492492 ]\n",
      "self.next: 127\n",
      "obs= [[[ 2.68481894 -2.22264255 -0.30740204  0.21329122 -1.42446799\n",
      "    0.10136691]\n",
      "  [-0.01855833  0.08627519 -0.2156993   0.11158608  0.03576728\n",
      "   -0.0109899 ]]\n",
      "\n",
      " [[ 4.04949855 -2.03849639 -2.35339876  1.6939501  -1.29906359\n",
      "   -2.71686147]\n",
      "  [ 0.10736005  0.02899594 -0.19041876  0.09867409  0.03339038\n",
      "   -0.21036152]]] reward= -7017876.72154988 done= False\n",
      "Step 128\n",
      "Action:  [ 1.78721    0.3059189 -1.5478595  1.5503893  4.5056934 -0.6492126]\n",
      "self.next: 128\n",
      "obs= [[[ 2.68296311 -2.21401503 -0.32897197  0.22444982 -1.42089126\n",
      "    0.10026792]\n",
      "  [ 0.06276905 -0.17372684  0.29150954 -0.02188869 -0.10815385\n",
      "   -0.13057859]]\n",
      "\n",
      " [[ 4.06023455 -2.0355968  -2.37244064  1.70381751 -1.29572455\n",
      "   -2.73789762]\n",
      "  [ 0.10743833  0.02853583 -0.19032262  0.09872535  0.03330714\n",
      "   -0.20966639]]] reward= -5949267.022262778 done= False\n",
      "Step 129\n",
      "Action:  [ 1.787209    0.30586922 -1.5479579   1.5502774   4.506051   -0.6492119 ]\n",
      "self.next: 129\n",
      "obs= [[[ 2.68924001 -2.23138771 -0.29982102  0.22226096 -1.43170664\n",
      "    0.08721006]\n",
      "  [-0.03338624  0.06721241 -0.03276921 -0.12483124  0.17815341\n",
      "   -0.16648689]]\n",
      "\n",
      " [[ 4.07097838 -2.03274321 -2.3914729   1.71369005 -1.29239384\n",
      "   -2.75886426]\n",
      "  [ 0.10754349  0.02804578 -0.19022429  0.09876427  0.03322919\n",
      "   -0.20895442]]] reward= -6910212.633789509 done= False\n",
      "Step 130\n",
      "Action:  [ 1.7866617   0.30594915 -1.547333    1.5499812   4.5035706  -0.6487531 ]\n",
      "self.next: 130\n",
      "obs= [[[ 2.68590139 -2.22466647 -0.30309794  0.20977783 -1.4138913\n",
      "    0.07056137]\n",
      "  [ 0.06962935 -0.04887149  0.01006877  0.0044392   0.07194022\n",
      "    0.0256529 ]]\n",
      "\n",
      " [[ 4.08173273 -2.02993864 -2.41049533  1.72356647 -1.28907092\n",
      "   -2.7797597 ]\n",
      "  [ 0.10767566  0.02752646 -0.19012419  0.09879061  0.03315647\n",
      "   -0.20822605]]] reward= -4705346.94598317 done= False\n",
      "Step 131\n",
      "Action:  [ 1.7873644   0.30598146 -1.5480429   1.5505809   4.506147   -0.6492299 ]\n",
      "self.next: 131\n",
      "obs= [[[ 2.69286432 -2.22955362 -0.30209106  0.21022175 -1.40669728\n",
      "    0.07312666]\n",
      "  [-0.04582714  0.2439632  -0.19666634 -0.28303406  0.19498188\n",
      "   -0.00747005]]\n",
      "\n",
      " [[ 4.0925003  -2.02718599 -2.42950775  1.73344553 -1.28575527\n",
      "   -2.80058231]\n",
      "  [ 0.10783487  0.02697855 -0.19002271  0.09880411  0.03308896\n",
      "   -0.20748173]]] reward= -6135891.075170965 done= False\n",
      "Step 132\n",
      "Action:  [ 1.7860702   0.30613464 -1.54679     1.5496942   4.5014257  -0.6484476 ]\n",
      "self.next: 132\n",
      "obs= [[[ 2.68828161 -2.2051573  -0.3217577   0.18191835 -1.38719909\n",
      "    0.07237966]\n",
      "  [-0.02650908 -0.06224175 -0.09903065  0.27266698 -0.14426488\n",
      "    0.17445546]]\n",
      "\n",
      " [[ 4.10328379 -2.02448813 -2.44851002  1.74332595 -1.28244637\n",
      "   -2.82133048]\n",
      "  [ 0.10802111  0.02640281 -0.18992019  0.09880452  0.03302663\n",
      "   -0.20672196]]] reward= -5858379.0266312575 done= False\n",
      "Step 133\n",
      "Action:  [ 1.78739     0.30596963 -1.5481021   1.5506318   4.506774   -0.649432  ]\n",
      "self.next: 133\n",
      "obs= [[[ 2.6856307  -2.21138148 -0.33166076  0.20918504 -1.40162558\n",
      "    0.0898252 ]\n",
      "  [-0.04030275  0.08772688 -0.04770481 -0.11733191  0.07014019\n",
      "    0.08945796]]\n",
      "\n",
      " [[ 4.1140859  -2.02184785 -2.46750204  1.7532064  -1.27914371\n",
      "   -2.84200267]\n",
      "  [ 0.10823429  0.0258     -0.18981697  0.09879156  0.03296944\n",
      "   -0.20594726]]] reward= -6971127.2981326245 done= False\n",
      "Step 134\n",
      "Action:  [ 1.7867236   0.30612755 -1.5474446   1.5502094   4.5038824  -0.64888155]\n",
      "self.next: 134\n",
      "obs= [[[ 2.68160043 -2.20260879 -0.33643124  0.19745185 -1.39461156\n",
      "    0.098771  ]\n",
      "  [ 0.03269716  0.06172076 -0.0937602  -0.12004738  0.29287549\n",
      "   -0.16436447]]\n",
      "\n",
      " [[ 4.12490933 -2.01926785 -2.48648373  1.76308555 -1.27584677\n",
      "   -2.8625974 ]\n",
      "  [ 0.1084743   0.02517095 -0.18971331  0.09876497  0.0329174\n",
      "   -0.20515819]]] reward= -4743478.7478691945 done= False\n",
      "Step 135\n",
      "Action:  [ 1.7863603   0.30601498 -1.5470225   1.5499115   4.5023375  -0.6484878 ]\n",
      "self.next: 135\n",
      "obs= [[[ 2.68487014 -2.19643671 -0.34580726  0.18544711 -1.36532401\n",
      "    0.08233455]\n",
      "  [ 0.00979772 -0.11637795  0.25890333 -0.12171445 -0.02662873\n",
      "    0.16858961]]\n",
      "\n",
      " [[ 4.13575676 -2.01675076 -2.50545506  1.77296205 -1.27255503\n",
      "   -2.88311322]\n",
      "  [ 0.10874092  0.02451649 -0.18960948  0.09872446  0.03287049\n",
      "   -0.20435532]]] reward= -6188731.559055258 done= False\n",
      "Step 136\n",
      "Action:  [ 1.7867792   0.30614007 -1.5475736   1.5502322   4.504461   -0.6489798 ]\n",
      "self.next: 136\n",
      "obs= [[[ 2.68584991e+00 -2.20807451e+00 -3.19916930e-01  1.73275669e-01\n",
      "   -1.36798689e+00  9.91935132e-02]\n",
      "  [ 2.82546793e-03  1.11154067e-02 -1.47295162e-02  4.79312063e-04\n",
      "   -1.30168934e-03 -5.14481326e-02]]\n",
      "\n",
      " [[ 4.14663085e+00 -2.01429911e+00 -2.52441601e+00  1.78283450e+00\n",
      "   -1.26926798e+00 -2.90354875e+00]\n",
      "  [ 1.09033900e-01  2.38374929e-02 -1.89505677e-01  9.86697581e-02\n",
      "    3.28287181e-02 -2.03539272e-01]]] reward= -7110354.124122522 done= False\n",
      "Step 137\n",
      "Action:  [ 1.7870145   0.30605054 -1.547713    1.5504698   4.504851   -0.6489663 ]\n",
      "self.next: 137\n",
      "obs= [[[ 2.68613246 -2.20696297 -0.32138988  0.1733236  -1.36811705\n",
      "    0.0940487 ]\n",
      "  [ 0.04172618  0.04509054 -0.08763583 -0.08711256  0.26063611\n",
      "   -0.34863334]]\n",
      "\n",
      " [[ 4.15753424 -2.01191536 -2.54336658  1.79270147 -1.26598511\n",
      "   -2.92390268]\n",
      "  [ 0.10935293  0.02313487 -0.18940206  0.09860056  0.03279211\n",
      "   -0.20271067]]] reward= -4457980.283158314 done= False\n",
      "Step 138\n",
      "Action:  [ 1.7861631  0.3059567 -1.5468271  1.5498049  4.501623  -0.6482918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 138\n",
      "obs= [[[ 2.69030508 -2.20245391 -0.33015346  0.16461234 -1.34205344\n",
      "    0.05918537]\n",
      "  [-0.05103787  0.02252931 -0.15184476  0.26508126 -0.14931921\n",
      "    0.07209771]]\n",
      "\n",
      " [[ 4.16846953 -2.00960187 -2.56230679  1.80256153 -1.2627059\n",
      "   -2.94417375]\n",
      "  [ 0.10969765  0.02240953 -0.18929876  0.09851655  0.03276069\n",
      "   -0.20187018]]] reward= -5566454.744739358 done= False\n",
      "Step 139\n",
      "Action:  [ 1.787051    0.30603087 -1.5477666   1.5505545   4.505387   -0.64913094]\n",
      "self.next: 139\n",
      "obs= [[[ 2.68520129 -2.20020098 -0.34533794  0.19112047 -1.35698536\n",
      "    0.06639514]\n",
      "  [ 0.02548831  0.04346701 -0.07259962 -0.08043442  0.14741792\n",
      "    0.01984974]]\n",
      "\n",
      " [[ 4.1794393  -2.00736092 -2.58123666  1.81241318 -1.25942983\n",
      "   -2.96436076]\n",
      "  [ 0.11006763  0.02166243 -0.18919586  0.09841743  0.03273451\n",
      "   -0.20101848]]] reward= -6537725.405072373 done= False\n",
      "Step 140\n",
      "Action:  [ 1.786657    0.30615303 -1.5473659   1.5503423   4.5034127  -0.6486995 ]\n",
      "self.next: 140\n",
      "obs= [[[ 2.68775012e+00 -2.19585428e+00 -3.52597902e-01  1.83077029e-01\n",
      "   -1.34224357e+00  6.83801103e-02]\n",
      "  [ 2.15308875e-02 -7.71747719e-02  2.35845835e-01 -1.79227095e-01\n",
      "    3.62694949e-04 -3.85342949e-02]]\n",
      "\n",
      " [[ 4.19044606e+00 -2.00519468e+00 -2.60015625e+00  1.82225493e+00\n",
      "   -1.25615638e+00 -2.98446261e+00]\n",
      "  [ 1.10462387e-01  2.08945157e-02 -1.89093366e-01  9.83028768e-02\n",
      "    3.27136008e-02 -2.00156286e-01]]] reward= -5709664.199055998 done= False\n",
      "Step 141\n",
      "Action:  [ 1.7865858  0.3061499 -1.5473579  1.5502214  4.503419  -0.6486751]\n",
      "self.next: 141\n",
      "obs= [[[ 2.68990321 -2.20357176 -0.32901332  0.16515432 -1.3422073\n",
      "    0.06452668]\n",
      "  [-0.05075287  0.01604927 -0.1688538   0.31785346 -0.17675009\n",
      "    0.12113079]]\n",
      "\n",
      " [[ 4.2014923  -2.00310523 -2.61906559  1.83208521 -1.25288502\n",
      "   -3.00447824]\n",
      "  [ 0.1108814   0.02010676 -0.18899128  0.09817255  0.03269804\n",
      "   -0.19928433]]] reward= -6292348.065058381 done= False\n",
      "Step 142\n",
      "Action:  [ 1.7869898   0.30606255 -1.5477084   1.5505855   4.5052223  -0.64910203]\n",
      "self.next: 142\n",
      "obs= [[[ 2.68482792 -2.20196683 -0.3458987   0.19693967 -1.35988231\n",
      "    0.07663976]\n",
      "  [ 0.03217502  0.02352293 -0.05712197 -0.08495251  0.25462988\n",
      "   -0.23856227]]\n",
      "\n",
      " [[ 4.21258044 -2.00109455 -2.63796471  1.84190247 -1.24961521\n",
      "   -3.02440667]\n",
      "  [ 0.1113241   0.01930013 -0.18888953  0.0980261   0.0326879\n",
      "   -0.19840337]]] reward= -6882075.915629371 done= False\n",
      "Step 143\n",
      "Action:  [ 1.7861876   0.30607125 -1.5468745   1.5499939   4.501626   -0.64828247]\n",
      "self.next: 143\n",
      "obs= [[[ 2.68804543e+00 -2.19961454e+00 -3.51610896e-01  1.88444414e-01\n",
      "   -1.33441932e+00  5.27835331e-02]\n",
      "  [-5.30692871e-03 -4.11454834e-02  4.34988022e-02  3.63857173e-03\n",
      "   -6.54437823e-02  7.14424700e-02]]\n",
      "\n",
      " [[ 4.22371285e+00 -1.99916454e+00 -2.65685367e+00  1.85170508e+00\n",
      "   -1.24634642e+00 -3.04424701e+00]\n",
      "  [ 1.11789859e-01  1.84756263e-02 -1.88787998e-01  9.78631801e-02\n",
      "    3.26832747e-02 -1.97514181e-01]]] reward= -5806978.1202771915 done= False\n",
      "Step 144\n",
      "Action:  [ 1.7868522   0.30618015 -1.5476073   1.5505654   4.504358   -0.64886874]\n",
      "self.next: 144\n",
      "obs= [[[ 2.68751473 -2.20372909 -0.34726102  0.18880827 -1.3409637\n",
      "    0.05992778]\n",
      "  [-0.07500637  0.03673951  0.06624006 -0.09281294 -0.03951964\n",
      "    0.3028864 ]]\n",
      "\n",
      " [[ 4.23489183 -1.99731697 -2.67573247  1.8614914  -1.24307809\n",
      "   -3.06399843]\n",
      "  [ 0.11227801  0.01763423 -0.18868652  0.09768342  0.03268426\n",
      "   -0.19661756]]] reward= -4868977.256749673 done= False\n",
      "Step 145\n",
      "Action:  [ 1.7863631   0.3063462  -1.5471728   1.550278    4.5028095  -0.64869916]\n",
      "self.next: 145\n",
      "obs= [[[ 2.68001410e+00 -2.20005513e+00 -3.40637009e-01  1.79526977e-01\n",
      "   -1.34491567e+00  9.02164199e-02]\n",
      "  [ 3.32265292e-04 -1.19737328e-03 -3.39955434e-04  9.80706684e-05\n",
      "   -5.85364117e-02  3.34147813e-01]]\n",
      "\n",
      " [[ 4.24611964e+00 -1.99555355e+00 -2.69460112e+00  1.87125974e+00\n",
      "   -1.23980967e+00 -3.08366018e+00]\n",
      "  [ 1.12787859e-01  1.67769134e-02 -1.88584893e-01  9.74864509e-02\n",
      "    3.26909591e-02 -1.95714319e-01]]] reward= -5507095.658282917 done= False\n",
      "Step 146\n",
      "Action:  [ 1.7866426   0.30632028 -1.5474185   1.550521    4.503755   -0.6488476 ]\n",
      "self.next: 146\n",
      "obs= [[[ 2.68004732 -2.20017487 -0.340671    0.17953678 -1.35076931\n",
      "    0.1236312 ]\n",
      "  [ 0.02856689  0.03838157 -0.06626452 -0.11376653  0.28190342\n",
      "   -0.19531782]]\n",
      "\n",
      " [[ 4.25739842 -1.99387586 -2.71345961  1.88100838 -1.23654057\n",
      "   -3.10323162]\n",
      "  [ 0.11331865  0.01590467 -0.18848284  0.09727188  0.03270351\n",
      "   -0.1948053 ]]] reward= -5946826.188012574 done= False\n",
      "Step 147\n",
      "Action:  [ 1.7859993   0.30614915 -1.5466899   1.549968    4.5008636  -0.6481305 ]\n",
      "self.next: 147\n",
      "obs= [[[ 2.68290401e+00 -2.19633671e+00 -3.47297457e-01  1.68160132e-01\n",
      "   -1.32257897e+00  1.04099419e-01]\n",
      "  [-1.00092479e-03 -2.45720119e-02  2.63653229e-02  2.04390009e-02\n",
      "   -2.12731136e-02  8.32219557e-03]]\n",
      "\n",
      " [[ 4.26873029e+00 -1.99228539e+00 -2.73230789e+00  1.89073557e+00\n",
      "   -1.23327022e+00 -3.12271215e+00]\n",
      "  [ 1.13869617e-01  1.50184692e-02 -1.88380047e-01  9.70393093e-02\n",
      "    3.27220355e-02 -1.93891348e-01]]] reward= -6418608.267060562 done= False\n",
      "Step 148\n",
      "Action:  [ 1.7866879   0.30619508 -1.5474263   1.5505277   4.5036445  -0.6486939 ]\n",
      "self.next: 148\n",
      "obs= [[[ 2.68280392 -2.19879392 -0.34466092  0.17020403 -1.32470628\n",
      "    0.10493164]\n",
      "  [ 0.05681344 -0.08913314  0.03167629  0.03196928  0.0751772\n",
      "   -0.09579615]]\n",
      "\n",
      " [[ 4.28011725 -1.99078355 -2.7511459   1.9004395  -1.22999802\n",
      "   -3.14210128]\n",
      "  [ 0.11443994  0.01411927 -0.18827616  0.09678834  0.03274669\n",
      "   -0.19297333]]] reward= -4956491.739017264 done= False\n",
      "Step 149\n",
      "Action:  [ 1.7866946   0.30613977 -1.547404    1.5505275   4.5035424  -0.6486055 ]\n",
      "self.next: 149\n",
      "obs= [[[ 2.68848526e+00 -2.20770723e+00 -3.41493296e-01  1.73400960e-01\n",
      "   -1.31718856e+00  9.53520240e-02]\n",
      "  [-5.91044775e-02  8.29581114e-02  2.16009345e-03 -8.23192097e-02\n",
      "   -4.54149845e-02  1.90769958e-01]]\n",
      "\n",
      " [[ 4.29156124e+00 -1.98937162e+00 -2.76997351e+00  1.91011834e+00\n",
      "   -1.22672335e+00 -3.16139861e+00]\n",
      "  [ 1.15028798e-01  1.32080121e-02 -1.88170755e-01  9.65185459e-02\n",
      "    3.27776276e-02 -1.92052131e-01]]] reward= -5755274.335996646 done= False\n",
      "Step 150\n",
      "Action:  [ 1.786322    0.30636087 -1.5471132   1.5503895   4.50239    -0.6485474 ]\n",
      "self.next: 150\n",
      "obs= [[[ 2.68257482e+00 -2.19941142e+00 -3.41277286e-01  1.65169039e-01\n",
      "   -1.32173006e+00  1.14429020e-01]\n",
      "  [ 4.52903973e-03  3.24040794e-02 -6.33488191e-02  2.60742974e-02\n",
      "    6.35611386e-04 -1.05976505e-01]]\n",
      "\n",
      " [[ 4.30306412e+00 -1.98805082e+00 -2.78879059e+00  1.91977019e+00\n",
      "   -1.22344559e+00 -3.18060383e+00]\n",
      "  [ 1.15635321e-01  1.22856272e-02 -1.88063385e-01  9.62295126e-02\n",
      "    3.28150142e-02 -1.91128637e-01]]] reward= -4906173.6868785815 done= False\n",
      "Step 151\n",
      "Action:  [ 1.786468    0.30618763 -1.5471907   1.5504429   4.5027013  -0.64848506]\n",
      "self.next: 151\n",
      "obs= [[[ 2.68302772e+00 -2.19617101e+00 -3.47612168e-01  1.67776469e-01\n",
      "   -1.32166649e+00  1.03831369e-01]\n",
      "  [-2.92236271e-04 -2.44108244e-02  2.56274499e-02  2.59811551e-02\n",
      "   -2.75303669e-02  1.01720977e-01]]\n",
      "\n",
      " [[ 4.31462765e+00 -1.98682226e+00 -2.80759693e+00  1.92939314e+00\n",
      "   -1.22016408e+00 -3.19971669e+00]\n",
      "  [ 1.16258634e-01  1.13530165e-02 -1.87953543e-01  9.59208057e-02\n",
      "    3.28590261e-02 -1.90203753e-01]]] reward= -5259508.4914898155 done= False\n",
      "Step 152\n",
      "Action:  [ 1.7865801   0.30627617 -1.5473343   1.5505749   4.503265   -0.64862865]\n",
      "self.next: 152\n",
      "obs= [[[ 2.68299850e+00 -2.19861209e+00 -3.45049423e-01  1.70374584e-01\n",
      "   -1.32441953e+00  1.14003467e-01]\n",
      "  [-2.20243084e-02 -5.14066809e-02  7.46515914e-02  2.11375189e-04\n",
      "   -3.89360096e-02 -9.76188742e-02]]\n",
      "\n",
      " [[ 4.32625352e+00 -1.98568695e+00 -2.82639228e+00  1.93898522e+00\n",
      "   -1.21687818e+00 -3.21873707e+00]\n",
      "  [ 1.16897845e-01  1.04110579e-02 -1.87840680e-01  9.55919866e-02\n",
      "    3.29098479e-02 -1.89278391e-01]]] reward= -5560060.264857542 done= False\n",
      "Step 153\n",
      "Action:  [ 1.7864392   0.30620432 -1.5471836   1.5504268   4.502711   -0.6484638 ]\n",
      "self.next: 153\n",
      "obs= [[[ 2.68079607e+00 -2.20375276e+00 -3.37584264e-01  1.70395722e-01\n",
      "   -1.32831313e+00  1.04241580e-01]\n",
      "  [ 9.63956829e-05  1.05698483e-03 -2.03399882e-03 -9.25536302e-05\n",
      "    3.89101917e-04  4.68340927e-04]]\n",
      "\n",
      " [[ 4.33794330e+00 -1.98464585e+00 -2.84517635e+00  1.94854442e+00\n",
      "   -1.21358720e+00 -3.23766490e+00]\n",
      "  [ 1.17552047e-01  9.46060013e-03 -1.87724206e-01  9.52426108e-02\n",
      "    3.29676720e-02 -1.88353468e-01]]] reward= -5479295.737187697 done= False\n",
      "Step 154\n",
      "Action:  [ 1.7864592   0.3062695  -1.5471989   1.5505304   4.5026717  -0.64847726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 154\n",
      "obs= [[[ 2.68080571 -2.20364706 -0.33778766  0.17038647 -1.32827422\n",
      "    0.10428841]\n",
      "  [-0.00458311 -0.00625794  0.03697695 -0.05410576  0.02670197\n",
      "    0.00473185]]\n",
      "\n",
      " [[ 4.34969851 -1.98369979 -2.86394877  1.95806868 -1.21029043\n",
      "   -3.25650025]\n",
      "  [ 0.11822033  0.00850246 -0.18760349  0.09487223  0.0330327\n",
      "   -0.18742991]]] reward= -5126146.726222428 done= False\n",
      "Step 155\n",
      "Action:  [ 1.786338    0.3062999  -1.5470862   1.5504663   4.5022063  -0.64838254]\n",
      "self.next: 155\n",
      "obs= [[[ 2.68034739 -2.20427286 -0.33408997  0.16497589 -1.32560402\n",
      "    0.1047616 ]\n",
      "  [ 0.17959354 -0.16425433  0.08248869  0.08264465  0.13944561\n",
      "   -0.35105122]]\n",
      "\n",
      " [[ 4.36152054 -1.98284954 -2.88270912  1.96755591 -1.20698716\n",
      "   -3.27524324]\n",
      "  [ 0.11890178  0.00753742 -0.18747787  0.09448039  0.03310513\n",
      "   -0.18650864]]] reward= -5103385.233773279 done= False\n",
      "Step 156\n",
      "Action:  [ 1.7862964   0.30606884 -1.5469877   1.5503049   4.5020947  -0.64821255]\n",
      "self.next: 156\n",
      "obs= [[[ 2.69830675 -2.22069829 -0.3258411   0.17324036 -1.31165946\n",
      "    0.06965648]\n",
      "  [-0.07067486 -0.00885468  0.10534998 -0.05482423 -0.14111579\n",
      "    0.13586094]]\n",
      "\n",
      " [[ 4.37341072 -1.9820958  -2.9014569   1.97700395 -1.20367665\n",
      "   -3.29389411]\n",
      "  [ 0.1195955   0.00656621 -0.18734663  0.09406663  0.03318519\n",
      "   -0.18559058]]] reward= -9172580.842405034 done= False\n",
      "Step 157\n",
      "Action:  [ 1.7863212  0.3063758 -1.5471318  1.5505227  4.5024085 -0.648472 ]\n",
      "self.next: 157\n",
      "obs= [[[ 2.69123926e+00 -2.22158376e+00 -3.15306102e-01  1.67757933e-01\n",
      "   -1.32577104e+00  8.32425706e-02]\n",
      "  [-1.03271633e-03  4.20326469e-02 -6.78829032e-02  2.43686047e-02\n",
      "    6.55102835e-02 -2.01278195e-02]]\n",
      "\n",
      " [[ 4.38537027e+00 -1.98143918e+00 -2.92019157e+00  1.98641061e+00\n",
      "   -1.20035813e+00 -3.31245316e+00]\n",
      "  [ 1.20300563e-01  5.58955191e-03 -1.87209050e-01  9.36304999e-02\n",
      "    3.32730754e-02 -1.84676674e-01]]] reward= -5990066.820360505 done= False\n",
      "Step 158\n",
      "Action:  [ 1.7862775   0.30629972 -1.5470184   1.5505198   4.5019026  -0.64830846]\n",
      "self.next: 158\n",
      "obs= [[[ 2.69113599e+00 -2.21738049e+00 -3.22094392e-01  1.70194793e-01\n",
      "   -1.31922001e+00  8.12297886e-02]\n",
      "  [-2.92884276e-03 -2.44409103e-02  5.50743787e-02 -5.51854196e-02\n",
      "   -3.61321333e-02  6.22341834e-02]]\n",
      "\n",
      " [[ 4.39740033e+00 -1.98088022e+00 -2.93891247e+00  1.99577366e+00\n",
      "   -1.19703082e+00 -3.33092083e+00]\n",
      "  [ 1.21016095e-01  4.60808614e-03 -1.87064356e-01  9.31715379e-02\n",
      "    3.33690187e-02 -1.83767827e-01]]] reward= -6092983.453933996 done= False\n",
      "Step 159\n",
      "Action:  [ 1.7863513  0.306357  -1.5471227  1.5505981  4.5022683 -0.6483783]\n",
      "self.next: 159\n",
      "obs= [[[ 2.69084311e+00 -2.21982458e+00 -3.16586954e-01  1.64676251e-01\n",
      "   -1.32283323e+00  8.74532070e-02]\n",
      "  [ 5.72338728e-02 -6.97161413e-02  1.46368443e-02  2.68340603e-02\n",
      "    7.28515871e-02 -5.20271979e-02]]\n",
      "\n",
      " [[ 4.40950193e+00 -1.98041942e+00 -2.95761891e+00  2.00509081e+00\n",
      "   -1.19369392e+00 -3.34929761e+00]\n",
      "  [ 1.21741216e-01  3.62242555e-03 -1.86911759e-01  9.26892874e-02\n",
      "    3.34732380e-02 -1.82864962e-01]]] reward= -4968962.438644772 done= False\n",
      "Step 160\n",
      "Action:  [ 1.7864193   0.30627686 -1.5471497   1.5506316   4.5023975  -0.64833564]\n",
      "self.next: 160\n",
      "obs= [[[ 2.69656649e+00 -2.22679620e+00 -3.15123270e-01  1.67359657e-01\n",
      "   -1.31554807e+00  8.22504872e-02]\n",
      "  [-6.76465853e-02  5.00873897e-02  1.70962993e-02 -3.39281930e-02\n",
      "   -6.97467927e-02  1.53434966e-01]]\n",
      "\n",
      " [[ 4.42167606e+00 -1.98005717e+00 -2.97631008e+00  2.01435974e+00\n",
      "   -1.19034660e+00 -3.36758411e+00]\n",
      "  [ 1.22475075e-01  2.63312908e-03 -1.86750446e-01  9.21832934e-02\n",
      "    3.35859565e-02 -1.81968986e-01]]] reward= -6289060.684739816 done= False\n",
      "Step 161\n",
      "Action:  [ 1.7861433  0.306425  -1.5469456  1.5505279  4.5016303 -0.6483135]\n",
      "self.next: 161\n",
      "obs= [[[ 2.68980183e+00 -2.22178746e+00 -3.13413640e-01  1.63966838e-01\n",
      "   -1.32252275e+00  9.75939838e-02]\n",
      "  [ 5.76483633e-03  1.11415197e-02 -1.62242313e-02 -3.06963295e-04\n",
      "    6.61782686e-04 -5.04549292e-02]]\n",
      "\n",
      " [[ 4.43392356e+00 -1.97979386e+00 -2.99498513e+00  2.02357807e+00\n",
      "   -1.18698800e+00 -3.38578101e+00]\n",
      "  [ 1.23216844e-01  1.64070395e-03 -1.86579584e-01  9.16531041e-02\n",
      "    3.37073975e-02 -1.81080800e-01]]] reward= -5398792.196014723 done= False\n",
      "Step 162\n",
      "Action:  [ 1.7862146   0.30632293 -1.5469674   1.5505496   4.5016766  -0.6482288 ]\n",
      "self.next: 162\n",
      "obs= [[[ 2.69037832e+00 -2.22067331e+00 -3.15036063e-01  1.63936142e-01\n",
      "   -1.32245657e+00  9.25484909e-02]\n",
      "  [ 6.16571687e-03  2.84379789e-02 -3.76878124e-03 -6.11805791e-02\n",
      "   -3.56940062e-02  2.75195906e-01]]\n",
      "\n",
      " [[ 4.44624525e+00 -1.97962979e+00 -3.01364309e+00  2.03274338e+00\n",
      "   -1.18361726e+00 -3.40388909e+00]\n",
      "  [ 1.23965727e-01  6.45602858e-04 -1.86398324e-01  9.10982730e-02\n",
      "    3.38377842e-02 -1.80201288e-01]]] reward= -5238128.0346464235 done= False\n",
      "Step 163\n",
      "Action:  [ 1.7861084   0.3064973  -1.546911    1.5506018   4.501474   -0.64829105]\n",
      "self.next: 163\n",
      "obs= [[[ 2.69099489e+00 -2.21782951e+00 -3.15412941e-01  1.57818084e-01\n",
      "   -1.32602597e+00  1.20068082e-01]\n",
      "  [-1.17595576e-02 -1.60446494e-03  1.44274602e-02 -3.12912884e-02\n",
      "    9.61846223e-02 -1.88923123e-01]]\n",
      "\n",
      " [[ 4.45864182e+00 -1.97956523e+00 -3.03228292e+00  2.04185321e+00\n",
      "   -1.18023348e+00 -3.42190922e+00]\n",
      "  [ 1.24720961e-01 -3.51777036e-04 -1.86205805e-01  9.05183590e-02\n",
      "    3.39773381e-02 -1.79331323e-01]]] reward= -6267687.5339974025 done= False\n",
      "Step 164\n",
      "Action:  [ 1.7858175   0.30628985 -1.5465684   1.550246    4.500229   -0.6479183 ]\n",
      "self.next: 164\n",
      "obs= [[[ 2.68981893e+00 -2.21798996e+00 -3.13970195e-01  1.54688955e-01\n",
      "   -1.31640751e+00  1.01175769e-01]\n",
      "  [ 6.81931777e-03  1.51982174e-02 -5.25548476e-02  5.88044042e-02\n",
      "   -9.38761298e-02  2.80447597e-01]]\n",
      "\n",
      " [[ 4.47111392e+00 -1.97960041e+00 -3.05090350e+00  2.05090504e+00\n",
      "   -1.17683575e+00 -3.43984235e+00]\n",
      "  [ 1.25481824e-01 -1.35109660e-03 -1.86001157e-01  8.99129280e-02\n",
      "    3.41262783e-02 -1.78471759e-01]]] reward= -5627619.208152881 done= False\n",
      "Step 165\n",
      "Action:  [ 1.7861854   0.30646318 -1.546985    1.550686    4.5018783  -0.64835685]\n",
      "self.next: 165\n",
      "obs= [[[ 2.69050087e+00 -2.21647013e+00 -3.19225680e-01  1.60569395e-01\n",
      "   -1.32579512e+00  1.29220529e-01]\n",
      "  [-6.44855895e-02  2.94697551e-02  6.19146519e-02 -1.70708054e-01\n",
      "    1.07358569e-01  2.88394299e-01]]\n",
      "\n",
      " [[ 4.48366210e+00 -1.97973552e+00 -3.06950362e+00  2.05989634e+00\n",
      "   -1.17342312e+00 -3.45768953e+00]\n",
      "  [ 1.26247635e-01 -2.35207522e-03 -1.85783507e-01  8.92815544e-02\n",
      "    3.42848213e-02 -1.77623433e-01]]] reward= -6340103.210270353 done= False\n",
      "Step 166\n",
      "Action:  [ 1.78552     0.30657557 -1.5463437   1.550232    4.499351   -0.6479009 ]\n",
      "self.next: 166\n",
      "obs= [[[ 2.68405231e+00 -2.21352316e+00 -3.13034215e-01  1.43498590e-01\n",
      "   -1.31505926e+00  1.58059959e-01]\n",
      "  [ 8.64942536e-03 -3.45287348e-02  2.56515589e-02  1.08582366e-03\n",
      "    3.89158370e-02 -9.68546344e-02]]\n",
      "\n",
      " [[ 4.49628686e+00 -1.97997072e+00 -3.08808197e+00  2.06882449e+00\n",
      "   -1.16999464e+00 -3.47545187e+00]\n",
      "  [ 1.27017762e-01 -3.35449248e-03 -1.85551977e-01  8.86238211e-02\n",
      "    3.44531781e-02 -1.76787161e-01]]] reward= -7113367.137944861 done= False\n",
      "Step 167\n",
      "Action:  [ 1.785967   0.3063326 -1.5467213  1.5504363  4.500806  -0.6480164]\n",
      "self.next: 167\n",
      "obs= [[[ 2.68491725e+00 -2.21697603e+00 -3.10469059e-01  1.43607172e-01\n",
      "   -1.31116768e+00  1.48374495e-01]\n",
      "  [-1.26053239e-02  1.47737391e-02 -2.07402646e-01  2.56383962e-01\n",
      "   -1.50138129e-02  1.77366921e-01]]\n",
      "\n",
      " [[ 4.50898864e+00 -1.98030617e+00 -3.10663716e+00  2.07768687e+00\n",
      "   -1.16654932e+00 -3.49313059e+00]\n",
      "  [ 1.27791621e-01 -4.35818915e-03 -1.85305696e-01  8.79393214e-02\n",
      "    3.46315566e-02 -1.75963736e-01]]] reward= -5660812.02051937 done= False\n",
      "Step 168\n",
      "Action:  [ 1.7860571   0.3063629  -1.5468229   1.5506057   4.5014715  -0.64824235]\n",
      "self.next: 168\n",
      "obs= [[[ 2.68365672 -2.21549866 -0.33120932  0.16924557 -1.31266906\n",
      "    0.16611119]\n",
      "  [ 0.12960341 -0.0877322   0.13179986 -0.23281451  0.36331793\n",
      "   -0.39286661]]\n",
      "\n",
      " [[ 4.5217678  -1.98074199 -3.12516773  2.08648081 -1.16308616\n",
      "   -3.51072696]\n",
      "  [ 0.12856868 -0.00536307 -0.18504379  0.08722766  0.03482016\n",
      "   -0.17515393]]] reward= -8646680.321544651 done= False\n",
      "Step 169\n",
      "Action:  [ 1.7848448   0.30627877 -1.5455918   1.5495523   4.496643   -0.6471198 ]\n",
      "self.next: 169\n",
      "obs= [[[ 2.69661706e+00 -2.22427188e+00 -3.18029338e-01  1.45964118e-01\n",
      "   -1.27633727e+00  1.26824526e-01]\n",
      "  [-4.57444422e-03  1.58919979e-03  5.40742587e-03 -3.33268390e-02\n",
      "    1.32187250e-01 -2.02933299e-01]]\n",
      "\n",
      " [[ 4.53462467e+00 -1.98127830e+00 -3.14367211e+00  2.09520357e+00\n",
      "   -1.15960415e+00 -3.52824235e+00]\n",
      "  [ 1.29348473e-01 -6.36908899e-03 -1.84765410e-01  8.64884488e-02\n",
      "    3.50191775e-02 -1.74358482e-01]]] reward= -9123970.604445837 done= False\n",
      "Step 170\n",
      "Action:  [ 1.7854748   0.30633423 -1.5462682   1.5501537   4.4990296  -0.6476568 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 170\n",
      "obs= [[[ 2.69615961 -2.22411296 -0.3174886   0.14263143 -1.26311854\n",
      "    0.1065312 ]\n",
      "  [-0.04939913  0.13270728 -0.28597565  0.11102615  0.16272158\n",
      "   -0.08475874]]\n",
      "\n",
      " [[ 4.54755952 -1.98191521 -3.16214865  2.10385242 -1.15610223\n",
      "   -3.5456782 ]\n",
      "  [ 0.13013058 -0.00737628 -0.1844697   0.08572132  0.0352288\n",
      "   -0.17357811]]] reward= -5986379.88214376 done= False\n",
      "Step 171\n",
      "Action:  [ 1.7850941   0.3063676  -1.545921    1.550002    4.497818   -0.64752835]\n",
      "self.next: 171\n",
      "obs= [[[ 2.6912197  -2.21084223 -0.34608616  0.15373405 -1.24684639\n",
      "    0.09805532]\n",
      "  [ 0.05302822 -0.06510177  0.03576906 -0.02364218  0.18979494\n",
      "   -0.20560544]]\n",
      "\n",
      " [[ 4.56057257 -1.98265284 -3.18059562  2.11242455 -1.15257935\n",
      "   -3.56303601]\n",
      "  [ 0.13091464 -0.00838473 -0.18415583  0.08492591  0.03544922\n",
      "   -0.17281352]]] reward= -8435454.531257842 done= False\n",
      "Step 172\n",
      "Action:  [ 1.7853483   0.30633527 -1.5461595   1.5501107   4.4986525  -0.6475462 ]\n",
      "self.next: 172\n",
      "obs= [[[ 2.69652252e+00 -2.21735241e+00 -3.42509255e-01  1.51369831e-01\n",
      "   -1.22786689e+00  7.74947788e-02]\n",
      "  [ 1.14224465e-03  2.25181103e-04 -7.97771564e-04 -6.04306432e-04\n",
      "    1.95543119e-03 -1.19293482e-03]]\n",
      "\n",
      " [[ 4.57366404e+00 -1.98349131e+00 -3.19901121e+00  2.12091714e+00\n",
      "   -1.14903443e+00 -3.58031736e+00]\n",
      "  [ 1.31700379e-01 -9.39457861e-03 -1.83822990e-01  8.41018655e-02\n",
      "    3.56805999e-02 -1.72065347e-01]]] reward= -6995021.2058789795 done= False\n",
      "Step 173\n",
      "Action:  [ 1.7855954   0.30642968 -1.5464498   1.5504084   4.4996624  -0.6478062 ]\n",
      "self.next: 173\n",
      "obs= [[[ 2.69663675e+00 -2.21732989e+00 -3.42589032e-01  1.51309401e-01\n",
      "   -1.22767135e+00  7.73754853e-02]\n",
      "  [-1.68351202e-03  5.01984256e-03 -1.22575872e-03 -6.41290563e-03\n",
      "   -8.66001814e-02  2.03528500e-01]]\n",
      "\n",
      " [[ 4.58683408e+00 -1.98443077e+00 -3.21739351e+00  2.12932733e+00\n",
      "   -1.14546637e+00 -3.59752390e+00]\n",
      "  [ 1.32487560e-01 -1.04060386e-02 -1.83470381e-01  8.32488593e-02\n",
      "    3.59231100e-02 -1.71334240e-01]]] reward= -5703990.174064102 done= False\n",
      "Step 174\n",
      "Action:  [ 1.7856182   0.3065228  -1.5465039   1.5505117   4.4999137  -0.64791274]\n",
      "self.next: 174\n",
      "obs= [[[ 2.6964684  -2.2168279  -0.34271161  0.15066811 -1.23633137\n",
      "    0.09772834]\n",
      "  [-0.07067322  0.02633236  0.07003254 -0.07860238 -0.04387555\n",
      "    0.11367785]]\n",
      "\n",
      " [[ 4.60008283 -1.98547137 -3.23574054  2.13765221 -1.14187406\n",
      "   -3.61465732]\n",
      "  [ 0.13327603 -0.01141937 -0.18309723  0.08236656  0.03617691\n",
      "   -0.1706208 ]]] reward= -5741528.569641048 done= False\n",
      "Step 175\n",
      "Action:  [ 1.7853448   0.30653095 -1.5462377   1.5502956   4.4988666  -0.6477048 ]\n",
      "self.next: 175\n",
      "obs= [[[ 2.68940107e+00 -2.21419467e+00 -3.35708353e-01  1.42807872e-01\n",
      "   -1.24071892e+00  1.09096120e-01]\n",
      "  [ 4.69464111e-03  2.07408011e-02  1.07047787e-03 -5.18993353e-02\n",
      "    2.60372630e-02 -1.78224944e-03]]\n",
      "\n",
      " [[ 4.61341044e+00 -1.98661331e+00 -3.25405027e+00  2.14588887e+00\n",
      "   -1.13825637e+00 -3.63171940e+00]\n",
      "  [ 1.34065682e-01 -1.24349063e-02 -1.82702799e-01  8.14546712e-02\n",
      "    3.64421498e-02 -1.69925587e-01]]] reward= -5626568.627873074 done= False\n",
      "Step 176\n",
      "Action:  [ 1.7853891   0.30647516 -1.5462462   1.5503334   4.4988475  -0.6476398 ]\n",
      "self.next: 176\n",
      "obs= [[[ 2.68987054 -2.21212059 -0.33560131  0.13761794 -1.2381152\n",
      "    0.10891789]\n",
      "  [ 0.03160113  0.0350024  -0.06371544 -0.09358299  0.25317278\n",
      "   -0.2866693 ]]\n",
      "\n",
      " [[ 4.626817   -1.9878568  -3.27232055  2.15403434 -1.13461215\n",
      "   -3.64871196]\n",
      "  [ 0.1348565  -0.01345302 -0.18228636  0.08051288  0.03671897\n",
      "   -0.16924915]]] reward= -5848782.251153312 done= False\n",
      "Step 177\n",
      "Action:  [ 1.7845793   0.30638283 -1.5454352   1.5496972   4.4958663  -0.6470257 ]\n",
      "self.next: 177\n",
      "obs= [[[ 2.69303065e+00 -2.20862035e+00 -3.41972849e-01  1.28259639e-01\n",
      "   -1.21279792e+00  8.02509647e-02]\n",
      "  [ 5.45852067e-03  1.51838480e-02 -2.03360956e-02 -1.62570093e-03\n",
      "    2.69319655e-03  4.50186047e-02]]\n",
      "\n",
      " [[ 4.64030265e+00 -1.98920210e+00 -3.29054918e+00  2.16208562e+00\n",
      "   -1.13094025e+00 -3.66563688e+00]\n",
      "  [ 1.35648524e-01 -1.44741337e-02 -1.81847223e-01  7.95409023e-02\n",
      "    3.70075184e-02 -1.68592010e-01]]] reward= -6813543.5476269405 done= False\n",
      "Step 178\n",
      "Action:  [ 1.7852745   0.30648637 -1.5461638   1.5503143   4.498612   -0.64759946]\n",
      "self.next: 178\n",
      "obs= [[[ 2.69357650e+00 -2.20710196e+00 -3.44006459e-01  1.28097069e-01\n",
      "   -1.21252860e+00  8.47528251e-02]\n",
      "  [-4.15478320e-03 -1.41686478e-02  1.77333992e-02  1.49437780e-03\n",
      "    3.79493552e-04  5.22471375e-02]]\n",
      "\n",
      " [[ 4.65386751e+00 -1.99064951e+00 -3.30873391e+00  2.17003971e+00\n",
      "   -1.12723950e+00 -3.68249608e+00]\n",
      "  [ 1.36441858e-01 -1.54987452e-02 -1.81384725e-01  7.85384636e-02\n",
      "    3.73079117e-02 -1.67954636e-01]]] reward= -6175832.060836885 done= False\n",
      "Step 179\n",
      "Action:  [ 1.7852473   0.30648896 -1.5461417   1.5503      4.498567   -0.6475809 ]\n",
      "self.next: 179\n",
      "obs= [[[ 2.69316102 -2.20851883 -0.34223312  0.12824651 -1.21249065\n",
      "    0.08997754]\n",
      "  [ 0.0533222  -0.06521049  0.13198935 -0.1356332   0.01416554\n",
      "    0.03941104]]\n",
      "\n",
      " [[ 4.66751169 -1.99219939 -3.32687238  2.17789356 -1.12350871\n",
      "   -3.69929154]\n",
      "  [ 0.13723668 -0.01652738 -0.18089823  0.0775053   0.03762028\n",
      "   -0.16733748]]] reward= -6185583.959776236 done= False\n",
      "Step 180\n",
      "Action:  [ 1.7852373  0.3065305 -1.5461317  1.550316   4.498391  -0.6474999]\n",
      "self.next: 180\n",
      "obs= [[[ 2.69849324e+00 -2.21503988e+00 -3.29034184e-01  1.14683188e-01\n",
      "   -1.21107410e+00  9.39186426e-02]\n",
      "  [-4.08657490e-04  1.42246915e-02 -1.22157417e-02 -2.25644304e-03\n",
      "    6.84836338e-02  2.61729043e-02]]\n",
      "\n",
      " [[ 4.68123536e+00 -1.99385213e+00 -3.34496220e+00  2.18564409e+00\n",
      "   -1.11974668e+00 -3.71602529e+00]\n",
      "  [ 1.38033213e-01 -1.75606328e-02 -1.80387143e-01  7.64411460e-02\n",
      "    3.79447242e-02 -1.66740982e-01]]] reward= -7143054.136370409 done= False\n",
      "Step 181\n",
      "Action:  [ 1.785081   0.3064997 -1.5459788  1.5502274  4.497901  -0.64744  ]\n",
      "self.next: 181\n",
      "obs= [[[ 2.69845238e+00 -2.21361741e+00 -3.30255758e-01  1.14457543e-01\n",
      "   -1.20422573e+00  9.65359331e-02]\n",
      "  [ 9.77102424e-04 -1.52592759e-03  3.01181758e-04  1.33459838e-03\n",
      "    2.02110803e-03 -1.69779713e-03]]\n",
      "\n",
      " [[ 4.69503868e+00 -1.99560819e+00 -3.36300092e+00  2.19328820e+00\n",
      "   -1.11595221e+00 -3.73269939e+00]\n",
      "  [ 1.38831773e-01 -1.85991174e-02 -1.79850885e-01  7.53457619e-02\n",
      "    3.82813670e-02 -1.66165526e-01]]] reward= -7035668.653958887 done= False\n",
      "Step 182\n",
      "Action:  [ 1.7851007   0.30648518 -1.5460039   1.5502484   4.4980264  -0.64744943]\n",
      "self.next: 182\n",
      "obs= [[[ 2.69855009 -2.21377    -0.33022564  0.114591   -1.20402362\n",
      "    0.09636615]\n",
      "  [-0.03410483  0.08549859 -0.05178214 -0.1175356   0.09226746\n",
      "    0.07553914]]\n",
      "\n",
      " [[ 4.70892186 -1.9974681  -3.380986    2.20082278 -1.11212407\n",
      "   -3.74931594]\n",
      "  [ 0.13963272 -0.01964351 -0.17928892  0.0742189   0.03863031\n",
      "   -0.16561149]]] reward= -6008388.236687977 done= False\n",
      "Step 183\n",
      "Action:  [ 1.7846627  0.3065934 -1.5456034  1.5500468  4.496348  -0.6471775]\n",
      "self.next: 183\n",
      "obs= [[[ 2.69513961 -2.20522014 -0.33540385  0.10283744 -1.19479688\n",
      "    0.10392007]\n",
      "  [ 0.05634809 -0.07578453 -0.00990073  0.08016641  0.05186315\n",
      "   -0.01326019]]\n",
      "\n",
      " [[ 4.72288513 -1.99943245 -3.3989149   2.20824467 -1.10826104\n",
      "   -3.76587709]\n",
      "  [ 0.14043647 -0.02069451 -0.17870073  0.07306034  0.03899164\n",
      "   -0.16507921]]] reward= -6325075.949864062 done= False\n",
      "Step 184\n",
      "Action:  [ 1.7851006   0.30644822 -1.5459954   1.5502571   4.498123   -0.64742476]\n",
      "self.next: 184\n",
      "obs= [[[ 2.70077441 -2.2127986  -0.33639393  0.11085408 -1.18961056\n",
      "    0.10259405]\n",
      "  [-0.00600489  0.01619531 -0.01036262 -0.02675271  0.02748045\n",
      "    0.05023217]]\n",
      "\n",
      " [[ 4.73692878 -2.0015019  -3.41678497  2.2155507  -1.10436188\n",
      "   -3.78238501]\n",
      "  [ 0.14124352 -0.02175288 -0.17808585  0.07186984  0.03936547\n",
      "   -0.16456903]]] reward= -7468414.471037688 done= False\n",
      "Step 185\n",
      "Action:  [ 1.7848629   0.30654064 -1.545798    1.5501794   4.497204   -0.6472963 ]\n",
      "self.next: 185\n",
      "obs= [[[ 2.70017393 -2.21117906 -0.33743019  0.10817881 -1.18686252\n",
      "    0.10761726]\n",
      "  [-0.06090562  0.03406131  0.05545792 -0.07968479  0.04971155\n",
      "    0.05396778]]\n",
      "\n",
      " [[ 4.75105313 -2.00367719 -3.43459355  2.22273769 -1.10042533\n",
      "   -3.79884191]\n",
      "  [ 0.1420544  -0.02281939 -0.17744382  0.07064717  0.03975187\n",
      "   -0.16408124]]] reward= -6369963.119850619 done= False\n",
      "Step 186\n",
      "Action:  [ 1.7845826  0.3065767 -1.5455441  1.5499943  4.4962535 -0.6471296]\n",
      "self.next: 186\n",
      "obs= [[[ 2.69408336 -2.20777293 -0.3318844   0.10021033 -1.18189136\n",
      "    0.11301404]\n",
      "  [ 0.01526658  0.01218482 -0.02762437 -0.0916997   0.16450067\n",
      "   -0.07825591]]\n",
      "\n",
      " [[ 4.76525857 -2.00595913 -3.45233794  2.22980241 -1.09645015\n",
      "   -3.81525004]\n",
      "  [ 0.1428697  -0.02389485 -0.17677422  0.06939212  0.04015094\n",
      "   -0.16361613]]] reward= -6375557.232961488 done= False\n",
      "Step 187\n",
      "Action:  [ 1.7844214   0.30652717 -1.5453609   1.5498875   4.4955163  -0.6469265 ]\n",
      "self.next: 187\n",
      "obs= [[[ 2.69561002e+00 -2.20655445e+00 -3.34646834e-01  9.10403631e-02\n",
      "   -1.16544129e+00  1.05188452e-01]\n",
      "  [-4.80179382e-03 -1.35331473e-02  1.92185644e-02 -2.66797055e-03\n",
      "    6.93524413e-03  4.62943253e-02]]\n",
      "\n",
      " [[ 4.77954554e+00 -2.00834862e+00 -3.47001536e+00  2.23674162e+00\n",
      "   -1.09243505e+00 -3.83161165e+00]\n",
      "  [ 1.43690069e-01 -2.49801068e-02 -1.76076666e-01  6.81044742e-02\n",
      "    4.05627681e-02 -1.63173958e-01]]] reward= -6768519.435388156 done= False\n",
      "Step 188\n",
      "Action:  [ 1.7846699   0.30653802 -1.5456318   1.550087    4.4966955  -0.6471743 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 188\n",
      "obs= [[[ 2.69512984 -2.20790777 -0.33272498  0.09077357 -1.16474777\n",
      "    0.10981788]\n",
      "  [-0.01716277  0.06971101 -0.25588968  0.22468854 -0.02058786\n",
      "   -0.00490626]]\n",
      "\n",
      " [[ 4.79391455 -2.01084663 -3.48762303  2.24355207 -1.08837877\n",
      "   -3.84792905]\n",
      "  [ 0.14451619 -0.02607603 -0.17535078  0.066784    0.04098743\n",
      "   -0.16275498]]] reward= -6468227.476142042 done= False\n",
      "Step 189\n",
      "Action:  [ 1.7843714  0.3064423 -1.5453354  1.5498792  4.4958873 -0.6470804]\n",
      "self.next: 189\n",
      "obs= [[[ 2.69341357e+00 -2.20093667e+00 -3.58313946e-01  1.13242420e-01\n",
      "   -1.16680655e+00  1.09327258e-01]\n",
      "  [-3.28741449e-04 -1.77765274e-02  1.86728201e-02 -5.85168887e-04\n",
      "    9.28429700e-02 -1.50993514e-01]]\n",
      "\n",
      " [[ 4.80836617e+00 -2.01345423e+00 -3.50515810e+00  2.25023047e+00\n",
      "   -1.08428003e+00 -3.86420454e+00]\n",
      "  [ 1.45348807e-01 -2.71834999e-02 -1.74596237e-01  6.54304897e-02\n",
      "    4.14250106e-02 -1.62359436e-01]]] reward= -7647639.81873835 done= False\n",
      "Step 190\n",
      "Action:  [ 1.7842599   0.30647397 -1.5452261   1.5497708   4.495208   -0.646851  ]\n",
      "self.next: 190\n",
      "obs= [[[ 2.69338069e+00 -2.20271432e+00 -3.56446664e-01  1.13183903e-01\n",
      "   -1.15752226e+00  9.42279064e-02]\n",
      "  [-5.24334491e-03 -7.43316746e-03  3.90715448e-02 -5.00136053e-02\n",
      "    2.37454427e-02  3.89877415e-03]]\n",
      "\n",
      " [[ 4.82290105e+00 -2.01617258e+00 -3.52261773e+00  2.25677351e+00\n",
      "   -1.08013753e+00 -3.88044049e+00]\n",
      "  [ 1.46188691e-01 -2.83034356e-02 -1.73812708e-01  6.40437164e-02\n",
      "    4.18755958e-02 -1.61987546e-01]]] reward= -6569717.344380217 done= False\n",
      "Step 191\n",
      "Action:  [ 1.7843757   0.30656022 -1.5453672   1.5499531   4.495647   -0.64695454]\n",
      "self.next: 191\n",
      "obs= [[[ 2.69285636 -2.20345763 -0.35253951  0.10818254 -1.15514771\n",
      "    0.09461778]\n",
      "  [ 0.03280775 -0.03608424  0.18006299 -0.14660971 -0.0511872\n",
      "   -0.02513345]]\n",
      "\n",
      " [[ 4.83751992 -2.01900292 -3.539999    2.26317789 -1.07594997\n",
      "   -3.89663924]\n",
      "  [ 0.14703666 -0.02943676 -0.1729999   0.06262346  0.04233927\n",
      "   -0.16163953]]] reward= -6197109.624204828 done= False\n",
      "Step 192\n",
      "Action:  [ 1.7843891   0.30658132 -1.5453869   1.5499593   4.495688   -0.6469252 ]\n",
      "self.next: 192\n",
      "obs= [[[ 2.69613713e+00 -2.20706606e+00 -3.34533210e-01  9.35215713e-02\n",
      "   -1.16026643e+00  9.21044391e-02]\n",
      "  [-4.49471710e-03 -2.49881664e-02  3.26830203e-02 -4.48637605e-03\n",
      "   -7.03755594e-02  1.25325728e-01]]\n",
      "\n",
      " [[ 4.85222358e+00 -2.02194660e+00 -3.55729899e+00  2.26944023e+00\n",
      "   -1.07171604e+00 -3.91280320e+00]\n",
      "  [ 1.47893570e-01 -3.05844201e-02 -1.72157549e-01  6.11694963e-02\n",
      "    4.28161204e-02 -1.61315595e-01]]] reward= -7971551.625929261 done= False\n",
      "Step 193\n",
      "Action:  [ 1.7844704   0.30658868 -1.545475    1.5500801   4.4961762  -0.6470685 ]\n",
      "self.next: 193\n",
      "obs= [[[ 2.69568766 -2.20956488 -0.33126491  0.09307293 -1.16730399\n",
      "    0.10463701]\n",
      "  [-0.03199698 -0.05047818  0.08566057  0.08435985 -0.15611873\n",
      "    0.03269916]]\n",
      "\n",
      " [[ 4.86701294 -2.02500504 -3.57451474  2.27555718 -1.06743443\n",
      "   -3.92893475]\n",
      "  [ 0.1487603  -0.03174736 -0.17128539  0.0596816   0.04330624\n",
      "   -0.16101595]]] reward= -6053557.320676405 done= False\n",
      "Step 194\n",
      "Action:  [ 1.784468    0.3065137  -1.5454658   1.5500025   4.49637    -0.64708775]\n",
      "self.next: 194\n",
      "obs= [[[ 2.69248796e+00 -2.21461269e+00 -3.22698852e-01  1.01508919e-01\n",
      "   -1.18291586e+00  1.07906928e-01]\n",
      "  [-9.76578661e-04  1.37240837e-03 -5.88381839e-04 -1.41386067e-04\n",
      "   -1.38683226e-03  1.32245103e-03]]\n",
      "\n",
      " [[ 4.88188897e+00 -2.02817978e+00 -3.59164328e+00  2.28152534e+00\n",
      "   -1.06310381e+00 -3.94503635e+00]\n",
      "  [ 1.49637764e-01 -3.29265574e-02 -1.70383193e-01  5.81595261e-02\n",
      "    4.38097089e-02 -1.60740792e-01]]] reward= -5989830.089554013 done= False\n",
      "Step 195\n",
      "Action:  [ 1.784336    0.3065556  -1.5453198   1.5499903   4.4955416  -0.64691144]\n",
      "self.next: 195\n",
      "obs= [[[ 2.69239030e+00 -2.21447545e+00 -3.22757690e-01  1.01494780e-01\n",
      "   -1.18305455e+00  1.08039173e-01]\n",
      "  [-1.45557385e-03  9.10659467e-02 -2.94553181e-01  1.37279288e-01\n",
      "    2.08586224e-01 -2.48430652e-01]]\n",
      "\n",
      " [[ 4.89685275e+00 -2.03147243e+00 -3.60868160e+00  2.28734129e+00\n",
      "   -1.05872284e+00 -3.96111043e+00]\n",
      "  [ 1.50526897e-01 -3.41229666e-02 -1.69450733e-01  5.66030506e-02\n",
      "    4.43266358e-02 -1.60490328e-01]]] reward= -6345791.743227784 done= False\n",
      "Step 196\n",
      "Action:  [ 1.7832632   0.30643424 -1.5442766   1.5491928   4.4918375  -0.6462646 ]\n",
      "self.next: 196\n",
      "obs= [[[ 2.69224475e+00 -2.20536886e+00 -3.52213008e-01  1.15222709e-01\n",
      "   -1.16219592e+00  8.31961076e-02]\n",
      "  [ 1.02598921e-02  1.94201005e-02 -1.60503242e-03 -5.07417793e-02\n",
      "   -4.86901553e-02  2.14872401e-01]]\n",
      "\n",
      " [[ 4.91190544e+00 -2.03488473e+00 -3.62562668e+00  2.29300160e+00\n",
      "   -1.05429017e+00 -3.97715946e+00]\n",
      "  [ 1.51428658e-01 -3.53375630e-02 -1.68487802e-01  5.50119275e-02\n",
      "    4.48571172e-02 -1.60264760e-01]]] reward= -8674429.98867844 done= False\n",
      "Step 197\n",
      "Action:  [ 1.7841356   0.30667472 -1.5451834   1.550007    4.4950104  -0.64686537]\n",
      "self.next: 197\n",
      "obs= [[[ 2.69327074 -2.20342685 -0.35237351  0.11014853 -1.16706494\n",
      "    0.10468335]\n",
      "  [ 0.03463881 -0.03537307  0.20606414 -0.22791147  0.11546991\n",
      "   -0.2510883 ]]\n",
      "\n",
      " [[ 4.9270483  -2.03841849 -3.64247546  2.29850279 -1.04980446\n",
      "   -3.99318594]\n",
      "  [ 0.15234402 -0.03657132 -0.16749421  0.05338591  0.04540126\n",
      "   -0.1600643 ]]] reward= -6885909.598045247 done= False\n",
      "Step 198\n",
      "Action:  [ 1.7835518  0.3065538 -1.544569   1.5494156  4.4926405 -0.6462562]\n",
      "self.next: 198\n",
      "obs= [[[ 2.69673462 -2.20696415 -0.3317671   0.08735738 -1.15551795\n",
      "    0.07957452]\n",
      "  [-0.03936017 -0.0802324   0.08976467  0.14327023 -0.18097785\n",
      "    0.17851728]]\n",
      "\n",
      " [[ 4.9422827  -2.04207562 -3.65922488  2.30384138 -1.04526434\n",
      "   -4.00919237]\n",
      "  [ 0.15327398 -0.0378252  -0.16646977  0.05172475  0.04595917\n",
      "   -0.15988915]]] reward= -8289287.073379106 done= False\n",
      "Step 199\n",
      "Action:  [ 1.7841429   0.30656034 -1.5451984   1.5499021   4.4955907  -0.6469482 ]\n",
      "self.next: 199\n",
      "obs= [[[ 2.6927986  -2.21498739 -0.32279063  0.10168441 -1.17361573\n",
      "    0.09742625]\n",
      "  [ 0.0385222   0.05715421 -0.09634102 -0.08952564  0.25454058\n",
      "   -0.28566637]]\n",
      "\n",
      " [[ 4.9576101  -2.04585814 -3.67587185  2.30901386 -1.04066842\n",
      "   -4.02518128]\n",
      "  [ 0.15421952 -0.03910016 -0.1654143   0.0500282   0.04653098\n",
      "   -0.15973955]]] reward= -7114222.642053392 done= False\n",
      "Step 200\n",
      "Action:  [ 1.7830983   0.3065201  -1.5441368   1.5491823   4.4910464  -0.64600927]\n",
      "self.next: 200\n",
      "obs= [[[ 2.69665082 -2.20927197 -0.33242473  0.09273184 -1.14816168\n",
      "    0.06885961]\n",
      "  [-0.02389672  0.05734642 -0.18425628  0.12607732  0.02952921\n",
      "    0.19598044]]\n",
      "\n",
      " [[ 4.97303205 -2.04976815 -3.69241328  2.31401668 -1.03601532\n",
      "   -4.04115524]\n",
      "  [ 0.15518165 -0.04039717 -0.16432764  0.048296    0.04711679\n",
      "   -0.15961572]]] reward= -7488213.362866003 done= False\n",
      "Step 201\n",
      "Action:  [ 1.7836703   0.3066202  -1.5447524   1.5497432   4.493634   -0.64660466]\n",
      "self.next: 201\n",
      "obs= [[[ 2.69426115e+00 -2.20353733e+00 -3.50850360e-01  1.05339575e-01\n",
      "   -1.14520875e+00  8.84576529e-02]\n",
      "  [-3.98390594e-03 -7.09510207e-03 -1.47404625e-02  4.78606589e-02\n",
      "    5.50802950e-02  1.30998469e-02]]\n",
      "\n",
      " [[ 4.98855022e+00 -2.05380787e+00 -3.70884605e+00  2.31884628e+00\n",
      "   -1.03130364e+00 -4.05711681e+00]\n",
      "  [ 1.56161367e-01 -4.17171511e-02 -1.63209633e-01  4.65278892e-02\n",
      "    4.77167515e-02 -1.59517906e-01]]] reward= -8291130.975800919 done= False\n",
      "Step 202\n",
      "Action:  [ 1.7836862   0.30657756 -1.5447494   1.5496836   4.493544   -0.6465045 ]\n",
      "self.next: 202\n",
      "obs= [[[ 2.69386276 -2.20424684 -0.35232441  0.11012564 -1.13970072\n",
      "    0.08976764]\n",
      "  [-0.01064623 -0.01762085  0.05387284 -0.0510183   0.02945147\n",
      "    0.0504314 ]]\n",
      "\n",
      " [[ 5.00416635 -2.05797959 -3.72516701  2.32349907 -1.02653197\n",
      "   -4.0730686 ]\n",
      "  [ 0.15715968 -0.04306103 -0.16206012  0.04472362  0.04833099\n",
      "   -0.15944637]]] reward= -7670646.442948853 done= False\n",
      "Step 203\n",
      "Action:  [ 1.7836493   0.30663076 -1.5447288   1.549711    4.493364   -0.64645797]\n",
      "self.next: 203\n",
      "obs= [[[ 2.69279813 -2.20600893 -0.34693712  0.10502381 -1.13675558\n",
      "    0.09481078]\n",
      "  [ 0.00822965  0.03261059 -0.01691124 -0.04524249  0.27735084\n",
      "   -0.17659732]]\n",
      "\n",
      " [[ 5.01988232 -2.06228569 -3.74137302  2.32797143 -1.02169887\n",
      "   -4.08901324]\n",
      "  [ 0.15817756 -0.04442971 -0.16087895  0.04288294  0.04895964\n",
      "   -0.15940138]]] reward= -6788319.5786407795 done= False\n",
      "Step 204\n",
      "Action:  [ 1.7828597   0.3065716  -1.5439566   1.5491127   4.4904737  -0.64589006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 204\n",
      "obs= [[[ 2.6936211  -2.20274787 -0.34862825  0.10049956 -1.10902049\n",
      "    0.07715105]\n",
      "  [-0.04603817 -0.05956396  0.22806793 -0.10050326  0.06296603\n",
      "   -0.09254216]]\n",
      "\n",
      " [[ 5.03570008 -2.06672866 -3.75746092  2.33225972 -1.0168029\n",
      "   -4.10495337]\n",
      "  [ 0.15921599 -0.04582406 -0.15966599  0.04100559  0.04960285\n",
      "   -0.15938322]]] reward= -9211268.234737411 done= False\n",
      "Step 205\n",
      "Action:  [ 1.7831441   0.30659866 -1.5442654   1.5493023   4.4917645  -0.6460952 ]\n",
      "self.next: 205\n",
      "obs= [[[ 2.68901728 -2.20870426 -0.32582145  0.09044924 -1.10272389\n",
      "    0.06789683]\n",
      "  [ 0.05465068 -0.07689528  0.02410596  0.01951167  0.17587587\n",
      "   -0.02325504]]\n",
      "\n",
      " [[ 5.05162168 -2.07131107 -3.77342752  2.33636028 -1.01184262\n",
      "   -4.1208917 ]\n",
      "  [ 0.16027593 -0.04724493 -0.15842109  0.03909135  0.05026079\n",
      "   -0.1593922 ]]] reward= -7965022.6845787475 done= False\n",
      "Step 206\n",
      "Action:  [ 1.7832891   0.30658236 -1.5443904   1.5494828   4.4922485  -0.64617413]\n",
      "self.next: 206\n",
      "obs= [[[ 2.69448235e+00 -2.21639379e+00 -3.23410857e-01  9.24004028e-02\n",
      "   -1.08513630e+00  6.55713258e-02]\n",
      "  [ 7.71969810e-03  1.10738485e-02 -1.81381374e-02  8.94454889e-04\n",
      "    1.71375769e-01 -2.32889559e-01]]\n",
      "\n",
      " [[ 5.06764927e+00 -2.07603556e+00 -3.78926963e+00  2.34026942e+00\n",
      "   -1.00681654e+00 -4.13683092e+00]\n",
      "  [ 1.61358293e-01 -4.86931295e-02 -1.57144120e-01  3.71399881e-02\n",
      "    5.09335966e-02 -1.59428641e-01]]] reward= -9106850.8617011 done= False\n",
      "Step 207\n",
      "Action:  [ 1.7826934   0.30652618 -1.543837    1.5490382   4.4901776  -0.64579934]\n",
      "self.next: 207\n",
      "obs= [[[ 2.69525432e+00 -2.21528641e+00 -3.25224671e-01  9.24898483e-02\n",
      "   -1.06799873e+00  4.22823699e-02]\n",
      "  [-9.71437706e-03 -2.74394060e-02  3.73878896e-02  2.50457281e-04\n",
      "    5.99971457e-03  9.01765124e-02]]\n",
      "\n",
      " [[ 5.08378510e+00 -2.08090487e+00 -3.80498404e+00  2.34398342e+00\n",
      "   -1.00172318e+00 -4.15277378e+00]\n",
      "  [ 1.62463981e-01 -5.01694324e-02 -1.55834946e-01  3.51512927e-02\n",
      "    5.16214386e-02 -1.59492887e-01]]] reward= -7690107.397839968 done= False\n",
      "Step 208\n",
      "Action:  [ 1.7831874   0.30663455 -1.5443567   1.5495229   4.4921436  -0.64619565]\n",
      "self.next: 208\n",
      "obs= [[[ 2.69428288e+00 -2.21803035e+00 -3.21485882e-01  9.25148940e-02\n",
      "   -1.06739876e+00  5.13000212e-02]\n",
      "  [-2.07928950e-03  2.31015324e-03 -3.46433910e-04 -1.64232988e-03\n",
      "   -1.02634722e-03  1.81384915e-03]]\n",
      "\n",
      " [[ 5.10003150e+00 -2.08592181e+00 -3.82056753e+00  2.34749855e+00\n",
      "   -9.96561036e-01 -4.16872307e+00]\n",
      "  [ 1.63593847e-01 -5.16745626e-02 -1.54493449e-01  3.31250794e-02\n",
      "    5.23244783e-02 -1.59585298e-01]]] reward= -7172878.8470977405 done= False\n",
      "Step 209\n",
      "Action:  [ 1.7830852   0.30660862 -1.5442538   1.5494555   4.491729   -0.64610183]\n",
      "self.next: 209\n",
      "obs= [[[ 2.69407495 -2.21779933 -0.32152053  0.09235066 -1.06750139\n",
      "    0.05148141]\n",
      "  [ 0.03806325  0.01141135  0.01212093 -0.17077718  0.02632346\n",
      "    0.38890894]]\n",
      "\n",
      " [[ 5.11639088 -2.09108927 -3.83601688  2.35081105 -0.99132859\n",
      "   -4.1846816 ]\n",
      "  [ 0.1647487  -0.05320919 -0.15311951  0.03106119  0.05304288\n",
      "   -0.15970625]]] reward= -6654220.03774698 done= False\n",
      "Step 210\n",
      "Action:  [ 1.7829052   0.30682898 -1.544133    1.5495661   4.491134   -0.64607644]\n",
      "self.next: 210\n",
      "obs= [[[ 2.69788128e+00 -2.21665820e+00 -3.20308433e-01  7.52729433e-02\n",
      "   -1.06486904e+00  9.03722998e-02]\n",
      "  [-3.66017495e-03  2.71018016e-02 -2.36306415e-02 -2.44499739e-02\n",
      "    1.06903376e-01 -1.36728717e-01]]\n",
      "\n",
      " [[ 5.13286575e+00 -2.09641019e+00 -3.85132883e+00  2.35391717e+00\n",
      "   -9.86024300e-01 -4.20065222e+00]\n",
      "  [ 1.65929289e-01 -5.47739372e-02 -1.51713017e-01  2.89594954e-02\n",
      "    5.37768059e-02 -1.59856151e-01]]] reward= -8163391.101286933 done= False\n",
      "Step 211\n",
      "Action:  [ 1.7826465   0.3065836  -1.543826    1.549136    4.4900947  -0.64576656]\n",
      "self.next: 211\n",
      "obs= [[[ 2.69751526e+00 -2.21394802e+00 -3.22671497e-01  7.28279459e-02\n",
      "   -1.05417871e+00  7.66994280e-02]\n",
      "  [-3.95690559e-02  5.36456530e-02 -1.32991322e-02 -7.87739649e-04\n",
      "   -9.04052998e-02  1.01126004e-01]]\n",
      "\n",
      " [[ 5.14945868e+00 -2.10188758e+00 -3.86650013e+00  2.35681312e+00\n",
      "   -9.80646619e-01 -4.21663784e+00]\n",
      "  [ 1.67136305e-01 -5.63693410e-02 -1.50273877e-01  2.68199158e-02\n",
      "    5.45264191e-02 -1.60035407e-01]]] reward= -7102002.479727559 done= False\n",
      "Step 212\n",
      "Action:  [ 1.7828397  0.3066568 -1.5440578  1.5493785  4.4910893 -0.6460122]\n",
      "self.next: 212\n",
      "obs= [[[ 2.69355836 -2.20858345 -0.32400141  0.07274917 -1.06321924\n",
      "    0.08681203]\n",
      "  [ 0.05498713 -0.04685623 -0.03726722  0.07215306  0.04417138\n",
      "   -0.10625212]]\n",
      "\n",
      " [[ 5.16617231 -2.10752452 -3.88152752  2.35949511 -0.97519398\n",
      "   -4.23264138]\n",
      "  [ 0.16837036 -0.05799587 -0.148802    0.02464242  0.05529188\n",
      "   -0.16024445]]] reward= -6711954.941973012 done= False\n",
      "Step 213\n",
      "Action:  [ 1.7828132   0.30654874 -1.5439795   1.5492615   4.490903   -0.6458794 ]\n",
      "self.next: 213\n",
      "obs= [[[ 2.69905707 -2.21326907 -0.32772813  0.07996448 -1.0588021\n",
      "    0.07618682]\n",
      "  [-0.04764145  0.05571244 -0.00911063 -0.02249343 -0.0615852\n",
      "    0.10130178]]\n",
      "\n",
      " [[ 5.18300935 -2.1133241  -3.89640772  2.36195935 -0.96966479\n",
      "   -4.24866582]\n",
      "  [ 0.16963199 -0.05965392 -0.14729733  0.02242702  0.05607333\n",
      "   -0.16048374]]] reward= -7484519.995342938 done= False\n",
      "Step 214\n",
      "Action:  [ 1.7826844   0.3066744  -1.543917    1.5493178   4.4905357  -0.64589345]\n",
      "self.next: 214\n",
      "obs= [[[ 2.69429292 -2.20769783 -0.3286392   0.07771513 -1.06496062\n",
      "    0.08631699]\n",
      "  [ 0.04124318 -0.06774353  0.02818548  0.02004571  0.06363214\n",
      "   -0.05532324]]\n",
      "\n",
      " [[ 5.19997255 -2.1192895  -3.91113745  2.36420206 -0.96405746\n",
      "   -4.2647142 ]\n",
      "  [ 0.17092162 -0.06134377 -0.14575981  0.02017383  0.05687091\n",
      "   -0.16075373]]] reward= -6809647.198064214 done= False\n",
      "Step 215\n",
      "Action:  [ 1.7827281   0.30659232 -1.5439115   1.5492594   4.490615   -0.64580005]\n",
      "self.next: 215\n",
      "obs= [[[ 2.69841724e+00 -2.21447218e+00 -3.25820647e-01  7.97197061e-02\n",
      "   -1.05859741e+00  8.07846702e-02]\n",
      "  [ 1.19234163e-02  4.29273129e-03 -1.82715909e-02  2.67151094e-02\n",
      "    1.49225961e-01 -4.31672593e-01]]\n",
      "\n",
      " [[ 5.21706471e+00 -2.12542387e+00 -3.92571343e+00  2.36621944e+00\n",
      "   -9.58370366e-01 -4.28078957e+00]\n",
      "  [ 1.72239583e-01 -6.30655989e-02 -1.44189419e-01  1.78830083e-02\n",
      "    5.76847494e-02 -1.61054900e-01]]] reward= -7572013.981161567 done= False\n",
      "Step 216\n",
      "Action:  [ 1.7815896   0.30646455 -1.5428206   1.5483422   4.48673    -0.6450839 ]\n",
      "self.next: 216\n",
      "obs= [[[ 2.69960958e+00 -2.21404291e+00 -3.27647806e-01  8.23912170e-02\n",
      "   -1.04367481e+00  3.76174109e-02]\n",
      "  [-9.59513567e-03 -2.02780337e-02  3.14867265e-02 -1.90562096e-03\n",
      "   -8.56956986e-02  1.39531701e-01]]\n",
      "\n",
      " [[ 5.23428867e+00 -2.13173043e+00 -3.94013237e+00  2.36800774e+00\n",
      "   -9.52601891e-01 -4.29689506e+00]\n",
      "  [ 1.73586082e-01 -6.48194708e-02 -1.42586166e-01  1.55548347e-02\n",
      "    5.85149549e-02 -1.61387717e-01]]] reward= -7308047.781008635 done= False\n",
      "Step 217\n",
      "Action:  [ 1.7826124   0.30666992 -1.5438682   1.5493236   4.4905124  -0.6458368 ]\n",
      "self.next: 217\n",
      "obs= [[[ 2.69865007e+00 -2.21607071e+00 -3.24499134e-01  8.22006549e-02\n",
      "   -1.05224438e+00  5.15705810e-02]\n",
      "  [-6.98122638e-04  1.53862936e-03  5.41134399e-04 -4.06659709e-03\n",
      "    2.23526533e-03  3.64625566e-04]]\n",
      "\n",
      " [[ 5.25164727e+00 -2.13821238e+00 -3.95439099e+00  2.36956322e+00\n",
      "   -9.46750396e-01 -4.31303383e+00]\n",
      "  [ 1.74961184e-01 -6.66053109e-02 -1.40950099e-01  1.31896846e-02\n",
      "    5.93616123e-02 -1.61752670e-01]]] reward= -6668502.37697857 done= False\n",
      "Step 218\n",
      "Action:  [ 1.7824477  0.306634  -1.5436893  1.5491848  4.4897647 -0.6456602]\n",
      "self.next: 218\n",
      "obs= [[[ 2.69858026 -2.21591685 -0.32444502  0.081794   -1.05202085\n",
      "    0.05160704]\n",
      "  [-0.05496481  0.04498486  0.00884517 -0.02200114 -0.06345612\n",
      "    0.05026403]]\n",
      "\n",
      " [[ 5.26914339 -2.14487291 -3.968486    2.37088219 -0.94081423\n",
      "   -4.3292091 ]\n",
      "  [ 0.17636481 -0.0684229  -0.1392813   0.01078806  0.06022478\n",
      "   -0.16215024]]] reward= -6924420.040161911 done= False\n",
      "Step 219\n",
      "Action:  [ 1.7822948   0.30666214 -1.5435672   1.5491236   4.489343   -0.6456126 ]\n",
      "self.next: 219\n",
      "obs= [[[ 2.69308378e+00 -2.21141836e+00 -3.23560503e-01  7.95938813e-02\n",
      "   -1.05836646e+00  5.66334467e-02]\n",
      "  [ 4.49696858e-02 -4.11138555e-02 -4.87378275e-03  3.38720146e-04\n",
      "    8.90679099e-02 -4.86408027e-02]]\n",
      "\n",
      " [[ 5.28677987e+00 -2.15171520e+00 -3.98241413e+00  2.37196100e+00\n",
      "   -9.34791757e-01 -4.34542413e+00]\n",
      "  [ 1.77796696e-01 -7.02718418e-02 -1.37579923e-01  8.35059660e-03\n",
      "    6.11044816e-02 -1.62580887e-01]]] reward= -7005935.743454662 done= False\n",
      "Step 220\n",
      "Action:  [ 1.7822922   0.30662093 -1.5435263   1.5490888   4.489199   -0.6454995 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 220\n",
      "obs= [[[ 2.69758075e+00 -2.21552975e+00 -3.24047881e-01  7.96277534e-02\n",
      "   -1.04945967e+00  5.17693665e-02]\n",
      "  [ 8.15524269e-05 -6.22983741e-04 -2.16349903e-04 -8.37016333e-04\n",
      "    3.76713429e-03  9.30125449e-02]]\n",
      "\n",
      " [[ 5.30455954e+00 -2.15874239e+00 -3.99617212e+00  2.37279606e+00\n",
      "   -9.28681309e-01 -4.36168221e+00]\n",
      "  [ 1.79256411e-01 -7.21515763e-02 -1.35846153e-01  5.87809806e-03\n",
      "    6.20007066e-02 -1.63045079e-01]]] reward= -7885655.498755579 done= False\n",
      "Step 221\n",
      "Action:  [ 1.7822978   0.30667385 -1.5435684   1.5491736   4.48938    -0.6455772 ]\n",
      "self.next: 221\n",
      "obs= [[[ 2.69758890e+00 -2.21559205e+00 -3.24069516e-01  7.95440517e-02\n",
      "   -1.04908296e+00  6.10706210e-02]\n",
      "  [-4.97574357e-03 -1.53806075e-02  2.01184187e-02 -6.42734649e-04\n",
      "    8.55265488e-02 -1.38109389e-01]]\n",
      "\n",
      " [[ 5.32248518e+00 -2.16595754e+00 -4.00975674e+00  2.37338387e+00\n",
      "   -9.22481238e-01 -4.37798672e+00]\n",
      "  [ 1.80743305e-01 -7.40613310e-02 -1.34080265e-01  3.37153884e-03\n",
      "    6.29133958e-02 -1.63543245e-01]]] reward= -7549345.269480138 done= False\n",
      "Step 222\n",
      "Action:  [ 1.7819084   0.30659756 -1.5431749   1.5488157   4.48796    -0.6452574 ]\n",
      "self.next: 222\n",
      "obs= [[[ 2.69709133e+00 -2.21713011e+00 -3.22057674e-01  7.94797783e-02\n",
      "   -1.04053031e+00  4.72596821e-02]\n",
      "  [-2.77068257e-03  1.25924130e-01 -1.23455255e-01 -1.32063315e-01\n",
      "    1.33439644e-01  3.07316310e-01]]\n",
      "\n",
      " [[ 5.34055951e+00 -2.17336368e+00 -4.02316476e+00  2.37372102e+00\n",
      "   -9.16189898e-01 -4.39434105e+00]\n",
      "  [ 1.82256503e-01 -7.60001167e-02 -1.32282609e-01  8.32092951e-04\n",
      "    6.38424379e-02 -1.64075786e-01]]] reward= -7213498.261054812 done= False\n",
      "Step 223\n",
      "Action:  [ 1.781644   0.3068453 -1.5430089  1.5489695  4.487021  -0.6452148]\n",
      "self.next: 223\n",
      "obs= [[[ 2.69681426e+00 -2.20453770e+00 -3.34403200e-01  6.62734468e-02\n",
      "   -1.02718634e+00  7.79913130e-02]\n",
      "  [-1.72993224e-02 -4.20229967e-02  6.00325612e-02 -3.97898437e-03\n",
      "    9.50455706e-02 -5.11316726e-02]]\n",
      "\n",
      " [[ 5.35878516e+00 -2.18096369e+00 -4.03639303e+00  2.37380423e+00\n",
      "   -9.09805655e-01 -4.41074862e+00]\n",
      "  [ 1.83794881e-01 -7.79667031e-02 -1.30453628e-01 -1.73884483e-03\n",
      "    6.47876610e-02 -1.64643060e-01]]] reward= -9378448.279632188 done= False\n",
      "Step 224\n",
      "Action:  [ 1.7817336  0.3066322 -1.5430356  1.5487485  4.4875326 -0.6451605]\n",
      "self.next: 224\n",
      "obs= [[[ 2.69508433e+00 -2.20874000e+00 -3.28399944e-01  6.58755483e-02\n",
      "   -1.01768178e+00  7.28781458e-02]\n",
      "  [-2.87587626e-02 -6.81112820e-02  6.95804752e-02  6.90111642e-02\n",
      "    4.23680043e-02 -1.71387089e-01]]\n",
      "\n",
      " [[ 5.37716465e+00 -2.18876036e+00 -4.04943839e+00  2.37363035e+00\n",
      "   -9.03326888e-01 -4.42721293e+00]\n",
      "  [ 1.85357046e-01 -7.99595991e-02 -1.28593869e-01 -4.33963730e-03\n",
      "    6.57488244e-02 -1.65245372e-01]]] reward= -7757897.2772018835 done= False\n",
      "Step 225\n",
      "Action:  [ 1.7815218   0.30655602 -1.5428311   1.5485355   4.4870195  -0.645042  ]\n",
      "self.next: 225\n",
      "obs= [[[ 2.69220845 -2.21555112 -0.3214419   0.07277666 -1.01344498\n",
      "    0.05573944]\n",
      "  [-0.01870695  0.07374337 -0.20667233  0.12890411  0.02649366\n",
      "    0.19343404]]\n",
      "\n",
      " [[ 5.39570036 -2.19675632 -4.06229778  2.37319638 -0.89675201\n",
      "   -4.44373747]\n",
      "  [ 0.18694131 -0.08197703 -0.126704   -0.00696838  0.06672561\n",
      "   -0.16588296]]] reward= -7209466.368306976 done= False\n",
      "Step 226\n",
      "Action:  [ 1.7815645   0.30668885 -1.5429252   1.5488254   4.4872513  -0.64520836]\n",
      "self.next: 226\n",
      "obs= [[[ 2.69033776e+00 -2.20817679e+00 -3.42109129e-01  8.56670758e-02\n",
      "   -1.01079562e+00  7.50828405e-02]\n",
      "  [-8.35980174e-03 -1.31091802e-02  2.03729262e-02  1.66761928e-03\n",
      "    5.90363167e-04  4.23094060e-02]]\n",
      "\n",
      " [[ 5.41439449e+00 -2.20495402e+00 -4.07496818e+00  2.37249954e+00\n",
      "   -8.90079445e-01 -4.46032576e+00]\n",
      "  [ 1.88545665e-01 -8.40169105e-02 -1.24784813e-01 -9.62287403e-03\n",
      "    6.77176056e-02 -1.66555982e-01]]] reward= -9019853.600003568 done= False\n",
      "Step 227\n",
      "Action:  [ 1.781709    0.3066668  -1.5430442   1.5488639   4.487607   -0.64517206]\n",
      "self.next: 227\n",
      "obs= [[[ 2.68950178 -2.2094877  -0.34007184  0.08583384 -1.01073658\n",
      "    0.07931378]\n",
      "  [ 0.06346193 -0.12943722  0.21641036 -0.10155417  0.03532826\n",
      "   -0.11145433]]\n",
      "\n",
      " [[ 5.43324905 -2.21335571 -4.08744666  2.37153726 -0.88330768\n",
      "   -4.47698136]\n",
      "  [ 0.19016777 -0.08607683 -0.12283726 -0.01230061  0.06872431\n",
      "   -0.1672645 ]]] reward= -7290871.503833542 done= False\n",
      "Step 228\n",
      "Action:  [ 1.7816943   0.30663574 -1.5430017   1.5487789   4.487467   -0.64501244]\n",
      "self.next: 228\n",
      "obs= [[[ 2.69584797e+00 -2.22243143e+00 -3.18430801e-01  7.56784204e-02\n",
      "   -1.00720375e+00  6.81683485e-02]\n",
      "  [-4.98741722e-02  4.06747172e-02 -1.68454292e-02  2.34157380e-02\n",
      "   -8.16465345e-02 -3.89522341e-04]]\n",
      "\n",
      " [[ 5.45226583e+00 -2.22196340e+00 -4.09973038e+00  2.37030720e+00\n",
      "   -8.76435254e-01 -4.49370781e+00]\n",
      "  [ 1.91804903e-01 -8.81540376e-02 -1.20862463e-01 -1.49987243e-02\n",
      "    6.97451097e-02 -1.68008455e-01]]] reward= -8332495.16623584 done= False\n",
      "Step 229\n",
      "Action:  [ 1.7815384   0.30664188 -1.5428953   1.5487689   4.487134   -0.6450888 ]\n",
      "self.next: 229\n",
      "obs= [[[ 2.69086055 -2.21836395 -0.32011534  0.07801999 -1.01536841\n",
      "    0.0681294 ]\n",
      "  [ 0.01047202  0.00964918  0.03993627 -0.08175578  0.10508053\n",
      "   -0.08924608]]\n",
      "\n",
      " [[ 5.47144632 -2.2307788  -4.11181663  2.36880732 -0.86946074\n",
      "   -4.51050866]\n",
      "  [ 0.19345398 -0.09024539 -0.1188617  -0.017714    0.07077927\n",
      "   -0.16878767]]] reward= -7711550.072902595 done= False\n",
      "Step 230\n",
      "Action:  [ 1.7813151   0.30666512 -1.5426645   1.5486283   4.4860716  -0.64481485]\n",
      "self.next: 230\n",
      "obs= [[[ 2.69190775e+00 -2.21739904e+00 -3.16121716e-01  6.98444159e-02\n",
      "   -1.00486036e+00  5.92047886e-02]\n",
      "  [ 1.35681297e-04 -6.54560817e-04 -7.30145548e-04  2.38473918e-03\n",
      "    8.54506794e-04 -1.10418953e-03]]\n",
      "\n",
      " [[ 5.49079172e+00 -2.23980334e+00 -4.12370280e+00  2.36703592e+00\n",
      "   -8.62382816e-01 -4.52738742e+00]\n",
      "  [ 1.95111509e-01 -9.23473687e-02 -1.16836476e-01 -2.04428331e-02\n",
      "    7.18259284e-02 -1.69601810e-01]]] reward= -7822214.310612536 done= False\n",
      "Step 231\n",
      "Action:  [ 1.7814128   0.30665413 -1.542776    1.5487242   4.4866934  -0.64494765]\n",
      "self.next: 231\n",
      "obs= [[[ 2.69192132e+00 -2.21746449e+00 -3.16194731e-01  7.00828898e-02\n",
      "   -1.00477490e+00  5.90943696e-02]\n",
      "  [ 8.89860377e-03  4.58586294e-03 -1.19791528e-02 -4.63579245e-03\n",
      "    8.94348856e-02 -1.28821345e-01]]\n",
      "\n",
      " [[ 5.51030287e+00 -2.24903808e+00 -4.13538645e+00  2.36499164e+00\n",
      "   -8.55200223e-01 -4.54434761e+00]\n",
      "  [ 1.96773562e-01 -9.44560451e-02 -1.14788487e-01 -2.31811955e-02\n",
      "    7.28840844e-02 -1.70450372e-01]]] reward= -7283616.964547634 done= False\n",
      "Step 232\n",
      "Action:  [ 1.7810644  0.3066239 -1.5424349  1.5484552  4.485416  -0.6446797]\n",
      "self.next: 232\n",
      "obs= [[[ 2.69281118 -2.21700591 -0.31739265  0.06961931 -0.99583142\n",
      "    0.04621224]\n",
      "  [ 0.03433093  0.00631304 -0.04122911 -0.07092878  0.2441903\n",
      "   -0.13842659]]\n",
      "\n",
      " [[ 5.52998023 -2.25848368 -4.1468653   2.36267352 -0.84791181\n",
      "   -4.56139264]\n",
      "  [ 0.19843579 -0.09656707 -0.11271967 -0.02592464  0.07395259\n",
      "   -0.17133266]]] reward= -7614427.024759497 done= False\n",
      "Step 233\n",
      "Action:  [ 1.780658    0.30666158 -1.5420603   1.5482315   4.4838843  -0.64437175]\n",
      "self.next: 233\n",
      "obs= [[[ 2.69624427 -2.2163746  -0.32151556  0.06252643 -0.97141239\n",
      "    0.03236958]\n",
      "  [-0.06536957  0.03500524  0.02997514 -0.04229942  0.04540097\n",
      "   -0.03629907]]\n",
      "\n",
      " [[ 5.54982381 -2.26814039 -4.15813726  2.36008106 -0.84051656\n",
      "   -4.57852591]\n",
      "  [ 0.2000934  -0.09867567 -0.11063221 -0.02866829  0.07503012\n",
      "   -0.17224777]]] reward= -8823280.855332637 done= False\n",
      "Step 234\n",
      "Action:  [ 1.7806972   0.30666852 -1.542147    1.5482942   4.484401   -0.644502  ]\n",
      "self.next: 234\n",
      "obs= [[[ 2.68970732 -2.21287408 -0.31851804  0.05829649 -0.96687229\n",
      "    0.02873967]\n",
      "  [ 0.05758858 -0.05092502 -0.00671127  0.02198018  0.14110488\n",
      "    0.19067628]]\n",
      "\n",
      " [[ 5.56983315 -2.27800795 -4.16920048  2.35721423 -0.83301354\n",
      "   -4.59575069]\n",
      "  [ 0.20174115 -0.10077664 -0.10852855 -0.0314068   0.07611523\n",
      "   -0.17319457]]] reward= -7451934.554348611 done= False\n",
      "Step 235\n",
      "Action:  [ 1.7809238   0.3067248  -1.5423672   1.5485425   4.485354   -0.64465266]\n",
      "self.next: 235\n",
      "obs= [[[ 2.69546617e+00 -2.21796658e+00 -3.19189170e-01  6.04945086e-02\n",
      "   -9.52761801e-01  4.78072971e-02]\n",
      "  [ 1.27632543e-03  1.33375869e-02 -1.46026435e-02 -2.24786337e-02\n",
      "    1.04408315e-01  3.47811867e-02]]\n",
      "\n",
      " [[ 5.59000726e+00 -2.28808562e+00 -4.18005334e+00  2.35407355e+00\n",
      "   -8.25402021e-01 -4.61307014e+00]\n",
      "  [ 2.03373366e-01 -1.02864337e-01 -1.06411385e-01 -3.41343785e-02\n",
      "    7.72062439e-02 -1.74171677e-01]]] reward= -10588048.991644222 done= False\n",
      "Step 236\n",
      "Action:  [ 1.7806861   0.30669463 -1.5421462   1.5483629   4.4844103  -0.64446884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 236\n",
      "obs= [[[ 2.69559381 -2.21663282 -0.32064943  0.05824665 -0.94232097\n",
      "    0.05128542]\n",
      "  [-0.02501422 -0.03284667  0.02602366  0.05469776  0.06505265\n",
      "   -0.03413093]]\n",
      "\n",
      " [[ 5.6103446  -2.29837205 -4.19069448  2.35066011 -0.8176814\n",
      "   -4.63048731]\n",
      "  [ 0.20498395 -0.10493272 -0.10428371 -0.0368448   0.07830136\n",
      "   -0.17517743]]] reward= -8559201.609252581 done= False\n",
      "Step 237\n",
      "Action:  [ 1.7805088  0.306635  -1.541976   1.5481697  4.4840593 -0.6443768]\n",
      "self.next: 237\n",
      "obs= [[[ 2.69309239 -2.21991749 -0.31804707  0.06371642 -0.9358157\n",
      "    0.04787232]\n",
      "  [ 0.0201913   0.02413851 -0.01373586 -0.05202257  0.02520711\n",
      "    0.31690224]]\n",
      "\n",
      " [[ 5.63084299 -2.30886532 -4.20112285  2.34697563 -0.80985126\n",
      "   -4.64800505]\n",
      "  [ 0.20656638 -0.10697536 -0.1021488  -0.0395314   0.07939857\n",
      "   -0.1762099 ]]] reward= -8203321.10686186 done= False\n",
      "Step 238\n",
      "Action:  [ 1.7806782   0.30679733 -1.5421921   1.5485412   4.48469    -0.6445524 ]\n",
      "self.next: 238\n",
      "obs= [[[ 2.69511151 -2.21750364 -0.31942065  0.05851416 -0.93329499\n",
      "    0.07956255]\n",
      "  [-0.05511203  0.01712416  0.06903115 -0.05347282 -0.05339737\n",
      "    0.18459281]]\n",
      "\n",
      " [[ 5.65149963 -2.31956286 -4.21133773  2.34302249 -0.8019114\n",
      "   -4.66562604]\n",
      "  [ 0.2081138  -0.10898544 -0.10001019 -0.0421871   0.08049572\n",
      "   -0.17726686]]] reward= -9308040.012176262 done= False\n",
      "Step 239\n",
      "Action:  [ 1.7806019   0.30674294 -1.5421093   1.5484097   4.4844804  -0.64447826]\n",
      "self.next: 239\n",
      "obs= [[[ 2.68960031e+00 -2.21579122e+00 -3.12517540e-01  5.31668822e-02\n",
      "   -9.38634730e-01  9.80218269e-02]\n",
      "  [-5.06687983e-03 -2.58193776e-02 -1.90628118e-01  3.82623367e-01\n",
      "   -7.48848526e-02 -3.40324276e-01]]\n",
      "\n",
      " [[ 5.67231101e+00 -2.33046140e+00 -4.22133875e+00  2.33880378e+00\n",
      "   -7.93861831e-01 -4.68335273e+00]\n",
      "  [ 2.09619007e-01 -1.10955850e-01 -9.78717269e-02 -4.48044735e-02\n",
      "    8.15904611e-02 -1.78345771e-01]]] reward= -7415279.966381666 done= False\n",
      "Step 240\n",
      "Action:  [ 1.7794992   0.30641174 -1.5409617   1.5472846   4.4812546  -0.6438934 ]\n",
      "self.next: 240\n",
      "obs= [[[ 2.68909362e+00 -2.21837316e+00 -3.31580352e-01  9.14292188e-02\n",
      "   -9.46123216e-01  6.39893993e-02]\n",
      "  [ 4.49574012e-04 -2.90651498e-03  6.05999550e-03 -4.60586639e-03\n",
      "    3.65134987e-03 -1.41420649e-03]]\n",
      "\n",
      " [[ 5.69327291e+00 -2.34155699e+00 -4.23112592e+00  2.33432333e+00\n",
      "   -7.85702785e-01 -4.70118731e+00]\n",
      "  [ 2.11074529e-01 -1.12879202e-01 -9.57374918e-02 -4.73757417e-02\n",
      "    8.26803044e-02 -1.79443794e-01]]] reward= -9819269.566366825 done= False\n",
      "Step 241\n",
      "Action:  [ 1.7805066   0.30667016 -1.5419815   1.5483136   4.484029   -0.6443202 ]\n",
      "self.next: 241\n",
      "obs= [[[ 2.68913858 -2.21866381 -0.33097435  0.09096863 -0.94575808\n",
      "    0.06384798]\n",
      "  [ 0.06227015 -0.03596935 -0.02638002  0.02108999 -0.02817158\n",
      "    0.26429174]]\n",
      "\n",
      " [[ 5.71438036 -2.35284491 -4.24069967  2.32958576 -0.77743475\n",
      "   -4.71913169]\n",
      "  [ 0.21247271 -0.11474792 -0.09361183 -0.04989288  0.08376261\n",
      "   -0.18055779]]] reward= -7414196.252616842 done= False\n",
      "Step 242\n",
      "Action:  [ 1.7807149   0.3067435  -1.5422057   1.5485836   4.4849935  -0.64451873]\n",
      "self.next: 242\n",
      "obs= [[[ 2.69536560e+00 -2.22226075e+00 -3.33612354e-01  9.30776309e-02\n",
      "   -9.48575238e-01  9.02771523e-02]\n",
      "  [-5.47445879e-05 -1.35183354e-03 -5.73806543e-06  2.59148188e-03\n",
      "   -2.88334829e-04 -8.52332070e-04]]\n",
      "\n",
      " [[ 5.73562764e+00 -2.36431970e+00 -4.25006085e+00  2.32459647e+00\n",
      "   -7.69058493e-01 -4.73718747e+00]\n",
      "  [ 2.13805783e-01 -1.16554300e-01 -9.14993198e-02 -5.23476725e-02\n",
      "    8.48346340e-02 -1.81684326e-01]]] reward= -8919211.149224162 done= False\n",
      "Step 243\n",
      "Action:  [ 1.7804866   0.30667093 -1.5419587   1.5483241   4.483976   -0.6442852 ]\n",
      "self.next: 243\n",
      "obs= [[[ 2.69536012e+00 -2.22239593e+00 -3.33612928e-01  9.33367791e-02\n",
      "   -9.48604072e-01  9.01919191e-02]\n",
      "  [ 1.48193304e-02  4.03783591e-03 -1.83223234e-02 -9.72790762e-02\n",
      "    1.87176572e-01 -1.92845901e-02]]\n",
      "\n",
      " [[ 5.75700821e+00 -2.37597513e+00 -4.25921079e+00  2.31936170e+00\n",
      "   -7.60575030e-01 -4.75535590e+00]\n",
      "  [ 2.15065956e-01 -1.18290627e-01 -8.94047095e-02 -5.47317960e-02\n",
      "    8.58935040e-02 -1.82819689e-01]]] reward= -7479986.321142865 done= False\n",
      "Step 244\n",
      "Action:  [ 1.7801007  0.3067204 -1.5415978  1.5481216  4.4823937 -0.6439618]\n",
      "self.next: 244\n",
      "obs= [[[ 2.69684206 -2.22199215 -0.33544516  0.08360887 -0.92988641\n",
      "    0.08826346]\n",
      "  [-0.0522184   0.04603015  0.00775343 -0.02420676  0.03185682\n",
      "   -0.21047159]]\n",
      "\n",
      " [[ 5.77851481 -2.38780419 -4.26815126  2.31388852 -0.75198568\n",
      "   -4.77363787]\n",
      "  [ 0.21624553 -0.11994925 -0.08733292 -0.05703692  0.0869363\n",
      "   -0.18395992]]] reward= -8561825.207547326 done= False\n",
      "Step 245\n",
      "Action:  [ 1.7796985   0.30661666 -1.5412228   1.547744    4.4813166  -0.6437641 ]\n",
      "self.next: 245\n",
      "obs= [[[ 2.69162021 -2.21738913 -0.33466982  0.0811882  -0.92670073\n",
      "    0.0672163 ]\n",
      "  [-0.00635897  0.06437621 -0.05810163 -0.11700574  0.11650694\n",
      "    0.29329041]]\n",
      "\n",
      " [[ 5.80013936 -2.39979912 -4.27688455  2.30818483 -0.74329205\n",
      "   -4.79203386]\n",
      "  [ 0.21733702 -0.12152269 -0.08528896 -0.05925482  0.08796005\n",
      "   -0.18510083]]] reward= -8250818.192496773 done= False\n",
      "Step 246\n",
      "Action:  [ 1.779817    0.3068356  -1.5414095   1.5481431   4.481841   -0.64392436]\n",
      "self.next: 246\n",
      "obs= [[[ 2.69098432e+00 -2.21095151e+00 -3.40479980e-01  6.94876217e-02\n",
      "   -9.15050039e-01  9.65453421e-02]\n",
      "  [-5.45478739e-03  9.88489778e-03 -3.36733198e-03 -2.18234917e-02\n",
      "    2.24181596e-02  6.06320058e-02]]\n",
      "\n",
      " [[ 5.82187306e+00 -2.41195139e+00 -4.28541344e+00  2.30225935e+00\n",
      "   -7.34496044e-01 -4.81054394e+00]\n",
      "  [ 2.18333246e-01 -1.23003799e-01 -8.32779197e-02 -6.13774648e-02\n",
      "    8.89618026e-02 -1.86238075e-01]]] reward= -9381020.44632777 done= False\n",
      "Step 247\n",
      "Action:  [ 1.7798741   0.30670503 -1.5414261   1.548021    4.482175   -0.6439033 ]\n",
      "self.next: 247\n",
      "obs= [[[ 2.69043884 -2.20996302 -0.34081671  0.06730527 -0.91280822\n",
      "    0.10260854]\n",
      "  [-0.01838135 -0.01467587  0.18547566 -0.24426161  0.09513348\n",
      "    0.07520757]]\n",
      "\n",
      " [[ 5.84370639 -2.42425177 -4.29374124  2.2961216  -0.72559986\n",
      "   -4.82916775]\n",
      "  [ 0.21922749 -0.12438581 -0.08130486 -0.06339718  0.08993863\n",
      "   -0.18736716]]] reward= -7825016.789273422 done= False\n",
      "Step 248\n",
      "Action:  [ 1.779606    0.3067814  -1.5411857   1.5479058   4.4810643  -0.64363015]\n",
      "self.next: 248\n",
      "obs= [[[ 2.6886007  -2.21143061 -0.32226915  0.04287911 -0.90329488\n",
      "    0.1101293 ]\n",
      "  [ 0.06170762 -0.04843046 -0.01180112  0.03701842  0.04422479\n",
      "   -0.05750426]]\n",
      "\n",
      " [[ 5.86562914 -2.43669035 -4.30187172  2.28978189 -0.716606\n",
      "   -4.84790447]\n",
      "  [ 0.2200136  -0.12566252 -0.07937479 -0.06530673  0.09088769\n",
      "   -0.18848353]]] reward= -8039711.042095289 done= False\n",
      "Step 249\n",
      "Action:  [ 1.779672    0.30664232 -1.5412151   1.5478272   4.4816327  -0.6437182 ]\n",
      "self.next: 249\n",
      "obs= [[[ 2.69477147e+00 -2.21627365e+00 -3.23449259e-01  4.65809536e-02\n",
      "   -8.98872397e-01  1.04378874e-01]\n",
      "  [-1.68011343e-02  4.12286832e-03 -1.41627164e-01  2.05507761e-01\n",
      "    2.36641061e-02 -1.86707223e-01]]\n",
      "\n",
      " [[ 5.88763050e+00 -2.44925660e+00 -4.30980920e+00  2.28325121e+00\n",
      "   -7.07517233e-01 -4.86675282e+00]\n",
      "  [ 2.20686108e-01 -1.26828353e-01 -7.74925882e-02 -6.70994619e-02\n",
      "    9.18062693e-02 -1.89582614e-01]]] reward= -8483537.823497979 done= False\n",
      "Step 250\n",
      "Action:  [ 1.7789786   0.30655316 -1.5405517   1.5472597   4.4795403  -0.6433992 ]\n",
      "self.next: 250\n",
      "obs= [[[ 2.69309135 -2.21586137 -0.33761198  0.06713173 -0.89650599\n",
      "    0.08570815]\n",
      "  [ 0.01080229  0.07924942 -0.08964315 -0.09300726  0.19834224\n",
      "    0.03396755]]\n",
      "\n",
      " [[ 5.90969911 -2.46193944 -4.31755846  2.27654127 -0.69833661\n",
      "   -4.88571108]\n",
      "  [ 0.22124035 -0.12787849 -0.07566292 -0.06876939  0.09269183\n",
      "   -0.19065989]]] reward= -8754267.973152597 done= False\n",
      "Step 251\n",
      "Action:  [ 1.7790596   0.3067552  -1.5406907   1.547605    4.479297   -0.64332914]\n",
      "self.next: 251\n",
      "obs= [[[ 2.69417158e+00 -2.20793642e+00 -3.46576291e-01  5.78310034e-02\n",
      "   -8.76671762e-01  8.91049066e-02]\n",
      "  [-2.15560830e-02  3.12006329e-02 -3.84704068e-02 -4.56961789e-02\n",
      "    4.16088153e-03  1.69445071e-01]]\n",
      "\n",
      " [[ 5.93182314e+00 -2.47472729e+00 -4.32512475e+00  2.26966433e+00\n",
      "   -6.89067423e-01 -4.90477707e+00]\n",
      "  [ 2.21672533e-01 -1.28808965e-01 -7.38902036e-02 -7.03113371e-02\n",
      "    9.35420277e-02 -1.91710949e-01]]] reward= -9593730.886232369 done= False\n",
      "Step 252\n",
      "Action:  [ 1.7792087   0.30674937 -1.5408589   1.5477368   4.4803014  -0.643513  ]\n",
      "self.next: 252\n",
      "obs= [[[ 2.69201597 -2.20481636 -0.35042333  0.05326139 -0.87625567\n",
      "    0.10604941]\n",
      "  [ 0.0606821  -0.10336848  0.06816971  0.08999471  0.03572221\n",
      "   -0.14785112]]\n",
      "\n",
      " [[ 5.9539904  -2.48760818 -4.33251377  2.26263319 -0.67971322\n",
      "   -4.92394816]\n",
      "  [ 0.22197985 -0.12961672 -0.07217853 -0.07172098  0.09435478\n",
      "   -0.19273158]]] reward= -8084176.16172852 done= False\n",
      "Step 253\n",
      "Action:  [ 1.7789599   0.30659714 -1.54056     1.547319    4.4796505  -0.6432553 ]\n",
      "self.next: 253\n",
      "obs= [[[ 2.69808418e+00 -2.21515321e+00 -3.43606361e-01  6.22608567e-02\n",
      "   -8.72683454e-01  9.12643018e-02]\n",
      "  [-1.46816642e-03  3.57263963e-04  2.78716398e-03 -3.84527712e-03\n",
      "    2.10756744e-03 -2.42606648e-05]]\n",
      "\n",
      " [[ 5.97618838e+00 -2.50056985e+00 -4.33973163e+00  2.25546109e+00\n",
      "   -6.70277742e-01 -4.94322132e+00]\n",
      "  [ 2.22160520e-01 -1.30299680e-01 -7.05316052e-02 -7.29949621e-02\n",
      "    9.51282854e-02 -1.93717809e-01]]] reward= -9006472.756190758 done= False\n",
      "Step 254\n",
      "Action:  [ 1.7790601   0.30667862 -1.5406932   1.5475597   4.479841   -0.6433465 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 254\n",
      "obs= [[[ 2.69793737e+00 -2.21511748e+00 -3.43327645e-01  6.18763290e-02\n",
      "   -8.72472697e-01  9.12618757e-02]\n",
      "  [ 8.23428634e-03 -2.90615233e-04 -6.46263639e-03 -5.83159827e-04\n",
      "    7.48496411e-02 -9.78433074e-02]]\n",
      "\n",
      " [[ 5.99840443e+00 -2.51359982e+00 -4.34678479e+00  2.24816160e+00\n",
      "   -6.60764913e-01 -4.96259310e+00]\n",
      "  [ 2.22213796e-01 -1.30856779e-01 -6.89527151e-02 -7.41309057e-02\n",
      "    9.58610345e-02 -1.94665970e-01]]] reward= -7674741.793393578 done= False\n",
      "Step 255\n",
      "Action:  [ 1.7787405  0.3066563 -1.5403813  1.5473144  4.478702  -0.6431047]\n",
      "self.next: 255\n",
      "obs= [[[ 2.69876079e+00 -2.21514654e+00 -3.43973908e-01  6.18180130e-02\n",
      "   -8.64987733e-01  8.14775449e-02]\n",
      "  [ 4.79074692e-03 -5.22727334e-03 -2.54983704e-02  4.50503885e-02\n",
      "   -1.52732962e-02  1.82823345e-01]]\n",
      "\n",
      " [[ 6.02062581e+00 -2.52668550e+00 -4.35368006e+00  2.24074851e+00\n",
      "   -6.51178810e-01 -4.98205970e+00]\n",
      "  [ 2.22140016e-01 -1.31287974e-01 -6.74446717e-02 -7.51274689e-02\n",
      "    9.65518563e-02 -1.95572756e-01]]] reward= -8223312.340898547 done= False\n",
      "Step 256\n",
      "Action:  [ 1.7788969   0.30672345 -1.540572    1.5475525   4.479648   -0.6433161 ]\n",
      "self.next: 256\n",
      "obs= [[[ 2.69923987 -2.21566927 -0.34652375  0.06632305 -0.86651506\n",
      "    0.09975988]\n",
      "  [-0.03433314  0.07018057 -0.01242403 -0.06322882  0.05773563\n",
      "   -0.14482789]]\n",
      "\n",
      " [[ 6.04283982 -2.5398143  -4.36042452  2.23323576 -0.64152362\n",
      "   -5.00161698]\n",
      "  [ 0.22194056 -0.13159423 -0.06600979 -0.07598434  0.09719992\n",
      "   -0.19643526]]] reward= -8931970.928120974 done= False\n",
      "Step 257\n",
      "Action:  [ 1.7783474   0.30666685 -1.5400271   1.5471101   4.477331   -0.6428431 ]\n",
      "self.next: 257\n",
      "obs= [[[ 2.69580655e+00 -2.20865121e+00 -3.47766148e-01  6.00001696e-02\n",
      "   -8.60741499e-01  8.52770902e-02]\n",
      "  [ 4.07458169e-02 -4.23430483e-02  3.01505673e-03  1.75839285e-02\n",
      "   -1.47167505e-02  1.97819141e-01]]\n",
      "\n",
      " [[ 6.06503387e+00 -2.55297372e+00 -4.36702550e+00  2.22563733e+00\n",
      "   -6.31803632e-01 -5.02126050e+00]\n",
      "  [ 2.21617837e-01 -1.31777502e-01 -6.46498729e-02 -7.67022157e-02\n",
      "    9.78047277e-02 -1.97251022e-01]]] reward= -7633986.65914411 done= False\n",
      "Step 258\n",
      "Action:  [ 1.7787204   0.30673245 -1.540413    1.5474844   4.479179   -0.64316815]\n",
      "self.next: 258\n",
      "obs= [[[ 2.69988114 -2.21288552 -0.34746464  0.06175856 -0.86221317\n",
      "    0.105059  ]\n",
      "  [-0.02648512 -0.02999352  0.05592257  0.09761673 -0.1197752\n",
      "    0.10606313]]\n",
      "\n",
      " [[ 6.08719566 -2.56615147 -4.37349049  2.21796711 -0.62202316\n",
      "   -5.0409856 ]\n",
      "  [ 0.22117519 -0.13184065 -0.06336619 -0.07728278  0.09836614\n",
      "   -0.19801803]]] reward= -9015757.113065459 done= False\n",
      "Step 259\n",
      "Action:  [ 1.7785529   0.30667284 -1.5402399   1.5472814   4.478851   -0.64309776]\n",
      "self.next: 259\n",
      "obs= [[[ 2.69723262 -2.21588487 -0.34187239  0.07152024 -0.87419069\n",
      "    0.11566532]\n",
      "  [ 0.03748452 -0.05281594 -0.00816043  0.06346058  0.03530518\n",
      "   -0.16867387]]\n",
      "\n",
      " [[ 6.10931317 -2.57933554 -4.37982711  2.21023883 -0.61218655\n",
      "   -5.06078741]\n",
      "  [ 0.22061683 -0.13178739 -0.0621595  -0.07772862  0.09888434\n",
      "   -0.19873475]]] reward= -8148664.8435097085 done= False\n",
      "Step 260\n",
      "Action:  [ 1.7783077   0.30661216 -1.5399529   1.5470388   4.4775643  -0.6427821 ]\n",
      "self.next: 260\n",
      "obs= [[[ 2.70098108 -2.22116647 -0.34268843  0.07786629 -0.87066018\n",
      "    0.09879793]\n",
      "  [-0.0166773   0.05750567  0.13793224 -0.38926229  0.23245199\n",
      "   -0.02199027]]\n",
      "\n",
      " [[ 6.13137486 -2.59251427 -4.38604306  2.20246597 -0.60229811\n",
      "   -5.08066088]\n",
      "  [ 0.21994777 -0.13162221 -0.06103006 -0.07804318  0.09935982\n",
      "   -0.19940011]]] reward= -8004938.323429348 done= False\n",
      "Step 261\n",
      "Action:  [ 1.7777425   0.30681953 -1.5394899   1.5469579   4.4750004  -0.64228284]\n",
      "self.next: 261\n",
      "obs= [[[ 2.69931335 -2.2154159  -0.3288952   0.03894006 -0.84741498\n",
      "    0.0965989 ]\n",
      "  [ 0.00836901  0.01164811  0.0083202  -0.04753972  0.01779808\n",
      "    0.02739055]]\n",
      "\n",
      " [[ 6.15336963 -2.60567649 -4.39214607  2.19466165 -0.59236213\n",
      "   -5.10060089]\n",
      "  [ 0.21917368 -0.13135023 -0.05997762 -0.07823066  0.09979337\n",
      "   -0.20001354]]] reward= -7961769.460890019 done= False\n",
      "Step 262\n",
      "Action:  [ 1.7780439   0.30670935 -1.5397784   1.5470573   4.476843   -0.64265   ]\n",
      "self.next: 262\n",
      "obs= [[[ 2.70015025e+00 -2.21425109e+00 -3.28063185e-01  3.41860922e-02\n",
      "   -8.45635170e-01  9.93379584e-02]\n",
      "  [-1.09821811e-02 -1.10456923e-02  2.16339406e-02 -2.21297330e-04\n",
      "    1.38742841e-03  3.53085666e-02]]\n",
      "\n",
      " [[ 6.17528700e+00 -2.61881152e+00 -4.39814383e+00  2.18683858e+00\n",
      "   -5.82382793e-01 -5.12060225e+00]\n",
      "  [ 2.18300761e-01 -1.30977147e-01 -5.90014997e-02 -7.82958965e-02\n",
      "    1.00186053e-01 -2.00574878e-01]]] reward= -7974278.817205712 done= False\n",
      "Step 263\n",
      "Action:  [ 1.7778535   0.30669525 -1.5396018   1.5469141   4.4764132  -0.64255446]\n",
      "self.next: 263\n",
      "obs= [[[ 2.69905203 -2.21535566 -0.32589979  0.03416396 -0.84549643\n",
      "    0.10286882]\n",
      "  [ 0.11832165  0.01550212 -0.1347641  -0.07636161  0.24830461\n",
      "    0.04658795]]\n",
      "\n",
      " [[ 6.19711708 -2.63190923 -4.40404398  2.17900899 -0.57236419\n",
      "   -5.14065974]\n",
      "  [ 0.21733569 -0.13050909 -0.0581006  -0.0782443   0.10053915\n",
      "   -0.2010844 ]]] reward= -8056210.591898327 done= False\n",
      "Step 264\n",
      "Action:  [ 1.7776191   0.30676097 -1.5393833   1.5468765   4.4751887  -0.64230704]\n",
      "self.next: 264\n",
      "obs= [[[ 2.71088419e+00 -2.21380544e+00 -3.39376200e-01  2.65278014e-02\n",
      "   -8.20665966e-01  1.07527610e-01]\n",
      "  [-3.56183310e-03 -8.17738526e-04 -1.79460229e-01  2.78306611e-01\n",
      "   -9.36978991e-02  4.15069177e-04]]\n",
      "\n",
      " [[ 6.21885065e+00 -2.64496014e+00 -4.40985404e+00  2.17118456e+00\n",
      "   -5.62310272e-01 -5.16076818e+00]\n",
      "  [ 2.16285425e-01 -1.29952522e-01 -5.72734491e-02 -7.80817097e-02\n",
      "    1.00854156e-01 -2.01542774e-01]]] reward= -11163738.459092874 done= False\n",
      "Step 265\n",
      "Action:  [ 1.7772136   0.30659965 -1.5389891   1.5464059   4.4748816  -0.64231515]\n",
      "self.next: 265\n",
      "obs= [[[ 2.71052801 -2.21388722 -0.35732222  0.05435846 -0.83003576\n",
      "    0.10756912]\n",
      "  [-0.04296472 -0.01505773  0.05917142  0.07316517 -0.16732736\n",
      "    0.01390208]]\n",
      "\n",
      " [[ 6.24047919 -2.65795539 -4.41558138  2.16337639 -0.55222486\n",
      "   -5.18092245]\n",
      "  [ 0.21515715 -0.12931412 -0.05651825 -0.07781432  0.10113272\n",
      "   -0.20195101]]] reward= -9250516.265158977 done= False\n",
      "Step 266\n",
      "Action:  [ 1.7774799   0.30665478 -1.5392579   1.5466658   4.475645   -0.6423748 ]\n",
      "self.next: 266\n",
      "obs= [[[ 2.70623154e+00 -2.21539299e+00 -3.51405081e-01  6.16749794e-02\n",
      "   -8.46768492e-01  1.08959325e-01]\n",
      "  [-1.34765783e-03 -6.59298059e-03 -1.90588560e-02  4.95539389e-02\n",
      "   -2.44518825e-02  3.05266095e-02]]\n",
      "\n",
      " [[ 6.26199490e+00 -2.67088681e+00 -4.42123321e+00  2.15559496e+00\n",
      "   -5.42111585e-01 -5.20111755e+00]\n",
      "  [ 2.13958148e-01 -1.28600675e-01 -5.58329186e-02 -7.74485463e-02\n",
      "    1.01376644e-01 -2.02310436e-01]]] reward= -7932220.787627884 done= False\n",
      "Step 267\n",
      "Action:  [ 1.7774607   0.30668882 -1.5392301   1.5467157   4.4753213  -0.6423004 ]\n",
      "self.next: 267\n",
      "obs= [[[ 2.70609677 -2.21605229 -0.35331097  0.06663037 -0.84921368\n",
      "    0.11201199]\n",
      "  [ 0.01164148 -0.00889601  0.20610313 -0.3045897   0.16750482\n",
      "   -0.24179717]]\n",
      "\n",
      " [[ 6.28339072 -2.68374687 -4.4268165   2.1478501  -0.53197392\n",
      "   -5.2213486 ]\n",
      "  [ 0.21269568 -0.12781902 -0.05521516 -0.07699096  0.10158781\n",
      "   -0.20262264]]] reward= -8154083.868441268 done= False\n",
      "Step 268\n",
      "Action:  [ 1.7766751   0.30670837 -1.538475    1.5461962   4.4719944  -0.64151466]\n",
      "self.next: 268\n",
      "obs= [[[ 2.70726092 -2.21694189 -0.33270065  0.0361714  -0.8324632\n",
      "    0.08783227]\n",
      "  [ 0.01478292  0.02121069 -0.06491047 -0.06704199  0.19094103\n",
      "   -0.06687115]]\n",
      "\n",
      " [[ 6.30466029 -2.69652877 -4.43233802  2.14015101 -0.52181514\n",
      "   -5.24161086]\n",
      "  [ 0.21137692 -0.12697591 -0.05466247 -0.07644816  0.10176817\n",
      "   -0.20288944]]] reward= -8393666.072270451 done= False\n",
      "Step 269\n",
      "Action:  [ 1.7766001   0.3067187  -1.5384444   1.5462041   4.4721627  -0.64166015]\n",
      "self.next: 269\n",
      "obs= [[[ 2.70873921e+00 -2.21482082e+00 -3.39191700e-01  2.94672047e-02\n",
      "   -8.13369095e-01  8.11451540e-02]\n",
      "  [ 1.04517705e-02  4.53838053e-03 -1.94199275e-01  2.72649012e-01\n",
      "   -8.96714704e-02  2.12127095e-01]]\n",
      "\n",
      " [[ 6.32579798e+00 -2.70922637e+00 -4.43780426e+00  2.13250619e+00\n",
      "   -5.11638323e-01 -5.26189981e+00]\n",
      "  [ 2.10008889e-01 -1.26077982e-01 -5.41722139e-02 -7.58267536e-02\n",
      "    1.01919735e-01 -2.03112832e-01]]] reward= -9206358.417879814 done= False\n",
      "Step 270\n",
      "Action:  [ 1.7765423   0.30667922 -1.5384132   1.5461768   4.4731855  -0.6419331 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 270\n",
      "obs= [[[ 2.70978439e+00 -2.21436698e+00 -3.58611628e-01  5.67321059e-02\n",
      "   -8.22336242e-01  1.02357864e-01]\n",
      "  [ 3.97185959e-04 -8.68906765e-02  1.11368659e-01  9.07814971e-02\n",
      "   -1.41814173e-01  9.31463210e-02]]\n",
      "\n",
      " [[ 6.34679887e+00 -2.72183416e+00 -4.44322148e+00  2.12492352e+00\n",
      "   -5.01446349e-01 -5.28221109e+00]\n",
      "  [ 2.08598372e-01 -1.25131671e-01 -5.37416685e-02 -7.51332214e-02\n",
      "    1.02044512e-01 -2.03294950e-01]]] reward= -10340234.292054003 done= False\n",
      "Step 271\n",
      "Action:  [ 1.776778    0.30668274 -1.5386274   1.5463105   4.4738092  -0.6419091 ]\n",
      "self.next: 271\n",
      "obs= [[[ 2.70982411e+00 -2.22305605e+00 -3.47474762e-01  6.58102556e-02\n",
      "   -8.36517660e-01  1.11672496e-01]\n",
      "  [-3.25952236e-02  3.11715346e-02  1.01238263e-03 -1.91246542e-02\n",
      "    2.28315595e-02  2.11483520e-01]]\n",
      "\n",
      " [[ 6.36765870e+00 -2.73434733e+00 -4.44859565e+00  2.11741019e+00\n",
      "   -4.91241898e-01 -5.30254058e+00]\n",
      "  [ 2.07151866e-01 -1.24143166e-01 -5.33680341e-02 -7.43739025e-02\n",
      "    1.02144507e-01 -2.03438032e-01]]] reward= -7937145.738340704 done= False\n",
      "Step 272\n",
      "Action:  [ 1.7766896   0.30679345 -1.5385672   1.5464345   4.4730706  -0.6418355 ]\n",
      "self.next: 272\n",
      "obs= [[[ 2.70656459e+00 -2.21993890e+00 -3.47373524e-01  6.38977902e-02\n",
      "   -8.34234504e-01  1.32820848e-01]\n",
      "  [-7.85082297e-04  9.28234996e-02 -1.16080109e-01 -9.39408168e-02\n",
      "    3.14680382e-01 -4.65422026e-01]]\n",
      "\n",
      " [[ 6.38837389e+00 -2.74676165e+00 -4.45393245e+00  2.10997280e+00\n",
      "   -4.81027447e-01 -5.32288439e+00]\n",
      "  [ 2.05675548e-01 -1.23118370e-01 -5.30484870e-02 -7.35549304e-02\n",
      "    1.02221693e-01 -2.03544383e-01]]] reward= -9166013.024816047 done= False\n",
      "Step 273\n",
      "Action:  [ 1.7747742  0.3066291 -1.5366883  1.544883   4.4658384 -0.6404335]\n",
      "self.next: 273\n",
      "obs= [[[ 2.70648608e+00 -2.21065655e+00 -3.58981535e-01  5.45037085e-02\n",
      "   -8.02766466e-01  8.62786450e-02]\n",
      "  [ 2.17622571e-03 -1.03113083e-02  3.07437017e-02 -2.11991979e-02\n",
      "    1.62068120e-01 -1.14330848e-01]]\n",
      "\n",
      " [[ 6.40894145e+00 -2.75907348e+00 -4.45923730e+00  2.10261731e+00\n",
      "   -4.70805278e-01 -5.34323883e+00]\n",
      "  [ 2.04175241e-01 -1.22062871e-01 -5.27802035e-02 -7.26821969e-02\n",
      "    1.02277998e-01 -2.03616340e-01]]] reward= -8720724.045847548 done= False\n",
      "Step 274\n",
      "Action:  [ 1.7755086   0.3067014  -1.5374508   1.545517    4.4691043  -0.64097315]\n",
      "self.next: 274\n",
      "obs= [[[ 2.7067037  -2.21168768 -0.35590716  0.05238379 -0.78655965\n",
      "    0.07484556]\n",
      "  [ 0.01170786 -0.06315509  0.05311755  0.01969472  0.08175284\n",
      "    0.12568389]]\n",
      "\n",
      " [[ 6.42935897 -2.77127977 -4.46451532  2.09534909 -0.46057748\n",
      "   -5.36360046]\n",
      "  [ 0.2026564  -0.12098192 -0.05256039 -0.07176132  0.10231529\n",
      "   -0.20365625]]] reward= -9220270.46586099 done= False\n",
      "Step 275\n",
      "Action:  [ 1.7756245   0.30675274 -1.5376078   1.5457181   4.470022   -0.641137  ]\n",
      "self.next: 275\n",
      "obs= [[[ 2.70787449 -2.21800319 -0.35059541  0.05435326 -0.77838437\n",
      "    0.08741395]\n",
      "  [-0.02403907 -0.02243785  0.17273509 -0.08552409  0.02694843\n",
      "   -0.13746275]]\n",
      "\n",
      " [[ 6.44962461 -2.78337796 -4.46977136  2.08817296 -0.45034595\n",
      "   -5.38396609]\n",
      "  [ 0.20112408 -0.11988041 -0.0523863  -0.07079763  0.10233537\n",
      "   -0.20366645]]] reward= -9860164.751448194 done= False\n",
      "Step 276\n",
      "Action:  [ 1.7752364   0.30669665 -1.5372192   1.5453827   4.4684925  -0.64077234]\n",
      "self.next: 276\n",
      "obs= [[[ 2.70547058e+00 -2.22024697e+00 -3.33321900e-01  4.58008517e-02\n",
      "   -7.75689526e-01  7.36676745e-02]\n",
      "  [-5.65728147e-02  1.04670862e-01 -1.98343810e-01  1.86820135e-01\n",
      "   -1.09443785e-01  3.72667355e-03]]\n",
      "\n",
      " [[ 6.46973702e+00 -2.79536600e+00 -4.47500999e+00  2.08109320e+00\n",
      "   -4.40112411e-01 -5.40433273e+00]\n",
      "  [ 1.99582966e-01 -1.18762899e-01 -5.22552534e-02 -6.97961410e-02\n",
      "    1.02339964e-01 -2.03649219e-01]]] reward= -7838624.105675632 done= False\n",
      "Step 277\n",
      "Action:  [ 1.7749621   0.30666903 -1.5369614   1.5452721   4.468069   -0.6408715 ]\n",
      "self.next: 277\n",
      "obs= [[[ 2.69981330e+00 -2.20977989e+00 -3.53156281e-01  6.44828652e-02\n",
      "   -7.86633905e-01  7.40403418e-02]\n",
      "  [-5.85139487e-03 -2.31758827e-02  2.96016921e-02  2.12059263e-02\n",
      "   -1.89753040e-02 -3.22419337e-02]]\n",
      "\n",
      " [[ 6.48969531e+00 -2.80724229e+00 -4.48023552e+00  2.07411358e+00\n",
      "   -4.29878415e-01 -5.42469765e+00]\n",
      "  [ 1.98037349e-01 -1.17633567e-01 -5.21646494e-02 -6.87615617e-02\n",
      "    1.02330696e-01 -2.03606803e-01]]] reward= -8372182.906100624 done= False\n",
      "Step 278\n",
      "Action:  [ 1.7750719   0.30670342 -1.5370698   1.545376    4.468288   -0.6407496 ]\n",
      "self.next: 278\n",
      "obs= [[[ 2.69922816e+00 -2.21209747e+00 -3.50196112e-01  6.66034578e-02\n",
      "   -7.88531435e-01  7.08161485e-02]\n",
      "  [ 1.74758326e-04  2.69792384e-05  3.82526159e-04 -1.90610983e-03\n",
      "    1.89550255e-03 -1.69346433e-04]]\n",
      "\n",
      " [[ 6.50949905e+00 -2.81900565e+00 -4.48545198e+00  2.06723743e+00\n",
      "   -4.19645345e-01 -5.44505833e+00]\n",
      "  [ 1.96491139e-01 -1.16496259e-01 -5.21119813e-02 -6.76982798e-02\n",
      "    1.02309117e-01 -2.03541370e-01]]] reward= -7633788.322533222 done= False\n",
      "Step 279\n",
      "Action:  [ 1.7749718   0.30672818 -1.536986    1.5453789   4.467933   -0.6406792 ]\n",
      "self.next: 279\n",
      "obs= [[[ 2.69924563e+00 -2.21209478e+00 -3.50157860e-01  6.64128468e-02\n",
      "   -7.88341885e-01  7.07992138e-02]\n",
      "  [-4.17196588e-02  3.84096484e-02  1.62269610e-03 -1.60984790e-02\n",
      "   -5.08195870e-02  1.37449537e-01]]\n",
      "\n",
      " [[ 6.52914816e+00 -2.83065528e+00 -4.49066318e+00  2.06046760e+00\n",
      "   -4.09414434e-01 -5.46541247e+00]\n",
      "  [ 1.94947884e-01 -1.15354476e-01 -5.20948414e-02 -6.66103705e-02\n",
      "    1.02276683e-01 -2.03455010e-01]]] reward= -7756073.300117923 done= False\n",
      "Step 280\n",
      "Action:  [ 1.7748268   0.30677992 -1.5368823   1.5453962   4.4676886  -0.64066195]\n",
      "self.next: 280\n",
      "obs= [[[ 2.69507367e+00 -2.20825381e+00 -3.49995590e-01  6.48029989e-02\n",
      "   -7.93423843e-01  8.45441675e-02]\n",
      "  [ 4.19137049e-04  3.56702191e-04 -2.72785540e-04 -2.59066979e-03\n",
      "    2.82128794e-03 -2.30306127e-04]]\n",
      "\n",
      " [[ 6.54864295e+00 -2.84219072e+00 -4.49587266e+00  2.05380656e+00\n",
      "   -3.99186765e-01 -5.48575797e+00]\n",
      "  [ 1.93410777e-01 -1.14211393e-01 -5.21109281e-02 -6.55016019e-02\n",
      "    1.02234758e-01 -2.03349728e-01]]] reward= -7800060.958554413 done= False\n",
      "Step 281\n",
      "Action:  [ 1.7745908  0.3067368 -1.536632   1.5451797  4.466806  -0.6404272]\n",
      "self.next: 281\n",
      "obs= [[[ 2.69511558e+00 -2.20821814e+00 -3.50022869e-01  6.45439319e-02\n",
      "   -7.93141715e-01  8.45211369e-02]\n",
      "  [ 2.11627709e-03  7.20212412e-03  1.40815433e-02 -4.14553535e-02\n",
      "    1.92990277e-02 -3.14141540e-02]]\n",
      "\n",
      " [[ 6.56798403e+00 -2.85361186e+00 -4.50108376e+00  2.04725640e+00\n",
      "   -3.88963290e-01 -5.50609294e+00]\n",
      "  [ 1.91882680e-01 -1.13069875e-01 -5.21580492e-02 -6.43754443e-02\n",
      "    1.02184619e-01 -2.03227433e-01]]] reward= -7722204.77641125 done= False\n",
      "Step 282\n",
      "Action:  [ 1.7743702   0.30674192 -1.5364289   1.5450642   4.4660354  -0.6402515 ]\n",
      "self.next: 282\n",
      "obs= [[[ 2.69532721e+00 -2.20749793e+00 -3.48614714e-01  6.03983966e-02\n",
      "   -7.91211812e-01  8.13797215e-02]\n",
      "  [ 3.86264041e-02 -4.30183975e-02  5.18486904e-03  1.60218536e-02\n",
      "    5.16833616e-02 -4.10206451e-02]]\n",
      "\n",
      " [[ 6.58717230e+00 -2.86491885e+00 -4.50629956e+00  2.04081886e+00\n",
      "   -3.78744828e-01 -5.52641569e+00]\n",
      "  [ 1.90366137e-01 -1.11932490e-01 -5.22341241e-02 -6.32350817e-02\n",
      "    1.02127449e-01 -2.03089942e-01]]] reward= -7465336.913593925 done= False\n",
      "Step 283\n",
      "Action:  [ 1.7741294   0.30672666 -1.5362016   1.5448841   4.4654284  -0.6400963 ]\n",
      "self.next: 283\n",
      "obs= [[[ 2.69918985 -2.21179977 -0.34809623  0.06200058 -0.78604348\n",
      "    0.07727766]\n",
      "  [ 0.03862332 -0.02832805 -0.03654408  0.04886862  0.04372292\n",
      "   -0.13536639]]\n",
      "\n",
      " [[ 6.60620891 -2.8761121  -4.51152297  2.03449535 -0.36853208\n",
      "   -5.54672468]\n",
      "  [ 0.1888634  -0.11080153 -0.05233718 -0.06208343  0.10206435\n",
      "   -0.20293897]]] reward= -8167851.507095785 done= False\n",
      "Step 284\n",
      "Action:  [ 1.7738185  0.3066904 -1.5358976  1.5446439  4.464404  -0.6398966]\n",
      "self.next: 284\n",
      "obs= [[[ 2.70305218 -2.21463257 -0.35175064  0.06688744 -0.78167118\n",
      "    0.06374102]\n",
      "  [-0.02454721 -0.02200511  0.0715607  -0.02605947  0.03710966\n",
      "   -0.08236024]]\n",
      "\n",
      " [[ 6.62509525 -2.88719225 -4.51675669  2.02828701 -0.35832565\n",
      "   -5.56701858]\n",
      "  [ 0.18737644 -0.10967903 -0.05246537 -0.06092313  0.10199634\n",
      "   -0.20277614]]] reward= -7805387.053614745 done= False\n",
      "Step 285\n",
      "Action:  [ 1.7735437   0.30673006 -1.5356741   1.5445337   4.4636045  -0.6397173 ]\n",
      "self.next: 285\n",
      "obs= [[[ 2.70059746 -2.21683309 -0.34459457  0.0642815  -0.77796022\n",
      "    0.05550499]\n",
      "  [-0.01228925  0.05099429 -0.03624497 -0.02328885 -0.08130757\n",
      "    0.21754765]]\n",
      "\n",
      " [[ 6.64383289 -2.89816016 -4.52200323  2.02219469 -0.34812601\n",
      "   -5.58729619]\n",
      "  [ 0.18590698 -0.10856678 -0.05261693 -0.0597566   0.10192435\n",
      "   -0.20260297]]] reward= -7559905.44691425 done= False\n",
      "Step 286\n",
      "Action:  [ 1.7737476   0.3068261  -1.5359206   1.5449214   4.464687   -0.63999885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 286\n",
      "obs= [[[ 2.69936854 -2.21173366 -0.34821906  0.06195261 -0.78609097\n",
      "    0.07725976]\n",
      "  [ 0.0299907  -0.04906211  0.01928481  0.0188818   0.048816\n",
      "   -0.10181927]]\n",
      "\n",
      " [[ 6.66242359 -2.90901684 -4.52726492  2.01621903 -0.33793358\n",
      "   -5.60755649]\n",
      "  [ 0.18445651 -0.10746636 -0.05279022 -0.05858602  0.10184926\n",
      "   -0.20242088]]] reward= -7717078.755376234 done= False\n",
      "Step 287\n",
      "Action:  [ 1.7732276   0.30671895 -1.5353696   1.5443555   4.4627233  -0.6394988 ]\n",
      "self.next: 287\n",
      "obs= [[[ 2.70236761 -2.21663987 -0.34629058  0.06384079 -0.78120937\n",
      "    0.06707783]\n",
      "  [-0.07773899  0.03494917  0.06528983  0.03440215 -0.19219917\n",
      "    0.21841738]]\n",
      "\n",
      " [[ 6.68086924 -2.91976347 -4.53254394  2.01036043 -0.32774865\n",
      "   -5.62779858]\n",
      "  [ 0.18302631 -0.10637914 -0.0529837  -0.05741336  0.10177184\n",
      "   -0.20223122]]] reward= -7702057.494347483 done= False\n",
      "Step 288\n",
      "Action:  [ 1.7731863   0.30680907 -1.5353963   1.5445387   4.463368   -0.639707  ]\n",
      "self.next: 288\n",
      "obs= [[[ 2.69459371 -2.21314495 -0.3397616   0.06728101 -0.80042929\n",
      "    0.08891957]\n",
      "  [ 0.02483085  0.00793535 -0.0624125  -0.04399773  0.17413161\n",
      "   -0.14003699]]\n",
      "\n",
      " [[ 6.69917188 -2.93040139 -4.53784231  2.0046191  -0.31757147\n",
      "   -5.6480217 ]\n",
      "  [ 0.18161744 -0.10530628 -0.05319592 -0.05624038  0.10169283\n",
      "   -0.20203521]]] reward= -7896448.761976534 done= False\n",
      "Step 289\n",
      "Action:  [ 1.7726765   0.30675417 -1.534854    1.5440933   4.4606     -0.6390908 ]\n",
      "self.next: 289\n",
      "obs= [[[ 2.69707679 -2.21235141 -0.34600285  0.06288124 -0.78301613\n",
      "    0.07491587]\n",
      "  [ 0.01189251  0.0338033  -0.23025341  0.25746352 -0.00914489\n",
      "   -0.2381652 ]]\n",
      "\n",
      " [[ 6.71733362 -2.94093201 -4.54316191  1.99899506 -0.30740219\n",
      "   -5.66822522]\n",
      "  [ 0.18023081 -0.10424882 -0.05342553 -0.05506869  0.10161288\n",
      "   -0.20183401]]] reward= -8123460.321816375 done= False\n",
      "Step 290\n",
      "Action:  [ 1.7719189   0.30662844 -1.5341043   1.5434277   4.458793   -0.6388419 ]\n",
      "self.next: 290\n",
      "obs= [[[ 2.69826604 -2.20897108 -0.36902819  0.08862759 -0.78393062\n",
      "    0.05109935]\n",
      "  [ 0.04672272 -0.05607539  0.19916853 -0.26423613  0.04507877\n",
      "    0.19118508]]\n",
      "\n",
      " [[ 6.7353567  -2.9513569  -4.54850446  1.99348819 -0.2972409\n",
      "   -5.68840862]\n",
      "  [ 0.17886716 -0.10320759 -0.05367127 -0.05389969  0.1015326\n",
      "   -0.2016287 ]]] reward= -8630518.823954005 done= False\n",
      "Step 291\n",
      "Action:  [ 1.7725704  0.3069036 -1.5348636  1.5443827  4.460839  -0.639028 ]\n",
      "self.next: 291\n",
      "obs= [[[ 2.70293832 -2.21457862 -0.34911134  0.06220397 -0.77942274\n",
      "    0.07021786]\n",
      "  [-0.05161901  0.03950587  0.01289403 -0.02062342 -0.01158386\n",
      "    0.07601185]]\n",
      "\n",
      " [[ 6.75324342 -2.96167765 -4.55387158  1.98809822 -0.28708764\n",
      "   -5.70857149]\n",
      "  [ 0.17752708 -0.10218333 -0.05393196 -0.05273465  0.10145254\n",
      "   -0.20142027]]] reward= -8263145.063617183 done= False\n",
      "Step 292\n",
      "Action:  [ 1.7722139   0.30681536 -1.5344977   1.5439888   4.459915   -0.6389501 ]\n",
      "self.next: 292\n",
      "obs= [[[ 2.69777641 -2.21062804 -0.34782193  0.06014163 -0.78058113\n",
      "    0.07781904]\n",
      "  [ 0.05910733 -0.09499447  0.03494347  0.04136531  0.09003097\n",
      "   -0.19893638]]\n",
      "\n",
      " [[ 6.77099613 -2.97189599 -4.55926478  1.98282475 -0.27694238\n",
      "   -5.72871352]\n",
      "  [ 0.17621104 -0.10117662 -0.0542065  -0.05157471  0.1013732\n",
      "   -0.20120964]]] reward= -7574179.957120444 done= False\n",
      "Step 293\n",
      "Action:  [ 1.7716093   0.30670792 -1.5338752   1.5433862   4.457886   -0.63842034]\n",
      "self.next: 293\n",
      "obs= [[[ 2.70368715e+00 -2.22012748e+00 -3.44327587e-01  6.42781631e-02\n",
      "   -7.71578029e-01  5.79254061e-02]\n",
      "  [ 7.73247187e-05 -8.99502303e-04  1.87121121e-03 -1.18552475e-04\n",
      "    3.27138513e-04 -5.59272901e-04]]\n",
      "\n",
      " [[ 6.78861723e+00 -2.98201365e+00 -4.56468543e+00  1.97766728e+00\n",
      "   -2.66805064e-01 -5.74883448e+00]\n",
      "  [ 1.74919379e-01 -1.00187936e-01 -5.44938841e-02 -5.04208382e-02\n",
      "    1.01295030e-01 -2.00997654e-01]]] reward= -7590281.111274438 done= False\n",
      "Step 294\n",
      "Action:  [ 1.7718182   0.30678603 -1.5341244   1.543737    4.4587393  -0.63864774]\n",
      "self.next: 294\n",
      "obs= [[[ 2.70369488e+00 -2.22021743e+00 -3.44140466e-01  6.42663079e-02\n",
      "   -7.71545315e-01  5.78694788e-02]\n",
      "  [ 2.80025707e-04 -1.32274052e-04 -1.58440447e-03  2.58764604e-03\n",
      "   -1.77562576e-03  1.90789415e-04]]\n",
      "\n",
      " [[ 6.80610917e+00 -2.99203244e+00 -4.57013482e+00  1.97262520e+00\n",
      "   -2.56675561e-01 -5.76893425e+00]\n",
      "  [ 1.73652345e-01 -9.92176561e-02 -5.47931475e-02 -4.92739269e-02\n",
      "    1.01218438e-01 -2.00785104e-01]]] reward= -7361029.2551344 done= False\n",
      "Step 295\n",
      "Action:  [ 1.77159     0.30679023 -1.5339172   1.5436208   4.458079   -0.6385033 ]\n",
      "self.next: 295\n",
      "obs= [[[ 2.70372288 -2.22023066 -0.34429891  0.06452507 -0.77172288\n",
      "    0.05788856]\n",
      "  [-0.03319763  0.04233627 -0.17355499  0.23751968 -0.13777923\n",
      "    0.09889077]]\n",
      "\n",
      " [[ 6.8234744  -3.00195421 -4.57561413  1.96769781 -0.24655372\n",
      "   -5.78901276]\n",
      "  [ 0.17241009 -0.09826606 -0.05510341 -0.04813474  0.10114379\n",
      "   -0.20057271]]] reward= -7336021.254746901 done= False\n",
      "Step 296\n",
      "Action:  [ 1.771119    0.30675438 -1.5334601   1.5433023   4.4572415  -0.63844067]\n",
      "self.next: 296\n",
      "obs= [[[ 2.70040312 -2.21599703 -0.3616544   0.08827704 -0.7855008\n",
      "    0.06777763]\n",
      "  [ 0.02931165  0.01444535  0.12124785 -0.23907152  0.13495836\n",
      "   -0.26755132]]\n",
      "\n",
      " [[ 6.84071541 -3.01178081 -4.58112447  1.96288433 -0.23643934\n",
      "   -5.80907003]\n",
      "  [ 0.17119268 -0.09733337 -0.05542385 -0.04700395  0.10107143\n",
      "   -0.20036113]]] reward= -8359382.202740495 done= False\n",
      "Step 297\n",
      "Action:  [ 1.770637    0.30677304 -1.5329989   1.543028    4.454273   -0.6376219 ]\n",
      "self.next: 297\n",
      "obs= [[[ 2.70333428 -2.2145525  -0.34952962  0.06436989 -0.77200497\n",
      "    0.0410225 ]\n",
      "  [-0.01554373 -0.01120111  0.0261019   0.0980296  -0.19353918\n",
      "    0.22727608]]\n",
      "\n",
      " [[ 6.85783468 -3.02151415 -4.58666686  1.95818394 -0.22633219\n",
      "   -5.82910614]\n",
      "  [ 0.17000012 -0.09641969 -0.05575371 -0.04588213  0.10100165\n",
      "   -0.20015098]]] reward= -8218233.730569894 done= False\n",
      "Step 298\n",
      "Action:  [ 1.7708552   0.30683511 -1.5332791   1.5433267   4.456808   -0.63823324]\n",
      "self.next: 298\n",
      "obs= [[[ 2.70177991e+00 -2.21567261e+00 -3.46919430e-01  7.41728484e-02\n",
      "   -7.91358883e-01  6.37501103e-02]\n",
      "  [-4.12863852e-04 -2.59598816e-04  4.80171005e-04  6.38701563e-04\n",
      "    1.16060855e-04 -3.26807244e-04]]\n",
      "\n",
      " [[ 6.87483469e+00 -3.03115612e+00 -4.59224223e+00  1.95359573e+00\n",
      "   -2.16232030e-01 -5.84912124e+00]\n",
      "  [ 1.68832339e-01 -9.55251035e-02 -5.60922702e-02 -4.47698004e-02\n",
      "    1.00934726e-01 -1.99942817e-01]]] reward= -7560985.985893242 done= False\n",
      "Step 299\n",
      "Action:  [ 1.7707525   0.30681238 -1.5331422   1.5432106   4.455604   -0.63794684]\n",
      "self.next: 299\n",
      "obs= [[[ 2.70173862 -2.21569857 -0.34687141  0.07423672 -0.79134728\n",
      "    0.06371743]\n",
      "  [-0.08785987  0.09793546 -0.01021064 -0.06347919  0.02648544\n",
      "    0.1076059 ]]\n",
      "\n",
      " [[ 6.89171792 -3.04070863 -4.59785146  1.94911875 -0.20613856\n",
      "   -5.86911552]\n",
      "  [ 0.16768922 -0.09464962 -0.05643888 -0.04366738  0.10087089\n",
      "   -0.19973716]]] reward= -7205038.920510548 done= False\n",
      "Step 300\n",
      "Action:  [ 1.7702987  0.3068977 -1.5327697  1.5430847  4.454118  -0.6377229]\n",
      "self.next: 300\n",
      "obs= [[[ 2.69295264e+00 -2.20590502e+00 -3.47892477e-01  6.78887998e-02\n",
      "   -7.88698732e-01  7.44780196e-02]\n",
      "  [ 8.25118047e-02 -8.65017269e-02  3.94783767e-03  4.20845111e-02\n",
      "    9.68038704e-02 -2.09031563e-02]]\n",
      "\n",
      " [[ 6.90848685e+00 -3.05017359e+00 -4.60349535e+00  1.94475201e+00\n",
      "   -1.96051468e-01 -5.88908924e+00]\n",
      "  [ 1.66570592e-01 -9.37932041e-02 -5.67929375e-02 -4.25752246e-02\n",
      "    1.00810370e-01 -1.99534473e-01]]] reward= -7364705.005027805 done= False\n",
      "Step 301\n",
      "Action:  [ 1.7700241   0.30681366 -1.5324771   1.5427624   4.4535084  -0.63743764]\n",
      "self.next: 301\n",
      "obs= [[[ 2.70120382 -2.2145552  -0.34749769  0.07209725 -0.77901835\n",
      "    0.0723877 ]\n",
      "  [-0.02710006 -0.01286161  0.03848651  0.09670543 -0.19296041\n",
      "    0.16986396]]\n",
      "\n",
      " [[ 6.92514391 -3.05955291 -4.60917464  1.94049449 -0.18597043\n",
      "   -5.90904268]\n",
      "  [ 0.16547625 -0.09295577 -0.05715387 -0.04149365  0.10075335\n",
      "   -0.19933519]]] reward= -8055189.209309459 done= False\n",
      "Step 302\n",
      "Action:  [ 1.7699411  0.3068434 -1.5324286  1.542839   4.454048  -0.6376102]\n",
      "self.next: 302\n",
      "obs= [[[ 2.69849381 -2.21584136 -0.34364904  0.08176779 -0.79831439\n",
      "    0.0893741 ]\n",
      "  [-0.03361944  0.06857198 -0.03027488 -0.04815518  0.07599182\n",
      "   -0.06285003]]\n",
      "\n",
      " [[ 6.94169153 -3.06884849 -4.61489003  1.93634512 -0.1758951\n",
      "   -5.9289762 ]\n",
      "  [ 0.16440594 -0.09213721 -0.05752114 -0.04042292  0.10070001\n",
      "   -0.19913971]]] reward= -7673044.89888302 done= False\n",
      "Step 303\n",
      "Action:  [ 1.7695827   0.30685133 -1.5320696   1.5426048   4.45171    -0.6371558 ]\n",
      "self.next: 303\n",
      "obs= [[[ 2.69513187 -2.20898416 -0.34667653  0.07695228 -0.79071521\n",
      "    0.0830891 ]\n",
      "  [-0.00848801 -0.00912311  0.20279827 -0.18376665 -0.10090846\n",
      "    0.23726953]]\n",
      "\n",
      " [[ 6.95813212 -3.07806221 -4.62064214  1.93230283 -0.16582509\n",
      "   -5.94889017]\n",
      "  [ 0.1633594  -0.09133736 -0.05789429 -0.03936323  0.1006505\n",
      "   -0.19894839]]] reward= -6897239.884373066 done= False\n",
      "Step 304\n",
      "Action:  [ 1.7695119   0.3069695  -1.5320894   1.5428476   4.4523406  -0.63717276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 304\n",
      "obs= [[[ 2.69428307e+00 -2.20989647e+00 -3.26396703e-01  5.85756107e-02\n",
      "   -8.00806051e-01  1.06816050e-01]\n",
      "  [-5.27819285e-02  2.39025259e-02 -2.72556758e-03  3.40521893e-02\n",
      "   -7.13769296e-02  2.66126931e-01]]\n",
      "\n",
      " [[ 6.97446806e+00 -3.08719595e+00 -4.62643157e+00  1.92836650e+00\n",
      "   -1.55760045e-01 -5.96878501e+00]\n",
      "  [ 1.62336318e-01 -9.05560407e-02 -5.82728425e-02 -3.83147419e-02\n",
      "    1.00604949e-01 -1.98761553e-01]]] reward= -8612518.303208478 done= False\n",
      "Step 305\n",
      "Action:  [ 1.7691972   0.30694115 -1.5317779   1.5425985   4.451628   -0.63711655]\n",
      "self.next: 305\n",
      "obs= [[[ 2.68900487 -2.20750622 -0.32666926  0.06198083 -0.80794374\n",
      "    0.13342874]\n",
      "  [ 0.10615134 -0.05902164 -0.20184308  0.27004238  0.02089116\n",
      "   -0.11558529]]\n",
      "\n",
      " [[ 6.9907017  -3.09625155 -4.63225885  1.92453503 -0.14569955\n",
      "   -5.98866117]\n",
      "  [ 0.16133638 -0.08979306 -0.05865639 -0.03727759  0.10056349\n",
      "   -0.19857951]]] reward= -7538668.476600498 done= False\n",
      "Step 306\n",
      "Action:  [ 1.7687616   0.30674747 -1.5312446   1.5419377   4.449942   -0.63674825]\n",
      "self.next: 306\n",
      "obs= [[[ 2.69962001e+00 -2.21340838e+00 -3.46853568e-01  8.89850674e-02\n",
      "   -8.05854628e-01  1.21870213e-01]\n",
      "  [ 4.13591965e-02 -3.58369778e-02 -4.35691302e-03  1.91716630e-02\n",
      "    4.50554052e-02 -1.39323624e-01]]\n",
      "\n",
      " [[ 7.00683533e+00 -3.10523086e+00 -4.63812449e+00  1.92080727e+00\n",
      "   -1.35643201e-01 -6.00851912e+00]\n",
      "  [ 1.60359234e-01 -8.90481893e-02 -5.90445510e-02 -3.62518694e-02\n",
      "    1.00526224e-01 -1.98402526e-01]]] reward= -8010439.298782818 done= False\n",
      "Step 307\n",
      "Action:  [ 1.7687789   0.30680928 -1.531298    1.5421009   4.449571   -0.6365815 ]\n",
      "self.next: 307\n",
      "obs= [[[ 2.70375593e+00 -2.21699208e+00 -3.47289260e-01  9.09022337e-02\n",
      "   -8.01349087e-01  1.07937851e-01]\n",
      "  [-4.35331809e-03 -3.05131770e-02  2.19169395e-01 -2.52956918e-01\n",
      "    6.76302836e-02  5.68318126e-02]]\n",
      "\n",
      " [[ 7.02287126e+00 -3.11413568e+00 -4.64402895e+00  1.91718208e+00\n",
      "   -1.25590579e-01 -6.02835937e+00]\n",
      "  [ 1.59404536e-01 -8.83211881e-02 -5.94369579e-02 -3.52376412e-02\n",
      "    1.00493246e-01 -1.98230856e-01]]] reward= -6810966.861593579 done= False\n",
      "Step 308\n",
      "Action:  [ 1.7684824   0.30695567 -1.5311161   1.5422325   4.448616   -0.6363131 ]\n",
      "self.next: 308\n",
      "obs= [[[ 2.70332060e+00 -2.22004340e+00 -3.25372320e-01  6.56065419e-02\n",
      "   -7.94586059e-01  1.13621032e-01]\n",
      "  [ 1.75605659e-02  2.52966631e-02 -7.24567591e-02  2.88725673e-02\n",
      "    2.46503334e-05  3.31539417e-02]]\n",
      "\n",
      " [[ 7.03881171e+00 -3.12296779e+00 -4.64997264e+00  1.91365832e+00\n",
      "   -1.15541254e-01 -6.04818246e+00]\n",
      "  [ 1.58471917e-01 -8.76118016e-02 -5.98332809e-02 -3.42349447e-02\n",
      "    1.00464638e-01 -1.98064726e-01]]] reward= -7913288.893624095 done= False\n",
      "Step 309\n",
      "Action:  [ 1.7684352   0.30688417 -1.531044    1.5421033   4.4488583  -0.6364766 ]\n",
      "self.next: 309\n",
      "obs= [[[ 2.70507665e+00 -2.21751373e+00 -3.32617996e-01  6.84937986e-02\n",
      "   -7.94583594e-01  1.16936426e-01]\n",
      "  [-2.22842195e-02 -4.39080045e-03 -1.30642950e-01  2.51810965e-01\n",
      "    8.30891601e-04 -3.56543469e-01]]\n",
      "\n",
      " [[ 7.05465890e+00 -3.13172897e+00 -4.65595597e+00  1.91023483e+00\n",
      "   -1.05494791e-01 -6.06798893e+00]\n",
      "  [ 1.57561002e-01 -8.69197635e-02 -6.02332114e-02 -3.32437956e-02\n",
      "    1.00440473e-01 -1.97904343e-01]]] reward= -6835444.761977909 done= False\n",
      "Step 310\n",
      "Action:  [ 1.7667613   0.30669573 -1.5293788   1.5406129   4.443523   -0.63547903]\n",
      "self.next: 310\n",
      "obs= [[[ 2.70284823e+00 -2.21795281e+00 -3.45682291e-01  9.36748951e-02\n",
      "   -7.94500505e-01  8.12820795e-02]\n",
      "  [-1.15848491e-02  4.64912168e-03 -1.85518851e-02  2.28103064e-02\n",
      "    4.75367689e-03 -6.32471886e-02]]\n",
      "\n",
      " [[ 7.07041500e+00 -3.14042095e+00 -4.66197929e+00  1.90691045e+00\n",
      "   -9.54507434e-02 -6.08777936e+00]\n",
      "  [ 1.56671411e-01 -8.62447979e-02 -6.06364622e-02 -3.22641893e-02\n",
      "    1.00420811e-01 -1.97749895e-01]]] reward= -8324407.184576472 done= False\n",
      "Step 311\n",
      "Action:  [ 1.7676146  0.3068619 -1.5302771  1.5415863  4.4463105 -0.6359142]\n",
      "self.next: 311\n",
      "obs= [[[ 2.70168975e+00 -2.21748790e+00 -3.47537480e-01  9.59559257e-02\n",
      "   -7.94025137e-01  7.49573606e-02]\n",
      "  [-6.70249194e-02  9.98539449e-04  2.47089793e-01 -1.76387923e-01\n",
      "   -1.69138436e-01  2.69195327e-01]]\n",
      "\n",
      " [[ 7.08608214e+00 -3.14904543e+00 -4.66804294e+00  1.90368403e+00\n",
      "   -8.54086622e-02 -6.10755435e+00]\n",
      "  [ 1.55802758e-01 -8.55866217e-02 -6.10427708e-02 -3.12961016e-02\n",
      "    1.00405710e-01 -1.97601554e-01]]] reward= -6883509.368667099 done= False\n",
      "Step 312\n",
      "Action:  [ 1.7673565  0.307034  -1.5301437  1.5418029  4.446257  -0.6358415]\n",
      "self.next: 312\n",
      "obs= [[[ 2.69498725e+00 -2.21738805e+00 -3.22828500e-01  7.83171334e-02\n",
      "   -8.10938981e-01  1.01876893e-01]\n",
      "  [-3.70169090e-02  4.47220462e-02 -3.51037360e-03 -2.89158992e-02\n",
      "   -3.99757041e-02  4.23255897e-02]]\n",
      "\n",
      " [[ 7.10166242e+00 -3.15760409e+00 -4.67414722e+00  1.90055442e+00\n",
      "   -7.53680912e-02 -6.12731451e+00]\n",
      "  [ 1.54954655e-01 -8.49449464e-02 -6.14518907e-02 -3.03394943e-02\n",
      "    1.00395216e-01 -1.97459476e-01]]] reward= -9337291.535460541 done= False\n",
      "Step 313\n",
      "Action:  [ 1.7672714  0.3069294 -1.5299878  1.5415736  4.445444  -0.6357159]\n",
      "self.next: 313\n",
      "obs= [[[ 2.69128556e+00 -2.21291584e+00 -3.23179538e-01  7.54255435e-02\n",
      "   -8.14936551e-01  1.06109452e-01]\n",
      "  [ 3.86760372e-02 -4.49675713e-02  4.39377861e-03  2.39664857e-02\n",
      "    4.68826733e-02 -4.41091491e-02]]\n",
      "\n",
      " [[ 7.11715789e+00 -3.16609859e+00 -4.68029241e+00  1.89752047e+00\n",
      "   -6.53285697e-02 -6.14706046e+00]\n",
      "  [ 1.54126714e-01 -8.43194796e-02 -6.18635939e-02 -2.93943152e-02\n",
      "    1.00389368e-01 -1.97323801e-01]]] reward= -7024979.066028202 done= False\n",
      "Step 314\n",
      "Action:  [ 1.7668328   0.30689114 -1.5295647   1.541213    4.4441214  -0.63536185]\n",
      "self.next: 314\n",
      "obs= [[[ 2.69515317e+00 -2.21741260e+00 -3.22740160e-01  7.78221921e-02\n",
      "   -8.10248284e-01  1.01698537e-01]\n",
      "  [ 3.87733753e-04 -9.58351771e-04  1.83092570e-03 -5.60956569e-04\n",
      "   -6.59224134e-04 -3.08183783e-04]]\n",
      "\n",
      " [[ 7.13257056e+00 -3.17453054e+00 -4.68647876e+00  1.89458104e+00\n",
      "   -5.52896328e-02 -6.16679284e+00]\n",
      "  [ 1.53318546e-01 -8.37099268e-02 -6.22776691e-02 -2.84605005e-02\n",
      "    1.00388203e-01 -1.97194659e-01]]] reward= -6448809.679630672 done= False\n",
      "Step 315\n",
      "Action:  [ 1.7666571   0.30691943 -1.5294224   1.5412031   4.44365    -0.63528585]\n",
      "self.next: 315\n",
      "obs= [[[ 2.69519194e+00 -2.21750843e+00 -3.22557067e-01  7.77660964e-02\n",
      "   -8.10314206e-01  1.01667719e-01]\n",
      "  [-9.53805006e-03 -3.43730712e-03  9.08947420e-03  4.24343574e-03\n",
      "    6.85911539e-05 -6.19848621e-02]]\n",
      "\n",
      " [[ 7.14790241e+00 -3.18290153e+00 -4.69270653e+00  1.89173499e+00\n",
      "   -4.52508125e-02 -6.18651230e+00]\n",
      "  [ 1.52529766e-01 -8.31159921e-02 -6.26939206e-02 -2.75379759e-02\n",
      "    1.00391749e-01 -1.97072165e-01]]] reward= -6677628.2750867335 done= False\n",
      "Step 316\n",
      "Action:  [ 1.7662348   0.30690125 -1.5290226   1.5409209   4.4423113  -0.6349972 ]\n",
      "self.next: 316\n",
      "obs= [[[ 2.69423813 -2.21785216 -0.32164812  0.07819044 -0.81030735\n",
      "    0.09546923]\n",
      "  [ 0.03426179  0.02286595 -0.23595913  0.1777606   0.09632022\n",
      "   -0.04298019]]\n",
      "\n",
      " [[ 7.16315539 -3.19121313 -4.69897592  1.88898119 -0.03521164\n",
      "   -6.20621952]\n",
      "  [ 0.15175999 -0.08253738 -0.06311217 -0.02662666  0.10040003\n",
      "   -0.19695643]]] reward= -6812499.570945456 done= False\n",
      "Step 317\n",
      "Action:  [ 1.7657204  0.3068935 -1.528542   1.5405768  4.4407263 -0.6347967]\n",
      "self.next: 317\n",
      "obs= [[[ 2.69766431 -2.21556557 -0.34524403  0.0959665  -0.80067533\n",
      "    0.09117121]\n",
      "  [-0.01811138 -0.00971901  0.02706888  0.09345291 -0.1892809\n",
      "    0.23200772]]\n",
      "\n",
      " [[ 7.17833139 -3.19946687 -4.70528714  1.88631852 -0.02517163\n",
      "   -6.22591516]\n",
      "  [ 0.15100884 -0.0819738  -0.06353224 -0.02572646  0.10041307\n",
      "   -0.19684754]]] reward= -7956555.856101918 done= False\n",
      "Step 318\n",
      "Action:  [ 1.7657237   0.30698985 -1.5286176   1.5408659   4.441926   -0.6349146 ]\n",
      "self.next: 318\n",
      "obs= [[[ 2.69585318e+00 -2.21653747e+00 -3.42537145e-01  1.05311791e-01\n",
      "   -8.19603415e-01  1.14371986e-01]\n",
      "  [ 1.15550715e-02  1.25420469e-03 -3.86475543e-02  4.95577570e-02\n",
      "   -2.32342133e-02 -6.01324206e-03]]\n",
      "\n",
      " [[ 7.19343227e+00 -3.20766424e+00 -4.71164036e+00  1.88374588e+00\n",
      "   -1.51303279e-02 -6.24559991e+00]\n",
      "  [ 1.50275934e-01 -8.14249470e-02 -6.39539792e-02 -2.48372790e-02\n",
      "    1.00430880e-01 -1.96745589e-01]]] reward= -7166175.267012018 done= False\n",
      "Step 319\n",
      "Action:  [ 1.7656608   0.30693537 -1.528502    1.540713    4.4407997  -0.634666  ]\n",
      "self.next: 319\n",
      "obs= [[[ 2.69700868e+00 -2.21641205e+00 -3.46401901e-01  1.10267567e-01\n",
      "   -8.21926836e-01  1.13770662e-01]\n",
      "  [-4.33677838e-03 -8.06606741e-03  1.35995401e-02  1.73508957e-04\n",
      "   -1.13399074e-03  9.34507798e-02]]\n",
      "\n",
      " [[ 7.20845986e+00 -3.21580674e+00 -4.71803576e+00  1.88126215e+00\n",
      "   -5.08723983e-03 -6.26527447e+00]\n",
      "  [ 1.49560911e-01 -8.08905443e-02 -6.43772440e-02 -2.39590187e-02\n",
      "    1.00453480e-01 -1.96650657e-01]]] reward= -6571395.0397648895 done= False\n",
      "Step 320\n",
      "Action:  [ 1.7653966   0.30700174 -1.5283024   1.5407023   4.4401298  -0.6344985 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 320\n",
      "obs= [[[ 2.69657501e+00 -2.21721866e+00 -3.45041947e-01  1.10284918e-01\n",
      "   -8.22040235e-01  1.23115740e-01]\n",
      "  [-2.82027540e-02  5.08987383e-02 -2.32669029e-02 -2.37909215e-02\n",
      "   -3.97551255e-02  1.07705442e-01]]\n",
      "\n",
      " [[ 7.22341596e+00 -3.22389579e+00 -4.72447349e+00  1.87886625e+00\n",
      "    4.95810815e-03 -6.28493954e+00]\n",
      "  [ 1.48863403e-01 -8.03703017e-02 -6.48018972e-02 -2.30915719e-02\n",
      "    1.00480878e-01 -1.96562814e-01]]] reward= -6303283.645958303 done= False\n",
      "Step 321\n",
      "Action:  [ 1.7651665   0.30702654 -1.5280977   1.5406523   4.4393773  -0.63437927]\n",
      "self.next: 321\n",
      "obs= [[[ 2.69375473 -2.21212878 -0.34736864  0.10790583 -0.82601575\n",
      "    0.13388628]\n",
      "  [-0.0277734   0.06575889 -0.01582741 -0.15870525  0.26684403\n",
      "   -0.42090966]]\n",
      "\n",
      " [[ 7.2383023  -3.23193282 -4.73095368  1.87655709  0.0150062\n",
      "   -6.30459582]\n",
      "  [ 0.14818306 -0.07986394 -0.06522781 -0.02223483  0.10051308\n",
      "   -0.19648213]]] reward= -6566548.242487314 done= False\n",
      "Step 322\n",
      "Action:  [ 1.7629849   0.3068869  -1.5259904   1.5389527   4.4309926  -0.63267565]\n",
      "self.next: 322\n",
      "obs= [[[ 2.69097739 -2.20555289 -0.34895138  0.0920353  -0.79933134\n",
      "    0.09179532]\n",
      "  [ 0.0119698   0.01091317 -0.02311703  0.09224859 -0.19176347\n",
      "    0.33432925]]\n",
      "\n",
      " [[ 7.2531206  -3.23991922 -4.73747646  1.87433361  0.0250575\n",
      "   -6.32424403]\n",
      "  [ 0.14751952 -0.07937118 -0.06565487 -0.02138868  0.1005501\n",
      "   -0.19640865]]] reward= -6991388.034199846 done= False\n",
      "Step 323\n",
      "Action:  [ 1.7639601   0.30708417 -1.5270594   1.5401189   4.436999   -0.63385373]\n",
      "self.next: 323\n",
      "obs= [[[ 2.69217437 -2.20446158 -0.35126308  0.10126016 -0.81850769\n",
      "    0.12522824]\n",
      "  [ 0.12796801 -0.18958458  0.0570486   0.19890474 -0.03368898\n",
      "   -0.03294459]]\n",
      "\n",
      " [[ 7.26787255 -3.24785634 -4.74404194  1.87219474  0.03511251\n",
      "   -6.3438849 ]\n",
      "  [ 0.14687244 -0.07889174 -0.06608297 -0.02055301  0.10059194\n",
      "   -0.19634244]]] reward= -6823225.3293288555 done= False\n",
      "Step 324\n",
      "Action:  [ 1.7635963   0.3069093  -1.5266243   1.5394555   4.4355083  -0.63335055]\n",
      "self.next: 324\n",
      "obs= [[[ 2.70497117 -2.22342003 -0.34555822  0.12115063 -0.82187659\n",
      "    0.12193378]\n",
      "  [-0.05260036  0.04423344  0.00999708 -0.02531366  0.06027029\n",
      "   -0.22321079]]\n",
      "\n",
      " [[ 7.2825598  -3.25574551 -4.75065024  1.87013944  0.04517171\n",
      "   -6.36351914]\n",
      "  [ 0.14624151 -0.07842538 -0.066512   -0.0197277   0.10063861\n",
      "   -0.19628355]]] reward= -8016860.386002127 done= False\n",
      "Step 325\n",
      "Action:  [ 1.763305    0.30693585 -1.5263271   1.5393459   4.4330807  -0.633034  ]\n",
      "self.next: 325\n",
      "obs= [[[ 2.69971113e+00 -2.21899669e+00 -3.44558512e-01  1.18619267e-01\n",
      "   -8.15849560e-01  9.96127056e-02]\n",
      "  [-3.45677514e-03  1.34572935e-02 -8.98481496e-03 -4.34997785e-03\n",
      "    4.93153342e-02 -1.67877688e-01]]\n",
      "\n",
      " [[ 7.29718395e+00 -3.26358805e+00 -4.75730144e+00  1.86816667e+00\n",
      "    5.52355697e-02 -6.38314750e+00]\n",
      "  [ 1.45626376e-01 -7.79718202e-02 -6.69418637e-02 -1.89126455e-02\n",
      "    1.00690094e-01 -1.96232020e-01]]] reward= -6965433.440945797 done= False\n",
      "Step 326\n",
      "Action:  [ 1.7630742   0.30695504 -1.5261414   1.5393059   4.4326854  -0.6328996 ]\n",
      "self.next: 326\n",
      "obs= [[[ 2.69936546 -2.21765096 -0.34545699  0.11818427 -0.81091803\n",
      "    0.08282494]\n",
      "  [ 0.06320671  0.03804307 -0.09906454 -0.09574581  0.29723863\n",
      "   -0.15902245]]\n",
      "\n",
      " [[ 7.31174659 -3.27138523 -4.76399563  1.8662754   0.06530458\n",
      "   -6.4027707 ]\n",
      "  [ 0.14502674 -0.07753082 -0.06737248 -0.01810772  0.10074641\n",
      "   -0.19618789]]] reward= -6545813.023108237 done= False\n",
      "Step 327\n",
      "Action:  [ 1.7623618   0.3070358  -1.5255504   1.5390375   4.429879   -0.63234574]\n",
      "self.next: 327\n",
      "obs= [[[ 2.70568613e+00 -2.21384665e+00 -3.55363447e-01  1.08609688e-01\n",
      "   -7.81194164e-01  6.69226921e-02]\n",
      "  [ 8.09686224e-03  6.17515079e-03 -1.46420747e-02 -2.68620016e-04\n",
      "    4.62799808e-04  6.14360214e-02]]\n",
      "\n",
      " [[ 7.32624926e+00 -3.27913831e+00 -4.77073288e+00  1.86446463e+00\n",
      "    7.53792200e-02 -6.42238949e+00]\n",
      "  [ 1.44442278e-01 -7.71021265e-02 -6.78037565e-02 -1.73128038e-02\n",
      "    1.00807551e-01 -1.96151198e-01]]] reward= -7132187.525564419 done= False\n",
      "Step 328\n",
      "Action:  [ 1.7624197   0.3070636  -1.5256594   1.5392264   4.4314394  -0.63261515]\n",
      "self.next: 328\n",
      "obs= [[[ 2.70649581e+00 -2.21322914e+00 -3.56827654e-01  1.08582826e-01\n",
      "   -7.81147884e-01  7.30662943e-02]\n",
      "  [ 1.27096902e-02  1.06689088e-02 -2.38207982e-02  1.30575067e-03\n",
      "   -2.03896488e-03 -3.00525647e-02]]\n",
      "\n",
      " [[ 7.34069349e+00 -3.28684852e+00 -4.77751325e+00  1.86273335e+00\n",
      "    8.54599751e-02 -6.44200461e+00]\n",
      "  [ 1.43872704e-01 -7.66855107e-02 -6.82356189e-02 -1.65277870e-02\n",
      "    1.00873521e-01 -1.96121977e-01]]] reward= -6241297.29962283 done= False\n",
      "Step 329\n",
      "Action:  [ 1.7620255  0.3070317 -1.5252743  1.5389427  4.4300857 -0.6323245]\n",
      "self.next: 329\n",
      "obs= [[[ 2.70776678e+00 -2.21216225e+00 -3.59209734e-01  1.08713402e-01\n",
      "   -7.81351780e-01  7.00610378e-02]\n",
      "  [-1.09573275e-02 -4.27535367e-03  1.45158904e-02  1.67403931e-03\n",
      "    1.01395875e-01 -2.01759079e-01]]\n",
      "\n",
      " [[ 7.35508076e+00 -3.29451708e+00 -4.78433681e+00  1.86108057e+00\n",
      "    9.55473272e-02 -6.46161681e+00]\n",
      "  [ 1.43317723e-01 -7.62807425e-02 -6.86679899e-02 -1.57525507e-02\n",
      "    1.00944318e-01 -1.96100259e-01]]] reward= -6459740.070753158 done= False\n",
      "Step 330\n",
      "Action:  [ 1.7609531   0.30698967 -1.5242636   1.5381415   4.4264116  -0.6315603 ]\n",
      "self.next: 330\n",
      "obs= [[[ 2.70667105e+00 -2.21258978e+00 -3.57758145e-01  1.08880805e-01\n",
      "   -7.71212193e-01  4.98851299e-02]\n",
      "  [ 6.12097862e-03  2.10028876e-02 -2.73900306e-02 -2.33941844e-02\n",
      "    2.55726731e-02  3.09989252e-02]]\n",
      "\n",
      " [[ 7.36941253e+00 -3.30214515e+00 -4.79120361e+00  1.85950532e+00\n",
      "    1.05641759e-01 -6.48122683e+00]\n",
      "  [ 1.42777056e-01 -7.58876026e-02 -6.91007975e-02 -1.49869790e-02\n",
      "    1.01019939e-01 -1.96086070e-01]]] reward= -6276518.924639594 done= False\n",
      "Step 331\n",
      "Action:  [ 1.7612116   0.30709302 -1.524584    1.5386386   4.4277506  -0.6318216 ]\n",
      "self.next: 331\n",
      "obs= [[[ 2.70728315 -2.21048949 -0.36049715  0.10654139 -0.76865493\n",
      "    0.05298502]\n",
      "  [-0.02402097 -0.01806522  0.06994243  0.06107111 -0.18788179\n",
      "    0.17186582]]\n",
      "\n",
      " [[ 7.38369024 -3.30973391 -4.79811369  1.85800662  0.11574375\n",
      "   -6.50083544]\n",
      "  [ 0.14225043 -0.07550588 -0.06953397 -0.01423096  0.10110039\n",
      "   -0.19607944]]] reward= -6155672.35848736 done= False\n",
      "Step 332\n",
      "Action:  [ 1.7607242   0.30711362 -1.5241476   1.5384214   4.4274015  -0.63168806]\n",
      "self.next: 332\n",
      "obs= [[[ 2.70488105e+00 -2.21229602e+00 -3.53502905e-01  1.12648498e-01\n",
      "   -7.87443105e-01  7.01716047e-02]\n",
      "  [-6.27463060e-03  3.22176214e-03 -2.36383202e-02  2.75952448e-02\n",
      "    5.76193559e-02 -1.26751227e-01]]\n",
      "\n",
      " [[ 7.39791528e+00 -3.31728450e+00 -4.80506709e+00  1.85658352e+00\n",
      "    1.25853792e-01 -6.52044338e+00]\n",
      "  [ 1.41737595e-01 -7.51353766e-02 -6.99674557e-02 -1.34843673e-02\n",
      "    1.01185657e-01 -1.96080383e-01]]] reward= -7481029.510988468 done= False\n",
      "Step 333\n",
      "Action:  [ 1.7602407   0.30703953 -1.523638    1.5379262   4.4246016  -0.6311463 ]\n",
      "self.next: 333\n",
      "obs= [[[ 2.70425359e+00 -2.21197384e+00 -3.55866737e-01  1.15408022e-01\n",
      "   -7.81681169e-01  5.74964820e-02]\n",
      "  [ 1.68488433e-02 -2.78958332e-03 -1.46170586e-02  2.52834583e-02\n",
      "   -8.20951075e-02  1.22848242e-01]]\n",
      "\n",
      " [[ 7.41208904e+00 -3.32479804e+00 -4.81206383e+00  1.85523509e+00\n",
      "    1.35972357e-01 -6.54005142e+00]\n",
      "  [ 1.41238293e-01 -7.47758994e-02 -7.04011773e-02 -1.27470990e-02\n",
      "    1.01275749e-01 -1.96088929e-01]]] reward= -6127567.84414364 done= False\n",
      "Step 334\n",
      "Action:  [ 1.7604034   0.30713156 -1.5238575   1.5383396   4.4259887  -0.6313798 ]\n",
      "self.next: 334\n",
      "obs= [[[ 2.70593847e+00 -2.21225280e+00 -3.57328443e-01  1.17936368e-01\n",
      "   -7.89890680e-01  6.97813063e-02]\n",
      "  [-2.07406133e-02 -9.40337198e-03  4.71486661e-03  2.77465483e-02\n",
      "    5.50613911e-02 -9.41309230e-02]]\n",
      "\n",
      " [[ 7.42621287e+00 -3.33227563e+00 -4.81910395e+00  1.85396038e+00\n",
      "    1.46099932e-01 -6.55966031e+00]\n",
      "  [ 1.40752286e-01 -7.44272689e-02 -7.08350794e-02 -1.20190375e-02\n",
      "    1.01370662e-01 -1.96105095e-01]]] reward= -6557661.532600656 done= False\n",
      "Step 335\n",
      "Action:  [ 1.7595243   0.30707547 -1.5230057   1.5376132   4.4226317  -0.63069206]\n",
      "self.next: 335\n",
      "obs= [[[ 2.70386441 -2.21319314 -0.35685696  0.12071102 -0.78438454\n",
      "    0.06036821]\n",
      "  [-0.0366026   0.04184831  0.04613787 -0.0968742  -0.02395624\n",
      "    0.10691439]]\n",
      "\n",
      " [[ 7.4402881  -3.33971835 -4.82618746  1.85275847  0.156237\n",
      "   -6.57927082]\n",
      "  [ 0.14027935 -0.07408932 -0.0712691  -0.01130007  0.10147039\n",
      "   -0.1961289 ]]] reward= -6185301.10453832 done= False\n",
      "Step 336\n",
      "Action:  [ 1.7595559  0.3072023 -1.5231179  1.5380231  4.423051  -0.6307477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 336\n",
      "obs= [[[ 2.70020415 -2.2090083  -0.35224317  0.1110236  -0.78678017\n",
      "    0.07105965]\n",
      "  [ 0.02617468 -0.03527824 -0.01645788  0.05008745 -0.0191033\n",
      "    0.02510843]]\n",
      "\n",
      " [[ 7.45431603 -3.34712728 -4.83331437  1.85162847  0.16638404\n",
      "   -6.59888371]\n",
      "  [ 0.13981926 -0.07376188 -0.07170319 -0.01059009  0.10157494\n",
      "   -0.19616036]]] reward= -6757906.2574836835 done= False\n",
      "Step 337\n",
      "Action:  [ 1.7590748  0.3071242 -1.5226362  1.5375682  4.4218946 -0.6304625]\n",
      "self.next: 337\n",
      "obs= [[[ 2.70282162e+00 -2.21253613e+00 -3.53888957e-01  1.16032347e-01\n",
      "   -7.88690495e-01  7.35704954e-02]\n",
      "  [ 5.99249252e-03  2.21078161e-02 -2.78256194e-02 -2.49506107e-02\n",
      "    2.44894207e-02  3.48545584e-02]]\n",
      "\n",
      " [[ 7.46829796e+00 -3.35450347e+00 -4.84048469e+00  1.85056946e+00\n",
      "    1.76541532e-01 -6.61849975e+00]\n",
      "  [ 1.39371820e-01 -7.34448195e-02 -7.21372772e-02 -9.88897587e-03\n",
      "    1.01684311e-01 -1.96199482e-01]]] reward= -6290993.358384174 done= False\n",
      "Step 338\n",
      "Action:  [ 1.7588518  0.3071763 -1.5224576  1.537573   4.4208827 -0.6302778]\n",
      "self.next: 338\n",
      "obs= [[[ 2.70342087e+00 -2.21032535e+00 -3.56671519e-01  1.13537286e-01\n",
      "   -7.86241553e-01  7.70559513e-02]\n",
      "  [ 1.52131372e-02 -7.71414760e-03 -6.04464680e-03  2.25789055e-02\n",
      "   -2.32175290e-02 -4.16831076e-03]]\n",
      "\n",
      " [[ 7.48223514e+00 -3.36184795e+00 -4.84769842e+00  1.84958056e+00\n",
      "    1.86709963e-01 -6.63811970e+00]\n",
      "  [ 1.38936830e-01 -7.31379958e-02 -7.25713160e-02 -9.19662599e-03\n",
      "    1.01798494e-01 -1.96246290e-01]]] reward= -6235130.440944784 done= False\n",
      "Step 339\n",
      "Action:  [ 1.7583704   0.30714634 -1.522       1.5372354   4.419687   -0.6299855 ]\n",
      "self.next: 339\n",
      "obs= [[[ 2.70494218e+00 -2.21109676e+00 -3.57275984e-01  1.15795177e-01\n",
      "   -7.88563306e-01  7.66391202e-02]\n",
      "  [ 9.96706996e-03  5.26384212e-03 -1.49213080e-02  6.69812429e-04\n",
      "    5.55198999e-02 -1.57046335e-01]]\n",
      "\n",
      " [[ 7.49612882e+00 -3.36916175e+00 -4.85495555e+00  1.84866090e+00\n",
      "    1.96889812e-01 -6.65774433e+00]\n",
      "  [ 1.38514109e-01 -7.28412883e-02 -7.30052461e-02 -8.51292781e-03\n",
      "    1.01917492e-01 -1.96300794e-01]]] reward= -6554257.559637371 done= False\n",
      "Step 340\n",
      "Action:  [ 1.7576588   0.30710885 -1.5213183   1.536713    4.416988   -0.6294366 ]\n",
      "self.next: 340\n",
      "obs= [[[ 2.70593889e+00 -2.21057038e+00 -3.58768115e-01  1.15862158e-01\n",
      "   -7.83011316e-01  6.09344867e-02]\n",
      "  [-1.39801080e-02 -2.40866413e-03  4.24318940e-02 -5.07965514e-02\n",
      "   -3.32224154e-02  2.24101969e-01]]\n",
      "\n",
      " [[ 7.50998023e+00 -3.37644588e+00 -4.86225607e+00  1.84780960e+00\n",
      "    2.07081562e-01 -6.67737441e+00]\n",
      "  [ 1.38103484e-01 -7.25545885e-02 -7.34390102e-02 -7.83777147e-03\n",
      "    1.02041304e-01 -1.96363003e-01]]] reward= -6431516.635094398 done= False\n",
      "Step 341\n",
      "Action:  [ 1.7576116  0.3073027 -1.5214177  1.5372119  4.4179177 -0.6295696]\n",
      "self.next: 341\n",
      "obs= [[[ 2.70454088e+00 -2.21081124e+00 -3.54524925e-01  1.10782503e-01\n",
      "   -7.86333557e-01  8.33446836e-02]\n",
      "  [ 8.17663338e-03  1.41302745e-02 -4.96253785e-02  2.81525499e-02\n",
      "    5.78445399e-02 -1.58077660e-01]]\n",
      "\n",
      " [[ 7.52379058e+00 -3.38370134e+00 -4.86959997e+00  1.84702583e+00\n",
      "    2.17285692e-01 -6.69701071e+00]\n",
      "  [ 1.37704798e-01 -7.22778009e-02 -7.38725515e-02 -7.17104672e-03\n",
      "    1.02169931e-01 -1.96432929e-01]]] reward= -6538122.077696817 done= False\n",
      "Step 342\n",
      "Action:  [ 1.7568216   0.30713063 -1.5205678   1.5362976   4.4145484  -0.62892884]\n",
      "self.next: 342\n",
      "obs= [[[ 2.70535854e+00 -2.20939822e+00 -3.59487463e-01  1.13597758e-01\n",
      "   -7.80549103e-01  6.75369176e-02]\n",
      "  [-3.32767687e-02 -2.74728131e-02  6.16140136e-02  1.12453595e-01\n",
      "   -2.70076428e-01  2.64254789e-01]]\n",
      "\n",
      " [[ 7.53756106e+00 -3.39092912e+00 -4.87698723e+00  1.84630872e+00\n",
      "    2.27502685e-01 -6.71665400e+00]\n",
      "  [ 1.37317904e-01 -7.20108449e-02 -7.43058101e-02 -6.51264413e-03\n",
      "    1.02303371e-01 -1.96510580e-01]]] reward= -6255278.507362559 done= False\n",
      "Step 343\n",
      "Action:  [ 1.7564778  0.3072681 -1.5203404  1.5365152  4.415704  -0.6290633]\n",
      "self.next: 343\n",
      "obs= [[[ 2.70203086e+00 -2.21214550e+00 -3.53326062e-01  1.24843117e-01\n",
      "   -8.07556746e-01  9.39623965e-02]\n",
      "  [-8.76060195e-03  8.86399761e-03  2.54762644e-02 -4.92692923e-02\n",
      "    1.21863199e-01 -2.30134171e-01]]\n",
      "\n",
      " [[ 7.55129285e+00 -3.39813021e+00 -4.88441781e+00  1.84565746e+00\n",
      "    2.37733022e-01 -6.73630506e+00]\n",
      "  [ 1.36942667e-01 -7.17536536e-02 -7.47387270e-02 -5.86245292e-03\n",
      "    1.02441625e-01 -1.96595965e-01]]] reward= -7593819.958079988 done= False\n",
      "Step 344\n",
      "Action:  [ 1.7558702  0.3071483 -1.5196853  1.5358037  4.4113417 -0.6281812]\n",
      "self.next: 344\n",
      "obs= [[[ 2.70115480e+00 -2.21125910e+00 -3.50778435e-01  1.19916188e-01\n",
      "   -7.95370426e-01  7.09489793e-02]\n",
      "  [ 6.49426037e-03  4.76558897e-03 -1.13649988e-02 -2.21542765e-03\n",
      "    2.25173684e-03  6.24346821e-02]]\n",
      "\n",
      " [[ 7.56498712e+00 -3.40530557e+00 -4.89189168e+00  1.84507121e+00\n",
      "    2.47977185e-01 -6.75596465e+00]\n",
      "  [ 1.36578966e-01 -7.15061758e-02 -7.51712399e-02 -5.22036193e-03\n",
      "    1.02584692e-01 -1.96689091e-01]]] reward= -6702337.05232475 done= False\n",
      "Step 345\n",
      "Action:  [ 1.756119   0.3072701 -1.5200164  1.5363345  4.4131985 -0.6285309]\n",
      "self.next: 345\n",
      "obs= [[[ 2.70180423e+00 -2.21078254e+00 -3.51914935e-01  1.19694645e-01\n",
      "   -7.95145252e-01  7.71924475e-02]\n",
      "  [ 1.45931973e-02 -2.28656036e-03 -1.21804557e-02  8.45102843e-04\n",
      "   -9.92333741e-02  3.63447049e-01]]\n",
      "\n",
      " [[ 7.57864501e+00 -3.41245619e+00 -4.89940881e+00  1.84454918e+00\n",
      "    2.58235654e-01 -6.77563356e+00]\n",
      "  [ 1.36226693e-01 -7.12683754e-02 -7.56032868e-02 -4.58625874e-03\n",
      "    1.02732573e-01 -1.96789965e-01]]] reward= -6602861.626298451 done= False\n",
      "Step 346\n",
      "Action:  [ 1.7557492   0.30741686 -1.5197729   1.5365236   4.413117   -0.6284899 ]\n",
      "self.next: 346\n",
      "obs= [[[ 2.70326355e+00 -2.21101120e+00 -3.53132981e-01  1.19779156e-01\n",
      "   -8.05068590e-01  1.13537152e-01]\n",
      "  [ 1.40569042e-02  4.18984986e-03 -1.79551909e-02  5.19720652e-05\n",
      "    5.87892899e-02 -1.55420091e-01]]\n",
      "\n",
      " [[ 7.59226768e+00 -3.41958303e+00 -4.90696914e+00  1.84409055e+00\n",
      "    2.68508911e-01 -6.79531256e+00]\n",
      "  [ 1.35885751e-01 -7.10402324e-02 -7.60348016e-02 -3.96003014e-03\n",
      "    1.02885267e-01 -1.96898593e-01]]] reward= -6987755.746265856 done= False\n",
      "Step 347\n",
      "Action:  [ 1.7550868   0.30719823 -1.5190034   1.5355499   4.4094796  -0.62774426]\n",
      "self.next: 347\n",
      "obs= [[[ 2.70466924e+00 -2.21059221e+00 -3.54928500e-01  1.19784353e-01\n",
      "   -7.99189661e-01  9.79951432e-02]\n",
      "  [ 1.27761207e-02 -6.12781901e-02  4.17338993e-02  6.24827112e-02\n",
      "    4.88038675e-02 -3.13671537e-01]]\n",
      "\n",
      " [[ 7.60585626e+00 -3.42668705e+00 -4.91457262e+00  1.84369455e+00\n",
      "    2.78797438e-01 -6.81500242e+00]\n",
      "  [ 1.35556058e-01 -7.08217435e-02 -7.64657157e-02 -3.34156160e-03\n",
      "    1.03042774e-01 -1.97014978e-01]]] reward= -6614847.099889976 done= False\n",
      "Step 348\n",
      "Action:  [ 1.7538402  0.307115  -1.5178118  1.5345852  4.4058204 -0.6269188]\n",
      "self.next: 348\n",
      "obs= [[[ 2.70594685e+00 -2.21672003e+00 -3.50755110e-01  1.26032624e-01\n",
      "   -7.94309274e-01  6.66279896e-02]\n",
      "  [ 1.29290219e-02  7.34546858e-04 -3.60720138e-02  4.65148796e-02\n",
      "   -2.49880159e-02 -2.59404436e-03]]\n",
      "\n",
      " [[ 7.61941186e+00 -3.43376922e+00 -4.92221919e+00  1.84336039e+00\n",
      "    2.89101715e-01 -6.83470392e+00]\n",
      "  [ 1.35237545e-01 -7.06129218e-02 -7.68959586e-02 -2.73073649e-03\n",
      "    1.03205093e-01 -1.97139126e-01]]] reward= -7157316.775367862 done= False\n",
      "Step 349\n",
      "Action:  [ 1.754573    0.30727214 -1.5186      1.5355141   4.408724   -0.62754214]\n",
      "self.next: 349\n",
      "obs= [[[ 2.70723975e+00 -2.21664658e+00 -3.54362311e-01  1.30684112e-01\n",
      "   -7.96808076e-01  6.63685851e-02]\n",
      "  [ 1.48046462e-02  2.07808616e-02 -1.09239457e-02 -4.94696352e-02\n",
      "    2.58959295e-02 -5.93763962e-02]]\n",
      "\n",
      " [[ 7.63293562e+00 -3.44083052e+00 -4.92990878e+00  1.84308732e+00\n",
      "    2.99422225e-01 -6.85441783e+00]\n",
      "  [ 1.34930157e-01 -7.04137978e-02 -7.73254590e-02 -2.12743490e-03\n",
      "    1.03372225e-01 -1.97271041e-01]]] reward= -6591058.24608894 done= False\n",
      "Step 350\n",
      "Action:  [ 1.7541664   0.30728832 -1.518238    1.535361    4.407043   -0.627161  ]\n",
      "self.next: 350\n",
      "obs= [[[ 2.70872022e+00 -2.21456849e+00 -3.55454706e-01  1.25737148e-01\n",
      "   -7.94218483e-01  6.04309455e-02]\n",
      "  [-3.22822464e-02  5.21755698e-02 -4.57932054e-02 -1.44629848e-04\n",
      "    2.39783765e-02 -2.92314257e-02]]\n",
      "\n",
      " [[ 7.64642864e+00 -3.44787190e+00 -4.93764133e+00  1.84287457e+00\n",
      "    3.09759447e-01 -6.87414493e+00]\n",
      "  [ 1.34633851e-01 -7.02244197e-02 -7.77541396e-02 -1.53153586e-03\n",
      "    1.03544170e-01 -1.97410724e-01]]] reward= -6795059.224048212 done= False\n",
      "Step 351\n",
      "Action:  [ 1.7534877   0.30732608 -1.5176418   1.5350212   4.405128   -0.6268212 ]\n",
      "self.next: 351\n",
      "obs= [[[ 2.70549199e+00 -2.20935093e+00 -3.60034027e-01  1.25722685e-01\n",
      "   -7.91820645e-01  5.75078029e-02]\n",
      "  [ 4.50542498e-02 -3.31668403e-02 -1.35565798e-02  2.74149951e-02\n",
      "    3.39223373e-02 -6.63517273e-02]]\n",
      "\n",
      " [[ 7.65989202e+00 -3.45489434e+00 -4.94541674e+00  1.84272142e+00\n",
      "    3.20113864e-01 -6.89388600e+00]\n",
      "  [ 1.34348599e-01 -7.00448534e-02 -7.81819208e-02 -9.42915328e-04\n",
      "    1.03720925e-01 -1.97558179e-01]]] reward= -6303105.551617971 done= False\n",
      "Step 352\n",
      "Action:  [ 1.752956    0.30729556 -1.5171528   1.5346854   4.403831   -0.6264161 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 352\n",
      "obs= [[[ 2.70999742e+00 -2.21266762e+00 -3.61389684e-01  1.28464185e-01\n",
      "   -7.88428411e-01  5.08726302e-02]\n",
      "  [-9.73388294e-04 -4.73622333e-03  8.00920065e-03  1.20960296e-04\n",
      "   -6.00811375e-02  2.20077676e-01]]\n",
      "\n",
      " [[ 7.67332688e+00 -3.46189882e+00 -4.95323494e+00  1.84262713e+00\n",
      "    3.30485957e-01 -6.91364182e+00]\n",
      "  [ 1.34074385e-01 -6.98751832e-02 -7.86087202e-02 -3.61446021e-04\n",
      "    1.03902490e-01 -1.97713408e-01]]] reward= -7193240.075109152 done= False\n",
      "Step 353\n",
      "Action:  [ 1.7528068  0.3074575 -1.5171239  1.5350451  4.4042525 -0.6264909]\n",
      "self.next: 353\n",
      "obs= [[[ 2.70990008e+00 -2.21314124e+00 -3.60588764e-01  1.28476281e-01\n",
      "   -7.94436525e-01  7.28803978e-02]\n",
      "  [-2.06252465e-02 -2.15055909e-03 -1.61218248e-01  2.76928829e-01\n",
      "   -9.25772435e-02 -6.16549645e-02]]\n",
      "\n",
      " [[ 7.68673432e+00 -3.46888634e+00 -4.96109581e+00  1.84259098e+00\n",
      "    3.40876206e-01 -6.93341316e+00]\n",
      "  [ 1.33811208e-01 -6.97155114e-02 -7.90344523e-02  2.13003103e-04\n",
      "    1.04088864e-01 -1.97876412e-01]]] reward= -7132836.597254324 done= False\n",
      "Step 354\n",
      "Action:  [ 1.7517301   0.30725208 -1.5159707   1.533839    4.400794   -0.62594783]\n",
      "self.next: 354\n",
      "obs= [[[ 2.70783756e+00 -2.21335629e+00 -3.76710589e-01  1.56169164e-01\n",
      "   -8.03694249e-01  6.67149014e-02]\n",
      "  [ 7.64634396e-03 -1.12166595e-02  2.56964403e-02 -2.25289625e-02\n",
      "    4.34538422e-03  1.54110584e-01]]\n",
      "\n",
      " [[ 7.70011544e+00 -3.47585789e+00 -4.96899925e+00  1.84261229e+00\n",
      "    3.51285092e-01 -6.95320080e+00]\n",
      "  [ 1.33559081e-01 -6.95659592e-02 -7.94590263e-02  7.80565647e-04\n",
      "    1.04280044e-01 -1.98047194e-01]]] reward= -6613876.742833068 done= False\n",
      "Step 355\n",
      "Action:  [ 1.7520969   0.30747646 -1.5164666   1.5347054   4.401809   -0.6259207 ]\n",
      "self.next: 355\n",
      "obs= [[[ 2.70860219e+00 -2.21447796e+00 -3.74140945e-01  1.53916268e-01\n",
      "   -8.03259711e-01  8.21259598e-02]\n",
      "  [-2.28852708e-02 -1.42983477e-02  3.43152947e-02  7.00806296e-03\n",
      "   -5.40240221e-03 -3.17552047e-02]]\n",
      "\n",
      " [[ 7.71347135e+00 -3.48281449e+00 -4.97694516e+00  1.84269034e+00\n",
      "    3.61713096e-01 -6.97300552e+00]\n",
      "  [ 1.33318029e-01 -6.94266658e-02 -7.98823512e-02  1.34138113e-03\n",
      "    1.04476029e-01 -1.98225755e-01]]] reward= -7776536.836448609 done= False\n",
      "Step 356\n",
      "Action:  [ 1.7513831   0.307384   -1.51574     1.5340601   4.399311   -0.62540245]\n",
      "self.next: 356\n",
      "obs= [[[ 2.70631366e+00 -2.21590780e+00 -3.70709416e-01  1.54617074e-01\n",
      "   -8.03799951e-01  7.89504393e-02]\n",
      "  [ 1.71925343e-02  3.59016382e-02 -5.16738278e-02 -2.76232155e-02\n",
      "    1.24043833e-01 -1.36017166e-01]]\n",
      "\n",
      " [[ 7.72680315e+00 -3.48975716e+00 -4.98493339e+00  1.84282448e+00\n",
      "    3.72160699e-01 -6.99282810e+00]\n",
      "  [ 1.33088090e-01 -6.92977892e-02 -8.03043291e-02  1.89559121e-03\n",
      "    1.04676816e-01 -1.98412095e-01]]] reward= -6828118.944902554 done= False\n",
      "Step 357\n",
      "Action:  [ 1.7508252   0.30738753 -1.5152351   1.533732    4.3968353  -0.62495196]\n",
      "self.next: 357\n",
      "obs= [[[ 2.70803292e+00 -2.21231763e+00 -3.75876798e-01  1.51854752e-01\n",
      "   -7.91395568e-01  6.53487228e-02]\n",
      "  [-6.02232385e-02 -3.49360149e-02  7.33893853e-02  1.40586661e-01\n",
      "   -2.80510998e-01  3.81893355e-01]]\n",
      "\n",
      " [[ 7.74011196e+00 -3.49668693e+00 -4.99296382e+00  1.84301404e+00\n",
      "    3.82628381e-01 -7.01266931e+00]\n",
      "  [ 1.32869316e-01 -6.91795053e-02 -8.07248605e-02  2.44334305e-03\n",
      "    1.04882401e-01 -1.98606219e-01]]] reward= -7485756.833998975 done= False\n",
      "Step 358\n",
      "Action:  [ 1.7498436   0.30757344 -1.5144444   1.5337021   4.3971434  -0.6248545 ]\n",
      "self.next: 358\n",
      "obs= [[[ 2.70201059e+00 -2.21581123e+00 -3.68537860e-01  1.65913418e-01\n",
      "   -8.19446668e-01  1.03538058e-01]\n",
      "  [ 1.25578909e-01  1.07158665e-02 -1.14917821e-01 -1.11129602e-01\n",
      "    2.51695466e-01 -4.61115836e-02]]\n",
      "\n",
      " [[ 7.75339889e+00 -3.50360488e+00 -5.00103631e+00  1.84325837e+00\n",
      "    3.93116621e-01 -7.03252993e+00]\n",
      "  [ 1.32661770e-01 -6.90720079e-02 -8.11438421e-02  2.98478782e-03\n",
      "    1.05092781e-01 -1.98808127e-01]]] reward= -7927179.6192594245 done= False\n",
      "Step 359\n",
      "Action:  [ 1.7504464   0.30748847 -1.5149654   1.5338964   4.3955073  -0.62457234]\n",
      "self.next: 359\n",
      "obs= [[[ 2.71456848e+00 -2.21473965e+00 -3.80029642e-01  1.54800458e-01\n",
      "   -7.94277121e-01  9.89268999e-02]\n",
      "  [ 7.81852173e-03  5.10988515e-02  1.03379824e-01 -2.57590067e-01\n",
      "    3.71500900e-02  1.60805706e-01]]\n",
      "\n",
      " [[ 7.76666507e+00 -3.51051209e+00 -5.00915069e+00  1.84355685e+00\n",
      "    4.03625899e-01 -7.05241074e+00]\n",
      "  [ 1.32465529e-01 -6.89755094e-02 -8.15611681e-02  3.52008267e-03\n",
      "    1.05307953e-01 -1.99017824e-01]]] reward= -9304186.093935156 done= False\n",
      "Step 360\n",
      "Action:  [ 1.7497853   0.30763873 -1.51446     1.5339411   4.394387   -0.62424284]\n",
      "self.next: 360\n",
      "obs= [[[ 2.71535034e+00 -2.20962976e+00 -3.69691660e-01  1.29041452e-01\n",
      "   -7.90562112e-01  1.15007471e-01]\n",
      "  [-5.22328466e-02 -3.25165722e-02  8.39053218e-02  9.30723826e-02\n",
      "   -1.34422241e-01  2.09564372e-02]]\n",
      "\n",
      " [[ 7.77991162e+00 -3.51740964e+00 -5.01730681e+00  1.84390886e+00\n",
      "    4.14156694e-01 -7.07231253e+00]\n",
      "  [ 1.32280679e-01 -6.88902382e-02 -8.19767284e-02  4.04938803e-03\n",
      "    1.05527910e-01 -1.99235313e-01]]] reward= -8850609.195275426 done= False\n",
      "Step 361\n",
      "Action:  [ 1.7486435   0.3074641  -1.5132911   1.5327315   4.3921995  -0.62377596]\n",
      "self.next: 361\n",
      "obs= [[[ 2.71012705e+00 -2.21288142e+00 -3.61301127e-01  1.38348690e-01\n",
      "   -8.04004336e-01  1.17103114e-01]\n",
      "  [-1.36036812e-03 -4.25801857e-04  3.58935471e-03  7.82317518e-04\n",
      "   -5.22278904e-03  1.37121185e-03]]\n",
      "\n",
      " [[ 7.79313969e+00 -3.52429866e+00 -5.02550448e+00  1.84431380e+00\n",
      "    4.24709485e-01 -7.09223606e+00]\n",
      "  [ 1.32107320e-01 -6.88164397e-02 -8.23904096e-02  4.57286905e-03\n",
      "    1.05752650e-01 -1.99460600e-01]]] reward= -7437284.501292548 done= False\n",
      "Step 362\n",
      "Action:  [ 1.7487552   0.30750617 -1.5134206   1.532973    4.3917613  -0.62370193]\n",
      "self.next: 362\n",
      "obs= [[[ 2.70999101e+00 -2.21292400e+00 -3.60942192e-01  1.38426922e-01\n",
      "   -8.04526615e-01  1.17240235e-01]\n",
      "  [-1.85944302e-02 -1.44324024e-03 -4.23673185e-03  2.40380860e-02\n",
      "   -5.60419763e-05  2.84620732e-02]]\n",
      "\n",
      " [[ 7.80635042e+00 -3.53118030e+00 -5.03374352e+00  1.84477109e+00\n",
      "    4.35284750e-01 -7.11218212e+00]\n",
      "  [ 1.31945561e-01 -6.87543753e-02 -8.28020978e-02  5.09069764e-03\n",
      "    1.05982166e-01 -1.99693692e-01]]] reward= -7371545.276894596 done= False\n",
      "Step 363\n",
      "Action:  [ 1.7481694   0.30754074 -1.5129098   1.5327213   4.3901725  -0.62336177]\n",
      "self.next: 363\n",
      "obs= [[[ 2.70813157e+00 -2.21306832e+00 -3.61365865e-01  1.40830730e-01\n",
      "   -8.04532219e-01  1.20086443e-01]\n",
      "  [-2.22754731e-02  4.05657033e-02  6.32544906e-03 -5.08889572e-02\n",
      "   -3.19981702e-02  1.05846421e-01]]\n",
      "\n",
      " [[ 7.81954498e+00 -3.53805574e+00 -5.04202373e+00  1.84528016e+00\n",
      "    4.45882967e-01 -7.13215149e+00]\n",
      "  [ 1.31795521e-01 -6.87043212e-02 -8.32116750e-02  5.60304907e-03\n",
      "    1.06216453e-01 -1.99934598e-01]]] reward= -7456365.214460165 done= False\n",
      "Step 364\n",
      "Action:  [ 1.7479008   0.3076269  -1.5127097   1.5328407   4.389425   -0.62318367]\n",
      "self.next: 364\n",
      "obs= [[[ 2.70590402e+00 -2.20901175e+00 -3.60733320e-01  1.35741834e-01\n",
      "   -8.07732036e-01  1.30671085e-01]\n",
      "  [ 4.87349225e-02 -3.09129779e-02 -1.88196090e-02  2.86432444e-02\n",
      "    1.32262544e-01 -1.52520469e-01]]\n",
      "\n",
      " [[ 7.83272453e+00 -3.54492617e+00 -5.05034490e+00  1.84584046e+00\n",
      "    4.56504612e-01 -7.15214495e+00]\n",
      "  [ 1.31657327e-01 -6.86665675e-02 -8.36190222e-02  6.11010396e-03\n",
      "    1.06455505e-01 -2.00183328e-01]]] reward= -7502591.789321421 done= False\n",
      "Step 365\n",
      "Action:  [ 1.7467177   0.3074966  -1.5115615   1.5317539   4.385244   -0.62226796]\n",
      "self.next: 365\n",
      "obs= [[[ 2.71077752e+00 -2.21210305e+00 -3.62615281e-01  1.38606159e-01\n",
      "   -7.94505782e-01  1.15419038e-01]\n",
      "  [-3.02428651e-02 -1.04105261e-02  4.12350933e-02  9.23331027e-02\n",
      "   -1.94261617e-01  1.77177779e-01]]\n",
      "\n",
      " [[ 7.84589026e+00 -3.55179283e+00 -5.05870680e+00  1.84645147e+00\n",
      "    4.67150163e-01 -7.17216328e+00]\n",
      "  [ 1.31531115e-01 -6.86414176e-02 -8.40240169e-02  6.61204674e-03\n",
      "    1.06699317e-01 -2.00439897e-01]]] reward= -9017223.81003532 done= False\n",
      "Step 366\n",
      "Action:  [ 1.7465305  0.3076348 -1.5114577  1.5321082  4.3866944 -0.6224981]\n",
      "self.next: 366\n",
      "obs= [[[ 2.70775323e+00 -2.21314410e+00 -3.58491772e-01  1.47839469e-01\n",
      "   -8.13931944e-01  1.33136816e-01]\n",
      "  [-1.99970923e-02  1.18177357e-02  8.33888164e-03  9.65703395e-02\n",
      "    7.48125121e-03 -2.40205265e-01]]\n",
      "\n",
      " [[ 7.85904337e+00 -3.55865697e+00 -5.06710921e+00  1.84711268e+00\n",
      "    4.77820095e-01 -7.19220727e+00]\n",
      "  [ 1.31417028e-01 -6.86291861e-02 -8.44265381e-02  7.10906724e-03\n",
      "    1.06947885e-01 -2.00704322e-01]]] reward= -7795818.083313792 done= False\n",
      "Step 367\n",
      "Action:  [ 1.7455842   0.30746865 -1.5104527   1.5310209   4.382049   -0.6216121 ]\n",
      "self.next: 367\n",
      "obs= [[[ 2.70575352e+00 -2.21196233e+00 -3.57657884e-01  1.57496503e-01\n",
      "   -8.13183819e-01  1.09116289e-01]\n",
      "  [-3.45826854e-02  1.56848587e-02 -8.08211105e-03  1.23812603e-01\n",
      "   -1.55610331e-01  5.66131629e-02]]\n",
      "\n",
      " [[ 7.87218508e+00 -3.56551989e+00 -5.07555186e+00  1.84782358e+00\n",
      "    4.88514883e-01 -7.21227770e+00]\n",
      "  [ 1.31315215e-01 -6.86301989e-02 -8.48264614e-02  7.60135861e-03\n",
      "    1.07201200e-01 -2.00976621e-01]]] reward= -8264858.252707208 done= False\n",
      "Step 368\n",
      "Action:  [ 1.7457396   0.3076095  -1.5106841   1.5316169   4.383896   -0.62191975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 368\n",
      "obs= [[[ 2.70229525 -2.21039384 -0.35846609  0.16987776 -0.82874485\n",
      "    0.11477761]\n",
      "  [-0.03420812 -0.00899833  0.04479193  0.08923842 -0.19279463\n",
      "    0.17708632]]\n",
      "\n",
      " [[ 7.8853166  -3.57238291 -5.08403451  1.84858372  0.499235\n",
      "   -7.23237536]\n",
      "  [ 0.13122583 -0.06864479 -0.08522366  0.00808912  0.10745926\n",
      "   -0.20125682]]] reward= -7618784.305156699 done= False\n",
      "Step 369\n",
      "Action:  [ 1.745347    0.3076956  -1.5103663   1.5316865   4.3832674  -0.62166715]\n",
      "self.next: 369\n",
      "obs= [[[ 2.69887444 -2.21129368 -0.3539869   0.17880161 -0.84802431\n",
      "    0.13248624]\n",
      "  [ 0.0500613  -0.02976422 -0.01939217  0.02954514  0.13313943\n",
      "   -0.30806304]]\n",
      "\n",
      " [[ 7.89843918 -3.57924739 -5.09255687  1.84939263  0.50998093\n",
      "   -7.25250104]\n",
      "  [ 0.13114903 -0.0686733  -0.08561802  0.00857255  0.10772206\n",
      "   -0.20154494]]] reward= -8054710.635799514 done= False\n",
      "Step 370\n",
      "Action:  [ 1.7442539  0.3074926 -1.5092336  1.530474   4.3775754 -0.6205291]\n",
      "self.next: 370\n",
      "obs= [[[ 2.70388057e+00 -2.21427010e+00 -3.55926119e-01  1.81756120e-01\n",
      "   -8.34710372e-01  1.01679934e-01]\n",
      "  [-8.32202000e-03 -7.92912630e-03 -5.51778092e-03  1.93116126e-02\n",
      "   -4.36772856e-02  1.21140389e-01]]\n",
      "\n",
      " [[ 7.91155408e+00 -3.58611472e+00 -5.10111867e+00  1.85024989e+00\n",
      "    5.20753135e-01 -7.27265554e+00]\n",
      "  [ 1.31084985e-01 -6.87160826e-02 -8.60094147e-02  9.05184887e-03\n",
      "    1.07989600e-01 -2.01841026e-01]]] reward= -8751802.949563427 done= False\n",
      "Step 371\n",
      "Action:  [ 1.744682    0.30773774 -1.5098096   1.5314872   4.3805327  -0.6210726 ]\n",
      "self.next: 371\n",
      "obs= [[[ 2.70304837e+00 -2.21506301e+00 -3.56477897e-01  1.83687281e-01\n",
      "   -8.39078101e-01  1.13793973e-01]\n",
      "  [-2.81805051e-02  1.32471644e-03  4.56581343e-02 -1.80674337e-02\n",
      "    9.15096088e-02 -3.05321982e-01]]\n",
      "\n",
      " [[ 7.92466258e+00 -3.59298633e+00 -5.10971962e+00  1.85115507e+00\n",
      "    5.31552095e-01 -7.29283964e+00]\n",
      "  [ 1.31033850e-01 -6.87734847e-02 -8.63977179e-02  9.52722890e-03\n",
      "    1.08261874e-01 -2.02145106e-01]]] reward= -8047869.984512861 done= False\n",
      "Step 372\n",
      "Action:  [ 1.7428889   0.307553   -1.5080246   1.5298973   4.3735614  -0.61964005]\n",
      "self.next: 372\n",
      "obs= [[[ 2.70023032e+00 -2.21493054e+00 -3.51912084e-01  1.81880538e-01\n",
      "   -8.29927140e-01  8.32617745e-02]\n",
      "  [ 1.29339990e-02  8.96061936e-03 -2.12047137e-02  1.70501210e-03\n",
      "   -6.25932748e-03 -2.60597887e-02]]\n",
      "\n",
      " [[ 7.93776597e+00 -3.59986368e+00 -5.11835939e+00  1.85210779e+00\n",
      "    5.42378283e-01 -7.31305415e+00]\n",
      "  [ 1.30995791e-01 -6.88458642e-02 -8.67828106e-02  9.99889441e-03\n",
      "    1.08538881e-01 -2.02457224e-01]]] reward= -8133219.398174067 done= False\n",
      "Step 373\n",
      "Action:  [ 1.7435014   0.3077056  -1.5087093   1.5307804   4.37653    -0.62019765]\n",
      "self.next: 373\n",
      "obs= [[[ 2.70152372e+00 -2.21403448e+00 -3.54032555e-01  1.82051039e-01\n",
      "   -8.30553072e-01  8.06557956e-02]\n",
      "  [-3.38475717e-02  6.44659848e-02 -2.84001210e-02 -6.03750335e-02\n",
      "    7.29331912e-04  1.64880473e-01]]\n",
      "\n",
      " [[ 7.95086555e+00 -3.60674826e+00 -5.12703767e+00  1.85310768e+00\n",
      "    5.53232171e-01 -7.33329987e+00]\n",
      "  [ 1.30970973e-01 -6.89335775e-02 -8.71645774e-02  1.04670554e-02\n",
      "    1.08820624e-01 -2.02777430e-01]]] reward= -8203500.062767806 done= False\n",
      "Step 374\n",
      "Action:  [ 1.7429607  0.3078966 -1.5083429  1.5309572  4.3751698 -0.6199337]\n",
      "self.next: 374\n",
      "obs= [[[ 2.69813896 -2.20758788 -0.35687257  0.17601354 -0.83048014\n",
      "    0.09714384]\n",
      "  [ 0.0289413  -0.03706478 -0.01623427  0.05138931  0.03593362\n",
      "   -0.04210493]]\n",
      "\n",
      " [[ 7.96396264 -3.61364162 -5.13575413  1.85415439  0.56411423\n",
      "   -7.35357762]\n",
      "  [ 0.13095956 -0.06903698 -0.0875429   0.01093192  0.10910711\n",
      "   -0.20310578]]] reward= -8502078.941393381 done= False\n",
      "Step 375\n",
      "Action:  [ 1.7419417   0.30773625 -1.5073214   1.5299742   4.372152   -0.6191812 ]\n",
      "self.next: 375\n",
      "obs= [[[ 2.70103309e+00 -2.21129436e+00 -3.58495994e-01  1.81152466e-01\n",
      "   -8.26886777e-01  9.29333499e-02]\n",
      "  [-2.14583661e-02 -4.40868850e-03  4.92032269e-02  6.80147033e-02\n",
      "   -9.38350131e-02 -1.48154782e-01]]\n",
      "\n",
      " [[ 7.97705860e+00 -3.62054532e+00 -5.14450842e+00  1.85524758e+00\n",
      "    5.75024944e-01 -7.37388820e+00]\n",
      "  [ 1.30961709e-01 -6.91564299e-02 -8.79176713e-02  1.13937007e-02\n",
      "    1.09398333e-01 -2.03442330e-01]]] reward= -8991460.674640572 done= False\n",
      "Step 376\n",
      "Action:  [ 1.7412144   0.30767977 -1.5065682   1.5294156   4.3701034  -0.6187242 ]\n",
      "self.next: 376\n",
      "obs= [[[ 2.69888725e+00 -2.21173523e+00 -3.53575672e-01  1.87953937e-01\n",
      "   -8.36270278e-01  7.81178716e-02]\n",
      "  [ 5.87322728e-03  4.32134739e-03 -8.64152710e-03 -2.06549025e-05\n",
      "   -2.47324148e-03  6.18552605e-02]]\n",
      "\n",
      " [[ 7.99015477e+00 -3.62746096e+00 -5.15330018e+00  1.85638695e+00\n",
      "    5.85964777e-01 -7.39423243e+00]\n",
      "  [ 1.30977581e-01 -6.92922748e-02 -8.82887769e-02  1.18526027e-02\n",
      "    1.09694311e-01 -2.03787153e-01]]] reward= -8347220.031096203 done= False\n",
      "Step 377\n",
      "Action:  [ 1.7412611   0.30785903 -1.5067643   1.5299933   4.3703933  -0.6187537 ]\n",
      "self.next: 377\n",
      "obs= [[[ 2.69947458 -2.21130309 -0.35443982  0.18795187 -0.8365176\n",
      "    0.0843034 ]\n",
      "  [-0.02004898  0.02282298 -0.02762568  0.11543372 -0.25697511\n",
      "    0.48326967]]\n",
      "\n",
      " [[ 8.00325253 -3.63439019 -5.16212906  1.85757221  0.59693421\n",
      "   -7.41461114]\n",
      "  [ 0.13100733 -0.06944486 -0.08865612  0.01230884  0.10999505\n",
      "   -0.20414032]]] reward= -9077136.109316157 done= False\n",
      "Step 378\n",
      "Action:  [ 1.7401112   0.3080896  -1.5058162   1.5299352   4.3694406  -0.61850613]\n",
      "self.next: 378\n",
      "obs= [[[ 2.69746968e+00 -2.20902079e+00 -3.57202393e-01  1.99495243e-01\n",
      "   -8.62215113e-01  1.32630365e-01]\n",
      "  [-5.42541113e-03  5.56180026e-02 -2.62348033e-02 -8.35967707e-02\n",
      "    1.19992234e-01 -1.82347648e-01]]\n",
      "\n",
      " [[ 8.01635326e+00 -3.64133468e+00 -5.17099467e+00  1.85880309e+00\n",
      "    6.07933713e-01 -7.43502518e+00]\n",
      "  [ 1.31051096e-01 -6.96145307e-02 -8.90195855e-02  1.27626027e-02\n",
      "    1.10300570e-01 -2.04501925e-01]]] reward= -9888448.62712297 done= False\n",
      "Step 379\n",
      "Action:  [ 1.739796    0.30780593 -1.5053476   1.5290313   4.364455   -0.61756843]\n",
      "self.next: 379\n",
      "obs= [[[ 2.69692714e+00 -2.20345899e+00 -3.59825873e-01  1.91135566e-01\n",
      "   -8.50215890e-01  1.14395600e-01]\n",
      "  [ 5.08840134e-02 -4.75897883e-02 -2.84379429e-02  8.66919670e-02\n",
      "   -4.33604433e-04  1.86068614e-02]]\n",
      "\n",
      " [[ 8.02945837e+00 -3.64829613e+00 -5.17989663e+00  1.86007935e+00\n",
      "    6.18963770e-01 -7.45547537e+00]\n",
      "  [ 1.31109030e-01 -6.98016142e-02 -8.93790914e-02  1.32141074e-02\n",
      "    1.10610882e-01 -2.04872048e-01]]] reward= -8665219.115899641 done= False\n",
      "Step 380\n",
      "Action:  [ 1.7394758   0.3078616  -1.5051264   1.5290428   4.36549    -0.61758995]\n",
      "self.next: 380\n",
      "obs= [[[ 2.70201554 -2.20821797 -0.36266967  0.19980476 -0.85025925\n",
      "    0.11625629]\n",
      "  [-0.01030849 -0.00837239  0.04312655 -0.02544303 -0.05446953\n",
      "    0.14314274]]\n",
      "\n",
      " [[ 8.04256927 -3.65527629 -5.18883454  1.86140076  0.63002486\n",
      "   -7.47596257]\n",
      "  [ 0.13118126 -0.07000644 -0.08973454  0.01366355  0.11092601\n",
      "   -0.20525079]]] reward= -9883914.790487107 done= False\n",
      "Step 381\n",
      "Action:  [ 1.7390611   0.30800167 -1.5048199   1.5292397   4.36445    -0.61731094]\n",
      "self.next: 381\n",
      "obs= [[[ 2.70098469 -2.20905521 -0.35835701  0.19726046 -0.8557062\n",
      "    0.13057056]\n",
      "  [ 0.05894207  0.05108078 -0.13341396  0.02426985  0.09935611\n",
      "   -0.19392714]]\n",
      "\n",
      " [[ 8.0556874  -3.66227693 -5.19780799  1.86276712  0.64111746\n",
      "   -7.49648765]\n",
      "  [ 0.13126793 -0.07022931 -0.09008586  0.01411112  0.11124598\n",
      "   -0.20563826]]] reward= -9306057.64779288 done= False\n",
      "Step 382\n",
      "Action:  [ 1.738502   0.3078313 -1.5041857  1.5283809  4.360963  -0.6168301]\n",
      "self.next: 382\n",
      "obs= [[[ 2.70687890e+00 -2.20394713e+00 -3.71698409e-01  1.99687444e-01\n",
      "   -8.45770592e-01  1.11177846e-01]\n",
      "  [-4.67409943e-02 -4.34135708e-02  8.87625208e-02  1.96294346e-03\n",
      "   -3.85918996e-02  4.70778552e-02]]\n",
      "\n",
      " [[ 8.06881419e+00 -3.66929986e+00 -5.20681658e+00  1.86417823e+00\n",
      "    6.52242058e-01 -7.51705148e+00]\n",
      "  [ 1.31369140e-01 -7.04705330e-02 -9.04329490e-02  1.45570062e-02\n",
      "    1.11570827e-01 -2.06034577e-01]]] reward= -9419304.720255863 done= False\n",
      "Step 383\n",
      "Action:  [ 1.7372762   0.30798706 -1.5031911   1.5282152   4.359173   -0.61609954]\n",
      "self.next: 383\n",
      "obs= [[[ 2.70220480e+00 -2.20828849e+00 -3.62822157e-01  1.99883739e-01\n",
      "   -8.49629782e-01  1.15885631e-01]\n",
      "  [ 1.17278846e-02 -6.88812685e-03  4.51721271e-02 -4.67981979e-02\n",
      "   -7.05996077e-02  1.86957907e-01]]\n",
      "\n",
      " [[ 8.08195111e+00 -3.67634692e+00 -5.21585988e+00  1.86563393e+00\n",
      "    6.63399141e-01 -7.53765494e+00]\n",
      "  [ 1.31485015e-01 -7.07304043e-02 -9.07757482e-02  1.50013965e-02\n",
      "    1.11900579e-01 -2.06439859e-01]]] reward= -9097271.432604326 done= False\n",
      "Step 384\n",
      "Action:  [ 1.7373716   0.30810562 -1.5033453   1.5286602   4.3597875  -0.61619526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 384\n",
      "obs= [[[ 2.70337759 -2.2089773  -0.35830494  0.19520392 -0.85668974\n",
      "    0.13458142]\n",
      "  [ 0.01244641 -0.01381445 -0.02311519  0.05571197  0.03143899\n",
      "   -0.12545443]]\n",
      "\n",
      " [[ 8.09509961 -3.68341996 -5.22493745  1.86713407  0.6745892\n",
      "   -7.55829892]\n",
      "  [ 0.13161566 -0.0710092  -0.09111419  0.01544447  0.11223528\n",
      "   -0.20685424]]] reward= -9893088.194274934 done= False\n",
      "Step 385\n",
      "Action:  [ 1.7364386   0.3079159  -1.502359    1.5275302   4.355925   -0.61549807]\n",
      "self.next: 385\n",
      "obs= [[[ 2.70462223e+00 -2.21035875e+00 -3.60616463e-01  2.00775115e-01\n",
      "   -8.53545844e-01  1.22035979e-01]\n",
      "  [ 4.26019818e-03 -1.03937791e-02  2.95290160e-02 -1.99604967e-02\n",
      "   -6.76590211e-04 -1.61975837e-03]]\n",
      "\n",
      " [[ 8.10826117e+00 -3.69052088e+00 -5.23404887e+00  1.86867852e+00\n",
      "    6.85812726e-01 -7.57898435e+00]\n",
      "  [ 1.31761167e-01 -7.13071895e-02 -9.14481983e-02  1.58863843e-02\n",
      "    1.12574975e-01 -2.07277868e-01]]] reward= -9242486.855239961 done= False\n",
      "Step 386\n",
      "Action:  [ 1.7360744  0.3080325 -1.502111   1.5277411  4.355273  -0.6152311]\n",
      "self.next: 386\n",
      "obs= [[[ 2.70504825e+00 -2.21139813e+00 -3.57663561e-01  1.98779066e-01\n",
      "   -8.53613503e-01  1.21874003e-01]\n",
      "  [ 7.85057599e-03  2.24850902e-03 -9.72987476e-03  1.90271419e-03\n",
      "   -3.54530434e-03  6.56054939e-02]]\n",
      "\n",
      " [[ 8.12143729e+00 -3.69765160e+00 -5.24319369e+00  1.87026716e+00\n",
      "    6.97070224e-01 -7.59971213e+00]\n",
      "  [ 1.31921630e-01 -7.16246255e-02 -9.17777286e-02  1.63273143e-02\n",
      "    1.12919717e-01 -2.07710886e-01]]] reward= -9546244.84520595 done= False\n",
      "Step 387\n",
      "Action:  [ 1.7356439  0.3081037 -1.5017688  1.5276881  4.3542585 -0.615022 ]\n",
      "self.next: 387\n",
      "obs= [[[ 2.70583330e+00 -2.21117327e+00 -3.58636549e-01  1.98969337e-01\n",
      "   -8.53968034e-01  1.28434552e-01]\n",
      "  [-3.98065463e-02  2.00476331e-02 -5.55260520e-03  1.12094489e-01\n",
      "   -1.50667040e-01  5.68431448e-02]]\n",
      "\n",
      " [[ 8.13462945e+00 -3.70481406e+00 -5.25237146e+00  1.87189989e+00\n",
      "    7.08362196e-01 -7.62048322e+00]\n",
      "  [ 1.32097127e-01 -7.19617509e-02 -9.21027249e-02  1.67674106e-02\n",
      "    1.13269562e-01 -2.08153455e-01]]] reward= -9829387.984240873 done= False\n",
      "Step 388\n",
      "Action:  [ 1.7349106  0.3080781 -1.501027   1.5271735  4.352839  -0.6147223]\n",
      "self.next: 388\n",
      "obs= [[[ 2.70185265e+00 -2.20916851e+00 -3.59191809e-01  2.10178786e-01\n",
      "   -8.69034738e-01  1.34118867e-01]\n",
      "  [ 3.99693246e-04 -9.45576614e-03  9.31742220e-03 -9.25148964e-04\n",
      "    6.32278230e-02 -1.19016662e-01]]\n",
      "\n",
      " [[ 8.14783917e+00 -3.71201023e+00 -5.26158173e+00  1.87357663e+00\n",
      "    7.19689152e-01 -7.64129857e+00]\n",
      "  [ 1.32287732e-01 -7.23187958e-02 -9.24231403e-02  1.72068193e-02\n",
      "    1.13624574e-01 -2.08605742e-01]]] reward= -9194362.406268079 done= False\n",
      "Step 389\n",
      "Action:  [ 1.7339399   0.30804625 -1.5001509   1.5266023   4.3485217  -0.6137495 ]\n",
      "self.next: 389\n",
      "obs= [[[ 2.70189262e+00 -2.21011409e+00 -3.58260067e-01  2.10086271e-01\n",
      "   -8.62711955e-01  1.22217200e-01]\n",
      "  [-4.09295917e-03 -2.48888733e-03 -1.74713422e-01  2.71098968e-01\n",
      "   -1.89106485e-01  3.76929418e-01]]\n",
      "\n",
      " [[ 8.16106794e+00 -3.71924211e+00 -5.27082405e+00  1.87529731e+00\n",
      "    7.31051609e-01 -7.66215914e+00]\n",
      "  [ 1.32493511e-01 -7.26959782e-02 -9.27389329e-02  1.76456783e-02\n",
      "    1.13984823e-01 -2.09067923e-01]]] reward= -9541293.014033599 done= False\n",
      "Step 390\n",
      "Action:  [ 1.7332387   0.3082543  -1.4996485   1.5268081   4.3496385  -0.61404806]\n",
      "self.next: 390\n",
      "obs= [[[ 2.70148332e+00 -2.21036298e+00 -3.75731409e-01  2.37196168e-01\n",
      "   -8.81622604e-01  1.59910142e-01]\n",
      "  [ 5.20378731e-03  3.50122803e-02  1.40403118e-01 -3.03453425e-01\n",
      "    1.62679512e-01 -2.80481638e-01]]\n",
      "\n",
      " [[ 8.17431729e+00 -3.72651171e+00 -5.28009794e+00  1.87706188e+00\n",
      "    7.42450092e-01 -7.68306593e+00]\n",
      "  [ 1.32714522e-01 -7.30935040e-02 -9.30500667e-02  1.80841159e-02\n",
      "    1.14350385e-01 -2.09540181e-01]]] reward= -10493832.772966212 done= False\n",
      "Step 391\n",
      "Action:  [ 1.7316378   0.30802274 -1.4980189   1.5256037   4.339991   -0.6117678 ]\n",
      "self.next: 391\n",
      "obs= [[[ 2.70200370e+00 -2.20686175e+00 -3.61691097e-01  2.06850826e-01\n",
      "   -8.65354653e-01  1.31861978e-01]\n",
      "  [ 2.84883975e-02 -2.28187807e-02 -3.93060376e-03 -5.66365571e-02\n",
      "    1.56231077e-01 -6.69553341e-02]]\n",
      "\n",
      " [[ 8.18758874e+00 -3.73382106e+00 -5.28940295e+00  1.87887029e+00\n",
      "    7.53885130e-01 -7.70401995e+00]\n",
      "  [ 1.32950818e-01 -7.35115697e-02 -9.33565076e-02  1.85222517e-02\n",
      "    1.14721342e-01 -2.10022708e-01]]] reward= -9888765.483313443 done= False\n",
      "Step 392\n",
      "Action:  [ 1.73176     0.30819663 -1.4983073   1.5258937   4.342037   -0.61223775]\n",
      "self.next: 392\n",
      "obs= [[[ 2.70485254 -2.20914363 -0.36208416  0.20118717 -0.84973155\n",
      "    0.12516644]\n",
      "  [ 0.01471853 -0.01295884  0.02515156 -0.0275495  -0.10045461\n",
      "    0.37054709]]\n",
      "\n",
      " [[ 8.20088383 -3.74117222 -5.2987386   1.88072252  0.76535726\n",
      "   -7.72502222]\n",
      "  [ 0.13320245 -0.07395036 -0.09365823  0.0189602   0.11509779\n",
      "   -0.2105157 ]]] reward= -10297616.257507415 done= False\n",
      "Step 393\n",
      "Action:  [ 1.7313628   0.30849403 -1.498113    1.5265235   4.343467   -0.6123688 ]\n",
      "self.next: 393\n",
      "obs= [[[ 2.70632439e+00 -2.21043951e+00 -3.59569002e-01  1.98432220e-01\n",
      "   -8.59777006e-01  1.62221154e-01]\n",
      "  [ 1.42333925e-02  4.07760677e-03 -1.73454814e-02 -1.07816324e-03\n",
      "   -7.36064423e-04  1.32018382e-01]]\n",
      "\n",
      " [[ 8.21420407e+00 -3.74856726e+00 -5.30810442e+00  1.88261854e+00\n",
      "    7.76867043e-01 -7.74607379e+00]\n",
      "  [ 1.33469448e-01 -7.44100490e-02 -9.39552072e-02  1.93980465e-02\n",
      "    1.15479812e-01 -2.11019377e-01]]] reward= -10922165.57044189 done= False\n",
      "Step 394\n",
      "Action:  [ 1.7311605   0.30835462 -1.4978331   1.5259954   4.3416147  -0.6120768 ]\n",
      "self.next: 394\n",
      "obs= [[[ 2.70774773e+00 -2.21003175e+00 -3.61303550e-01  1.98324404e-01\n",
      "   -8.59850612e-01  1.75422992e-01]\n",
      "  [-4.84039465e-03  8.89240499e-03 -2.97129017e-02  2.55795673e-02\n",
      "   -2.02703195e-03  1.26195234e-03]]\n",
      "\n",
      " [[ 8.22755101e+00 -3.75600826e+00 -5.31749994e+00  1.88455834e+00\n",
      "    7.88415024e-01 -7.76717573e+00]\n",
      "  [ 1.33751860e-01 -7.48908062e-02 -9.42474184e-02  1.98358955e-02\n",
      "    1.15867524e-01 -2.11533939e-01]]] reward= -10398015.97577146 done= False\n",
      "Step 395\n",
      "Action:  [ 1.7303909   0.30828017 -1.497065    1.5253656   4.3389235  -0.61154085]\n",
      "self.next: 395\n",
      "obs= [[[ 2.70726369 -2.20914251 -0.36427484  0.20088236 -0.86005332\n",
      "    0.17554919]\n",
      "  [-0.02625239  0.03394635 -0.01287374 -0.02951381  0.08061088\n",
      "   -0.25444798]]\n",
      "\n",
      " [[ 8.2409262  -3.76349734 -5.32692468  1.88654193  0.80000178\n",
      "   -7.78832912]\n",
      "  [ 0.13404972 -0.07539279 -0.09453484  0.02027382  0.11626103\n",
      "   -0.21205961]]] reward= -9582192.19763839 done= False\n",
      "Step 396\n",
      "Action:  [ 1.7287997  0.3081755 -1.4955263  1.5241777  4.3328047 -0.6103056]\n",
      "self.next: 396\n",
      "obs= [[[ 2.70463846e+00 -2.20574787e+00 -3.65562214e-01  1.97930980e-01\n",
      "   -8.51992227e-01  1.50104389e-01]\n",
      "  [ 5.54153898e-02  1.43082187e-02 -6.64921040e-02 -2.37507668e-03\n",
      "    5.94014990e-02  3.15762220e-02]]\n",
      "\n",
      " [[ 8.25433117e+00 -3.77103662e+00 -5.33637817e+00  1.88856931e+00\n",
      "    8.11627880e-01 -7.80953509e+00]\n",
      "  [ 1.34363047e-01 -7.59161560e-02 -9.48174654e-02  2.07118965e-02\n",
      "    1.16660455e-01 -2.12596627e-01]]] reward= -9191287.019052014 done= False\n",
      "Step 397\n",
      "Action:  [ 1.729046    0.3083878  -1.4959435   1.5249655   4.334939   -0.61060625]\n",
      "self.next: 397\n",
      "obs= [[[ 2.71017999 -2.20431705 -0.37221142  0.19769347 -0.84605208\n",
      "    0.15326201]\n",
      "  [-0.08694267  0.02001889  0.0664204  -0.03307172 -0.02693842\n",
      "    0.05554369]]\n",
      "\n",
      " [[ 8.26776748 -3.77862824 -5.34585992  1.8906405   0.82329393\n",
      "   -7.83079475]\n",
      "  [ 0.13469188 -0.07646105 -0.09509527  0.02115018  0.11706592\n",
      "   -0.21314521]]] reward= -10576624.07483465 done= False\n",
      "Step 398\n",
      "Action:  [ 1.7274145   0.30847278 -1.4944764   1.5242745   4.330584   -0.6095644 ]\n",
      "self.next: 398\n",
      "obs= [[[ 2.70148573e+00 -2.20231516e+00 -3.65569385e-01  1.94386300e-01\n",
      "   -8.48745919e-01  1.58816379e-01]\n",
      "  [ 1.30846748e-02 -1.73435018e-02  4.67585908e-03  3.08362059e-02\n",
      "   -3.12058773e-02  1.48935958e-01]]\n",
      "\n",
      " [[ 8.28123667e+00 -3.78627434e+00 -5.35536944e+00  1.89275552e+00\n",
      "    8.35000517e-01 -7.85210927e+00]\n",
      "  [ 1.35036247e-01 -7.70276169e-02 -9.53682419e-02  2.15887204e-02\n",
      "    1.17477548e-01 -2.13705616e-01]]] reward= -9738177.437441478 done= False\n",
      "Step 399\n",
      "Action:  [ 1.7270799   0.30851996 -1.4942238   1.5242964   4.330428   -0.6094084 ]\n",
      "self.next: 399\n",
      "obs= [[[ 2.70279420e+00 -2.20404951e+00 -3.65101799e-01  1.97469920e-01\n",
      "   -8.51866507e-01  1.73709975e-01]\n",
      "  [ 2.90562891e-02 -1.58301758e-02 -1.41722187e-02  1.69105701e-03\n",
      "    8.04500430e-05  4.63755285e-02]]\n",
      "\n",
      " [[ 8.29474029e+00 -3.79397710e+00 -5.36490627e+00  1.89491439e+00\n",
      "    8.46748272e-01 -7.87347983e+00]\n",
      "  [ 1.35396171e-01 -7.76159975e-02 -9.56363675e-02  2.20275598e-02\n",
      "    1.17895490e-01 -2.14278079e-01]]] reward= -10451512.103716139 done= False\n",
      "Step 400\n",
      "Action:  [ 1.72662    0.3084675 -1.4937654  1.5239702  4.328443  -0.6089947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 400\n",
      "obs= [[[ 2.70569982e+00 -2.20563253e+00 -3.66519021e-01  1.97639026e-01\n",
      "   -8.51858462e-01  1.78347528e-01]\n",
      "  [ 6.42668432e-03  3.13899475e-03 -9.64344346e-03 -8.16614946e-04\n",
      "    2.73462126e-04  6.59222811e-02]]\n",
      "\n",
      " [[ 8.30827991e+00 -3.80173870e+00 -5.37446990e+00  1.89711715e+00\n",
      "    8.58537821e-01 -7.89490764e+00]\n",
      "  [ 1.35771680e-01 -7.82263315e-02 -9.58996327e-02  2.24667278e-02\n",
      "    1.18319888e-01 -2.14862853e-01]]] reward= -9905404.519490864 done= False\n",
      "Step 401\n",
      "Action:  [ 1.7259092   0.3085334  -1.4931523   1.5237226   4.3263884  -0.60854876]\n",
      "self.next: 401\n",
      "obs= [[[ 2.70634249e+00 -2.20531863e+00 -3.67483365e-01  1.97557365e-01\n",
      "   -8.51831116e-01  1.84939756e-01]\n",
      "  [-1.23011045e-02 -2.13035381e-02  3.20128290e-02  3.93806267e-03\n",
      "    5.79333841e-02 -8.71212566e-02]]\n",
      "\n",
      " [[ 8.32185707e+00 -3.80956134e+00 -5.38405987e+00  1.89936382e+00\n",
      "    8.70369810e-01 -7.91639393e+00]\n",
      "  [ 1.36162802e-01 -7.88587569e-02 -9.61580227e-02  2.29062447e-02\n",
      "    1.18750895e-01 -2.15460197e-01]]] reward= -9912751.156703182 done= False\n",
      "Step 402\n",
      "Action:  [ 1.7245082   0.30846334 -1.4918307   1.5227453   4.321745   -0.6074997 ]\n",
      "self.next: 402\n",
      "obs= [[[ 2.70511238e+00 -2.20744899e+00 -3.64282082e-01  1.97951171e-01\n",
      "   -8.46037777e-01  1.76227631e-01]\n",
      "  [ 6.04969526e-03  2.78175114e-03 -6.97826357e-03 -4.27748117e-03\n",
      "    4.81078877e-04  6.72559624e-02]]\n",
      "\n",
      " [[ 8.33547336e+00 -3.81744721e+00 -5.39367567e+00  1.90165444e+00\n",
      "    8.82244899e-01 -7.93793994e+00]\n",
      "  [ 1.36569568e-01 -7.95134127e-02 -9.64115206e-02  2.33461203e-02\n",
      "    1.19188671e-01 -2.16070370e-01]]] reward= -9605038.23067063 done= False\n",
      "Step 403\n",
      "Action:  [ 1.7243931   0.30860367 -1.4918175   1.5231272   4.322092   -0.60753226]\n",
      "self.next: 403\n",
      "obs= [[[ 2.70571735 -2.20717081 -0.36497991  0.19752342 -0.84598967\n",
      "    0.18295323]\n",
      "  [ 0.02969395  0.01828403  0.12927308 -0.2678936   0.03333736\n",
      "    0.08215328]]\n",
      "\n",
      " [[ 8.34913031 -3.82539855 -5.40331682  1.90398906  0.89416377\n",
      "   -7.95954698]\n",
      "  [ 0.13699201 -0.08019044 -0.09666011  0.02378636  0.11963339\n",
      "   -0.21669364]]] reward= -9808462.666203082 done= False\n",
      "Step 404\n",
      "Action:  [ 1.7231616   0.30869913 -1.4907558   1.5229924   4.317741   -0.60635203]\n",
      "self.next: 404\n",
      "obs= [[[ 2.70868675e+00 -2.20534241e+00 -3.52052601e-01  1.70734063e-01\n",
      "   -8.42655933e-01  1.91168554e-01]\n",
      "  [-1.02424965e-03  2.37284093e-03 -2.03635298e-01  2.92621499e-01\n",
      "   -2.82757768e-02  2.60061193e-02]]\n",
      "\n",
      " [[ 8.36282951e+00 -3.83341760e+00 -5.41298283e+00  1.90636769e+00\n",
      "    9.06127105e-01 -7.98121635e+00]\n",
      "  [ 1.37430162e-01 -8.08899769e-02 -9.69037699e-02  2.42269414e-02\n",
      "    1.20085213e-01 -2.17330273e-01]]] reward= -10629790.786964692 done= False\n",
      "Step 405\n",
      "Action:  [ 1.7224114   0.30853102 -1.4899943   1.5216695   4.3169703  -0.6067092 ]\n",
      "self.next: 405\n",
      "obs= [[[ 2.70858432e+00 -2.20510512e+00 -3.72416130e-01  1.99996213e-01\n",
      "   -8.45483511e-01  1.93769166e-01]\n",
      "  [ 5.25537280e-03  1.85435751e-02 -2.45735365e-02  2.14841529e-03\n",
      "   -5.90658693e-02  1.77493239e-02]]\n",
      "\n",
      " [[ 8.37657253e+00 -3.84150659e+00 -5.42267321e+00  1.90879039e+00\n",
      "    9.18135626e-01 -8.00294937e+00]\n",
      "  [ 1.37884064e-01 -8.16121727e-02 -9.71424770e-02  2.46678567e-02\n",
      "    1.20544336e-01 -2.17980547e-01]]] reward= -9703498.93246958 done= False\n",
      "Step 406\n",
      "Action:  [ 1.7224025   0.30863574 -1.4899876   1.5222201   4.316315   -0.6062203 ]\n",
      "self.next: 406\n",
      "obs= [[[ 2.70910986e+00 -2.20325077e+00 -3.74873484e-01  2.00211054e-01\n",
      "   -8.51390098e-01  1.95544099e-01]\n",
      "  [-3.13777758e-02 -7.21871482e-03  2.12117889e-01 -1.73942880e-01\n",
      "    2.00774682e-04 -4.33574514e-02]]\n",
      "\n",
      " [[ 8.39036094e+00 -3.84966781e+00 -5.43238746e+00  1.91125717e+00\n",
      "    9.30190060e-01 -8.02474743e+00]\n",
      "  [ 1.38353757e-01 -8.23571754e-02 -9.73762056e-02  2.51090736e-02\n",
      "    1.21010944e-01 -2.18644735e-01]]] reward= -9341066.463849055 done= False\n",
      "Step 407\n",
      "Action:  [ 1.7202286   0.30868804 -1.4880317   1.5212936   4.3095946  -0.60438323]\n",
      "self.next: 407\n",
      "obs= [[[ 2.70597208 -2.20397264 -0.3536617   0.18281677 -0.85137002\n",
      "    0.19120835]\n",
      "  [ 0.0867373  -0.08654633 -0.1495981   0.30719701  0.07639567\n",
      "   -0.23727963]]\n",
      "\n",
      " [[ 8.40419631 -3.85790353 -5.44212508  1.91376808  0.94229115\n",
      "   -8.0466119 ]\n",
      "  [ 0.13883929 -0.08312514 -0.09760492  0.02555055  0.12148523\n",
      "   -0.21932312]]] reward= -10461248.95546245 done= False\n",
      "Step 408\n",
      "Action:  [ 1.7196486   0.30842826 -1.4873905   1.5198998   4.3083034  -0.6045703 ]\n",
      "self.next: 408\n",
      "obs= [[[ 2.71464581 -2.21262727 -0.36862151  0.21353647 -0.84373045\n",
      "    0.16748039]\n",
      "  [ 0.01959726  0.0279309  -0.02067054 -0.09651878  0.0195609\n",
      "    0.09174158]]\n",
      "\n",
      " [[ 8.41808024 -3.86621604 -5.45188557  1.91632313  0.95443968\n",
      "   -8.06854421]\n",
      "  [ 0.13934071 -0.08391622 -0.0978286   0.02599224  0.12196741\n",
      "   -0.22001598]]] reward= -9137212.843193114 done= False\n",
      "Step 409\n",
      "Action:  [ 1.7204098   0.30884293 -1.4883366   1.5218158   4.310287   -0.604767  ]\n",
      "self.next: 409\n",
      "obs= [[[ 2.71660554 -2.20983418 -0.37068856  0.20388459 -0.84177436\n",
      "    0.17665455]\n",
      "  [-0.0630267   0.01696171  0.01926377  0.06157179 -0.04679831\n",
      "    0.04473716]]\n",
      "\n",
      " [[ 8.43201431 -3.87460766 -5.46166843  1.91892236  0.96663642\n",
      "   -8.09054581]\n",
      "  [ 0.13985807 -0.08473058 -0.09804719  0.02643408  0.12245768\n",
      "   -0.2207236 ]]] reward= -9277227.54230795 done= False\n",
      "Step 410\n",
      "Action:  [ 1.7188845  0.3088272 -1.4869012  1.5207471  4.306683  -0.6039452]\n",
      "self.next: 410\n",
      "obs= [[[ 2.71030287e+00 -2.20813801e+00 -3.68762182e-01  2.10041768e-01\n",
      "   -8.46454194e-01  1.81128265e-01]\n",
      "  [ 1.74969812e-02  8.08578067e-03 -2.44141019e-02 -1.97098805e-03\n",
      "    6.91479369e-04 -2.18936496e-02]]\n",
      "\n",
      " [[ 8.44600012e+00 -3.88308072e+00 -5.47147315e+00  1.92156577e+00\n",
      "    9.78882186e-01 -8.11261817e+00]\n",
      "  [ 1.40391441e-01 -8.55683966e-02 -9.82606453e-02  2.68760031e-02\n",
      "    1.22956268e-01 -2.21446268e-01]]] reward= -9095504.937585268 done= False\n",
      "Step 411\n",
      "Action:  [ 1.7185488   0.30878952 -1.4865797   1.520643    4.3050485  -0.60354865]\n",
      "self.next: 411\n",
      "obs= [[[ 2.71205257 -2.20732943 -0.37120359  0.20984467 -0.84638505\n",
      "    0.1789389 ]\n",
      "  [ 0.03005969 -0.06054468  0.18099134 -0.2071151   0.17182379\n",
      "   -0.13157266]]\n",
      "\n",
      " [[ 8.46003926 -3.89163756 -5.48129921  1.92425337  0.99117781\n",
      "   -8.1347628 ]\n",
      "  [ 0.14094088 -0.08642984 -0.09846892  0.02731792  0.1234634\n",
      "   -0.22218427]]] reward= -8834439.654037995 done= False\n",
      "Step 412\n",
      "Action:  [ 1.7156157   0.30879438 -1.4839771   1.519304    4.295548   -0.6010827 ]\n",
      "self.next: 412\n",
      "obs= [[[ 2.71505853e+00 -2.21338390e+00 -3.53104458e-01  1.89133159e-01\n",
      "   -8.29202667e-01  1.65781634e-01]\n",
      "  [ 2.41036447e-02  8.65658950e-03 -3.31134667e-02  1.83311875e-03\n",
      "    8.04254126e-06  4.24351567e-02]]\n",
      "\n",
      " [[ 8.47413335e+00 -3.90028055e+00 -5.49114610e+00  1.92698516e+00\n",
      "    1.00352415e+00 -8.15698122e+00]\n",
      "  [ 1.41506447e-01 -8.73150832e-02 -9.86719596e-02  2.77597456e-02\n",
      "    1.23979301e-01 -2.22937891e-01]]] reward= -9475951.9237785 done= False\n",
      "Step 413\n",
      "Action:  [ 1.71702     0.30891407 -1.4853054   1.5201656   4.301093   -0.6025884 ]\n",
      "self.next: 413\n",
      "obs= [[[ 2.71746890e+00 -2.21251824e+00 -3.56415804e-01  1.89316471e-01\n",
      "   -8.29201863e-01  1.70025149e-01]\n",
      "  [-5.06953455e-02  5.31207589e-02 -2.29165145e-03 -3.16227152e-02\n",
      "   -8.66720175e-02  1.75094188e-01]]\n",
      "\n",
      " [[ 8.48828399e+00 -3.90901205e+00 -5.50101330e+00  1.92976113e+00\n",
      "    1.01592208e+00 -8.17927501e+00]\n",
      "  [ 1.42088226e-01 -8.82243212e-02 -9.88696941e-02  2.82013681e-02\n",
      "    1.24504222e-01 -2.23707424e-01]]] reward= -8728652.488076821 done= False\n",
      "Step 414\n",
      "Action:  [ 1.7159846   0.30910155 -1.4844366   1.5200856   4.298682   -0.6020275 ]\n",
      "self.next: 414\n",
      "obs= [[[ 2.71239936e+00 -2.20720616e+00 -3.56644970e-01  1.86154199e-01\n",
      "   -8.37869065e-01  1.87534568e-01]\n",
      "  [ 3.13255992e-02  3.56135061e-02 -6.78794319e-02  1.86298316e-03\n",
      "    4.62551936e-02 -3.22563154e-02]]\n",
      "\n",
      " [[ 8.50249282e+00 -3.91783449e+00 -5.51090027e+00  1.93258127e+00\n",
      "    1.02837250e+00 -8.20164576e+00]\n",
      "  [ 1.42686288e-01 -8.91577410e-02 -9.90620526e-02  2.86426713e-02\n",
      "    1.25038408e-01 -2.24493152e-01]]] reward= -8923712.091482313 done= False\n",
      "Step 415\n",
      "Action:  [ 1.7152524  0.3089607 -1.4837093  1.519299   4.295323  -0.6013718]\n",
      "self.next: 415\n",
      "obs= [[[ 2.71553192 -2.20364481 -0.36343291  0.1863405  -0.83324355\n",
      "    0.18430894]\n",
      "  [ 0.01443367  0.02135641 -0.20902339  0.26102088  0.02752742\n",
      "   -0.2058967 ]]\n",
      "\n",
      " [[ 8.51676145 -3.92675026 -5.52080647  1.93544554  1.04087635\n",
      "   -8.22409507]\n",
      "  [ 0.14330071 -0.09011554 -0.09924896  0.02908352  0.12558211\n",
      "   -0.22529536]]] reward= -8269609.637275113 done= False\n",
      "Step 416\n",
      "Action:  [ 1.7135653   0.30879173 -1.4820534   1.517677    4.290367   -0.60062987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 416\n",
      "obs= [[[ 2.71697529e+00 -2.20150917e+00 -3.84335251e-01  2.12442586e-01\n",
      "   -8.30490804e-01  1.63719266e-01]\n",
      "  [ 5.34983435e-03 -6.02848975e-04 -4.11900572e-03  4.40416936e-03\n",
      "   -8.98458001e-03  6.70918898e-02]]\n",
      "\n",
      " [[ 8.53109152e+00 -3.93576181e+00 -5.53073137e+00  1.93835389e+00\n",
      "    1.05343456e+00 -8.24662461e+00]\n",
      "  [ 1.43931577e-01 -9.10979085e-02 -9.94303139e-02  2.95237805e-02\n",
      "    1.26135605e-01 -2.26114342e-01]]] reward= -7338246.13002572 done= False\n",
      "Step 417\n",
      "Action:  [ 1.713217    0.30910796 -1.4819431   1.5187223   4.290465   -0.6000237 ]\n",
      "self.next: 417\n",
      "obs= [[[ 2.71751027e+00 -2.20156946e+00 -3.84747152e-01  2.12883003e-01\n",
      "   -8.31389262e-01  1.70428455e-01]\n",
      "  [-1.66015682e-02  1.55910673e-02  7.12283942e-04 -3.27075193e-02\n",
      "    3.38844540e-02  7.11373500e-03]]\n",
      "\n",
      " [[ 8.54548467e+00 -3.94487160e+00 -5.54067440e+00  1.94130627e+00\n",
      "    1.06604812e+00 -8.26923604e+00]\n",
      "  [ 1.44578967e-01 -9.21050541e-02 -9.96060340e-02  2.99632821e-02\n",
      "    1.26699153e-01 -2.26950370e-01]]] reward= -8135397.379151423 done= False\n",
      "Step 418\n",
      "Action:  [ 1.7120973   0.30913627 -1.4809396   1.5181936   4.286561   -0.5991978 ]\n",
      "self.next: 418\n",
      "obs= [[[ 2.71585012e+00 -2.20001035e+00 -3.84675924e-01  2.09612251e-01\n",
      "   -8.28000816e-01  1.71139829e-01]\n",
      "  [-5.51393652e-03  4.28432145e-03  2.55749642e-02  6.36081669e-02\n",
      "   -8.30167949e-02 -2.20053353e-02]]\n",
      "\n",
      " [[ 8.55994257e+00 -3.95408211e+00 -5.55063501e+00  1.94430260e+00\n",
      "    1.07871803e+00 -8.29193108e+00]\n",
      "  [ 1.45242962e-01 -9.31371759e-02 -9.97760093e-02  3.04018529e-02\n",
      "    1.27273036e-01 -2.27803727e-01]]] reward= -7732189.660757041 done= False\n",
      "Step 419\n",
      "Action:  [ 1.71141     0.30907354 -1.4802139   1.5176618   4.2856064  -0.5988256 ]\n",
      "self.next: 419\n",
      "obs= [[[ 2.71529872e+00 -2.19958192e+00 -3.82118427e-01  2.15973068e-01\n",
      "   -8.36302496e-01  1.68939295e-01]\n",
      "  [ 5.85948432e-03  5.31181243e-02 -7.89587427e-02 -3.93358256e-02\n",
      "    5.85671158e-02 -8.58691577e-03]]\n",
      "\n",
      " [[ 8.57446687e+00 -3.96339583e+00 -5.56061261e+00  1.94734278e+00\n",
      "    1.09144534e+00 -8.31471145e+00]\n",
      "  [ 1.45923643e-01 -9.41944748e-02 -9.99401257e-02  3.08393002e-02\n",
      "    1.27857542e-01 -2.28674687e-01]]] reward= -8242894.988602072 done= False\n",
      "Step 420\n",
      "Action:  [ 1.7108026   0.30921894 -1.479805    1.5177388   4.2823052  -0.5983501 ]\n",
      "self.next: 420\n",
      "obs= [[[ 2.71588467e+00 -2.19427011e+00 -3.90014301e-01  2.12039485e-01\n",
      "   -8.30445784e-01  1.68080604e-01]\n",
      "  [-2.46049426e-02  5.15016289e-03  4.44416850e-02 -5.61465981e-02\n",
      "    1.43142064e-01 -4.42067632e-01]]\n",
      "\n",
      " [[ 8.58905923e+00 -3.97281528e+00 -5.57060662e+00  1.95042671e+00\n",
      "    1.10423109e+00 -8.33757892e+00]\n",
      "  [ 1.46621090e-01 -9.52771497e-02 -1.00098259e-01  3.12754148e-02\n",
      "    1.28452966e-01 -2.29563519e-01]]] reward= -7182090.940290689 done= False\n",
      "Step 421\n",
      "Action:  [ 1.7067425   0.30891082 -1.4758843   1.5146955   4.268797   -0.59533   ]\n",
      "self.next: 421\n",
      "obs= [[[ 2.71342418 -2.19375509 -0.38557013  0.20642483 -0.81613158\n",
      "    0.12387384]\n",
      "  [ 0.08066508 -0.02147059  0.11459521 -0.17270619 -0.05754116\n",
      "    0.32195483]]\n",
      "\n",
      " [[ 8.60372134 -3.98234299 -5.58061644  1.95355425  1.11707639\n",
      "   -8.36053527]\n",
      "  [ 0.14733538 -0.09638539 -0.10025027  0.03170997  0.12905961\n",
      "   -0.23047049]]] reward= -7895315.394010737 done= False\n",
      "Step 422\n",
      "Action:  [ 1.7079285   0.30957985 -1.4774286   1.5175077   4.276702   -0.5962889 ]\n",
      "self.next: 422\n",
      "obs= [[[ 2.72149069e+00 -2.19590215e+00 -3.74110612e-01  1.89154207e-01\n",
      "   -8.21885693e-01  1.56069323e-01]\n",
      "  [ 2.66226547e-02 -6.27942381e-02  9.45730463e-03  9.31061239e-02\n",
      "   -8.21314889e-03 -3.06376298e-02]]\n",
      "\n",
      " [[ 8.61845488e+00 -3.99198153e+00 -5.59064147e+00  1.95672525e+00\n",
      "    1.12998235e+00 -8.38358232e+00]\n",
      "  [ 1.48066570e-01 -9.75193980e-02 -1.00396027e-01  3.21427047e-02\n",
      "    1.29677786e-01 -2.31395843e-01]]] reward= -9062023.907962902 done= False\n",
      "Step 423\n",
      "Action:  [ 1.7073861   0.30919483 -1.4767126   1.5159855   4.2743845  -0.5960827 ]\n",
      "self.next: 423\n",
      "obs= [[[ 2.72415295e+00 -2.20218157e+00 -3.73164882e-01  1.98464819e-01\n",
      "   -8.22707008e-01  1.53005560e-01]\n",
      "  [-7.80414823e-03  5.15234160e-03  1.40624545e-03 -3.05818132e-02\n",
      "    8.79707494e-02 -3.10521117e-02]]\n",
      "\n",
      " [[ 8.63326154e+00 -4.00173347e+00 -5.60068107e+00  1.95993952e+00\n",
      "    1.14295013e+00 -8.40672191e+00]\n",
      "  [ 1.48814735e-01 -9.86793382e-02 -1.00535363e-01  3.25733586e-02\n",
      "    1.30307816e-01 -2.32339837e-01]]] reward= -6882224.700180901 done= False\n",
      "Step 424\n",
      "Action:  [ 1.7065902   0.30935517 -1.4760932   1.5159329   4.270727   -0.5954252 ]\n",
      "self.next: 424\n",
      "obs= [[[ 2.72337254 -2.20166634 -0.37302426  0.19540664 -0.81390993\n",
      "    0.14990035]\n",
      "  [-0.04813954 -0.03184014  0.07973288  0.12592998 -0.23516987\n",
      "    0.13610107]]\n",
      "\n",
      " [[ 8.64814301 -4.0116014  -5.61073461  1.96319686  1.15598091\n",
      "   -8.42995589]\n",
      "  [ 0.14957992 -0.09986538 -0.10066812  0.03300163  0.13095002\n",
      "   -0.2333027 ]]] reward= -6531307.236050718 done= False\n",
      "Step 425\n",
      "Action:  [ 1.7056428   0.30936658 -1.4751202   1.5156415   4.271444   -0.5951137 ]\n",
      "self.next: 425\n",
      "obs= [[[ 2.71855858e+00 -2.20485035e+00 -3.65050969e-01  2.07999636e-01\n",
      "   -8.37426920e-01  1.63510456e-01]\n",
      "  [-7.71652185e-03  2.63188986e-02 -1.58439281e-02 -3.68305243e-02\n",
      "    1.40749273e-01 -3.94598222e-01]]\n",
      "\n",
      " [[ 8.66310100e+00 -4.02158794e+00 -5.62080142e+00  1.96649702e+00\n",
      "    1.16907591e+00 -8.45328616e+00]\n",
      "  [ 1.50362168e-01 -1.01077679e-01 -1.00794106e-01  3.34272020e-02\n",
      "    1.31604747e-01 -2.34284664e-01]]] reward= -7920479.094411586 done= False\n",
      "Step 426\n",
      "Action:  [ 1.7035671   0.30912557 -1.4731089   1.51369     4.2599187  -0.5932066 ]\n",
      "self.next: 426\n",
      "obs= [[[ 2.71778693 -2.20221846 -0.36663536  0.20431658 -0.82335199\n",
      "    0.12405063]\n",
      "  [-0.03162819  0.07837701 -0.05102098  0.06557852 -0.29322832\n",
      "    0.42917792]]\n",
      "\n",
      " [[ 8.67813722 -4.03169571 -5.63088083  1.96983974  1.18223639\n",
      "   -8.47671463]\n",
      "  [ 0.1511615  -0.10231636 -0.10091314  0.03384972  0.13227232\n",
      "   -0.23528593]]] reward= -6805269.312245131 done= False\n",
      "Step 427\n",
      "Action:  [ 1.704439   0.3097823 -1.4742258  1.5159924  4.2686086 -0.5946398]\n",
      "self.next: 427\n",
      "obs= [[[ 2.71462411e+00 -2.19438076e+00 -3.71737460e-01  2.10874436e-01\n",
      "   -8.52674825e-01  1.66968426e-01]\n",
      "  [ 8.61457438e-04  8.15007305e-04 -1.35791383e-03 -2.43516407e-03\n",
      "    4.08810219e-03 -1.02454476e-03]]\n",
      "\n",
      " [[ 8.69325337e+00 -4.04192735e+00 -5.64097215e+00  1.97322471e+00\n",
      "    1.19546362e+00 -8.50024322e+00]\n",
      "  [ 1.51977920e-01 -1.03581539e-01 -1.01025024e-01  3.42688061e-02\n",
      "    1.32953113e-01 -2.36306684e-01]]] reward= -7897494.936145978 done= False\n",
      "Step 428\n",
      "Action:  [ 1.7032988   0.30948585 -1.4730871   1.5147797   4.2621017  -0.5931784 ]\n",
      "self.next: 428\n",
      "obs= [[[ 2.71471026e+00 -2.19429926e+00 -3.71873251e-01  2.10630919e-01\n",
      "   -8.52266015e-01  1.66865971e-01]\n",
      "  [-7.16023317e-03 -5.02232420e-03  3.89024656e-02 -5.95286578e-02\n",
      "    9.12081248e-02 -1.01066846e-01]]\n",
      "\n",
      " [[ 8.70845116e+00 -4.05228550e+00 -5.65107465e+00  1.97665159e+00\n",
      "    1.20875893e+00 -8.52387389e+00]\n",
      "  [ 1.52811417e-01 -1.04873288e-01 -1.01129536e-01  3.46840487e-02\n",
      "    1.33647466e-01 -2.37347109e-01]]] reward= -6098495.4194971975 done= False\n",
      "Step 429\n",
      "Action:  [ 1.7014652   0.30949196 -1.4714421   1.5138423   4.2558928  -0.5917573 ]\n",
      "self.next: 429\n",
      "obs= [[[ 2.71399423e+00 -2.19480149e+00 -3.67983005e-01  2.04678053e-01\n",
      "   -8.43145203e-01  1.56759287e-01]\n",
      "  [ 6.03973035e-03 -3.55570966e-02 -1.47075622e-01  2.95800550e-01\n",
      "   -1.16727682e-01  6.23582307e-02]]\n",
      "\n",
      " [[ 8.72373230e+00 -4.06277283e+00 -5.66118760e+00  1.98012000e+00\n",
      "    1.22212368e+00 -8.54760860e+00]\n",
      "  [ 1.53661948e-01 -1.06191656e-01 -1.01226450e-01  3.50950008e-02\n",
      "    1.34355749e-01 -2.38407350e-01]]] reward= -5799534.441835029 done= False\n",
      "Step 430\n",
      "Action:  [ 1.701524   0.3094376 -1.4714599  1.5136875  4.259159  -0.5925609]\n",
      "self.next: 430\n",
      "obs= [[[ 2.71459821e+00 -2.19835720e+00 -3.82690567e-01  2.34258108e-01\n",
      "   -8.54817971e-01  1.62995110e-01]\n",
      "  [-7.54411206e-04 -4.79438007e-02  4.85729075e-02  1.24336168e-01\n",
      "   -1.76776682e-01  5.42277464e-02]]\n",
      "\n",
      " [[ 8.73909850e+00 -4.07339199e+00 -5.67131025e+00  1.98362950e+00\n",
      "    1.23555925e+00 -8.57144933e+00]\n",
      "  [ 1.54529443e-01 -1.07536648e-01 -1.01315524e-01  3.55011781e-02\n",
      "    1.35078338e-01 -2.39487537e-01]]] reward= -5916195.197059589 done= False\n",
      "Step 431\n",
      "Action:  [ 1.7007748   0.30950326 -1.4707015   1.513739    4.2572093  -0.59157586]\n",
      "self.next: 431\n",
      "obs= [[[ 2.71452277 -2.20315158 -0.37783328  0.24669173 -0.87249564\n",
      "    0.16841788]\n",
      "  [ 0.07479408 -0.07183563 -0.0313094   0.04870379  0.09881229\n",
      "   -0.04004283]]\n",
      "\n",
      " [[ 8.75455144 -4.08414566 -5.6814418   1.98717961  1.24906708\n",
      "   -8.59539809]\n",
      "  [ 0.1554138  -0.10890823 -0.10139651  0.03590206  0.13581561\n",
      "   -0.24058777]]] reward= -6712536.525888733 done= False\n",
      "Step 432\n",
      "Action:  [ 1.699994    0.30954868 -1.4701389   1.5134176   4.2527966  -0.59078425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 432\n",
      "obs= [[[ 2.72200217 -2.21033515 -0.38096422  0.2515621  -0.86261441\n",
      "    0.1644136 ]\n",
      "  [-0.02046457  0.06786956 -0.02254764 -0.09641716  0.01353126\n",
      "    0.09755484]]\n",
      "\n",
      " [[ 8.77009282 -4.09503648 -5.69158145  1.99076982  1.26264865\n",
      "   -8.61945686]\n",
      "  [ 0.15631488 -0.1103063  -0.10146912  0.03629707  0.13656795\n",
      "   -0.24170811]]] reward= -6161685.756449972 done= False\n",
      "Step 433\n",
      "Action:  [ 1.699686    0.30985382 -1.4699576   1.5139517   4.251384   -0.59065944]\n",
      "self.next: 433\n",
      "obs= [[[ 2.71995572e+00 -2.20354819e+00 -3.83218981e-01  2.41920389e-01\n",
      "   -8.61261283e-01  1.74169085e-01]\n",
      "  [-1.40225440e-02 -1.90528369e-03  1.69533158e-02 -1.09561051e-03\n",
      "    1.05415300e-01 -4.38089470e-01]]\n",
      "\n",
      " [[ 8.78572431e+00 -4.10606711e+00 -5.70172836e+00  1.99439953e+00\n",
      "    1.27630544e+00 -8.64362767e+00]\n",
      "  [ 1.57232491e-01 -1.11730720e-01 -1.01533100e-01  3.66856021e-02\n",
      "    1.37335740e-01 -2.42848588e-01]]] reward= -5474168.295318964 done= False\n",
      "Step 434\n",
      "Action:  [ 1.695823    0.30935076 -1.4661026   1.5105133   4.238256   -0.5878299 ]\n",
      "self.next: 434\n",
      "obs= [[[ 2.71855346 -2.20373872 -0.38152365  0.24181083 -0.85071975\n",
      "    0.13036014]\n",
      "  [ 0.03707387 -0.08537581  0.07302035  0.10335605 -0.22960037\n",
      "    0.36649169]]\n",
      "\n",
      " [[ 8.80144756 -4.11724018 -5.71188167  1.99806809  1.29003901\n",
      "   -8.66791253]\n",
      "  [ 0.1581664  -0.11318126 -0.10158813  0.03706699  0.13811938\n",
      "   -0.2440092 ]]] reward= -6400236.608702912 done= False\n",
      "Step 435\n",
      "Action:  [ 1.6965957   0.30993995 -1.467185    1.5129559   4.2476487  -0.5888403 ]\n",
      "self.next: 435\n",
      "obs= [[[ 2.72226085e+00 -2.21227630e+00 -3.74221614e-01  2.52146433e-01\n",
      "   -8.73679791e-01  1.67009308e-01]\n",
      "  [ 6.32081864e-03  7.36142568e-03 -1.18450044e-02 -2.86428727e-03\n",
      "    1.06263102e-01 -2.44056292e-01]]\n",
      "\n",
      " [[ 8.81726420e+00 -4.12855831e+00 -5.72204049e+00  2.00177479e+00\n",
      "    1.30385095e+00 -8.69231345e+00]\n",
      "  [ 1.59116328e-01 -1.14657631e-01 -1.01633919e-01  3.74405130e-02\n",
      "    1.38919275e-01 -2.45189898e-01]]] reward= -6541719.418782876 done= False\n",
      "Step 436\n",
      "Action:  [ 1.6958759   0.30959505 -1.4663149   1.5113047   4.239387   -0.5878717 ]\n",
      "self.next: 436\n",
      "obs= [[[ 2.72289293e+00 -2.21154016e+00 -3.75406114e-01  2.51860004e-01\n",
      "   -8.63053480e-01  1.42603678e-01]\n",
      "  [-4.48915290e-02 -4.70686329e-03  4.83105669e-02  9.24084519e-02\n",
      "   -1.99091177e-01  1.83610042e-01]]\n",
      "\n",
      " [[ 8.83317583e+00 -4.14002407e+00 -5.73220388e+00  2.00551884e+00\n",
      "    1.31774288e+00 -8.71683244e+00]\n",
      "  [ 1.60081912e-01 -1.16159445e-01 -1.01670130e-01  3.78054008e-02\n",
      "    1.39735814e-01 -2.46390574e-01]]] reward= -5574730.184219521 done= False\n",
      "Step 437\n",
      "Action:  [ 1.6956857   0.30991533 -1.4662553   1.5122837   4.243423   -0.5881329 ]\n",
      "self.next: 437\n",
      "obs= [[[ 2.71840378e+00 -2.21201084e+00 -3.70575058e-01  2.61100849e-01\n",
      "   -8.82962598e-01  1.60964683e-01]\n",
      "  [-4.58666026e-04 -2.85006187e-04  2.35282237e-03 -2.03374829e-03\n",
      "   -1.78781637e-03  1.36888686e-03]]\n",
      "\n",
      " [[ 8.84918402e+00 -4.15164002e+00 -5.74237089e+00  2.00929938e+00\n",
      "    1.33171646e+00 -8.74147150e+00]\n",
      "  [ 1.61062735e-01 -1.17686219e-01 -1.01696433e-01  3.81608159e-02\n",
      "    1.40569403e-01 -2.47611077e-01]]] reward= -5943136.278159745 done= False\n",
      "Step 438\n",
      "Action:  [ 1.6948068   0.30986243 -1.4654735   1.5117217   4.2383432  -0.5872094 ]\n",
      "self.next: 438\n",
      "obs= [[[ 2.71835791e+00 -2.21203934e+00 -3.70339775e-01  2.60897474e-01\n",
      "   -8.83141380e-01  1.61101571e-01]\n",
      "  [ 1.90755729e-02  1.76623066e-02 -6.20890498e-02  2.83253646e-02\n",
      "   -1.17149837e-03  4.17509672e-02]]\n",
      "\n",
      " [[ 8.86529030e+00 -4.16340864e+00 -5.75254054e+00  2.01311546e+00\n",
      "    1.34577340e+00 -8.76623261e+00]\n",
      "  [ 1.62058298e-01 -1.19237363e-01 -1.01712473e-01  3.85058581e-02\n",
      "    1.41420439e-01 -2.48851186e-01]]] reward= -5285843.53388509 done= False\n",
      "Step 439\n",
      "Action:  [ 1.6943543   0.30994248 -1.4651155   1.5116489   4.2371564  -0.58701783]\n",
      "self.next: 439\n",
      "obs= [[[ 2.72026547e+00 -2.21027311e+00 -3.76548680e-01  2.63730011e-01\n",
      "   -8.83258530e-01  1.65276668e-01]\n",
      "  [ 9.93925028e-03 -7.15398848e-03 -5.11274631e-03  1.95229624e-03\n",
      "    5.46121949e-02 -3.57432080e-02]]\n",
      "\n",
      " [[ 8.88149613e+00 -4.17533238e+00 -5.76271178e+00  2.01696605e+00\n",
      "    1.35991545e+00 -8.79111773e+00]\n",
      "  [ 1.63068017e-01 -1.20812163e-01 -1.01717889e-01  3.88395580e-02\n",
      "    1.42289321e-01 -2.50110619e-01]]] reward= -5604650.998073152 done= False\n",
      "Step 440\n",
      "Action:  [ 1.6924506  0.3099427 -1.4633951  1.5107049  4.2312775 -0.585552 ]\n",
      "self.next: 440\n",
      "obs= [[[ 2.72125939e+00 -2.21098851e+00 -3.77059955e-01  2.63925241e-01\n",
      "   -8.77797310e-01  1.61702347e-01]\n",
      "  [-5.44020634e-02  1.12956981e-01 -8.48543199e-03 -1.09565639e-01\n",
      "   -1.05724781e-01  2.90029904e-02]]\n",
      "\n",
      " [[ 8.89780293e+00 -4.18741359e+00 -5.77288357e+00  2.02085000e+00\n",
      "    1.37414438e+00 -8.81612879e+00]\n",
      "  [ 1.64091213e-01 -1.22409771e-01 -1.01712303e-01  3.91608726e-02\n",
      "    1.43176438e-01 -2.51389017e-01]]] reward= -5761807.598997242 done= False\n",
      "Step 441\n",
      "Action:  [ 1.692258    0.31008723 -1.4631593   1.5110186   4.2305026  -0.5855077 ]\n",
      "self.next: 441\n",
      "obs= [[[ 2.71581919 -2.19969281 -0.3779085   0.25296868 -0.88836979\n",
      "    0.16460265]\n",
      "  [-0.03067006 -0.04229971  0.04924553  0.09712283 -0.12964477\n",
      "    0.16095134]]\n",
      "\n",
      " [[ 8.91421205 -4.19965457 -5.7830548   2.02476609  1.38846202\n",
      "   -8.84126769]\n",
      "  [ 0.16512711 -0.12402919 -0.10169533  0.03946868  0.14408218\n",
      "   -0.25268594]]] reward= -6279462.317173508 done= False\n",
      "Step 442\n",
      "Action:  [ 1.689696    0.31013098 -1.4609339   1.5099959   4.226501   -0.5838904 ]\n",
      "self.next: 442\n",
      "obs= [[[ 2.71275218e+00 -2.20392278e+00 -3.72983945e-01  2.62680960e-01\n",
      "   -9.01334265e-01  1.80697780e-01]\n",
      "  [-6.00402429e-03 -1.56263204e-02 -2.79364373e-03  6.00057543e-02\n",
      "   -3.45460818e-02  1.42218236e-02]]\n",
      "\n",
      " [[ 8.93072476e+00 -4.21205749e+00 -5.79322433e+00  2.02871296e+00\n",
      "    1.40287024e+00 -8.86653628e+00]\n",
      "  [ 1.66174795e-01 -1.25669249e-01 -1.01666566e-01  3.97617876e-02\n",
      "    1.45006913e-01 -2.54000857e-01]]] reward= -5613579.159417514 done= False\n",
      "Step 443\n",
      "Action:  [ 1.6892263   0.31006613 -1.4604582   1.5095525   4.2233696  -0.5834132 ]\n",
      "self.next: 443\n",
      "obs= [[[ 2.71215178 -2.20548542 -0.37326331  0.26868154 -0.90478887\n",
      "    0.18211996]\n",
      "  [-0.0102541   0.0370964  -0.03147962  0.00976163 -0.06753831\n",
      "    0.10867211]]\n",
      "\n",
      " [[ 8.94734224 -4.22462441 -5.80339099  2.03268914  1.41737093\n",
      "   -8.89193637]\n",
      "  [ 0.16723326 -0.12732861 -0.10162561  0.0400389   0.145951\n",
      "   -0.25533314]]] reward= -5541598.545001182 done= False\n",
      "Step 444\n",
      "Action:  [ 1.6887544  0.3102472 -1.4600928  1.5097684  4.22203   -0.5831494]\n",
      "self.next: 444\n",
      "obs= [[[ 2.71112637e+00 -2.20177578e+00 -3.76411272e-01  2.69657698e-01\n",
      "   -9.11542704e-01  1.92987174e-01]\n",
      "  [ 5.20234362e-02 -1.34014072e-02 -3.74133017e-02 -1.30185948e-03\n",
      "    1.65369343e-01 -1.79633889e-01]]\n",
      "\n",
      " [[ 8.96406556e+00 -4.23735727e+00 -5.81355355e+00  2.03669303e+00\n",
      "    1.43196603e+00 -8.91746968e+00]\n",
      "  [ 1.68301351e-01 -1.29005735e-01 -1.01572040e-01  4.02986517e-02\n",
      "    1.46914799e-01 -2.56682063e-01]]] reward= -5364054.100041524 done= False\n",
      "Step 445\n",
      "Action:  [ 1.6861982  0.3100641 -1.4577484  1.507901   4.2122874 -0.5810894]\n",
      "self.next: 445\n",
      "obs= [[[ 2.71632871 -2.20311592 -0.3801526   0.26952751 -0.89500577\n",
      "    0.17502378]\n",
      "  [-0.01346894 -0.04045304  0.07968325  0.057718   -0.12609605\n",
      "    0.05570181]]\n",
      "\n",
      " [[ 8.9808957  -4.25025785 -5.82371076  2.04072289  1.44665751\n",
      "   -8.94313789]\n",
      "  [ 0.16937776 -0.13069886 -0.10150544  0.04053957  0.14789862\n",
      "   -0.25804677]]] reward= -6726158.812608409 done= False\n",
      "Step 446\n",
      "Action:  [ 1.6856039   0.31018043 -1.4571625   1.5082805   4.214518   -0.5808246 ]\n",
      "self.next: 446\n",
      "obs= [[[ 2.71498182 -2.20716122 -0.37218428  0.27529931 -0.90761538\n",
      "    0.18059397]\n",
      "  [-0.0310398   0.02207628 -0.0402147   0.08852051 -0.09862067\n",
      "   -0.01190303]]\n",
      "\n",
      " [[ 8.99783348 -4.26332773 -5.8338613   2.04477685  1.46144737\n",
      "   -8.96894257]\n",
      "  [ 0.17046101 -0.13240599 -0.10142538  0.0407601   0.14890275\n",
      "   -0.25942628]]] reward= -5492458.888584821 done= False\n",
      "Step 447\n",
      "Action:  [ 1.6855762   0.31018865 -1.4571116   1.5081156   4.2131968  -0.5809719 ]\n",
      "self.next: 447\n",
      "obs= [[[ 2.71187784 -2.20495359 -0.37620575  0.28415136 -0.91747744\n",
      "    0.17940366]\n",
      "  [ 0.06792815 -0.0521394  -0.01607315 -0.04569177  0.20867257\n",
      "   -0.07848299]]\n",
      "\n",
      " [[ 9.01487958 -4.27656833 -5.84400384  2.04885286  1.47633765\n",
      "   -8.99488519]\n",
      "  [ 0.17154949 -0.13412489 -0.10133144  0.04095857  0.14992748\n",
      "   -0.26081948]]] reward= -5030520.834670758 done= False\n",
      "Step 448\n",
      "Action:  [ 1.6825235   0.31030893 -1.4545953   1.5069579   4.2023845  -0.578426  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 448\n",
      "obs= [[[ 2.71867065e+00 -2.21016753e+00 -3.77813062e-01  2.79582186e-01\n",
      "   -8.96610184e-01  1.71555363e-01]\n",
      "  [-3.23178681e-02  1.12127889e-03  3.37415892e-02  8.14549368e-02\n",
      "   -1.87964245e-01  9.66511401e-02]]\n",
      "\n",
      " [[ 9.03203453e+00 -4.28998082e+00 -5.85413698e+00  2.05294871e+00\n",
      "    1.49133040e+00 -9.02096714e+00]\n",
      "  [ 1.72641368e-01 -1.35853029e-01 -1.01223185e-01  4.11332367e-02\n",
      "    1.50973019e-01 -2.62225122e-01]]] reward= -7219749.923531404 done= False\n",
      "Step 449\n",
      "Action:  [ 1.6831841   0.31033608 -1.4549755   1.5075094   4.2081547  -0.5792828 ]\n",
      "self.next: 449\n",
      "obs= [[[ 2.71543887e+00 -2.21005541e+00 -3.74438903e-01  2.87727680e-01\n",
      "   -9.15406609e-01  1.81220477e-01]\n",
      "  [-1.11924689e-02  1.01922875e-02  2.38265860e-02 -6.21776876e-02\n",
      "    4.03985887e-02  6.92198664e-03]]\n",
      "\n",
      " [[ 9.04929866e+00 -4.30356612e+00 -5.86425930e+00  2.05706204e+00\n",
      "    1.50642770e+00 -9.04718965e+00]\n",
      "  [ 1.73734633e-01 -1.37587607e-01 -1.01100208e-01  4.12822354e-02\n",
      "    1.52039562e-01 -2.63641789e-01]]] reward= -5122693.761534147 done= False\n",
      "Step 450\n",
      "Action:  [ 1.6811442  0.3104695 -1.4532871  1.5067704  4.19955   -0.5775497]\n",
      "self.next: 450\n",
      "obs= [[[ 2.71431962e+00 -2.20903618e+00 -3.72056245e-01  2.81509911e-01\n",
      "   -9.11366750e-01  1.81912676e-01]\n",
      "  [ 2.38559514e-02  8.74560570e-03 -3.22627100e-02  9.64760273e-04\n",
      "   -1.65547806e-03  4.48937962e-02]]\n",
      "\n",
      " [[ 9.06667213e+00 -4.31732488e+00 -5.87436932e+00  2.06119026e+00\n",
      "    1.52163165e+00 -9.07355383e+00]\n",
      "  [ 1.74827064e-01 -1.39325501e-01 -1.00962093e-01  4.14036098e-02\n",
      "    1.53127241e-01 -2.65067898e-01]]] reward= -5370341.076234895 done= False\n",
      "Step 451\n",
      "Action:  [ 1.6808329   0.31049445 -1.4530113   1.5066925   4.1994634  -0.5774731 ]\n",
      "self.next: 451\n",
      "obs= [[[ 2.71670522 -2.20816162 -0.37528252  0.28160639 -0.9115323\n",
      "    0.18640206]\n",
      "  [ 0.03466852 -0.05031835  0.01706952  0.03795713  0.01735867\n",
      "    0.01944101]]\n",
      "\n",
      " [[ 9.08415483 -4.33125743 -5.88446553  2.06533062  1.53694438\n",
      "   -9.10006062]\n",
      "  [ 0.17591622 -0.14106326 -0.10080845  0.0414953   0.15423614\n",
      "   -0.26650169]]] reward= -5903287.249972949 done= False\n",
      "Step 452\n",
      "Action:  [ 1.6789557   0.31046826 -1.4513148   1.5058091   4.1948094  -0.57607526]\n",
      "self.next: 452\n",
      "obs= [[[ 2.72017207e+00 -2.21319345e+00 -3.73575563e-01  2.85402100e-01\n",
      "   -9.09796431e-01  1.88346156e-01]\n",
      "  [ 1.83774958e-02  8.70718398e-03 -2.83684890e-02  1.57748477e-03\n",
      "   -6.70145397e-04 -2.04393838e-02]]\n",
      "\n",
      " [[ 9.10174645e+00 -4.34536376e+00 -5.89454637e+00  2.06948015e+00\n",
      "    1.55236799e+00 -9.12671079e+00]\n",
      "  [ 1.76999441e-01 -1.42797096e-01 -1.00638895e-01  4.15551662e-02\n",
      "    1.55366258e-01 -2.67941237e-01]]] reward= -6387302.114269056 done= False\n",
      "Step 453\n",
      "Action:  [ 1.6786517  0.3104958 -1.4509993  1.505678   4.1930227 -0.5759036]\n",
      "self.next: 453\n",
      "obs= [[[ 2.72200982 -2.21232273 -0.37641241  0.28555985 -0.90986345\n",
      "    0.18630222]\n",
      "  [ 0.01811883 -0.05800835  0.03973422  0.03983139  0.01981886\n",
      "    0.03849758]]\n",
      "\n",
      " [[ 9.1194464  -4.35964347 -5.90461026  2.07363567  1.56790462\n",
      "   -9.15350492]\n",
      "  [ 0.17807382 -0.14452284 -0.10045308  0.04158096  0.15651755\n",
      "   -0.26938439]]] reward= -5528029.581747504 done= False\n",
      "Step 454\n",
      "Action:  [ 1.6764172   0.31058934 -1.4490691   1.5049093   4.1879883  -0.5742881 ]\n",
      "self.next: 454\n",
      "obs= [[[ 2.7238217  -2.21812357 -0.37243899  0.28954299 -0.90788156\n",
      "    0.19015198]\n",
      "  [ 0.01652277 -0.01014992 -0.03014383  0.06363336 -0.0388264\n",
      "    0.05670247]]\n",
      "\n",
      " [[ 9.13725378 -4.37409576 -5.91465557  2.07779377  1.58355637\n",
      "   -9.18044336]\n",
      "  [ 0.17913619 -0.14623597 -0.1002507   0.04157035  0.15768985\n",
      "   -0.27082882]]] reward= -6516137.409799514 done= False\n",
      "Step 455\n",
      "Action:  [ 1.6766049   0.31062293 -1.4491999   1.5050516   4.188579   -0.57457954]\n",
      "self.next: 455\n",
      "obs= [[[ 2.72547398 -2.21913856 -0.37545337  0.29590632 -0.9117642\n",
      "    0.19582222]\n",
      "  [-0.02597152  0.09510803 -0.04684317 -0.10414218  0.0744112\n",
      "   -0.17659818]]\n",
      "\n",
      " [[ 9.1551674  -4.38871935 -5.92468064  2.0819508   1.59932536\n",
      "   -9.20752624]\n",
      "  [ 0.18018318 -0.14793157 -0.10003145  0.04152095  0.15888294\n",
      "   -0.27227197]]] reward= -6198438.770173101 done= False\n",
      "Step 456\n",
      "Action:  [ 1.6745875   0.31061435 -1.447303    1.5038195   4.178764   -0.5729721 ]\n",
      "self.next: 456\n",
      "obs= [[[ 2.72287683e+00 -2.20962776e+00 -3.80137690e-01  2.85492105e-01\n",
      "   -9.04323080e-01  1.78162405e-01]\n",
      "  [-1.20439391e-02  8.12466661e-03  3.06701292e-02 -6.37010219e-02\n",
      "    3.82437337e-02  6.60374657e-03]]\n",
      "\n",
      " [[ 9.17318572e+00 -4.40351251e+00 -5.93468379e+00  2.08610290e+00\n",
      "    1.61521365e+00 -9.23475343e+00]\n",
      "  [ 1.81211121e-01 -1.49604314e-01 -9.97951149e-02  4.14302950e-02\n",
      "    1.60096462e-01 -2.73711098e-01]]] reward= -5604737.576067088 done= False\n",
      "Step 457\n",
      "Action:  [ 1.672304    0.31081843 -1.4454075   1.5034559   4.175026   -0.5713623 ]\n",
      "self.next: 457\n",
      "obs= [[[ 2.72167243e+00 -2.20881529e+00 -3.77070677e-01  2.79122003e-01\n",
      "   -9.00498707e-01  1.78822779e-01]\n",
      "  [ 4.65164599e-02 -3.78692634e-02 -7.60740413e-03  3.58791766e-02\n",
      "    1.29639224e-01 -1.64026988e-01]]\n",
      "\n",
      " [[ 9.19130683e+00 -4.41847294e+00 -5.94466330e+00  2.09024592e+00\n",
      "    1.63122330e+00 -9.26212454e+00]\n",
      "  [ 1.82216116e-01 -1.51248509e-01 -9.95415054e-02  4.12958775e-02\n",
      "    1.61329959e-01 -2.75143225e-01]]] reward= -5642198.329490302 done= False\n",
      "Step 458\n",
      "Action:  [ 1.6707146  0.3106468 -1.4439172  1.5020914  4.170025  -0.570253 ]\n",
      "self.next: 458\n",
      "obs= [[[ 2.72632408 -2.21260222 -0.37783142  0.28270992 -0.88753478\n",
      "    0.16242008]\n",
      "  [-0.02733272  0.05109752 -0.02487791 -0.03274253 -0.02579246\n",
      "    0.04679674]]\n",
      "\n",
      " [[ 9.20952844 -4.43359779 -5.95461745  2.09437551  1.64735629\n",
      "   -9.28963887]\n",
      "  [ 0.18319402 -0.15285806 -0.09927051  0.04111516  0.16258285\n",
      "   -0.27656517]]] reward= -6568333.740837341 done= False\n",
      "Step 459\n",
      "Action:  [ 1.6707464   0.31096417 -1.4440289   1.502989    4.1711054  -0.57048005]\n",
      "self.next: 459\n",
      "obs= [[[ 2.72359081e+00 -2.20749246e+00 -3.80319209e-01  2.79435668e-01\n",
      "   -8.90114030e-01  1.67099754e-01]\n",
      "  [ 2.39347646e-02  9.63573109e-03 -3.43553467e-02  1.36268359e-03\n",
      "    1.25206011e-03  4.42752194e-02]]\n",
      "\n",
      " [[ 9.22784784e+00 -4.44888360e+00 -5.96454450e+00  2.09848703e+00\n",
      "    1.66361458e+00 -9.31729538e+00]\n",
      "  [ 1.84140439e-01 -1.54426481e-01 -9.89820722e-02  4.08856001e-02\n",
      "    1.63854411e-01 -2.77973538e-01]]] reward= -6155081.944286455 done= False\n",
      "Step 460\n",
      "Action:  [ 1.6692582   0.310963   -1.442711    1.5023689   4.1673803  -0.56939745]\n",
      "self.next: 460\n",
      "obs= [[[ 2.72598428e+00 -2.20652889e+00 -3.83754743e-01  2.79571936e-01\n",
      "   -8.89988824e-01  1.71527276e-01]\n",
      "  [ 4.29699829e-02 -5.94410158e-02 -9.16053728e-03  1.06188542e-01\n",
      "   -2.91964541e-02  1.58091479e-02]]\n",
      "\n",
      " [[ 9.24626189e+00 -4.46432625e+00 -5.97444271e+00  2.10257559e+00\n",
      "    1.68000002e+00 -9.34509274e+00]\n",
      "  [ 1.85050777e-01 -1.55946943e-01 -9.86762383e-02  4.06046664e-02\n",
      "    1.65143779e-01 -2.79364736e-01]]] reward= -6099855.041626407 done= False\n",
      "Step 461\n",
      "Action:  [ 1.6677271   0.31084436 -1.44126     1.5015115   4.164574   -0.568325  ]\n",
      "self.next: 461\n",
      "obs= [[[ 2.73028128e+00 -2.21247299e+00 -3.84670797e-01  2.90190790e-01\n",
      "   -8.92908469e-01  1.73108191e-01]\n",
      "  [-4.71463631e-03  1.13091205e-02  1.60275021e-02 -6.10532263e-02\n",
      "    4.02888714e-02  7.28292581e-02]]\n",
      "\n",
      " [[ 9.26476696e+00 -4.47992094e+00 -5.98431033e+00  2.10663606e+00\n",
      "    1.69651440e+00 -9.37302921e+00]\n",
      "  [ 1.85920222e-01 -1.57412264e-01 -9.83531291e-02  4.02698745e-02\n",
      "    1.66449930e-01 -2.80734976e-01]]] reward= -6358351.554741213 done= False\n",
      "Step 462\n",
      "Action:  [ 1.6658598   0.31117424 -1.4397305   1.50128     4.1574984  -0.56689674]\n",
      "self.next: 462\n",
      "obs= [[[ 2.72980982e+00 -2.21134208e+00 -3.83068047e-01  2.84085468e-01\n",
      "   -8.88879582e-01  1.80391117e-01]\n",
      "  [ 6.16863656e-03  1.09872982e-02 -1.61840044e-02 -1.68326570e-03\n",
      "    1.08144872e-01 -2.49285719e-01]]\n",
      "\n",
      " [[ 9.28335899e+00 -4.49566217e+00 -5.99414564e+00  2.11066304e+00\n",
      "    1.71315939e+00 -9.40110271e+00]\n",
      "  [ 1.86743788e-01 -1.58814964e-01 -9.80129689e-02  3.98788165e-02\n",
      "    1.67771674e-01 -2.82080297e-01]]] reward= -6241789.48974834 done= False\n",
      "Step 463\n",
      "Action:  [ 1.6637509   0.3108454  -1.4376016   1.4992522   4.1495175  -0.56538826]\n",
      "self.next: 463\n",
      "obs= [[[ 2.73042668 -2.21024335 -0.38468645  0.28391714 -0.8780651\n",
      "    0.15546255]\n",
      "  [-0.03129151  0.04217035 -0.20673071  0.23381911 -0.03982152\n",
      "    0.01488693]]\n",
      "\n",
      " [[ 9.30203337 -4.51154366 -6.00394694  2.11465092  1.72993656\n",
      "   -9.42931074]\n",
      "  [ 0.18751635 -0.1601473  -0.09765609  0.03942919  0.16910765\n",
      "   -0.28339658]]] reward= -6012451.472028339 done= False\n",
      "Step 464\n",
      "Action:  [ 1.6649739   0.31109247 -1.4388883   1.5003047   4.1560354  -0.56707215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 464\n",
      "obs= [[[ 2.72729753e+00 -2.20602632e+00 -4.05359518e-01  3.07299053e-01\n",
      "   -8.82047247e-01  1.56951238e-01]\n",
      "  [ 2.64375650e-02 -6.06434277e-02  2.09878213e-01 -1.75668582e-01\n",
      "    2.37902383e-03 -1.29255213e-03]]\n",
      "\n",
      " [[ 9.32078500e+00 -4.52755839e+00 -6.01371255e+00  2.11859384e+00\n",
      "    1.74684732e+00 -9.45765040e+00]\n",
      "  [ 1.88232666e-01 -1.61401342e-01 -9.72829408e-02  3.89188549e-02\n",
      "    1.70456314e-01 -2.84679597e-01]]] reward= -8682164.61584092 done= False\n",
      "Step 465\n",
      "Action:  [ 1.658697    0.31113416 -1.4331098   1.4984254   4.138098   -0.56127137]\n",
      "self.next: 465\n",
      "obs= [[[ 2.72994129 -2.21209066 -0.3843717   0.28973219 -0.88180934\n",
      "    0.15682198]\n",
      "  [-0.04474154  0.01192431  0.05668927  0.02309651 -0.15017129\n",
      "    0.10404762]]\n",
      "\n",
      " [[ 9.33960827 -4.54369853 -6.02344084  2.12248573  1.76389295\n",
      "   -9.48611836]\n",
      "  [ 0.18888745 -0.16256899 -0.09689409  0.03834584  0.17181594\n",
      "   -0.28592499]]] reward= -6589220.72470709 done= False\n",
      "Step 466\n",
      "Action:  [ 1.6604817   0.31127083 -1.4347161   1.4992741   4.1451964  -0.5632254 ]\n",
      "self.next: 466\n",
      "obs= [[[ 2.72546713e+00 -2.21089823e+00 -3.78702770e-01  2.92041846e-01\n",
      "   -8.96826473e-01  1.67226745e-01]\n",
      "  [ 3.68767599e-03  3.11461066e-03 -7.47898216e-03  2.70911422e-03\n",
      "   -8.58393960e-03  6.98816622e-02]]\n",
      "\n",
      " [[ 9.35849701e+00 -4.55995543e+00 -6.03313025e+00  2.12632031e+00\n",
      "    1.78107455e+00 -9.51471086e+00]\n",
      "  [ 1.89475410e-01 -1.63642110e-01 -9.64902417e-02  3.77084148e-02\n",
      "    1.73184612e-01 -2.87128370e-01]]] reward= -7115399.201300213 done= False\n",
      "Step 467\n",
      "Action:  [ 1.6589588   0.31137535 -1.433481    1.4986789   4.139344   -0.56210214]\n",
      "self.next: 467\n",
      "obs= [[[ 2.7258359  -2.21058677 -0.37945067  0.29231276 -0.89768487\n",
      "    0.17421491]\n",
      "  [ 0.02104279  0.03443817 -0.10092279  0.0419689   0.11769206\n",
      "   -0.18341421]]\n",
      "\n",
      " [[ 9.37744455 -4.57631964 -6.04277928  2.13009115  1.79839301\n",
      "   -9.54342369]\n",
      "  [ 0.1899913  -0.16461257 -0.09607223  0.03700512  0.17456023\n",
      "   -0.28828531]]] reward= -6746741.541205629 done= False\n",
      "Step 468\n",
      "Action:  [ 1.6574078   0.31123123 -1.4320129   1.4971639   4.132051   -0.56110454]\n",
      "self.next: 468\n",
      "obs= [[[ 2.72794018 -2.20714295 -0.38954295  0.29650965 -0.88591566\n",
      "    0.15587349]\n",
      "  [ 0.01005557 -0.0330643   0.04285129  0.02837372 -0.05233714\n",
      "    0.05745275]]\n",
      "\n",
      " [[ 9.39644368 -4.59278089 -6.0523865   2.13379167  1.81584903\n",
      "   -9.57225222]\n",
      "  [ 0.19042998 -0.16547237 -0.09564101  0.03623482  0.17594052\n",
      "   -0.28939143]]] reward= -6709176.913271869 done= False\n",
      "Step 469\n",
      "Action:  [ 1.6553179   0.31139335 -1.4301436   1.4972403   4.130342   -0.55944633]\n",
      "self.next: 469\n",
      "obs= [[[ 2.72894574e+00 -2.21044938e+00 -3.85257818e-01  2.99347019e-01\n",
      "   -8.91149375e-01  1.61618765e-01]\n",
      "  [-2.55708812e-02 -8.71706338e-03  3.56680796e-02 -1.03407699e-03\n",
      "   -3.92870617e-03 -4.30273322e-02]]\n",
      "\n",
      " [[ 9.41548668e+00 -4.60932813e+00 -6.06195060e+00  2.13741515e+00\n",
      "    1.83344308e+00 -9.60119137e+00]\n",
      "  [ 1.90786512e-01 -1.66213703e-01 -9.51977071e-02  3.53967324e-02\n",
      "    1.77323004e-01 -2.90442400e-01]]] reward= -6808294.261491602 done= False\n",
      "Step 470\n",
      "Action:  [ 1.6533245   0.31140655 -1.4283198   1.4962262   4.1232643  -0.5580132 ]\n",
      "self.next: 470\n",
      "obs= [[[ 2.72638865e+00 -2.21132109e+00 -3.81691010e-01  2.99243612e-01\n",
      "   -8.91542245e-01  1.57316032e-01]\n",
      "  [-4.56305236e-03 -5.45858242e-03 -1.29632763e-02  1.50606499e-01\n",
      "   -2.32297483e-01  2.88685139e-01]]\n",
      "\n",
      " [[ 9.43456533e+00 -4.62594950e+00 -6.07147037e+00  2.14095482e+00\n",
      "    1.85117538e+00 -9.63023561e+00]\n",
      "  [ 1.91056210e-01 -1.66829110e-01 -9.47435426e-02  3.44904614e-02\n",
      "    1.78705064e-01 -2.91434037e-01]]] reward= -7350831.479016145 done= False\n",
      "Step 471\n",
      "Action:  [ 1.6535441   0.3116415  -1.428544    1.4970989   4.1289244  -0.55866265]\n",
      "self.next: 471\n",
      "obs= [[[ 2.72593234e+00 -2.21186694e+00 -3.82987338e-01  3.14304261e-01\n",
      "   -9.14771994e-01  1.86184546e-01]\n",
      "  [ 2.67060408e-03  3.89055676e-02 -1.93836368e-02 -6.00183081e-02\n",
      "    9.04737973e-02 -2.30061034e-01]]\n",
      "\n",
      " [[ 9.45367095e+00 -4.64263241e+00 -6.08094473e+00  2.14440387e+00\n",
      "    1.86904589e+00 -9.65937901e+00]\n",
      "  [ 1.91234711e-01 -1.67311554e-01 -9.42798879e-02  3.35160587e-02\n",
      "    1.80083921e-01 -2.92362339e-01]]] reward= -7218635.663175698 done= False\n",
      "Step 472\n",
      "Action:  [ 1.6499655  0.3113674 -1.4251724  1.4944127  4.1108193 -0.5555329]\n",
      "self.next: 472\n",
      "obs= [[[ 2.72619940e+00 -2.20797639e+00 -3.84925702e-01  3.08302431e-01\n",
      "   -9.05724614e-01  1.63178442e-01]\n",
      "  [-2.03095561e-03 -1.62221236e-02 -4.01763329e-03  6.29900435e-02\n",
      "   -4.40493916e-02  8.04866655e-02]]\n",
      "\n",
      " [[ 9.47279442e+00 -4.65936357e+00 -6.09037272e+00  2.14775547e+00\n",
      "    1.88705428e+00 -9.68861524e+00]\n",
      "  [ 1.91318049e-01 -1.67654541e-01 -9.38082243e-02  3.24740363e-02\n",
      "    1.81456649e-01 -2.93223537e-01]]] reward= -7517608.101988162 done= False\n",
      "Step 473\n",
      "Action:  [ 1.6492952   0.31168216 -1.424759    1.4951323   4.113761   -0.55530345]\n",
      "self.next: 473\n",
      "obs= [[[ 2.72599631e+00 -2.20959860e+00 -3.85327465e-01  3.14601435e-01\n",
      "   -9.10129553e-01  1.71227109e-01]\n",
      "  [-3.47782869e-02  5.29473630e-02 -1.55696006e-02 -7.66127821e-04\n",
      "   -1.08238143e-01  3.12417463e-01]]\n",
      "\n",
      " [[ 9.49192623e+00 -4.67612902e+00 -6.09975354e+00  2.15100288e+00\n",
      "    1.90519995e+00 -9.71793760e+00]\n",
      "  [ 1.91302729e-01 -1.67852230e-01 -9.33301496e-02  3.13653926e-02\n",
      "    1.82820223e-01 -2.94014161e-01]]] reward= -7232100.325896054 done= False\n",
      "Step 474\n",
      "Action:  [ 1.647567    0.31218854 -1.4233663   1.4952718   4.109731   -0.5543276 ]\n",
      "self.next: 474\n",
      "obs= [[[ 2.72251848 -2.20430386 -0.38688442  0.31452482 -0.92095337\n",
      "    0.20246886]\n",
      "  [-0.03979795  0.03199692  0.02619968 -0.01241007 -0.01246967\n",
      "   -0.09147274]]\n",
      "\n",
      " [[ 9.5110565  -4.69291424 -6.10908655  2.15413942  1.92348197\n",
      "   -9.74733901]\n",
      "  [ 0.19118578 -0.16789953 -0.09284735  0.03019163  0.18417152\n",
      "   -0.29473108]]] reward= -7313272.443019767 done= False\n",
      "Step 475\n",
      "Action:  [ 1.6444914   0.31169283 -1.4202701   1.492879    4.0980964  -0.55173296]\n",
      "self.next: 475\n",
      "obs= [[[ 2.71853868 -2.20110417 -0.38426446  0.31328382 -0.92220033\n",
      "    0.19332158]\n",
      "  [ 0.02137509 -0.07242481  0.0282629   0.10675646 -0.02558486\n",
      "   -0.03823043]]\n",
      "\n",
      " [[ 9.53017508 -4.7097042  -6.11837129  2.15715858  1.94189912\n",
      "   -9.77681212]\n",
      "  [ 0.19096483 -0.1677922  -0.0923616   0.02895477  0.18550734\n",
      "   -0.29537157]]] reward= -7723786.821322083 done= False\n",
      "Step 476\n",
      "Action:  [ 1.6425388   0.3116334  -1.4185389   1.4922098   4.0952854  -0.55033064]\n",
      "self.next: 476\n",
      "obs= [[[ 2.72067619 -2.20834665 -0.38143817  0.32395946 -0.92475882\n",
      "    0.18949854]\n",
      "  [ 0.03268558  0.05013097 -0.06052079  0.02305172 -0.15508349\n",
      "    0.16904729]]\n",
      "\n",
      " [[ 9.54927156 -4.72648342 -6.12760745  2.16005406  1.96044986\n",
      "   -9.80634928]\n",
      "  [ 0.19063812 -0.16752691 -0.09187473  0.02765733  0.18682447\n",
      "   -0.29593331]]] reward= -7443977.107928033 done= False\n",
      "Step 477\n",
      "Action:  [ 1.6439186   0.3119829  -1.4198079   1.4935634   4.099496   -0.55157584]\n",
      "self.next: 477\n",
      "obs= [[[ 2.72394475 -2.20333356 -0.38749025  0.32626463 -0.94026717\n",
      "    0.20640327]\n",
      "  [-0.06125743  0.01118682  0.07512339  0.01646819 -0.1517274\n",
      "    0.2008652 ]]\n",
      "\n",
      " [[ 9.56833538 -4.74323611 -6.13679492  2.16281979  1.9791323\n",
      "   -9.83594261]\n",
      "  [ 0.19020459 -0.16710132 -0.09138861  0.02630234  0.18811967\n",
      "   -0.29641448]]] reward= -7749737.166007431 done= False\n",
      "Step 478\n",
      "Action:  [ 1.6390674   0.31218034 -1.4154687   1.4918839   4.0869875  -0.54800004]\n",
      "self.next: 478\n",
      "obs= [[[ 2.71781901 -2.20221487 -0.37997791  0.32791145 -0.95543991\n",
      "    0.22648979]\n",
      "  [-0.0260595  -0.0117836   0.01479744  0.06854462 -0.10319695\n",
      "    0.18919427]]\n",
      "\n",
      " [[ 9.58735583 -4.75994624 -6.14593378  2.16545003  1.99794427\n",
      "   -9.86558406]\n",
      "  [ 0.18966382 -0.16651414 -0.09090513  0.02489331  0.18938975\n",
      "   -0.29681374]]] reward= -7838238.001942158 done= False\n",
      "Step 479\n",
      "Action:  [ 1.6374824   0.31220818 -1.4140888   1.4912479   4.082483   -0.5469383 ]\n",
      "self.next: 479\n",
      "obs= [[[ 2.71521306 -2.20339323 -0.37849816  0.33476591 -0.9657596\n",
      "    0.24540921]\n",
      "  [ 0.02842412 -0.02899267 -0.02591156  0.11429089  0.02151652\n",
      "   -0.12166221]]\n",
      "\n",
      " [[ 9.60632222 -4.77659765 -6.15502429  2.16793936  2.01688324\n",
      "   -9.89526543]\n",
      "  [ 0.18901615 -0.16576512 -0.09042617  0.02343417  0.19063155\n",
      "   -0.29713026]]] reward= -7425305.391798492 done= False\n",
      "Step 480\n",
      "Action:  [ 1.635737   0.3118406 -1.4123232  1.4894902  4.074955  -0.545505 ]\n",
      "self.next: 480\n",
      "obs= [[[ 2.71805547 -2.2062925  -0.38108932  0.346195   -0.96360795\n",
      "    0.23324299]\n",
      "  [-0.03987369  0.04638606 -0.15505849  0.23491362 -0.19879575\n",
      "    0.14273831]]\n",
      "\n",
      " [[ 9.62522383 -4.79317417 -6.16406691  2.17028277  2.0359464\n",
      "   -9.92497846]\n",
      "  [ 0.18826257 -0.16485507 -0.08995361  0.02192928  0.19184201\n",
      "   -0.29736374]]] reward= -7983165.904805944 done= False\n",
      "Step 481\n",
      "Action:  [ 1.6368589   0.3121324  -1.413382    1.490747    4.0814123  -0.54702383]\n",
      "self.next: 481\n",
      "obs= [[[ 2.7140681  -2.2016539  -0.39659517  0.36968637 -0.98348753\n",
      "    0.24751682]\n",
      "  [ 0.02250028 -0.05233461  0.20430256 -0.21614692  0.10081641\n",
      "   -0.01955646]]\n",
      "\n",
      " [[ 9.64405009 -4.80965967 -6.17306227  2.1724757   2.0551306\n",
      "   -9.95471483]\n",
      "  [ 0.18740476 -0.16378585 -0.08948925  0.02038335  0.1930182\n",
      "   -0.29751438]]] reward= -7977816.423663519 done= False\n",
      "Step 482\n",
      "Action:  [ 1.6260555   0.3122625  -1.4036847   1.4865507   4.0461698  -0.53783655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 482\n",
      "obs= [[[ 2.71631813e+00 -2.20688736e+00 -3.76164912e-01  3.48071673e-01\n",
      "   -9.73405887e-01  2.45561178e-01]\n",
      "  [-2.82662717e-02  7.99622027e-02 -4.65899454e-02 -2.87193582e-03\n",
      "   -5.90122412e-02  1.07489674e-02]]\n",
      "\n",
      " [[ 9.66279056e+00 -4.82603826e+00 -6.18201120e+00  2.17451404e+00\n",
      "    2.07443242e+00 -9.98446627e+00]\n",
      "  [ 1.86445043e-01 -1.62560334e-01 -8.90348377e-02  1.88013814e-02\n",
      "    1.94157311e-01 -2.97582891e-01]]] reward= -8440678.14127664 done= False\n",
      "Step 483\n",
      "Action:  [ 1.6307055   0.31238094 -1.4078431   1.4884099   4.0604935  -0.542058  ]\n",
      "self.next: 483\n",
      "obs= [[[ 2.71349150e+00 -2.19889114e+00 -3.80823907e-01  3.47784480e-01\n",
      "   -9.79307111e-01  2.46636075e-01]\n",
      "  [-4.81685654e-03 -4.97674735e-02  4.98261505e-02  8.93805858e-02\n",
      "   -8.44993161e-02  5.09659755e-03]]\n",
      "\n",
      " [[ 9.68143507e+00 -4.84229429e+00 -6.19091468e+00  2.17639417e+00\n",
      "    2.09384815e+00 -1.00142246e+01]\n",
      "  [ 1.85386353e-01 -1.61182347e-01 -8.85920343e-02  1.71886360e-02\n",
      "    1.95256719e-01 -2.97570471e-01]]] reward= -7610017.592546774 done= False\n",
      "Step 484\n",
      "Action:  [ 1.6263787  0.3122038 -1.4038556  1.486706   4.051489  -0.5387255]\n",
      "self.next: 484\n",
      "obs= [[[  2.71300981  -2.20386788  -0.37584129   0.35672254  -0.98775704\n",
      "     0.24714573]\n",
      "  [  0.01819215   0.07967563  -0.09274769  -0.0882803    0.13044931\n",
      "    -0.02752015]]\n",
      "\n",
      " [[  9.6999737   -4.85841253  -6.19977389   2.17811304   2.11337382\n",
      "   -10.04398161]\n",
      "  [  0.18423215  -0.15965659  -0.08816239   0.01555054   0.19631398\n",
      "    -0.29747876]]] reward= -7654197.868174581 done= False\n",
      "Step 485\n",
      "Action:  [ 1.6249774   0.31272814 -1.4029245   1.4862401   4.041266   -0.53794235]\n",
      "self.next: 485\n",
      "obs= [[[  2.71482903  -2.19590032  -0.38511606   0.34789451  -0.97471211\n",
      "     0.24439372]\n",
      "  [ -0.01485083  -0.04848952   0.04028621   0.06845988  -0.09356627\n",
      "     0.09436892]]\n",
      "\n",
      " [[  9.71839692  -4.87437819  -6.20859012   2.17966809   2.13300522\n",
      "   -10.07372948]\n",
      "  [  0.18298637  -0.15798856  -0.08774734   0.01389264   0.19732685\n",
      "    -0.2973098 ]]] reward= -7563432.228594398 done= False\n",
      "Step 486\n",
      "Action:  [ 1.6215663   0.31253326 -1.3996402   1.48533     4.0386267  -0.5354111 ]\n",
      "self.next: 486\n",
      "obs= [[[  2.71334395  -2.20074927  -0.38108744   0.3547405   -0.98406874\n",
      "     0.25383061]\n",
      "  [  0.07259265  -0.01700431   0.1137689   -0.16768624   0.04817021\n",
      "    -0.05662427]]\n",
      "\n",
      " [[  9.73669556  -4.89017704  -6.21736486   2.18105735   2.15273791\n",
      "   -10.10346046]\n",
      "  [  0.18165338  -0.15618444  -0.08734818   0.01222052   0.1982933\n",
      "    -0.29706603]]] reward= -7316046.805129337 done= False\n",
      "Step 487\n",
      "Action:  [ 1.6176622  0.312503  -1.3960316  1.4834812  4.0233736 -0.5319973]\n",
      "self.next: 487\n",
      "obs= [[[ 2.72060321e+00 -2.20244970e+00 -3.69710550e-01  3.37971872e-01\n",
      "   -9.79251719e-01  2.48168185e-01]\n",
      "  [ 5.73933996e-03 -2.61499721e-02 -1.30707008e-01  2.32330884e-01\n",
      "   -2.09773979e-02 -5.67087936e-02]]\n",
      "\n",
      " [[ 9.75486089e+00 -4.90579549e+00 -6.22609968e+00  2.18227941e+00\n",
      "    2.17256724e+00 -1.01331671e+01]\n",
      "  [ 1.80237860e-01 -1.54251007e-01 -8.69660882e-02  1.05397863e-02\n",
      "    1.99211549e-01 -2.96750188e-01]]] reward= -9126236.718961887 done= False\n",
      "Step 488\n",
      "Action:  [ 1.6200988   0.31247166 -1.3983512   1.4841318   4.033323   -0.53483766]\n",
      "self.next: 488\n",
      "obs= [[[ 2.72117714e+00 -2.20506470e+00 -3.82781251e-01  3.61204960e-01\n",
      "   -9.81349458e-01  2.42497306e-01]\n",
      "  [-3.01201645e-02  3.75493746e-02 -3.11914809e-02  2.23611033e-02\n",
      "   -5.74427781e-02  1.27090754e-01]]\n",
      "\n",
      " [[ 9.77288468e+00 -4.92122059e+00 -6.23479629e+00  2.18333339e+00\n",
      "    2.19248839e+00 -1.01628421e+01]\n",
      "  [ 1.78744759e-01 -1.52195520e-01 -8.66020792e-02  8.85594098e-03\n",
      "    2.00080022e-01 -2.96365293e-01]]] reward= -8419841.924200494 done= False\n",
      "Step 489\n",
      "Action:  [ 1.6166302   0.31304225 -1.3953313   1.4838004   4.0232377  -0.5321234 ]\n",
      "self.next: 489\n",
      "obs= [[[ 2.71816513e+00 -2.20130976e+00 -3.85900399e-01  3.63441071e-01\n",
      "   -9.87093736e-01  2.55206381e-01]\n",
      "  [-8.96141094e-03 -2.59257987e-02  5.91312806e-02  5.99930360e-02\n",
      "   -2.31508220e-02 -1.22972898e-01]]\n",
      "\n",
      " [[ 9.79075916e+00 -4.93644014e+00 -6.24345649e+00  2.18421898e+00\n",
      "    2.21249639e+00 -1.01924786e+01]\n",
      "  [ 1.77179198e-01 -1.50025589e-01 -8.62570269e-02  7.17438438e-03\n",
      "    2.00897373e-01 -2.95914576e-01]]] reward= -6993509.827872767 done= False\n",
      "Step 490\n",
      "Action:  [ 1.6119897   0.31259844 -1.3908569   1.4811705   4.010103   -0.52839637]\n",
      "self.next: 490\n",
      "obs= [[[ 2.71726899e+00 -2.20390234e+00 -3.79987271e-01  3.69440374e-01\n",
      "   -9.89408818e-01  2.42909091e-01]\n",
      "  [-3.48906190e-04 -3.74996623e-04  3.38985665e-07  2.91459081e-03\n",
      "   -3.94576915e-04 -1.12584678e-03]]\n",
      "\n",
      " [[ 9.80847708e+00 -4.95144270e+00 -6.25208220e+00  2.18493642e+00\n",
      "    2.23258613e+00 -1.02220701e+01]\n",
      "  [ 1.75546414e-01 -1.47749082e-01 -8.59316588e-02  5.50034308e-03\n",
      "    2.01662485e-01 -2.95401443e-01]]] reward= -7818289.291917627 done= False\n",
      "Step 491\n",
      "Action:  [ 1.6104705   0.31298164 -1.3896878   1.4812014   4.0052466  -0.5274638 ]\n",
      "self.next: 491\n",
      "obs= [[[ 2.71723410e+00 -2.20393984e+00 -3.79987237e-01  3.69731833e-01\n",
      "   -9.89448276e-01  2.42796506e-01]\n",
      "  [-4.15912536e-02  5.03588426e-03  1.07194953e-02  7.73990440e-02\n",
      "   -1.16010324e-01  7.09390378e-02]]\n",
      "\n",
      " [[ 9.82603172e+00 -4.96621761e+00 -6.26067536e+00  2.18548645e+00\n",
      "    2.25275238e+00 -1.02516102e+01]\n",
      "  [ 1.73851683e-01 -1.45374019e-01 -8.56265634e-02  3.83883669e-03\n",
      "    2.02374467e-01 -2.94829424e-01]]] reward= -7206381.266465698 done= False\n",
      "Step 492\n",
      "Action:  [ 1.6086459  0.3130647 -1.387965   1.4808466  4.0029125 -0.5263123]\n",
      "self.next: 492\n",
      "obs= [[[ 2.71307497e+00 -2.20343625e+00 -3.78915288e-01  3.77471738e-01\n",
      "   -1.00104931e+00  2.49890410e-01]\n",
      "  [ 2.52505400e-02 -4.71945518e-02  9.56595929e-04  6.50870270e-02\n",
      "    1.73967459e-02 -5.57923718e-02]]\n",
      "\n",
      " [[ 9.84341688e+00 -4.98075501e+00 -6.26923802e+00  2.18587034e+00\n",
      "    2.27298983e+00 -1.02810932e+01]\n",
      "  [ 1.72100256e-01 -1.42908466e-01 -8.53421890e-02  2.19464021e-03\n",
      "    2.03032634e-01 -2.94202119e-01]]] reward= -6857181.921613592 done= False\n",
      "Step 493\n",
      "Action:  [ 1.6049528   0.31298304 -1.3846642   1.4790187   3.990718   -0.523458  ]\n",
      "self.next: 493\n",
      "obs= [[[ 2.71560002e+00 -2.20815571e+00 -3.78819628e-01  3.83980440e-01\n",
      "   -9.99309634e-01  2.44311173e-01]\n",
      "  [-1.18660106e-02 -1.25162245e-02  2.22559603e-01 -2.82261842e-01\n",
      "    2.59211342e-02  1.17347500e-01]]\n",
      "\n",
      " [[ 9.86062691e+00 -4.99504585e+00 -6.27777224e+00  2.18608980e+00\n",
      "    2.29329309e+00 -1.03105134e+01]\n",
      "  [ 1.70297298e-01 -1.40360448e-01 -8.50788527e-02  5.72260560e-04\n",
      "    2.03636497e-01 -2.93523162e-01]]] reward= -7632321.67876918 done= False\n",
      "Step 494\n",
      "Action:  [ 1.5969741   0.31357887 -1.3775727   1.4768801   3.9668179  -0.5171829 ]\n",
      "self.next: 494\n",
      "obs= [[[ 2.71441342e+00 -2.20940733e+00 -3.56563668e-01  3.55754256e-01\n",
      "   -9.96717520e-01  2.56045923e-01]\n",
      "  [ 5.06076471e-02  2.58177576e-02 -7.58965591e-02 -4.65033943e-02\n",
      "    1.02434000e-01 -1.28096555e-01]]\n",
      "\n",
      " [[ 9.87765664e+00 -5.00908190e+00 -6.28628012e+00  2.18614703e+00\n",
      "    2.31365674e+00 -1.03398657e+01]\n",
      "  [ 1.68447842e-01 -1.37737865e-01 -8.48367491e-02 -1.02408487e-03\n",
      "    2.04185753e-01 -2.92796177e-01]]] reward= -7780575.037582011 done= False\n",
      "Step 495\n",
      "Action:  [ 1.6004565   0.31326956 -1.3807188   1.4772373   3.974515   -0.5203868 ]\n",
      "self.next: 495\n",
      "obs= [[[ 2.71947419e+00 -2.20682556e+00 -3.64153324e-01  3.51103917e-01\n",
      "   -9.86474120e-01  2.43236268e-01]\n",
      "  [-3.53954700e-02 -1.15965110e-02  2.05914702e-02  7.41020343e-02\n",
      "   -1.04535224e-01  1.12525839e-01]]\n",
      "\n",
      " [[ 9.89450142e+00 -5.02285569e+00 -6.29476380e+00  2.18604462e+00\n",
      "    2.33407531e+00 -1.03691453e+01]\n",
      "  [ 1.66556760e-01 -1.35048440e-01 -8.46159687e-02 -2.59048361e-03\n",
      "    2.04680291e-01 -2.92024763e-01]]] reward= -7357962.651771475 done= False\n",
      "Step 496\n",
      "Action:  [ 1.5979452   0.31351376 -1.3784443   1.4772983   3.9742224  -0.5187175 ]\n",
      "self.next: 496\n",
      "obs= [[[ 2.71593464e+00 -2.20798521e+00 -3.62094177e-01  3.58514120e-01\n",
      "   -9.96927643e-01  2.54488851e-01]\n",
      "  [ 1.71522859e-02  1.06402820e-02 -2.74572318e-02 -1.51542637e-03\n",
      "    1.14159303e-01 -1.82662416e-01]]\n",
      "\n",
      " [[ 9.91115710e+00 -5.03636053e+00 -6.30322539e+00  2.18578557e+00\n",
      "    2.35454334e+00 -1.03983478e+01]\n",
      "  [ 1.64628700e-01 -1.32299628e-01 -8.44164917e-02 -4.12333426e-03\n",
      "    2.05120143e-01 -2.91212439e-01]]] reward= -6769522.147767035 done= False\n",
      "Step 497\n",
      "Action:  [ 1.5936098   0.31341672 -1.3745432   1.4745328   3.956073   -0.5155191 ]\n",
      "self.next: 497\n",
      "obs= [[[ 2.71764987e+00 -2.20692118e+00 -3.64839900e-01  3.58362578e-01\n",
      "   -9.85511713e-01  2.36222610e-01]\n",
      "  [ 6.28465947e-02  1.22174359e-02 -4.85667575e-02 -2.43028390e-02\n",
      "   -2.20542400e-03  1.58075987e-02]]\n",
      "\n",
      " [[ 9.92761997e+00 -5.04959049e+00 -6.31166704e+00  2.18537324e+00\n",
      "    2.37505536e+00 -1.04274690e+01]\n",
      "  [ 1.62668076e-01 -1.29498590e-01 -8.42382085e-02 -5.61934659e-03\n",
      "    2.05505481e-01 -2.90362629e-01]]] reward= -7648801.435575016 done= False\n",
      "Step 498\n",
      "Action:  [ 1.5934454   0.3136563  -1.3744305   1.4754422   3.9583366  -0.51538134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 498\n",
      "obs= [[[ 2.72393453e+00 -2.20569944e+00 -3.69696575e-01  3.55932294e-01\n",
      "   -9.85732255e-01  2.37803370e-01]\n",
      "  [ 4.21951947e-02  1.85076478e-02 -2.30166917e-01  2.19319086e-01\n",
      "    1.25742747e-01 -1.92655571e-01]]\n",
      "\n",
      " [[ 9.94388678e+00 -5.06254035e+00 -6.32009086e+00  2.18481130e+00\n",
      "    2.39560591e+00 -1.04565053e+01]\n",
      "  [ 1.60679047e-01 -1.26652150e-01 -8.40809347e-02 -7.07554439e-03\n",
      "    2.05836624e-01 -2.89478656e-01]]] reward= -7390120.10783038 done= False\n",
      "Step 499\n",
      "Action:  [ 1.5921997   0.31359568 -1.373461    1.473888    3.952905   -0.5152944 ]\n",
      "self.next: 499\n",
      "obs= [[[ 2.72815405e+00 -2.20384867e+00 -3.92713267e-01  3.77864202e-01\n",
      "   -9.73157980e-01  2.18537813e-01]\n",
      "  [-2.97673456e-02  2.33675615e-02  1.48495605e-01 -1.07388744e-01\n",
      "   -9.04366278e-02 -2.45486798e-02]]\n",
      "\n",
      " [[ 9.95995468e+00 -5.07520557e+00 -6.32849896e+00  2.18410375e+00\n",
      "    2.41618957e+00 -1.04854532e+01]\n",
      "  [ 1.58665498e-01 -1.23766763e-01 -8.39444125e-02 -8.48925615e-03\n",
      "    2.06113996e-01 -2.88563711e-01]]] reward= -9412602.571945602 done= False\n",
      "Step 500\n",
      "Action:  [ 1.5844296  0.3137723 -1.3660772  1.472184   3.9345193 -0.5085529]\n",
      "self.next: 500\n",
      "obs= [[[ 2.72517731e+00 -2.20151191e+00 -3.77863707e-01  3.67125328e-01\n",
      "   -9.82201643e-01  2.16082945e-01]\n",
      "  [ 2.30071708e-02  9.34068260e-03 -1.96448481e-01  2.11815632e-01\n",
      "    9.54638429e-03 -3.91196726e-03]]\n",
      "\n",
      " [[ 9.97582123e+00 -5.08758224e+00 -6.33689340e+00  2.18325482e+00\n",
      "    2.43680097e+00 -1.05143095e+01]\n",
      "  [ 1.56631029e-01 -1.20848492e-01 -8.38283239e-02 -9.85810593e-03\n",
      "    2.06338119e-01 -2.87620840e-01]]] reward= -7469561.065149099 done= False\n",
      "Step 501\n",
      "Action:  [ 1.5874417  0.3139631 -1.3692181  1.4731916  3.943036  -0.5118513]\n",
      "self.next: 501\n",
      "obs= [[[ 2.72747803e+00 -2.20057785e+00 -3.97508555e-01  3.88306891e-01\n",
      "   -9.81247005e-01  2.15691748e-01]\n",
      "  [ 5.38554064e-02 -5.74402834e-02  2.76439155e-02  2.57171796e-02\n",
      "    1.18194020e-02 -5.33679725e-03]]\n",
      "\n",
      " [[ 9.99148434e+00 -5.09966709e+00 -6.34527623e+00  2.18226901e+00\n",
      "    2.45743478e+00 -1.05430716e+01]\n",
      "  [ 1.54578970e-01 -1.17903012e-01 -8.37323114e-02 -1.11800035e-02\n",
      "    2.06509624e-01 -2.86652962e-01]]] reward= -8726067.277218096 done= False\n",
      "Step 502\n",
      "Action:  [ 1.5800414   0.31397405 -1.3623816   1.4706596   3.922879   -0.5056662 ]\n",
      "self.next: 502\n",
      "obs= [[[ 2.73286357e+00 -2.20632187e+00 -3.94744163e-01  3.90878609e-01\n",
      "   -9.80065064e-01  2.15158068e-01]\n",
      "  [-5.11566526e-02  5.32672543e-02 -3.47516511e-03 -4.45515810e-02\n",
      "    9.35376110e-02 -3.69719408e-01]]\n",
      "\n",
      " [[ 1.00069422e+01 -5.11145739e+00 -6.35364946e+00  2.18115101e+00\n",
      "    2.47808574e+00 -1.05717369e+01]\n",
      "  [ 1.52512350e-01 -1.14935579e-01 -8.36559666e-02 -1.24531276e-02\n",
      "    2.06629196e-01 -2.85662827e-01]]] reward= -7585672.515676582 done= False\n",
      "Step 503\n",
      "Action:  [ 1.5739332   0.31383836 -1.3566941   1.4669462   3.8994603  -0.5016613 ]\n",
      "self.next: 503\n",
      "obs= [[[ 2.72774791e+00 -2.20099515e+00 -3.95091680e-01  3.86423451e-01\n",
      "   -9.70711303e-01  1.78186127e-01]\n",
      "  [-3.55809346e-02  4.99226911e-02 -2.52413287e-02  2.40180742e-03\n",
      "   -2.19759056e-01  5.84798386e-01]]\n",
      "\n",
      " [[ 1.00221935e+01 -5.12295095e+00 -6.36201506e+00  2.17990570e+00\n",
      "    2.49874866e+00 -1.06003032e+01]\n",
      "  [ 1.50433930e-01 -1.11951053e-01 -8.35988568e-02 -1.36759130e-02\n",
      "    2.06697596e-01 -2.84653044e-01]]] reward= -6521605.596027267 done= False\n",
      "Step 504\n",
      "Action:  [ 1.5758146   0.31550938 -1.3589627   1.471014    3.9162598  -0.5037619 ]\n",
      "self.next: 504\n",
      "obs= [[[ 2.72418981e+00 -2.19600288e+00 -3.97615813e-01  3.86663632e-01\n",
      "   -9.92687209e-01  2.36665966e-01]\n",
      "  [ 6.50043858e-03  4.89225456e-03 -1.10149750e-02 -2.28963175e-03\n",
      "    1.13234968e-01 -3.17267609e-01]]\n",
      "\n",
      " [[ 1.00372369e+01 -5.13414606e+00 -6.37037494e+00  2.17853811e+00\n",
      "    2.51941842e+00 -1.06287685e+01]\n",
      "  [ 1.48346209e-01 -1.08953899e-01 -8.35605336e-02 -1.48470369e-02\n",
      "    2.06715657e-01 -2.83626080e-01]]] reward= -7480116.098351702 done= False\n",
      "Step 505\n",
      "Action:  [ 1.5674251   0.31408724 -1.3509083   1.464886    3.8828416  -0.4969313 ]\n",
      "self.next: 505\n",
      "obs= [[[ 2.72483986e+00 -2.19551365e+00 -3.98717310e-01  3.86434669e-01\n",
      "   -9.81363712e-01  2.04939205e-01]\n",
      "  [ 3.42766001e-02  1.21775236e-02 -4.59747085e-02  7.27087366e-05\n",
      "   -1.15297268e-01  3.53290719e-01]]\n",
      "\n",
      " [[ 1.00520715e+01 -5.14504145e+00 -6.37873100e+00  2.17705340e+00\n",
      "    2.54008999e+00 -1.06571311e+01]\n",
      "  [ 1.46251407e-01 -1.05948183e-01 -8.35405174e-02 -1.59653949e-02\n",
      "    2.06684229e-01 -2.82584234e-01]]] reward= -6684664.9579809755 done= False\n",
      "Step 506\n",
      "Action:  [ 1.5700893   0.31523812 -1.3537139   1.4685644   3.8981004  -0.4992101 ]\n",
      "self.next: 506\n",
      "obs= [[[ 2.72826752e+00 -2.19429590e+00 -4.03314781e-01  3.86441939e-01\n",
      "   -9.92893439e-01  2.40268277e-01]\n",
      "  [-1.86484759e-02  3.10166999e-03  1.70878154e-02  8.02730653e-02\n",
      "   -2.76943860e-02 -1.69519090e-01]]\n",
      "\n",
      " [[ 1.00666966e+01 -5.15563626e+00 -6.38708505e+00  2.17545686e+00\n",
      "    2.56075841e+00 -1.06853895e+01]\n",
      "  [ 1.44151518e-01 -1.02937609e-01 -8.35383377e-02 -1.70300944e-02\n",
      "    2.06604232e-01 -2.81529685e-01]]] reward= -7320397.037045908 done= False\n",
      "Step 507\n",
      "Action:  [ 1.5635498   0.31436634 -1.3473814   1.4644977   3.8768618  -0.49413827]\n",
      "self.next: 507\n",
      "obs= [[[ 2.72640267e+00 -2.19398573e+00 -4.01605999e-01  3.94469246e-01\n",
      "   -9.95662877e-01  2.23316368e-01]\n",
      "  [-2.61045014e-02  6.19843540e-03  1.82862226e-02  3.86872053e-03\n",
      "   -5.33685534e-02  1.06494288e-01]]\n",
      "\n",
      " [[ 1.00811118e+01 -5.16593003e+00 -6.39543888e+00  2.17375385e+00\n",
      "    2.58141883e+00 -1.07135425e+01]\n",
      "  [ 1.42048283e-01 -9.99255074e-02 -8.35535046e-02 -1.80404294e-02\n",
      "    2.06476590e-01 -2.80464452e-01]]] reward= -6344106.821493871 done= False\n",
      "Step 508\n",
      "Action:  [ 1.5611024   0.31510177 -1.3454599   1.4647851   3.8713763  -0.49249652]\n",
      "self.next: 508\n",
      "obs= [[[ 2.72379222e+00 -2.19336589e+00 -3.99777377e-01  3.94856118e-01\n",
      "   -1.00099973e+00  2.33965797e-01]\n",
      "  [ 5.35400794e-02 -2.75528512e-02 -2.82179979e-03 -2.16392350e-02\n",
      "    5.93773263e-02 -7.87759361e-02]]\n",
      "\n",
      " [[ 1.00953166e+01 -5.17592258e+00 -6.40379423e+00  2.17194981e+00\n",
      "    2.60206649e+00 -1.07415889e+01]\n",
      "  [ 1.39943233e-01 -9.69148743e-02 -8.35855407e-02 -1.89958701e-02\n",
      "    2.06302270e-01 -2.79390434e-01]]] reward= -6311358.657307085 done= False\n",
      "Step 509\n",
      "Action:  [ 1.5566359   0.31486094 -1.341375    1.4624139   3.856155   -0.4890774 ]\n",
      "self.next: 509\n",
      "obs= [[[ 2.72914623e+00 -2.19612118e+00 -4.00059557e-01  3.92692194e-01\n",
      "   -9.95062000e-01  2.26088203e-01]\n",
      "  [-3.76467312e-02 -4.62492993e-03  2.39816568e-02  1.46396623e-01\n",
      "   -1.31171157e-01 -6.81798383e-02]]\n",
      "\n",
      " [[ 1.01093109e+01 -5.18561406e+00 -6.41215279e+00  2.17005022e+00\n",
      "    2.62269672e+00 -1.07695280e+01]\n",
      "  [ 1.37837691e-01 -9.39083791e-02 -8.36339683e-02 -1.98960459e-02\n",
      "    2.06082249e-01 -2.78309401e-01]]] reward= -6809857.601231752 done= False\n",
      "Step 510\n",
      "Action:  [ 1.5552946   0.3147246  -1.3399136   1.462365    3.8577816  -0.48828894]\n",
      "self.next: 510\n",
      "obs= [[[  2.72538155  -2.19658367  -0.39766139   0.40733186  -1.00817912\n",
      "     0.21927022]\n",
      "  [  0.08311822  -0.01662913   0.10803839  -0.3362369    0.27783228\n",
      "    -0.05144063]]\n",
      "\n",
      " [[ 10.12309469  -5.1950049   -6.42051618   2.16806062   2.64330494\n",
      "   -10.79735892]\n",
      "  [  0.13573279  -0.09090839  -0.08369832  -0.02074073   0.20581753\n",
      "    -0.27722301]]] reward= -5904764.157754432 done= False\n",
      "Step 511\n",
      "Action:  [ 1.5434701   0.31563625 -1.3298354   1.4573827   3.8129501  -0.4793912 ]\n",
      "self.next: 511\n",
      "obs= [[[  2.73369338  -2.19824658  -0.38685755   0.37370817  -0.98039589\n",
      "     0.21412616]\n",
      "  [ -0.02974953  -0.09737458  -0.04781436   0.44190028  -0.26869065\n",
      "     0.0146448 ]]\n",
      "\n",
      " [[ 10.13666797  -5.20409574  -6.42888602   2.16598655   2.6638867\n",
      "   -10.82508122]\n",
      "  [  0.13362949  -0.08791698  -0.08377815  -0.02152983   0.20550909\n",
      "    -0.27613278]]] reward= -7741762.3112977175 done= False\n",
      "Step 512\n",
      "Action:  [ 1.551326    0.31447834 -1.336273    1.4614515   3.8542235  -0.48582843]\n",
      "self.next: 512\n",
      "obs= [[[  2.73071842  -2.20798404  -0.39163899   0.4178982   -1.00726495\n",
      "     0.21559064]\n",
      "  [ -0.05063325   0.07368362  -0.02364576   0.03294358  -0.20322679\n",
      "     0.14582263]]\n",
      "\n",
      " [[ 10.15003092  -5.21288744  -6.43726383   2.16383356   2.68443761\n",
      "   -10.8526945 ]\n",
      "  [  0.1315286   -0.08493598  -0.08387301  -0.02226338   0.20515799\n",
      "    -0.27504018]]] reward= -7905338.399823591 done= False\n",
      "Step 513\n",
      "Action:  [ 1.5486177   0.31567335 -1.3340222   1.461124    3.83926    -0.4837582 ]\n",
      "self.next: 513\n",
      "obs= [[[ 2.72565510e+00 -2.20061568e+00 -3.94003564e-01  4.21192553e-01\n",
      "   -1.02758763e+00  2.30172899e-01]\n",
      "  [ 2.30730024e-02 -5.90922359e-02  3.68349894e-02  5.13653310e-02\n",
      "    5.90095560e-03 -5.25840951e-02]]\n",
      "\n",
      " [[ 1.01631838e+01 -5.22138104e+00 -6.44565113e+00  2.16160723e+00\n",
      "    2.70495340e+00 -1.08801985e+01]\n",
      "  [ 1.29430752e-01 -8.19669450e-02 -8.39824836e-02 -2.29414875e-02\n",
      "    2.04765209e-01 -2.73946525e-01]]] reward= -6157891.00334926 done= False\n",
      "Step 514\n",
      "Action:  [ 1.5398449   0.31539455 -1.3261955   1.4570433   3.8128183  -0.47700265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 514\n",
      "obs= [[[ 2.72796240e+00 -2.20652490e+00 -3.90320065e-01  4.26329086e-01\n",
      "   -1.02699754e+00  2.24914490e-01]\n",
      "  [-6.21231949e-03  1.41317856e-02  1.46417119e-02  6.21713906e-02\n",
      "   -1.95973649e-01  7.49686448e-02]]\n",
      "\n",
      " [[ 1.01761269e+01 -5.22957773e+00 -6.45404938e+00  2.15931308e+00\n",
      "    2.72542993e+00 -1.09075932e+01]\n",
      "  [ 1.27336471e-01 -7.90112209e-02 -8.41061606e-02 -2.35643956e-02\n",
      "    2.04331763e-01 -2.72853060e-01]]] reward= -6391620.717959365 done= False\n",
      "Step 515\n",
      "Action:  [ 1.5407953   0.31555638 -1.3268205   1.458298    3.8188422  -0.4778029 ]\n",
      "self.next: 515\n",
      "obs= [[[  2.72734117  -2.20511172  -0.38885589   0.43254623  -1.0465949\n",
      "     0.23241135]\n",
      "  [ -0.03138249   0.12729234  -0.29298116   0.05965664   0.13726213\n",
      "     0.05241344]]\n",
      "\n",
      " [[ 10.18886051  -5.23747885  -6.46246      2.15695664   2.7458631\n",
      "   -10.93487847]\n",
      "  [  0.12524616  -0.07606995  -0.08424366  -0.02413241   0.20385868\n",
      "    -0.27176095]]] reward= -5783994.9518338265 done= False\n",
      "Step 516\n",
      "Action:  [ 1.5389096   0.31683716 -1.3260854   1.4571126   3.8030975  -0.47786832]\n",
      "self.next: 516\n",
      "obs= [[[ 2.72420292e+00 -2.19238249e+00 -4.18154010e-01  4.38511889e-01\n",
      "   -1.03286869e+00  2.37652698e-01]\n",
      "  [ 9.32318388e-02 -1.94958291e-01  2.74835833e-01  7.01638080e-02\n",
      "   -1.81276875e-01  2.62134997e-03]]\n",
      "\n",
      " [[ 1.02013851e+01 -5.24508585e+00 -6.47088436e+00  2.15454340e+00\n",
      "    2.76624897e+00 -1.09620546e+01]\n",
      "  [ 1.23160109e-01 -7.31440550e-02 -8.43946170e-02 -2.46459270e-02\n",
      "    2.03346955e-01 -2.70671286e-01]]] reward= -9302275.067814108 done= False\n",
      "Step 517\n",
      "Action:  [ 1.5260462  0.3150374 -1.3132228  1.452734   3.782571  -0.4659843]\n",
      "self.next: 517\n",
      "obs= [[[  2.7335261   -2.21187832  -0.39067043   0.44552827  -1.05099638\n",
      "     0.23791483]\n",
      "  [ -0.0179362    0.04981688   0.14208917  -0.22382159  -0.01325212\n",
      "     0.02086013]]\n",
      "\n",
      " [[ 10.21370113  -5.25240025  -6.47932383   2.1520788    2.78658367\n",
      "   -10.9891217 ]\n",
      "  [  0.1210785   -0.07023431  -0.08455868  -0.0251054    0.20279759\n",
      "    -0.26958506]]] reward= -8704196.083847001 done= False\n",
      "Step 518\n",
      "Action:  [ 1.5245104   0.31643355 -1.3123513   1.4521459   3.7669005  -0.46580762]\n",
      "self.next: 518\n",
      "obs= [[[ 2.73173248e+00 -2.20689663e+00 -3.76461510e-01  4.23146111e-01\n",
      "   -1.05232159e+00  2.40000846e-01]\n",
      "  [ 1.08355015e-02 -2.70491295e-02  4.51189526e-02  5.43355422e-02\n",
      "   -1.34534642e-01  3.21230096e-01]]\n",
      "\n",
      " [[ 1.02258090e+01 -5.25942368e+00 -6.48777969e+00  2.14956826e+00\n",
      "    2.80686342e+00 -1.10160802e+01]\n",
      "  [ 1.19001462e-01 -6.73413341e-02 -8.47355269e-02 -2.55113315e-02\n",
      "    2.02211600e-01 -2.68503227e-01]]] reward= -7182263.777959239 done= False\n",
      "Step 519\n",
      "Action:  [ 1.5263811   0.3168029  -1.3142614   1.4541229   3.7805598  -0.46768174]\n",
      "self.next: 519\n",
      "obs= [[[ 2.73281603e+00 -2.20960154e+00 -3.71949615e-01  4.28579666e-01\n",
      "   -1.06577505e+00  2.72123855e-01]\n",
      "  [ 4.96848957e-03 -1.68655714e-02 -1.61038494e-02  8.27446630e-02\n",
      "   -5.43205717e-02 -1.10098549e-02]]\n",
      "\n",
      " [[ 1.02377091e+01 -5.26615782e+00 -6.49625325e+00  2.14701713e+00\n",
      "    2.82708458e+00 -1.10429305e+01]\n",
      "  [ 1.16929023e-01 -6.44655782e-02 -8.49248615e-02 -2.58643119e-02\n",
      "    2.01589972e-01 -2.67426671e-01]]] reward= -7194648.868535341 done= False\n",
      "Step 520\n",
      "Action:  [ 1.5215797   0.31627932 -1.3097311   1.45145     3.7634861  -0.4641389 ]\n",
      "self.next: 520\n",
      "obs= [[[  2.73331288  -2.2112881   -0.37356      0.43685413  -1.07120711\n",
      "     0.27102287]\n",
      "  [ -0.06012738   0.09844198  -0.18465507   0.17420908  -0.02734342\n",
      "    -0.06699849]]\n",
      "\n",
      " [[ 10.24940203  -5.27260438  -6.50474573   2.1444307    2.84724358\n",
      "   -11.06967319]\n",
      "  [  0.11486115  -0.06160737  -0.08512639  -0.02616495   0.20093368\n",
      "    -0.26635621]]] reward= -5794729.126644143 done= False\n",
      "Step 521\n",
      "Action:  [ 1.5209583   0.31678244 -1.3093956   1.4511505   3.758859   -0.46458334]\n",
      "self.next: 521\n",
      "obs= [[[ 2.72730014e+00 -2.20144390e+00 -3.92025507e-01  4.54275040e-01\n",
      "   -1.07394145e+00  2.64323021e-01]\n",
      "  [ 6.63398001e-02 -9.93728230e-02  1.79904906e-01 -3.66858169e-02\n",
      "   -1.65972868e-03 -2.41688359e-01]]\n",
      "\n",
      " [[ 1.02608881e+01 -5.27876511e+00 -6.51325837e+00  2.14181420e+00\n",
      "    2.86733695e+00 -1.10963088e+01]\n",
      "  [ 1.12797753e-01 -5.87669324e-02 -8.53398664e-02 -2.64139104e-02\n",
      "    2.00243714e-01 -2.65292608e-01]]] reward= -7131226.718672372 done= False\n",
      "Step 522\n",
      "Action:  [ 1.5060854   0.3158181  -1.2953553   1.444848    3.7194278  -0.45209366]\n",
      "self.next: 522\n",
      "obs= [[[ 2.73393412e+00 -2.21138119e+00 -3.74035016e-01  4.50606458e-01\n",
      "   -1.07410742e+00  2.40154185e-01]\n",
      "  [ 2.42594796e-02  6.93747029e-03 -3.25612877e-02  3.53428789e-03\n",
      "   -3.51331474e-03  5.21153109e-02]]\n",
      "\n",
      " [[ 1.02721679e+01 -5.28464181e+00 -6.52179236e+00  2.13917281e+00\n",
      "    2.88736132e+00 -1.11228381e+01]\n",
      "  [ 1.10738688e-01 -5.59443528e-02 -8.55650264e-02 -2.66118852e-02\n",
      "    1.99521012e-01 -2.64236584e-01]]] reward= -7688408.287870296 done= False\n",
      "Step 523\n",
      "Action:  [ 1.5110596   0.317119   -1.3004607   1.4481034   3.7324367  -0.45674828]\n",
      "self.next: 523\n",
      "obs= [[[  2.73636007  -2.21068744  -0.37729114   0.45095989  -1.07445876\n",
      "     0.24536572]\n",
      "  [ -0.02203977   0.06914053  -0.21603725   0.17286497   0.10858006\n",
      "    -0.32312037]]\n",
      "\n",
      " [[ 10.28324179  -5.29023624  -6.53034886   2.13651162   2.90731342\n",
      "   -11.14926173]\n",
      "  [  0.10868379  -0.05313965  -0.08580166  -0.02675961   0.19876655\n",
      "    -0.26318882]]] reward= -5984125.686290123 done= False\n",
      "Step 524\n",
      "Action:  [ 1.5055513   0.3168538  -1.2955062   1.4444859   3.711969   -0.45376757]\n",
      "self.next: 524\n",
      "obs= [[[ 2.73415609e+00 -2.20377339e+00 -3.98894870e-01  4.68246384e-01\n",
      "   -1.06360075e+00  2.13053679e-01]\n",
      "  [-5.58707294e-02  4.65675207e-02  3.27126709e-02  1.10705369e-04\n",
      "   -7.50341571e-02  1.03923106e-01]]\n",
      "\n",
      " [[ 1.02941102e+01 -5.29555021e+00 -6.53892903e+00  2.13383566e+00\n",
      "    2.92719008e+00 -1.11755806e+01]\n",
      "  [ 1.06632827e-01 -5.03527466e-02 -8.60495634e-02 -2.68578396e-02\n",
      "    1.97981275e-01 -2.62149946e-01]]] reward= -7275573.146295274 done= False\n",
      "Step 525\n",
      "Action:  [ 1.5020508   0.31771377 -1.2923396   1.4454178   3.7090437  -0.4504366 ]\n",
      "self.next: 525\n",
      "obs= [[[ 2.72856902e+00 -2.19911663e+00 -3.95623603e-01  4.68257455e-01\n",
      "   -1.07110417e+00  2.23445990e-01]\n",
      "  [ 5.60433067e-02 -4.09669658e-02 -1.47173405e-02  5.25556764e-02\n",
      "   -1.31437195e-03 -8.00053877e-02]]\n",
      "\n",
      " [[ 1.03047735e+01 -5.30058548e+00 -6.54753398e+00  2.13114988e+00\n",
      "    2.94698821e+00 -1.12017956e+01]\n",
      "  [ 1.04585563e-01 -4.75834822e-02 -8.63085452e-02 -2.69073628e-02\n",
      "    1.97166114e-01 -2.61120548e-01]]] reward= -5654397.162419219 done= False\n",
      "Step 526\n",
      "Action:  [ 1.4969796  0.3171128 -1.2875994  1.4428561  3.6942222 -0.4465077]\n",
      "self.next: 526\n",
      "obs= [[[ 2.73417335e+00 -2.20321333e+00 -3.97095337e-01  4.73513022e-01\n",
      "   -1.07123560e+00  2.15445451e-01]\n",
      "  [ 3.31050184e-04 -5.25454244e-02  2.24534873e-01 -1.69043785e-01\n",
      "   -5.93377006e-02  1.08244821e-01]]\n",
      "\n",
      " [[ 1.03152320e+01 -5.30534383e+00 -6.55616484e+00  2.12845914e+00\n",
      "    2.96670482e+00 -1.12279077e+01]\n",
      "  [ 1.02541723e-01 -4.48316345e-02 -8.65784362e-02 -2.69089851e-02\n",
      "    1.96321992e-01 -2.60101178e-01]]] reward= -5582214.684941927 done= False\n",
      "Step 527\n",
      "Action:  [ 1.4887627   0.31770265 -1.28015     1.4405928   3.672665   -0.44004953]\n",
      "self.next: 527\n",
      "obs= [[[  2.73420646  -2.20846787  -0.37464185   0.45660864  -1.07716937\n",
      "     0.22626993]\n",
      "  [  0.01825862   0.11520722  -0.32941725   0.11476703   0.1917631\n",
      "    -0.16197833]]\n",
      "\n",
      " [[ 10.32548618  -5.30982699  -6.56482268   2.12576824   2.98633702\n",
      "   -11.25391778]\n",
      "  [  0.10050101  -0.04209692  -0.08685908  -0.02686353   0.19544982\n",
      "    -0.25909235]]] reward= -6987274.147198685 done= False\n",
      "Step 528\n",
      "Action:  [ 1.4937527   0.31828913 -1.2853951   1.4411491   3.6763124  -0.44586614]\n",
      "self.next: 528\n",
      "obs= [[[ 2.73603232e+00 -2.19694715e+00 -4.07583574e-01  4.68085346e-01\n",
      "   -1.05799306e+00  2.10072100e-01]\n",
      "  [-4.04815609e-02 -4.10602694e-03  4.32893444e-02  8.62380409e-02\n",
      "   -1.43841507e-01  8.52289471e-02]]\n",
      "\n",
      " [[ 1.03355363e+01 -5.31403668e+00 -6.57350859e+00  2.12308189e+00\n",
      "    3.00588200e+00 -1.12798270e+01]\n",
      "  [ 9.84631399e-02 -3.93789936e-02 -8.71503551e-02 -2.67718518e-02\n",
      "    1.94550518e-01 -2.58094567e-01]]] reward= -8422567.180582896 done= False\n",
      "Step 529\n",
      "Action:  [ 1.4868386   0.31794068 -1.2784851   1.4405283   3.6704957  -0.43947804]\n",
      "self.next: 529\n",
      "obs= [[[ 2.73198416e+00 -2.19735775e+00 -4.03254640e-01  4.76709150e-01\n",
      "   -1.07237721e+00  2.18594994e-01]\n",
      "  [ 1.82400795e-02  7.65045079e-03 -2.47321381e-02 -2.54068200e-03\n",
      "    1.33615325e-03 -1.65717697e-02]]\n",
      "\n",
      " [[ 1.03453826e+01 -5.31797458e+00 -6.58222362e+00  2.12040471e+00\n",
      "    3.02533705e+00 -1.13056365e+01]\n",
      "  [ 9.64277789e-02 -3.66774769e-02 -8.74521245e-02 -2.66348032e-02\n",
      "    1.93624969e-01 -2.57108267e-01]]] reward= -5468808.9775676 done= False\n",
      "Step 530\n",
      "Action:  [ 1.4814842   0.31823516 -1.2738274   1.4379551   3.6499243  -0.4357644 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 530\n",
      "obs= [[[  2.73380817  -2.19659271  -0.40572785   0.47645508  -1.0722436\n",
      "     0.21693782]\n",
      "  [ -0.04896173  -0.03860228   0.25721666  -0.0888618   -0.25136925\n",
      "     0.2211563 ]]\n",
      "\n",
      " [[ 10.35502537  -5.32164233  -6.59096884   2.11774123   3.04469955\n",
      "   -11.3313473 ]\n",
      "  [  0.09439461  -0.03399194  -0.08776428  -0.02645326   0.19267405\n",
      "    -0.25613388]]] reward= -5359495.649822778 done= False\n",
      "Step 531\n",
      "Action:  [ 1.4751141  0.3183063 -1.2676018  1.4369435  3.640715  -0.4304194]\n",
      "self.next: 531\n",
      "obs= [[[ 2.72891200e+00 -2.20045294e+00 -3.80006187e-01  4.67568902e-01\n",
      "   -1.09738052e+00  2.39053447e-01]\n",
      "  [ 1.44536894e-02  7.08324589e-03 -1.90518719e-01  2.24018468e-01\n",
      "    1.77950796e-03 -6.79627116e-02]]\n",
      "\n",
      " [[ 1.03644648e+01 -5.32504152e+00 -6.59974527e+00  2.11509590e+00\n",
      "    3.06396695e+00 -1.13569607e+01]\n",
      "  [ 9.23632929e-02 -3.13219062e-02 -8.80867385e-02 -2.62281004e-02\n",
      "    1.91698651e-01 -2.55171796e-01]]] reward= -8114520.284148237 done= False\n",
      "Step 532\n",
      "Action:  [ 1.4775598   0.31834123 -1.2703741   1.4367502   3.6406717  -0.4335652 ]\n",
      "self.next: 532\n",
      "obs= [[[  2.73035737  -2.19974461  -0.39905806   0.48997075  -1.09720257\n",
      "     0.23225718]\n",
      "  [  0.03987194  -0.03729114   0.16727089  -0.16564887  -0.06182186\n",
      "     0.14081749]]\n",
      "\n",
      " [[ 10.37370116  -5.32817372  -6.60855394   2.11247309   3.08313682\n",
      "   -11.38247787]\n",
      "  [  0.09033352  -0.02866689  -0.08841941  -0.02596023   0.19069963\n",
      "    -0.2542224 ]]] reward= -7572122.535227173 done= False\n",
      "Step 533\n",
      "Action:  [ 1.4668168   0.3188694  -1.2604115   1.4334338   3.6114304  -0.42460594]\n",
      "self.next: 533\n",
      "obs= [[[ 2.73434456e+00 -2.20347373e+00 -3.82330970e-01  4.73405861e-01\n",
      "   -1.10338476e+00  2.46338925e-01]\n",
      "  [ 3.45760247e-02  1.92926039e-02 -5.34163251e-02 -1.91341922e-03\n",
      "    1.10795231e-01 -2.00248040e-01]]\n",
      "\n",
      " [[ 1.03827345e+01 -5.33104040e+00 -6.61739588e+00  2.10987707e+00\n",
      "    3.10220678e+00 -1.14079001e+01]\n",
      "  [ 8.83049382e-02 -2.60263687e-02 -8.87622223e-02 -2.56505446e-02\n",
      "    1.89677829e-01 -2.53286021e-01]]] reward= -7479879.854637334 done= False\n",
      "Step 534\n",
      "Action:  [ 1.4630567   0.31868273 -1.2572248   1.4306958   3.5950434  -0.4227969 ]\n",
      "self.next: 534\n",
      "obs= [[[ 2.73780216e+00 -2.20154447e+00 -3.87672603e-01  4.73214519e-01\n",
      "   -1.09230524e+00  2.26314121e-01]\n",
      "  [-5.47809077e-04  1.90020224e-02  9.09533335e-03 -8.42171337e-02\n",
      "    5.61254652e-02  7.44148064e-02]]\n",
      "\n",
      " [[ 1.03915650e+01 -5.33364304e+00 -6.62627210e+00  2.10731201e+00\n",
      "    3.12117456e+00 -1.14332287e+01]\n",
      "  [ 8.62772381e-02 -2.33997851e-02 -8.91151183e-02 -2.52999611e-02\n",
      "    1.88634102e-01 -2.52362993e-01]]] reward= -5114700.329658733 done= False\n",
      "Step 535\n",
      "Action:  [ 1.4607592   0.31964508 -1.2554189   1.4311509   3.5906963  -0.4211938 ]\n",
      "self.next: 535\n",
      "obs= [[[ 2.73774738e+00 -2.19964426e+00 -3.86763069e-01  4.64792806e-01\n",
      "   -1.08669269e+00  2.33755602e-01]\n",
      "  [-2.05049114e-02  2.17074161e-02 -1.79118050e-01  2.55347964e-01\n",
      "   -7.77081968e-02 -1.01205217e-02]]\n",
      "\n",
      " [[ 1.04001927e+01 -5.33598302e+00 -6.63518361e+00  2.10478202e+00\n",
      "    3.14003797e+00 -1.14584650e+01]\n",
      "  [ 8.42500980e-02 -2.07865753e-02 -8.94780505e-02 -2.49093995e-02\n",
      "    1.87569286e-01 -2.51453615e-01]]] reward= -5231235.670697069 done= False\n",
      "Step 536\n",
      "Action:  [ 1.4632546   0.31907943 -1.2574948   1.4325731   3.6033762  -0.42350873]\n",
      "self.next: 536\n",
      "obs= [[[  2.73569689  -2.19747352  -0.40467487   0.4903276   -1.09446351\n",
      "     0.23274355]\n",
      "  [ -0.06589973   0.02685336   0.039325     0.07770049  -0.25002224\n",
      "     0.14005001]]\n",
      "\n",
      " [[ 10.40861774  -5.33806168  -6.64413142   2.10229108   3.1587949\n",
      "   -11.48361037]\n",
      "  [  0.08222321  -0.01818616  -0.08985098  -0.02447979   0.18648421\n",
      "    -0.25055817]]] reward= -7463350.294832406 done= False\n",
      "Step 537\n",
      "Action:  [ 1.4565065  0.3193895 -1.2509884  1.4310442  3.58817   -0.4179894]\n",
      "self.next: 537\n",
      "obs= [[[ 2.72910692e+00 -2.19478819e+00 -4.00742374e-01  4.98097652e-01\n",
      "   -1.11946573e+00  2.46748551e-01]\n",
      "  [ 3.84133244e-03  1.48647727e-03 -6.53324055e-03  2.99535771e-03\n",
      "   -2.08741806e-03  6.66539605e-02]]\n",
      "\n",
      " [[ 1.04168401e+01 -5.33988029e+00 -6.65311652e+00  2.09984310e+00\n",
      "    3.17744332e+00 -1.15086662e+01]\n",
      "  [ 8.01962627e-02 -1.55979274e-02 -9.02338712e-02 -2.40120565e-02\n",
      "    1.85379691e-01 -2.49676908e-01]]] reward= -6463770.509025005 done= False\n",
      "Step 538\n",
      "Action:  [ 1.4487936   0.31997836 -1.2444501   1.4273489   3.5598052  -0.41264045]\n",
      "self.next: 538\n",
      "obs= [[[  2.72949105  -2.19463954  -0.4013957    0.49839719  -1.11967447\n",
      "     0.25341395]\n",
      "  [ -0.05704453   0.0115653    0.04433009   0.0795517   -0.19154175\n",
      "     0.04637795]]\n",
      "\n",
      " [[ 10.42485969  -5.34144009  -6.6621399    2.09744189   3.19598129\n",
      "   -11.53363388]\n",
      "  [  0.07816896  -0.01302127  -0.0906267   -0.02350714   0.18425652\n",
      "    -0.24881007]]] reward= -5101480.693959223 done= False\n",
      "Step 539\n",
      "Action:  [ 1.4454849   0.31960213 -1.2410189   1.4268993   3.5560873  -0.41004026]\n",
      "self.next: 539\n",
      "obs= [[[ 2.72378660e+00 -2.19348301e+00 -3.96962689e-01  5.06352358e-01\n",
      "   -1.13882865e+00  2.58051742e-01]\n",
      "  [ 7.72088820e-02  6.74537053e-02 -1.66916030e-01 -1.31007209e-01\n",
      "    2.09591616e-01  2.43697582e-02]]\n",
      "\n",
      " [[ 1.04326766e+01 -5.34274221e+00 -6.67120257e+00  2.09509118e+00\n",
      "    3.21440694e+00 -1.15585149e+01]\n",
      "  [ 7.61410217e-02 -1.04555718e-02 -9.10294510e-02 -2.29659736e-02\n",
      "    1.83115508e-01 -2.47957871e-01]]] reward= -5973113.04526918 done= False\n",
      "Step 540\n",
      "Action:  [ 1.4400203   0.32115912 -1.2369952   1.4233181   3.5252585  -0.40714642]\n",
      "self.next: 540\n",
      "obs= [[[ 2.73150749e+00 -2.18673764e+00 -4.13654292e-01  4.93251637e-01\n",
      "   -1.11786949e+00  2.60488718e-01]\n",
      "  [ 8.50460616e-02 -4.52009998e-02 -1.54142855e-02  3.33416467e-02\n",
      "    1.14027886e-01 -2.09697146e-01]]\n",
      "\n",
      " [[ 1.04402907e+01 -5.34378777e+00 -6.68030552e+00  2.09279458e+00\n",
      "    3.23271850e+00 -1.15833107e+01]\n",
      "  [ 7.41121740e-02 -7.90019762e-03 -9.14421139e-02 -2.23895060e-02\n",
      "    1.81957437e-01 -2.47120518e-01]]] reward= -5755714.314125557 done= False\n",
      "Step 541\n",
      "Action:  [ 1.4317961   0.31971347 -1.2289475   1.4199252   3.5096326  -0.4004161 ]\n",
      "self.next: 541\n",
      "obs= [[[ 2.74001209e+00 -2.19125774e+00 -4.15195721e-01  4.96585802e-01\n",
      "   -1.10646670e+00  2.39519003e-01]\n",
      "  [-1.45194814e-01  1.86328720e-02  1.05997522e-01  1.76894397e-01\n",
      "   -3.83566637e-01  2.58651278e-01]]\n",
      "\n",
      " [[ 1.04477019e+01 -5.34457779e+00 -6.68944973e+00  2.09055563e+00\n",
      "    3.25091424e+00 -1.16080227e+01]\n",
      "  [ 7.20821603e-02 -5.35451763e-03 -9.18646818e-02 -2.17786851e-02\n",
      "    1.80783092e-01 -2.46298195e-01]]] reward= -6272084.839149045 done= False\n",
      "Step 542\n",
      "Action:  [ 1.4368297   0.32034266 -1.2331097   1.4252204   3.5389638  -0.4042078 ]\n",
      "self.next: 542\n",
      "obs= [[[ 2.72549261e+00 -2.18939445e+00 -4.04595968e-01  5.14275241e-01\n",
      "   -1.14482336e+00  2.65384131e-01]\n",
      "  [ 3.40537712e-02 -7.36869717e-02  6.18578057e-02  1.13617753e-01\n",
      "   -1.26995783e-01  1.12179379e-01]]\n",
      "\n",
      " [[ 1.04549101e+01 -5.34511324e+00 -6.69863620e+00  2.08837776e+00\n",
      "    3.26899255e+00 -1.16326525e+01]\n",
      "  [ 7.00507459e-02 -2.81789990e-03 -9.22971627e-02 -2.11344652e-02\n",
      "    1.79593264e-01 -2.45491080e-01]]] reward= -7035445.901747887 done= False\n",
      "Step 543\n",
      "Action:  [ 1.4294314   0.32027122 -1.2266082   1.4214389   3.512447   -0.39843833]\n",
      "self.next: 543\n",
      "obs= [[[ 2.72889799e+00 -2.19676315e+00 -3.98410188e-01  5.25637017e-01\n",
      "   -1.15752294e+00  2.76602069e-01]\n",
      "  [-1.55458074e-02  4.19639234e-02 -4.91633534e-02  2.53537289e-02\n",
      "   -6.79655666e-02  1.17417853e-01]]\n",
      "\n",
      " [[ 1.04619152e+01 -5.34539503e+00 -6.70786592e+00  2.08626432e+00\n",
      "    3.28695187e+00 -1.16572017e+01]\n",
      "  [ 6.80176878e-02 -2.89696805e-04 -9.27395550e-02 -2.04577902e-02\n",
      "    1.78388698e-01 -2.44699316e-01]]] reward= -5487307.764109227 done= False\n",
      "Step 544\n",
      "Action:  [ 1.4264513   0.32135868 -1.2242441   1.4203466   3.497899   -0.39705896]\n",
      "self.next: 544\n",
      "obs= [[[ 2.72734341e+00 -2.19256676e+00 -4.03326523e-01  5.28172390e-01\n",
      "   -1.16431950e+00  2.88343854e-01]\n",
      "  [-2.45553920e-02 -9.60666173e-02  1.22064867e-01  1.94858318e-01\n",
      "   -2.42045100e-01  8.41150714e-02]]\n",
      "\n",
      " [[ 1.04687170e+01 -5.34542400e+00 -6.71713987e+00  2.08421854e+00\n",
      "    3.30479074e+00 -1.16816716e+01]\n",
      "  [ 6.59827725e-02  2.23073152e-03 -9.31918699e-02 -1.97496143e-02\n",
      "    1.77170156e-01 -2.43923045e-01]]] reward= -5385587.686171866 done= False\n",
      "Step 545\n",
      "Action:  [ 1.4203162   0.3201203  -1.2180299   1.418705    3.4913683  -0.39173993]\n",
      "self.next: 545\n",
      "obs= [[[ 2.72488787e+00 -2.20217342e+00 -3.91120036e-01  5.47658221e-01\n",
      "   -1.18852401e+00  2.96755361e-01]\n",
      "  [ 1.70142447e-02  2.76326964e-02 -1.96417890e-02 -8.51346107e-02\n",
      "    5.88548419e-02 -2.52199342e-03]]\n",
      "\n",
      " [[ 1.04753152e+01 -5.34520093e+00 -6.72645906e+00  2.08224357e+00\n",
      "    3.32250776e+00 -1.17060639e+01]\n",
      "  [ 6.39457997e-02  4.74402481e-03 -9.36541175e-02 -1.90108949e-02\n",
      "    1.75938389e-01 -2.43162391e-01]]] reward= -5354071.104182552 done= False\n",
      "Step 546\n",
      "Action:  [ 1.4128996   0.32169327 -1.2119681   1.4145703   3.4549785  -0.3872862 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 546\n",
      "obs= [[[ 2.72658929e+00 -2.19941015e+00 -3.93084215e-01  5.39144760e-01\n",
      "   -1.18263852e+00  2.96503162e-01]\n",
      "  [ 2.26007476e-02 -8.20612490e-02  3.73246345e-02  1.44807782e-01\n",
      "   -6.17027536e-02 -6.90939664e-02]]\n",
      "\n",
      " [[ 1.04817098e+01 -5.34472653e+00 -6.73582447e+00  2.08034249e+00\n",
      "    3.34010160e+00 -1.17303801e+01]\n",
      "  [ 6.19065769e-02  7.25082828e-03 -9.41263125e-02 -1.82425808e-02\n",
      "    1.74694130e-01 -2.42417464e-01]]] reward= -5278952.543554841 done= False\n",
      "Step 547\n",
      "Action:  [ 1.4095218   0.3206333  -1.20851     1.4138845   3.4545276  -0.38433978]\n",
      "self.next: 547\n",
      "obs= [[[ 2.72884937e+00 -2.20761627e+00 -3.89351752e-01  5.53625539e-01\n",
      "   -1.18880880e+00  2.89593765e-01]\n",
      "  [-1.14647592e-02  3.20937593e-02 -1.93680760e-02  7.31258274e-02\n",
      "   -7.33810199e-02 -2.17916977e-02]]\n",
      "\n",
      " [[ 1.04879005e+01 -5.34400144e+00 -6.74523710e+00  2.07851823e+00\n",
      "    3.35757101e+00 -1.17546219e+01]\n",
      "  [ 5.98649406e-02  9.75177425e-03 -9.46084731e-02 -1.74456347e-02\n",
      "    1.73438126e-01 -2.41688369e-01]]] reward= -4988343.29958563 done= False\n",
      "Step 548\n",
      "Action:  [ 1.4081885   0.32156003 -1.2074748   1.4138128   3.4474711  -0.383853  ]\n",
      "self.next: 548\n",
      "obs= [[[ 2.72770289e+00 -2.20440690e+00 -3.91288560e-01  5.60938121e-01\n",
      "   -1.19614690e+00  2.87414596e-01]\n",
      "  [ 3.69836270e-02  1.30610824e-02 -4.92770608e-02  1.04599959e-03\n",
      "   -3.37774329e-03 -2.92148460e-02]]\n",
      "\n",
      " [[ 1.04938870e+01 -5.34302627e+00 -6.75469795e+00  2.07677366e+00\n",
      "    3.37491482e+00 -1.17787907e+01]\n",
      "  [ 5.78207336e-02  1.22475000e-02 -9.51006195e-02 -1.66210097e-02\n",
      "    1.72171103e-01 -2.40975195e-01]]] reward= -5219337.241504558 done= False\n",
      "Step 549\n",
      "Action:  [ 1.402961    0.32188264 -1.2028294   1.4115295   3.4296982  -0.38021412]\n",
      "self.next: 549\n",
      "obs= [[[ 2.73140125e+00 -2.20310079e+00 -3.96216266e-01  5.61042721e-01\n",
      "   -1.19648468e+00  2.84493111e-01]\n",
      "  [ 2.35069211e-03  5.34105607e-04 -5.23397079e-03  5.27215570e-03\n",
      "   -6.62563127e-03  7.00284595e-02]]\n",
      "\n",
      " [[ 1.04996690e+01 -5.34180152e+00 -6.76420801e+00  2.07511156e+00\n",
      "    3.39213194e+00 -1.18028882e+01]\n",
      "  [ 5.57738123e-02  1.47386392e-02 -9.56027690e-02 -1.57696601e-02\n",
      "    1.70893776e-01 -2.40278015e-01]]] reward= -5221728.950516865 done= False\n",
      "Step 550\n",
      "Action:  [ 1.3988436   0.32243693 -1.1992654   1.4104666   3.419281   -0.37742218]\n",
      "self.next: 550\n",
      "obs= [[[  2.73163632  -2.20304738  -0.39673966   0.56156994  -1.19714724\n",
      "     0.29149596]\n",
      "  [  0.0243113   -0.03890175   0.01643861   0.06319875  -0.06427482\n",
      "     0.01812333]]\n",
      "\n",
      " [[ 10.50524643  -5.34032765  -6.77376829   2.0735346    3.40922131\n",
      "   -11.82691603]\n",
      "  [  0.05372405   0.01722582  -0.09611494  -0.01489254   0.16960686\n",
      "    -0.2395969 ]]] reward= -4596305.080620701 done= False\n",
      "Step 551\n",
      "Action:  [ 1.3950126   0.321988   -1.1955309   1.409258    3.4115498  -0.37437108]\n",
      "self.next: 551\n",
      "obs= [[[ 2.73406745e+00 -2.20693755e+00 -3.95095802e-01  5.67889812e-01\n",
      "   -1.20357472e+00  2.93308290e-01]\n",
      "  [-7.70064832e-02  7.94224385e-03  2.44078533e-01 -1.77336360e-01\n",
      "   -1.63862037e-01  1.91739612e-01]]\n",
      "\n",
      " [[ 1.05106188e+01 -5.33860507e+00 -6.78337978e+00  2.07204534e+00\n",
      "    3.42618200e+00 -1.18508757e+01]\n",
      "  [ 5.16713442e-02  1.97096627e-02 -9.66371605e-02 -1.39906067e-02\n",
      "    1.68311067e-01 -2.38931910e-01]]] reward= -4836958.85452102 done= False\n",
      "Step 552\n",
      "Action:  [ 1.3870503   0.32293573 -1.1882138   1.4069344   3.3894897  -0.36852774]\n",
      "self.next: 552\n",
      "obs= [[[ 2.72636680e+00 -2.20614333e+00 -3.70687949e-01  5.50156176e-01\n",
      "   -1.21996093e+00  3.12482251e-01]\n",
      "  [ 2.86944116e-02 -3.72406404e-02  1.10487537e-02  6.23089048e-02\n",
      "   -6.62184687e-02  8.34646054e-02]]\n",
      "\n",
      " [[ 1.05157860e+01 -5.33663410e+00 -6.79304350e+00  2.07064628e+00\n",
      "    3.44301311e+00 -1.18747689e+01]\n",
      "  [ 4.96155876e-02  2.21907909e-02 -9.71694412e-02 -1.30648054e-02\n",
      "    1.67007086e-01 -2.38283090e-01]]] reward= -8546774.171088474 done= False\n",
      "Step 553\n",
      "Action:  [ 1.387911    0.32258722 -1.1891625   1.4071083   3.3918772  -0.3694547 ]\n",
      "self.next: 553\n",
      "obs= [[[ 2.72923625e+00 -2.20986739e+00 -3.69583073e-01  5.56387066e-01\n",
      "   -1.22658277e+00  3.20828712e-01]\n",
      "  [ 3.30579820e-02  1.77668881e-02 -5.20783191e-02  7.78971150e-03\n",
      "    9.85901608e-02 -1.94305130e-01]]\n",
      "\n",
      " [[ 1.05207475e+01 -5.33441502e+00 -6.80276044e+00  2.06933980e+00\n",
      "    3.45971381e+00 -1.18985972e+01]\n",
      "  [ 4.75567087e-02  2.46698111e-02 -9.77118074e-02 -1.21160898e-02\n",
      "    1.65695621e-01 -2.37650491e-01]]] reward= -4832663.52231998 done= False\n",
      "Step 554\n",
      "Action:  [ 1.3770939   0.32267132 -1.1794187   1.4014087   3.3535724  -0.36215663]\n",
      "self.next: 554\n",
      "obs= [[[ 2.73254204e+00 -2.20809070e+00 -3.74790905e-01  5.57166037e-01\n",
      "   -1.21672376e+00  3.01398199e-01]\n",
      "  [-7.92400663e-02 -6.13916184e-03 -8.81437343e-02  3.82403860e-01\n",
      "   -3.15351114e-01  7.11098247e-02]]\n",
      "\n",
      " [[ 1.05255032e+01 -5.33194804e+00 -6.81253162e+00  2.06812819e+00\n",
      "    3.47628338e+00 -1.19223623e+01]\n",
      "  [ 4.54946304e-02  2.71473359e-02 -9.82642717e-02 -1.11454006e-02\n",
      "    1.64377344e-01 -2.37034141e-01]]] reward= -5501004.062832609 done= False\n",
      "Step 555\n",
      "Action:  [ 1.3864883   0.32222953 -1.1875374   1.4080925   3.3965425  -0.36886176]\n",
      "self.next: 555\n",
      "obs= [[[ 2.72461804e+00 -2.20870462e+00 -3.83605279e-01  5.95406423e-01\n",
      "   -1.24825887e+00  3.08509181e-01]\n",
      "  [ 5.42788977e-02  1.45786308e-02  1.04163924e-01 -2.42673321e-01\n",
      "    1.13096850e-01 -3.13791954e-02]]\n",
      "\n",
      " [[ 1.05300527e+01 -5.32923331e+00 -6.82235805e+00  2.06701365e+00\n",
      "    3.49272111e+00 -1.19460657e+01]\n",
      "  [ 4.34293184e-02  2.96239530e-02 -9.88268602e-02 -1.01536918e-02\n",
      "    1.63052962e-01 -2.36434084e-01]]] reward= -8402466.670374943 done= False\n",
      "Step 556\n",
      "Action:  [ 1.3662419   0.32377917 -1.1695536   1.3975261   3.3204532  -0.35418168]\n",
      "self.next: 556\n",
      "obs= [[[ 2.73004593e+00 -2.20724676e+00 -3.73188886e-01  5.71139091e-01\n",
      "   -1.23694918e+00  3.05371262e-01]\n",
      "  [ 2.06740399e-02  6.67797670e-03 -2.74507672e-02 -2.06006290e-04\n",
      "    1.83878555e-03 -1.47941111e-02]]\n",
      "\n",
      " [[ 1.05343956e+01 -5.32627091e+00 -6.83224074e+00  2.06599828e+00\n",
      "    3.50902641e+00 -1.19697091e+01]\n",
      "  [ 4.13607051e-02  3.21002737e-02 -9.93995737e-02 -9.14188569e-03\n",
      "    1.61723107e-01 -2.35850326e-01]]] reward= -9035696.242867928 done= False\n",
      "Step 557\n",
      "Action:  [ 1.368331    0.3236652  -1.1715195   1.3995882   3.331781   -0.35601982]\n",
      "self.next: 557\n",
      "obs= [[[ 2.73211333e+00 -2.20657896e+00 -3.75933963e-01  5.71118491e-01\n",
      "   -1.23676530e+00  3.03891851e-01]\n",
      "  [-1.07564791e-01  1.93686692e-02  8.83104704e-02  7.58470967e-02\n",
      "   -2.47213877e-01  2.31236996e-01]]\n",
      "\n",
      " [[ 1.05385317e+01 -5.32306089e+00 -6.84218069e+00  2.06508409e+00\n",
      "    3.52519872e+00 -1.19932941e+01]\n",
      "  [ 3.92887854e-02  3.45768689e-02 -9.99824345e-02 -8.11092912e-03\n",
      "    1.60388475e-01 -2.35282903e-01]]] reward= -4851004.080284558 done= False\n",
      "Step 558\n",
      "Action:  [ 1.3685691   0.32413304 -1.1715701   1.4016607   3.341166   -0.35624477]\n",
      "self.next: 558\n",
      "obs= [[[ 2.72135685e+00 -2.20464209e+00 -3.67102916e-01  5.78703200e-01\n",
      "   -1.26148669e+00  3.27015550e-01]\n",
      "  [ 4.87344722e-02  2.56148158e-02 -7.39755837e-02 -1.07266517e-04\n",
      "    1.07265167e-01 -2.72068867e-01]]\n",
      "\n",
      " [[ 1.05424605e+01 -5.31960320e+00 -6.85217894e+00  2.06427300e+00\n",
      "    3.54123757e+00 -1.20168224e+01]\n",
      "  [ 3.72135446e-02  3.70543169e-02 -1.00575451e-01 -7.06175168e-03\n",
      "    1.59049726e-01 -2.34731833e-01]]] reward= -6056279.0669675 done= False\n",
      "Step 559\n",
      "Action:  [ 1.3528926   0.3235981  -1.1573329   1.3923265   3.2833877  -0.34530613]\n",
      "self.next: 559\n",
      "obs= [[[ 2.72623030e+00 -2.20208061e+00 -3.74500474e-01  5.78692474e-01\n",
      "   -1.25076017e+00  2.99808664e-01]\n",
      "  [-1.46319674e-01  6.96811598e-02  1.02246374e-01  5.83636323e-02\n",
      "   -2.61798242e-01 -2.72291638e-02]]\n",
      "\n",
      " [[ 1.05461819e+01 -5.31589777e+00 -6.86223648e+00  2.06356683e+00\n",
      "    3.55714254e+00 -1.20402956e+01]\n",
      "  [ 3.51349674e-02  3.95331951e-02 -1.01178622e-01 -5.99526885e-03\n",
      "    1.57707490e-01 -2.34197120e-01]]] reward= -5954812.972208807 done= False\n",
      "Step 560\n",
      "Action:  [ 1.3534476   0.3239592  -1.1575351   1.3956217   3.2966359  -0.34540465]\n",
      "self.next: 560\n",
      "obs= [[[ 2.71159833e+00 -2.19511249e+00 -3.64275837e-01  5.84528837e-01\n",
      "   -1.27694000e+00  2.97085747e-01]\n",
      "  [-3.51302041e-02  2.40262562e-02  1.14350578e-02  7.30816551e-02\n",
      "   -1.82789848e-01  1.59384366e-01]]\n",
      "\n",
      " [[ 1.05496954e+01 -5.31194445e+00 -6.87235434e+00  2.06296730e+00\n",
      "    3.57291329e+00 -1.20637153e+01]\n",
      "  [ 3.30530796e-02  4.20140549e-02 -1.01791957e-01 -4.91240743e-03\n",
      "    1.56362438e-01 -2.33678791e-01]]] reward= -7075485.026949163 done= False\n",
      "Step 561\n",
      "Action:  [ 1.3546293   0.3247568  -1.1589007   1.3962668   3.2987843  -0.34654558]\n",
      "self.next: 561\n",
      "obs= [[[ 2.70808531e+00 -2.19270987e+00 -3.63132331e-01  5.91837002e-01\n",
      "   -1.29521898e+00  3.13024184e-01]\n",
      "  [-6.47196020e-03 -8.83491137e-02  7.01331132e-02  1.53143497e-01\n",
      "   -6.89835583e-02 -5.24012346e-02]]\n",
      "\n",
      " [[ 1.05530007e+01 -5.30774304e+00 -6.88253354e+00  2.06247606e+00\n",
      "    3.58854953e+00 -1.20870832e+01]\n",
      "  [ 3.09679021e-02  4.44974485e-02 -1.02415456e-01 -3.81407678e-03\n",
      "    1.55015207e-01 -2.33176858e-01]]] reward= -5193381.759668994 done= False\n",
      "Step 562\n",
      "Action:  [ 1.3426093   0.32388362 -1.1477822   1.3905836   3.265286   -0.33760142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 562\n",
      "obs= [[[ 2.70743811e+00 -2.20154478e+00 -3.56119020e-01  6.07151352e-01\n",
      "   -1.30211734e+00  3.07784060e-01]\n",
      "  [ 3.05407513e-02  8.29213209e-03 -3.93770299e-02  4.29658379e-03\n",
      "    1.18204853e-03  1.10155862e-01]]\n",
      "\n",
      " [[ 1.05560975e+01 -5.30329330e+00 -6.89277509e+00  2.06209465e+00\n",
      "    3.60405105e+00 -1.21104009e+01]\n",
      "  [ 2.88794594e-02  4.69839225e-02 -1.03049107e-01 -2.70117683e-03\n",
      "    1.53666418e-01 -2.32691327e-01]]] reward= -5242955.665900012 done= False\n",
      "Step 563\n",
      "Action:  [ 1.3433346   0.32558462 -1.1489114   1.3910899   3.2604516  -0.33888096]\n",
      "self.next: 563\n",
      "obs= [[[ 2.71049219e+00 -2.20071557e+00 -3.60056723e-01  6.07581011e-01\n",
      "   -1.30199913e+00  3.18799647e-01]\n",
      "  [ 1.19338166e-01  6.75552015e-02 -1.88543362e-01 -2.10451810e-01\n",
      "    4.19153019e-01 -3.92754555e-01]]\n",
      "\n",
      " [[ 1.05589854e+01 -5.29859491e+00 -6.90308000e+00  2.06182453e+00\n",
      "    3.61941769e+00 -1.21336700e+01]\n",
      "  [ 2.67878022e-02  4.94740052e-02 -1.03692906e-01 -1.57460452e-03\n",
      "    1.52316707e-01 -2.32222219e-01]]] reward= -5001666.549884373 done= False\n",
      "Step 564\n",
      "Action:  [ 1.3228791   0.32555896 -1.1303593   1.3781953   3.1832411  -0.32543895]\n",
      "self.next: 564\n",
      "obs= [[[ 2.72242601e+00 -2.19396005e+00 -3.78911059e-01  5.86535830e-01\n",
      "   -1.26008383e+00  2.79524191e-01]\n",
      "  [-8.27676179e-02  8.28229923e-03  7.63595347e-02  6.68279810e-02\n",
      "   -1.82630548e-01  6.63622773e-02]]\n",
      "\n",
      " [[ 1.05616642e+01 -5.29364751e+00 -6.91344929e+00  2.06166707e+00\n",
      "    3.63464936e+00 -1.21568922e+01]\n",
      "  [ 2.46929680e-02  5.19682273e-02 -1.04346828e-01 -4.35238345e-04\n",
      "    1.50966671e-01 -2.31769537e-01]]] reward= -7664782.995610274 done= False\n",
      "Step 565\n",
      "Action:  [ 1.3336504  0.3253811 -1.139853   1.3885113  3.2391663 -0.3318713]\n",
      "self.next: 565\n",
      "obs= [[[ 2.71414924e+00 -2.19313182e+00 -3.71275105e-01  5.93218628e-01\n",
      "   -1.27834689e+00  2.86160419e-01]\n",
      "  [ 3.61275723e-02 -5.57571191e-02  1.97922100e-02  6.62184011e-02\n",
      "   -3.48749178e-03 -7.42842750e-02]]\n",
      "\n",
      " [[ 1.05641335e+01 -5.28845068e+00 -6.92388397e+00  2.06162355e+00\n",
      "    3.64974603e+00 -1.21800692e+01]\n",
      "  [ 2.25950484e-02  5.44670812e-02 -1.05010870e-01  7.16028895e-04\n",
      "    1.49616966e-01 -2.31333322e-01]]] reward= -5412841.295042595 done= False\n",
      "Step 566\n",
      "Action:  [ 1.3258667   0.32516924 -1.132803    1.3841329   3.2130027  -0.32632485]\n",
      "self.next: 566\n",
      "obs= [[[ 2.71776200e+00 -2.19870753e+00 -3.69295884e-01  5.99840468e-01\n",
      "   -1.27869564e+00  2.78731991e-01]\n",
      "  [ 2.21798873e-02  1.14537409e-02 -3.20362408e-02  8.40715505e-04\n",
      "    1.05363800e-01 -1.17724831e-01]]\n",
      "\n",
      " [[ 1.05663930e+01 -5.28300398e+00 -6.93438506e+00  2.06169515e+00\n",
      "    3.66470773e+00 -1.22032025e+01]\n",
      "  [ 2.04940982e-02  5.69710767e-02 -1.05684996e-01  1.87834135e-03\n",
      "    1.48268173e-01 -2.30913582e-01]]] reward= -4824397.042444283 done= False\n",
      "Step 567\n",
      "Action:  [ 1.3194022  0.3260866 -1.1272306  1.3810005  3.1886938 -0.3223747]\n",
      "self.next: 567\n",
      "obs= [[[ 2.71997999e+00 -2.19756216e+00 -3.72499509e-01  5.99924539e-01\n",
      "   -1.26815926e+00  2.66959508e-01]\n",
      "  [-7.34098597e-02  2.89110204e-02  4.55489915e-02  7.20560902e-02\n",
      "   -3.57280446e-01  3.74577977e-01]]\n",
      "\n",
      " [[ 1.05684424e+01 -5.27730687e+00 -6.94495356e+00  2.06188299e+00\n",
      "    3.67953454e+00 -1.22262939e+01]\n",
      "  [ 1.83901977e-02  5.94807013e-02 -1.06369176e-01  3.05084490e-03\n",
      "    1.46920889e-01 -2.30510344e-01]]] reward= -5365304.678383658 done= False\n",
      "Step 568\n",
      "Action:  [ 1.3321176   0.3267303  -1.1384747   1.3895504   3.2381165  -0.33142638]\n",
      "self.next: 568\n",
      "obs= [[[ 2.71263900e+00 -2.19467105e+00 -3.67944609e-01  6.07130148e-01\n",
      "   -1.30388730e+00  3.04417306e-01]\n",
      "  [-1.06467092e-01 -2.42681438e-02  1.32164885e-01  7.06437184e-02\n",
      "   -1.15675148e-01 -5.25025391e-03]]\n",
      "\n",
      " [[ 1.05702814e+01 -5.27135880e+00 -6.95559047e+00  2.06218807e+00\n",
      "    3.69422663e+00 -1.22493449e+01]\n",
      "  [ 1.62834517e-02  6.19964186e-02 -1.07063384e-01  4.23268761e-03\n",
      "    1.45575733e-01 -2.30123651e-01]]] reward= -6646159.658232265 done= False\n",
      "Step 569\n",
      "Action:  [ 1.3108019   0.3261638  -1.1190361   1.379476    3.172731   -0.31594393]\n",
      "self.next: 569\n",
      "obs= [[[ 2.70199230e+00 -2.19709787e+00 -3.54728121e-01  6.14194520e-01\n",
      "   -1.31545482e+00  3.03892281e-01]\n",
      "  [ 8.77513169e-02 -2.70324017e-02 -8.68758250e-02  1.59524690e-01\n",
      "   -2.96376212e-02 -2.11274989e-01]]\n",
      "\n",
      " [[ 1.05719098e+01 -5.26515916e+00 -6.96629681e+00  2.06261134e+00\n",
      "    3.70878421e+00 -1.22723573e+01]\n",
      "  [ 1.41739298e-02  6.45187061e-02 -1.07767558e-01  5.42305347e-03\n",
      "    1.44233248e-01 -2.29753521e-01]]] reward= -5313036.727396796 done= False\n",
      "Step 570\n",
      "Action:  [ 1.3097771  0.3255462 -1.1179036  1.3780065  3.1664379 -0.3152845]\n",
      "self.next: 570\n",
      "obs= [[[ 2.71076743e+00 -2.19980111e+00 -3.63415703e-01  6.30146989e-01\n",
      "   -1.31841858e+00  2.82764782e-01]\n",
      "  [-1.42465725e-02 -4.66159483e-03  1.89270414e-01 -1.67150851e-01\n",
      "   -1.09698050e-01  9.87958375e-02]]\n",
      "\n",
      " [[ 1.05733272e+01 -5.25870728e+00 -6.97707357e+00  2.06315365e+00\n",
      "    3.72320753e+00 -1.22953326e+01]\n",
      "  [ 1.20617498e-02  6.70480007e-02 -1.08481659e-01  6.62111940e-03\n",
      "    1.42894032e-01 -2.29400008e-01]]] reward= -5566747.120374514 done= False\n",
      "Step 571\n",
      "Action:  [ 1.3048037   0.32711235 -1.1134937   1.3771256   3.1518981  -0.31166524]\n",
      "self.next: 571\n",
      "obs= [[[ 2.70934277e+00 -2.20026727e+00 -3.44488662e-01  6.13431904e-01\n",
      "   -1.32938838e+00  2.92644365e-01]\n",
      "  [ 2.18002960e-02  8.42051420e-03 -2.92528474e-02  1.37130904e-03\n",
      "   -5.25845360e-03  4.85195553e-02]]\n",
      "\n",
      " [[ 1.05745334e+01 -5.25200248e+00 -6.98792173e+00  2.06381576e+00\n",
      "    3.73749693e+00 -1.23182726e+01]\n",
      "  [ 9.94701752e-03  6.95847384e-02 -1.09205630e-01  7.82608589e-03\n",
      "    1.41558652e-01 -2.29063160e-01]]] reward= -7944230.4446792025 done= False\n",
      "Step 572\n",
      "Action:  [ 1.3036532   0.32753947 -1.1128327   1.3765341   3.1458445  -0.31157944]\n",
      "self.next: 572\n",
      "obs= [[[ 2.71152280e+00 -2.19942522e+00 -3.47413947e-01  6.13569035e-01\n",
      "   -1.32991423e+00  2.97496321e-01]\n",
      "  [ 1.79836948e-02 -6.68396719e-02  4.89007165e-02  7.12459727e-02\n",
      "   -1.32436317e-04 -6.42776642e-02]]\n",
      "\n",
      " [[ 1.05755281e+01 -5.24504401e+00 -6.99884230e+00  2.06459837e+00\n",
      "    3.75165280e+00 -1.23411789e+01]\n",
      "  [ 7.82985173e-03  7.21293332e-02 -1.09939407e-01  9.03716553e-03\n",
      "    1.40227671e-01 -2.28743037e-01]]] reward= -4602729.041178142 done= False\n",
      "Step 573\n",
      "Action:  [ 1.2955058   0.32681984 -1.1051704   1.3730009   3.1255262  -0.30547628]\n",
      "self.next: 573\n",
      "obs= [[[ 2.71332117e+00 -2.20610918e+00 -3.42523875e-01  6.20693632e-01\n",
      "   -1.32992747e+00  2.91068554e-01]\n",
      "  [ 3.10028741e-02 -6.85414137e-02  6.79727947e-02  4.24719672e-02\n",
      "   -9.37773066e-03 -1.37535653e-01]]\n",
      "\n",
      " [[ 1.05763110e+01 -5.23783108e+00 -7.00983624e+00  2.06550208e+00\n",
      "    3.76567557e+00 -1.23640532e+01]\n",
      "  [ 5.71037048e-03  7.46821871e-02 -1.10682916e-01  1.02535890e-02\n",
      "    1.38901637e-01 -2.28439703e-01]]] reward= -4793083.994853685 done= False\n",
      "Step 574\n",
      "Action:  [ 1.2899561   0.32670298 -1.0999583   1.3706241   3.1093152  -0.30146867]\n",
      "self.next: 574\n",
      "obs= [[[ 2.71642146e+00 -2.21296332e+00 -3.35726596e-01  6.24940829e-01\n",
      "   -1.33086525e+00  2.77314989e-01]\n",
      "  [ 2.79043658e-03 -2.77244067e-04 -1.52924424e-03  1.78563764e-04\n",
      "   -2.13255688e-03  6.26661705e-02]]\n",
      "\n",
      " [[ 1.05768821e+01 -5.23036286e+00 -7.02090453e+00  2.06652744e+00\n",
      "    3.77956573e+00 -1.23868972e+01]\n",
      "  [ 3.58870209e-03  7.72436824e-02 -1.11436080e-01  1.14746033e-02\n",
      "    1.37581097e-01 -2.28153234e-01]]] reward= -5109829.880084137 done= False\n",
      "Step 575\n",
      "Action:  [ 1.2915393   0.32831153 -1.101901    1.3722053   3.1110113  -0.30333796]\n",
      "self.next: 575\n",
      "obs= [[[ 2.71670050e+00 -2.21299105e+00 -3.35879520e-01  6.24958685e-01\n",
      "   -1.33107850e+00  2.83581606e-01]\n",
      "  [ 1.87850944e-02 -1.96823335e-02 -1.74193282e-01  3.13057217e-01\n",
      "   -7.30128529e-02 -9.85660432e-02]]\n",
      "\n",
      " [[ 1.05772410e+01 -5.22263849e+00 -7.03204814e+00  2.06767490e+00\n",
      "    3.79332384e+00 -1.24097125e+01]\n",
      "  [ 1.46498268e-03  7.98141821e-02 -1.12198815e-01  1.26994723e-02\n",
      "    1.36266594e-01 -2.27883720e-01]]] reward= -4404314.264218867 done= False\n",
      "Step 576\n",
      "Action:  [ 1.2917001   0.3273176  -1.10184     1.3725568   3.1157067  -0.30360356]\n",
      "self.next: 576\n",
      "obs= [[[ 2.71857901e+00 -2.21495928e+00 -3.53298848e-01  6.56264407e-01\n",
      "   -1.33837979e+00  2.73725002e-01]\n",
      "  [ 1.25987106e-02  9.22231933e-02 -7.76309046e-02 -1.69777014e-01\n",
      "    7.66418886e-02  5.04067577e-02]]\n",
      "\n",
      " [[ 1.05773875e+01 -5.21465707e+00 -7.04326802e+00  2.06894485e+00\n",
      "    3.80695050e+00 -1.24325009e+01]\n",
      "  [-6.60648865e-04  8.23940291e-02 -1.12971024e-01  1.39274772e-02\n",
      "    1.34958657e-01 -2.27631255e-01]]] reward= -7528073.71168554 done= False\n",
      "Step 577\n",
      "Action:  [ 1.2809216   0.3299343  -1.0924549   1.367345    3.071907   -0.29670817]\n",
      "self.next: 577\n",
      "obs= [[[ 2.71983888e+00 -2.20573696e+00 -3.61061939e-01  6.39286706e-01\n",
      "   -1.33071560e+00  2.78765678e-01]\n",
      "  [ 3.33207333e-02  5.20193887e-02  6.32717472e-02 -2.85647535e-01\n",
      "    7.11747726e-02  1.15514865e-01]]\n",
      "\n",
      " [[ 1.05773214e+01 -5.20641767e+00 -7.05456512e+00  2.07033760e+00\n",
      "    3.82044637e+00 -1.24552640e+01]\n",
      "  [-2.78806202e-03  8.49835571e-02 -1.13752600e-01  1.51579282e-02\n",
      "    1.33657788e-01 -2.27395939e-01]]] reward= -6025892.288623764 done= False\n",
      "Step 578\n",
      "Action:  [ 1.2754432   0.3301357  -1.0873513   1.3651015   3.057043   -0.29258868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 578\n",
      "obs= [[[ 2.72317095e+00 -2.20053502e+00 -3.54734764e-01  6.10721952e-01\n",
      "   -1.32359812e+00  2.90317164e-01]\n",
      "  [-6.81495985e-02 -1.77275539e-02 -8.72817498e-02  3.76462976e-01\n",
      "   -2.39635559e-01  3.72973374e-02]]\n",
      "\n",
      " [[ 1.05770426e+01 -5.19791931e+00 -7.06594038e+00  2.07185339e+00\n",
      "    3.83381214e+00 -1.24780036e+01]\n",
      "  [-4.91710274e-03  8.75830634e-02 -1.14543433e-01  1.63901427e-02\n",
      "    1.32364507e-01 -2.27177894e-01]]] reward= -8253617.334930949 done= False\n",
      "Step 579\n",
      "Action:  [ 1.2830496   0.32807493 -1.0939343   1.3708048   3.0958493  -0.29773435]\n",
      "self.next: 579\n",
      "obs= [[[ 2.71635599e+00 -2.20230778e+00 -3.63462939e-01  6.48368250e-01\n",
      "   -1.34756168e+00  2.94046898e-01]\n",
      "  [ 1.52402936e-02 -7.35963420e-02  8.50398038e-02  4.76086928e-02\n",
      "   -1.13358732e-02 -5.74309598e-02]]\n",
      "\n",
      " [[ 1.05765509e+01 -5.18916101e+00 -7.07739472e+00  2.07349240e+00\n",
      "    3.84704860e+00 -1.25007214e+01]\n",
      "  [-7.04760708e-03  9.01928191e-02 -1.15343405e-01  1.76234574e-02\n",
      "    1.31079336e-01 -2.26977255e-01]]] reward= -8618925.718371266 done= False\n",
      "Step 580\n",
      "Action:  [ 1.2658759   0.32863486 -1.0781947   1.3618609   3.0387828  -0.28534368]\n",
      "self.next: 580\n",
      "obs= [[[ 2.71788002e+00 -2.20966741e+00 -3.54958959e-01  6.53129119e-01\n",
      "   -1.34869526e+00  2.88303802e-01]\n",
      "  [ 2.15936342e-02  1.71566074e-02 -6.60084030e-02  2.65665910e-02\n",
      "    2.38085192e-03  4.81191848e-02]]\n",
      "\n",
      " [[ 1.05758461e+01 -5.18014173e+00 -7.08892906e+00  2.07525475e+00\n",
      "    3.86015653e+00 -1.25234191e+01]\n",
      "  [-9.17944007e-03  9.28130946e-02 -1.16152375e-01  1.88572484e-02\n",
      "    1.29802733e-01 -2.26794150e-01]]] reward= -5081686.523351142 done= False\n",
      "Step 581\n",
      "Action:  [ 1.2673137   0.3300636  -1.0799291   1.3630413   3.038456   -0.28718266]\n",
      "self.next: 581\n",
      "obs= [[[ 2.72003939e+00 -2.20795175e+00 -3.61559799e-01  6.55785778e-01\n",
      "   -1.34845718e+00  2.93115720e-01]\n",
      "  [-1.67089882e-02  2.74495072e-02 -1.10876614e-02  2.14189954e-03\n",
      "    3.42521974e-02 -2.72551186e-01]]\n",
      "\n",
      " [[ 1.05749282e+01 -5.17086042e+00 -7.10054430e+00  2.07714047e+00\n",
      "    3.87313680e+00 -1.25460986e+01]\n",
      "  [-1.13124279e-02  9.54441122e-02 -1.16970212e-01  2.00908973e-02\n",
      "    1.28535203e-01 -2.26628741e-01]]] reward= -4417797.484286504 done= False\n",
      "Step 582\n",
      "Action:  [ 1.2514529   0.32928324 -1.0650446   1.354989    2.9908683  -0.27595717]\n",
      "self.next: 582\n",
      "obs= [[[  2.71836849  -2.2052068   -0.36266856   0.65599997  -1.34503196\n",
      "     0.2658606 ]\n",
      "  [  0.05262954  -0.11889917   0.24189419  -0.09839323  -0.01498179\n",
      "    -0.07257351]]\n",
      "\n",
      " [[ 10.57379692  -5.161316    -7.11224132   2.07914956   3.88599032\n",
      "   -12.56876144]\n",
      "  [ -0.01344641   0.09808608  -0.11779676   0.02132382   0.1272772\n",
      "    -0.22648119]]] reward= -5306033.830354796 done= False\n",
      "Step 583\n",
      "Action:  [ 1.2512769   0.32895154 -1.0646641   1.3558122   2.9967961  -0.27489924]\n",
      "self.next: 583\n",
      "obs= [[[ 2.72363144e+00 -2.21709672e+00 -3.38479146e-01  6.46160645e-01\n",
      "   -1.34653014e+00  2.58603250e-01]\n",
      "  [-3.00560977e-02  5.56870071e-02 -2.71130976e-02  8.22787313e-04\n",
      "   -1.04113054e-01  1.58392130e-01]]\n",
      "\n",
      " [[ 1.05724523e+01 -5.15150740e+00 -7.12402100e+00  2.08128195e+00\n",
      "    3.89871804e+00 -1.25914096e+01]\n",
      "  [-1.55812179e-02  1.00739166e-01 -1.18631853e-01  2.25554339e-02\n",
      "    1.26029217e-01 -2.26351671e-01]]] reward= -8215071.032728871 done= False\n",
      "Step 584\n",
      "Action:  [ 1.2589095   0.33123434 -1.0723981   1.3610116   3.0154626  -0.2817426 ]\n",
      "self.next: 584\n",
      "obs= [[[ 2.72062583e+00 -2.21152802e+00 -3.41190455e-01  6.46242923e-01\n",
      "   -1.35694144e+00  2.74442463e-01]\n",
      "  [-8.81839701e-03  5.98780858e-03  3.58874055e-02 -3.59727558e-02\n",
      "   -5.86864240e-02  3.66798213e-02]]\n",
      "\n",
      " [[ 1.05708942e+01 -5.14143348e+00 -7.13588418e+00  2.08353749e+00\n",
      "    3.91132096e+00 -1.26140447e+01]\n",
      "  [-1.77166591e-02  1.03403514e-01 -1.19475338e-01  2.37852064e-02\n",
      "    1.24791704e-01 -2.26240388e-01]]] reward= -4812405.85895807 done= False\n",
      "Step 585\n",
      "Action:  [ 1.2489997   0.3308285  -1.063087    1.3561776   2.986452   -0.27451771]\n",
      "self.next: 585\n",
      "obs= [[[ 2.71974399e+00 -2.21092924e+00 -3.37601715e-01  6.42645648e-01\n",
      "   -1.36281009e+00  2.78110446e-01]\n",
      "  [-6.34708977e-02  2.87462800e-02  2.56378991e-03  1.02528918e-01\n",
      "   -1.79634522e-01  1.71009996e-01]]\n",
      "\n",
      " [[ 1.05691225e+01 -5.13109313e+00 -7.14783172e+00  2.08591601e+00\n",
      "    3.92380013e+00 -1.26366688e+01]\n",
      "  [-1.98525662e-02  1.06079241e-01 -1.20327018e-01  2.50126174e-02\n",
      "    1.23565096e-01 -2.26147535e-01]]] reward= -4976405.012294957 done= False\n",
      "Step 586\n",
      "Action:  [ 1.2517722   0.3313107  -1.0657486   1.3588163   2.9982576  -0.27680197]\n",
      "self.next: 586\n",
      "obs= [[[  2.7133969   -2.20805461  -0.33734534   0.65289854  -1.38077354\n",
      "     0.29521145]\n",
      "  [  0.01449447  -0.04151974   0.0266677    0.07443566  -0.07334245\n",
      "    -0.03831304]]\n",
      "\n",
      " [[ 10.56713724  -5.1204852   -7.15986442   2.08841727   3.93615664\n",
      "   -12.65928352]\n",
      "  [ -0.02198874   0.10876642  -0.12118671   0.02623717   0.12234984\n",
      "    -0.22607333]]] reward= -5384485.122115928 done= False\n",
      "Step 587\n",
      "Action:  [ 1.2404003   0.33054873 -1.0550038   1.3526465   2.96364    -0.2684717 ]\n",
      "self.next: 587\n",
      "obs= [[[ 2.71484635e+00 -2.21220658e+00 -3.34678566e-01  6.60342106e-01\n",
      "   -1.38810778e+00  2.91380141e-01]\n",
      "  [-1.37481163e-02  1.18134894e-02 -1.71949451e-01  3.76522840e-01\n",
      "   -2.42412361e-01  1.81748168e-01]]\n",
      "\n",
      " [[ 1.05649384e+01 -5.10960856e+00 -7.17198309e+00  2.09104099e+00\n",
      "    3.94839163e+00 -1.26818908e+01]\n",
      "  [-2.41250045e-02  1.11465107e-01 -1.22054196e-01  2.74583939e-02\n",
      "    1.21146361e-01 -2.26018004e-01]]] reward= -4222897.043768252 done= False\n",
      "Step 588\n",
      "Action:  [ 1.2534146   0.33112198 -1.0671973   1.360277    3.0058963  -0.2782704 ]\n",
      "self.next: 588\n",
      "obs= [[[ 2.71347154e+00 -2.21102523e+00 -3.51873511e-01  6.97994390e-01\n",
      "   -1.41234902e+00  3.09554957e-01]\n",
      "  [ 5.24967982e-03 -4.72525509e-04  1.69114242e-01 -1.70162406e-01\n",
      "   -1.08711134e-01  7.75988165e-02]]\n",
      "\n",
      " [[ 1.05625259e+01 -5.09846205e+00 -7.18418851e+00  2.09378683e+00\n",
      "    3.96050626e+00 -1.27044926e+01]\n",
      "  [-2.62611337e-02  1.14175294e-01 -1.22929277e-01  2.86758426e-02\n",
      "    1.19955089e-01 -2.25981801e-01]]] reward= -8546176.723605158 done= False\n",
      "Step 589\n",
      "Action:  [ 1.2312446   0.33191553 -1.0464907   1.3490788   2.9341252  -0.26223326]\n",
      "self.next: 589\n",
      "obs= [[[  2.71399651  -2.21107249  -0.33496209   0.68097815  -1.42322013\n",
      "     0.31731484]\n",
      "  [ -0.10178025   0.0596783    0.04389798   0.06195722  -0.20132709\n",
      "     0.02364815]]\n",
      "\n",
      " [[ 10.55989975  -5.08704452  -7.19648144   2.09665441   3.97250177\n",
      "   -12.72709083]\n",
      "  [ -0.02839695   0.11689697  -0.12381171   0.02988911   0.1187764\n",
      "    -0.22596496]]] reward= -7798081.8397550685 done= False\n",
      "Step 590\n",
      "Action:  [ 1.2288933   0.33209378 -1.0445005   1.3491324   2.9295125  -0.26112443]\n",
      "self.next: 590\n",
      "obs= [[[ 2.70381848e+00 -2.20510466e+00 -3.30572288e-01  6.87173871e-01\n",
      "   -1.44335284e+00  3.19679654e-01]\n",
      "  [-8.47005957e-04 -1.27941513e-03  4.18403429e-03  6.23383151e-05\n",
      "   -2.41454856e-03  1.19059392e-06]]\n",
      "\n",
      " [[ 1.05570601e+01 -5.07535483e+00 -7.20886261e+00  2.09964332e+00\n",
      "    3.98437941e+00 -1.27496873e+01]\n",
      "  [-3.05322109e-02  1.19630047e-01 -1.24701260e-01  3.10977834e-02\n",
      "    1.17610727e-01 -2.25967755e-01]]] reward= -5533720.093915195 done= False\n",
      "Step 591\n",
      "Action:  [ 1.2212939   0.33251885 -1.0376738   1.3445122   2.902553   -0.2560754 ]\n",
      "self.next: 591\n",
      "obs= [[[ 2.70373378e+00 -2.20523260e+00 -3.30153885e-01  6.87180105e-01\n",
      "   -1.44359430e+00  3.19679773e-01]\n",
      "  [-7.27335226e-02  1.24660757e-02  6.06552707e-02  6.56287911e-02\n",
      "   -1.65927384e-01  1.85035233e-01]]\n",
      "\n",
      " [[ 1.05540068e+01 -5.06339182e+00 -7.22133274e+00  2.10275310e+00\n",
      "    3.99614049e+00 -1.27722841e+01]\n",
      "  [-3.26667059e-02  1.22374422e-01 -1.25597677e-01  3.23015096e-02\n",
      "    1.16458445e-01 -2.25990459e-01]]] reward= -4274187.146730626 done= False\n",
      "Step 592\n",
      "Action:  [ 1.2237391   0.33309704 -1.0399839   1.3473737   2.9143438  -0.25795123]\n",
      "self.next: 592\n",
      "obs= [[[ 2.69646043e+00 -2.20398599e+00 -3.24088357e-01  6.93742984e-01\n",
      "   -1.46018703e+00  3.38183296e-01]\n",
      "  [ 2.17144321e-02 -3.22588440e-03  1.10348603e-02 -2.81954051e-02\n",
      "   -1.19473718e-03 -1.76778298e-02]]\n",
      "\n",
      " [[ 1.05507402e+01 -5.05115438e+00 -7.23389250e+00  2.10598325e+00\n",
      "    4.00778633e+00 -1.27948831e+01]\n",
      "  [-3.48001886e-02  1.25129931e-01 -1.26500701e-01  3.34999390e-02\n",
      "    1.15319951e-01 -2.26033364e-01]]] reward= -5098807.050472237 done= False\n",
      "Step 593\n",
      "Action:  [ 1.2123635   0.33297572 -1.0293893   1.3407053   2.8755908  -0.25003394]\n",
      "self.next: 593\n",
      "obs= [[[  2.69863187  -2.20430858  -0.32298487   0.69092344  -1.46030651\n",
      "     0.33641551]\n",
      "  [ -0.02964182   0.01749819   0.15601894  -0.14390802  -0.16630297\n",
      "     0.19690989]]\n",
      "\n",
      " [[ 10.54726015  -5.03864139  -7.24654257   2.10933325   4.01931833\n",
      "   -12.81748648]\n",
      "  [ -0.03693242   0.12789638  -0.12741005   0.03469276   0.11419561\n",
      "    -0.22609676]]] reward= -4932497.231728132 done= False\n",
      "Step 594\n",
      "Action:  [ 1.2134463   0.33379412 -1.0303305   1.3426746   2.8817542  -0.2508437 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 594\n",
      "obs= [[[ 2.69566769e+00 -2.20255876e+00 -3.07382977e-01  6.76532642e-01\n",
      "   -1.47693681e+00  3.56106502e-01]\n",
      "  [-2.94651136e-02  3.58590415e-02 -1.81575128e-01  2.36314802e-01\n",
      "   -6.17809664e-02 -5.00443808e-03]]\n",
      "\n",
      " [[ 1.05435669e+01 -5.02585175e+00 -7.25928358e+00  2.11280252e+00\n",
      "    4.03073789e+00 -1.28400962e+01]\n",
      "  [-3.90631413e-02  1.30673507e-01 -1.28325432e-01  3.58796746e-02\n",
      "    1.13085789e-01 -2.26180954e-01]]] reward= -6697192.538413514 done= False\n",
      "Step 595\n",
      "Action:  [ 1.2109795   0.3334932  -1.0284281   1.3411585   2.8726168  -0.24987368]\n",
      "self.next: 595\n",
      "obs= [[[  2.69272118  -2.19897286  -0.32554049   0.70016412  -1.4831149\n",
      "     0.35560606]\n",
      "  [  0.04096251  -0.01349377   0.14708504  -0.2328609    0.15143568\n",
      "    -0.37877541]]\n",
      "\n",
      " [[ 10.53966059  -5.0127844   -7.27211612   2.11639049   4.04204647\n",
      "   -12.86271425]\n",
      "  [ -0.04119208   0.13346102  -0.12924655   0.03706042   0.11199085\n",
      "    -0.22628626]]] reward= -7520015.137215476 done= False\n",
      "Step 596\n",
      "Action:  [ 1.1845654   0.332647   -1.0033486   1.3255501   2.788695   -0.23083146]\n",
      "self.next: 596\n",
      "obs= [[[  2.69681743  -2.20032223  -0.31083199   0.67687803  -1.46797133\n",
      "     0.31772852]\n",
      "  [  0.04604822  -0.04829273   0.03600322   0.03641228   0.09925393\n",
      "    -0.25385956]]\n",
      "\n",
      " [[ 10.53554138  -4.9994383   -7.28504078   2.12009653   4.05324555\n",
      "   -12.88534288]\n",
      "  [ -0.04331897   0.13625858  -0.13017308   0.03823476   0.11091113\n",
      "    -0.22641299]]] reward= -9263218.417447826 done= False\n",
      "Step 597\n",
      "Action:  [ 1.1895063   0.33294937 -1.00835     1.3294834   2.8077204  -0.23461337]\n",
      "self.next: 597\n",
      "obs= [[[ 2.70142225e+00 -2.20515151e+00 -3.07231664e-01  6.80519260e-01\n",
      "   -1.45804594e+00  2.92342562e-01]\n",
      "  [-4.83348272e-03  1.11114037e-02 -3.93380418e-02  3.67506734e-02\n",
      "   -4.19923334e-03  3.63771589e-04]]\n",
      "\n",
      " [[ 1.05312095e+01 -4.98581244e+00 -7.29805808e+00  2.12392001e+00\n",
      "    4.06433666e+00 -1.29079842e+01]\n",
      "  [-4.54434856e-02  1.39065762e-01 -1.31104698e-01  3.94024748e-02\n",
      "    1.09846991e-01 -2.26561484e-01]]] reward= -5950116.006293791 done= False\n",
      "Step 598\n",
      "Action:  [ 1.1940911   0.33461317 -1.0130694   1.3336807   2.8207455  -0.23842229]\n",
      "self.next: 598\n",
      "obs= [[[  2.7009389   -2.20404037  -0.31116547   0.68419433  -1.45846586\n",
      "     0.29237894]\n",
      "  [ -0.02900215   0.06286877  -0.03407577   0.06157367  -0.1228927\n",
      "    -0.07281783]]\n",
      "\n",
      " [[ 10.52666514  -4.97190586  -7.31116855   2.12786025   4.07532136\n",
      "   -12.93064033]\n",
      "  [ -0.04756533   0.14188212  -0.13204107   0.04056337   0.10879877\n",
      "    -0.22673207]]] reward= -4411876.564898139 done= False\n",
      "Step 599\n",
      "Action:  [ 1.1905037  0.3345325 -1.0095749  1.3326766  2.8117278 -0.235919 ]\n",
      "self.next: 599\n",
      "obs= [[[ 2.69803869e+00 -2.19775349e+00 -3.14573045e-01  6.90351694e-01\n",
      "   -1.47075513e+00  2.85097156e-01]\n",
      "  [-1.06554156e-02  3.27375986e-02 -1.65943244e-01  2.09953524e-01\n",
      "   -6.52843287e-02 -3.23015475e-02]]\n",
      "\n",
      " [[ 1.05219086e+01 -4.95771765e+00 -7.32437266e+00  2.13191659e+00\n",
      "    4.08620124e+00 -1.29533135e+01]\n",
      "  [-4.96841719e-02  1.44707148e-01 -1.32981834e-01  4.17172722e-02\n",
      "    1.07766783e-01 -2.26925074e-01]]] reward= -4890267.470179886 done= False\n",
      "Step 600\n",
      "Action:  [ 1.1898896   0.33490956 -1.0092896   1.3324121   2.8090162  -0.23603262]\n",
      "self.next: 600\n",
      "obs= [[[ 2.69697315e+00 -2.19447973e+00 -3.31167370e-01  7.11347047e-01\n",
      "   -1.47728357e+00  2.81867001e-01]\n",
      "  [ 3.55477594e-02  1.61599571e-02 -4.87123086e-02 -4.06668754e-03\n",
      "   -7.94465027e-04 -4.22553252e-02]]\n",
      "\n",
      " [[ 1.05169402e+01 -4.94324693e+00 -7.33767084e+00  2.13608832e+00\n",
      "    4.09697792e+00 -1.29760060e+01]\n",
      "  [-5.17996678e-02  1.47540269e-01 -1.33926622e-01  4.28640422e-02\n",
      "    1.06751358e-01 -2.27140839e-01]]] reward= -6581725.136073062 done= False\n",
      "Step 601\n",
      "Action:  [ 1.1803951   0.33550185 -1.0004237   1.3275286   2.7781782  -0.22939123]\n",
      "self.next: 601\n",
      "obs= [[[  2.70052792  -2.19286373  -0.3360386    0.71094038  -1.47736301\n",
      "     0.27764147]\n",
      "  [  0.07481198  -0.08285871   0.1849181   -0.16765785   0.05784671\n",
      "    -0.08753123]]\n",
      "\n",
      " [[ 10.51176022  -4.92849291  -7.35106351   2.14037472   4.10765305\n",
      "   -12.99872013]\n",
      "  [ -0.05391146   0.15038086  -0.13487505   0.04400356   0.1057528\n",
      "    -0.22737969]]] reward= -4621532.118638584 done= False\n",
      "Step 602\n",
      "Action:  [ 1.1714933   0.33498192 -0.9919068   1.3226229   2.753358   -0.22267802]\n",
      "self.next: 602\n",
      "obs= [[[ 2.70800912e+00 -2.20114961e+00 -3.17546790e-01  6.94174592e-01\n",
      "   -1.47157834e+00  2.68888346e-01]\n",
      "  [-5.19067083e-02  7.24508373e-03  4.30770523e-02  3.67933650e-03\n",
      "    3.28535326e-02 -2.10892450e-01]]\n",
      "\n",
      " [[ 1.05063691e+01 -4.91345482e+00 -7.36455101e+00  2.14477508e+00\n",
      "    4.11822833e+00 -1.30214581e+01]\n",
      "  [-5.60191653e-02  1.53228245e-01 -1.35826716e-01  4.51357072e-02\n",
      "    1.04771411e-01 -2.27641975e-01]]] reward= -8268810.144087397 done= False\n",
      "Step 603\n",
      "Action:  [ 1.1653463   0.3354432  -0.9866077   1.3200134   2.7337732  -0.21925373]\n",
      "self.next: 603\n",
      "obs= [[[ 2.70281845e+00 -2.20042510e+00 -3.13239085e-01  6.94542526e-01\n",
      "   -1.46829299e+00  2.47799101e-01]\n",
      "  [ 1.41179266e-02  1.96308137e-02 -6.65002576e-02  3.22278513e-02\n",
      "    1.89027339e-03 -2.29262020e-02]]\n",
      "\n",
      " [[ 1.05007672e+01 -4.89813200e+00 -7.37813368e+00  2.14928865e+00\n",
      "    4.12870548e+00 -1.30442223e+01]\n",
      "  [-5.81223830e-02  1.56081668e-01 -1.36781219e-01  4.62604168e-02\n",
      "    1.03807498e-01 -2.27928012e-01]]] reward= -5039382.174020922 done= False\n",
      "Step 604\n",
      "Action:  [ 1.1701691   0.33649012 -0.9913836   1.3235573   2.7474315  -0.22300194]\n",
      "self.next: 604\n",
      "obs= [[[  2.70423024  -2.19846202  -0.31988911   0.69776531  -1.46810396\n",
      "     0.24550648]\n",
      "  [ -0.03146193   0.02430874   0.04039459   0.0296511   -0.16385457\n",
      "    -0.01380578]]\n",
      "\n",
      " [[ 10.49495492  -4.88252383  -7.3918118    2.15391469   4.13908623\n",
      "   -13.06701509]\n",
      "  [ -0.06022069   0.15894032  -0.13773814   0.04737762   0.10286136\n",
      "    -0.22823813]]] reward= -4412719.373340783 done= False\n",
      "Step 605\n",
      "Action:  [ 1.167688    0.336314   -0.98882824  1.3234591   2.7439964  -0.22104849]\n",
      "self.next: 605\n",
      "obs= [[[  2.70108405  -2.19603114  -0.31584965   0.70073042  -1.48448942\n",
      "     0.2441259 ]\n",
      "  [  0.05328418  -0.0320502   -0.01958264   0.07299279   0.0933602\n",
      "    -0.27686556]]\n",
      "\n",
      " [[ 10.48893285  -4.8666298   -7.40558562   2.15865245   4.14937236\n",
      "   -13.08983891]\n",
      "  [ -0.06231364   0.16180335  -0.13869704   0.04848727   0.10193329\n",
      "    -0.22857265]]] reward= -5121763.704701952 done= False\n",
      "Step 606\n",
      "Action:  [ 1.1552659   0.3357464  -0.977367    1.3149887   2.7031565  -0.21276635]\n",
      "self.next: 606\n",
      "obs= [[[ 2.70641247e+00 -2.19923616e+00 -3.17807916e-01  7.08029700e-01\n",
      "   -1.47515340e+00  2.16439347e-01]\n",
      "  [ 1.77421033e-04 -5.22149627e-02  5.33265894e-02  7.80515001e-02\n",
      "   -7.93864795e-02  6.54626068e-02]]\n",
      "\n",
      " [[ 1.04827015e+01 -4.85044946e+00 -7.41945532e+00  2.16350118e+00\n",
      "    4.15956569e+00 -1.31126962e+01]\n",
      "  [-6.44007759e-02  1.64669814e-01 -1.39657476e-01  4.95893477e-02\n",
      "    1.01023537e-01 -2.28931875e-01]]] reward= -5381324.376352342 done= False\n",
      "Step 607\n",
      "Action:  [ 1.1615281  0.336948  -0.9834525  1.3207583  2.7255752 -0.217192 ]\n",
      "self.next: 607\n",
      "obs= [[[ 2.70643021e+00 -2.20445766e+00 -3.12475257e-01  7.15834850e-01\n",
      "   -1.48309205e+00  2.22985607e-01]\n",
      "  [ 8.06682405e-02 -1.21981767e-02  1.13101360e-01 -2.41650396e-01\n",
      "    6.14532391e-02 -5.63198391e-02]]\n",
      "\n",
      " [[ 1.04762614e+01 -4.83398248e+00 -7.43342107e+00  2.16846011e+00\n",
      "    4.16966804e+00 -1.31355894e+01]\n",
      "  [-6.64816105e-02  1.67538730e-01 -1.40618988e-01  5.06838350e-02\n",
      "    1.00132407e-01 -2.29316100e-01]]] reward= -4552941.341138983 done= False\n",
      "Step 608\n",
      "Action:  [ 1.150124    0.33761552 -0.97278816  1.3138653   2.6852372  -0.20943868]\n",
      "self.next: 608\n",
      "obs= [[[  2.71449704  -2.20567748  -0.30116512   0.69166981  -1.47694672\n",
      "     0.21735362]\n",
      "  [ -0.03286784   0.03791509  -0.18475343   0.24188539  -0.06306512\n",
      "    -0.01608708]]\n",
      "\n",
      " [[ 10.46961325  -4.81722861  -7.44748297   2.1735285    4.17968128\n",
      "   -13.15852097]\n",
      "  [ -0.06855564   0.17040905  -0.1415811    0.05177074   0.09926015\n",
      "    -0.2297256 ]]] reward= -8387115.993281991 done= False\n",
      "Step 609\n",
      "Action:  [ 1.157362    0.33774647 -0.9801008   1.318969    2.7096047  -0.21537021]\n",
      "self.next: 609\n",
      "obs= [[[  2.71121025  -2.20188597  -0.31964046   0.71585835  -1.48325324\n",
      "     0.21574492]\n",
      "  [ -0.01729909  -0.0773933    0.27296494  -0.09767669  -0.11364772\n",
      "    -0.0316518 ]]\n",
      "\n",
      " [[ 10.46275768  -4.8001877   -7.46164108   2.17870557   4.1896073\n",
      "   -13.18149353]\n",
      "  [ -0.07062233   0.17327966  -0.14254334   0.05285008   0.09840703\n",
      "    -0.23016065]]] reward= -7363703.840584331 done= False\n",
      "Step 610\n",
      "Action:  [ 1.1443917   0.33724633 -0.967374    1.312611    2.6751466  -0.20536621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 610\n",
      "obs= [[[  2.70948034  -2.2096253   -0.29234397   0.70609068  -1.49461801\n",
      "     0.21257974]\n",
      "  [ -0.08710087   0.08142259  -0.17105261   0.29226976  -0.12381413\n",
      "    -0.09439347]]\n",
      "\n",
      " [[ 10.45569545  -4.78285974  -7.47589541   2.18399058   4.199448\n",
      "   -13.2045096 ]\n",
      "  [ -0.07268113   0.1761494   -0.14350521   0.05392189   0.0975733\n",
      "    -0.23062148]]] reward= -6479944.262036028 done= False\n",
      "Step 611\n",
      "Action:  [ 1.1485146   0.33806893 -0.97190493  1.3150911   2.6837113  -0.20959601]\n",
      "self.next: 611\n",
      "obs= [[[  2.70077026  -2.20148304  -0.30944923   0.73531766  -1.50699942\n",
      "     0.20314039]\n",
      "  [ -0.0427587   -0.10614627   0.11098036   0.19521747  -0.18687305\n",
      "     0.13973311]]\n",
      "\n",
      " [[ 10.44842734  -4.7652448   -7.49024593   2.18938277   4.20920533\n",
      "   -13.22757174]\n",
      "  [ -0.07473147   0.17901702  -0.1444662    0.0549862    0.09675921\n",
      "    -0.23110831]]] reward= -7854295.681583129 done= False\n",
      "Step 612\n",
      "Action:  [ 1.1460216   0.33799133 -0.9692425   1.3149413   2.6820858  -0.20725912]\n",
      "self.next: 612\n",
      "obs= [[[ 2.69649439e+00 -2.21209767e+00 -2.98351195e-01  7.54839403e-01\n",
      "   -1.52568672e+00  2.17113699e-01]\n",
      "  [-5.45141054e-02  1.01604491e-01 -1.30126713e-02 -1.30553637e-01\n",
      "   -7.18637968e-02  8.54711948e-02]]\n",
      "\n",
      " [[ 1.04409542e+01 -4.74734309e+00 -7.50469255e+00  2.19488139e+00\n",
      "    4.21888125e+00 -1.32506826e+01]\n",
      "  [-7.67727401e-02  1.81881258e-01 -1.45425817e-01  5.60430677e-02\n",
      "    9.59649951e-02 -2.31621350e-01]]] reward= -6448980.021299247 done= False\n",
      "Step 613\n",
      "Action:  [ 1.1347363   0.3404876  -0.95916116  1.3089077   2.637037   -0.20057118]\n",
      "self.next: 613\n",
      "obs= [[[ 2.69104297e+00 -2.20193722e+00 -2.99652462e-01  7.41784040e-01\n",
      "   -1.53287310e+00  2.25660818e-01]\n",
      "  [-4.08138755e-02 -8.88215937e-02  2.74689309e-01  1.11300189e-02\n",
      "   -1.89823974e-01 -3.95914705e-02]]\n",
      "\n",
      " [[ 1.04332769e+01 -4.72915497e+00 -7.51923514e+00  2.20048570e+00\n",
      "    4.22847775e+00 -1.32738447e+01]\n",
      "  [-7.88043340e-02  1.84740763e-01 -1.46383521e-01  5.70925574e-02\n",
      "    9.51908796e-02 -2.32160750e-01]]] reward= -5749315.8657104755 done= False\n",
      "Step 614\n",
      "Action:  [ 1.1304159   0.33801883 -0.9544069   1.3067492   2.6346643  -0.19643883]\n",
      "self.next: 614\n",
      "obs= [[[  2.68696159  -2.21081938  -0.27218353   0.74289704  -1.5518555\n",
      "     0.22170167]\n",
      "  [ -0.04125487   0.03314036   0.04625215   0.01865302  -0.22031589\n",
      "     0.25023533]]\n",
      "\n",
      " [[ 10.42539648  -4.71068089  -7.53387349   2.20619495   4.23799684\n",
      "   -13.29706079]\n",
      "  [ -0.0808256    0.18759414  -0.14733879   0.05813473   0.0944371\n",
      "    -0.23272665]]] reward= -5515404.69000284 done= False\n",
      "Step 615\n",
      "Action:  [ 1.1365054   0.340398   -0.96072423  1.3113685   2.6482003  -0.20178844]\n",
      "self.next: 615\n",
      "obs= [[[  2.6828361   -2.20750534  -0.26755832   0.74476234  -1.57388709\n",
      "     0.2467252 ]\n",
      "  [  0.06651309   0.06782147  -0.17044393   0.03779475   0.08803095\n",
      "    -0.27422048]]\n",
      "\n",
      " [[ 10.41731392  -4.69192148  -7.54860737   2.21200842   4.24744055\n",
      "   -13.32033345]\n",
      "  [ -0.08283588   0.19043994  -0.14829109   0.05916965   0.09370386\n",
      "    -0.23331917]]] reward= -5283115.858820776 done= False\n",
      "Step 616\n",
      "Action:  [ 1.1200469   0.33953187 -0.94539446  1.2996253   2.5912633  -0.19085415]\n",
      "self.next: 616\n",
      "obs= [[[  2.68948741  -2.20072319  -0.28460271   0.74854182  -1.565084\n",
      "     0.21930316]\n",
      "  [ -0.07154408  -0.04117757   0.32980415  -0.21821079  -0.1628208\n",
      "     0.21986842]]\n",
      "\n",
      " [[ 10.40903033  -4.67287749  -7.56343648   2.21792539   4.25681094\n",
      "   -13.34366537]\n",
      "  [ -0.08483449   0.19327667  -0.14923988   0.0601974    0.09299137\n",
      "    -0.23393835]]] reward= -5255651.931007917 done= False\n",
      "Step 617\n",
      "Action:  [ 1.1202188   0.34086975 -0.94544476  1.3027737   2.59931    -0.19059917]\n",
      "self.next: 617\n",
      "obs= [[[ 2.68233300e+00 -2.20484095e+00 -2.51622295e-01  7.26720739e-01\n",
      "   -1.58136608e+00  2.41289999e-01]\n",
      "  [ 3.09924879e-02  1.75403618e-02 -4.80034098e-02 -3.19548084e-04\n",
      "   -1.38314996e-03 -5.28994165e-02]]\n",
      "\n",
      " [[ 1.04005469e+01 -4.65354982e+00 -7.57836046e+00  2.22394513e+00\n",
      "    4.26611007e+00 -1.33670592e+01]\n",
      "  [-8.68207255e-02  1.96102798e-01 -1.50184607e-01  6.12180533e-02\n",
      "    9.22998268e-02 -2.34584226e-01]]] reward= -7082876.158377517 done= False\n",
      "Step 618\n",
      "Action:  [ 1.1164325   0.34056085 -0.94224155  1.2996296   2.5829945  -0.18858439]\n",
      "self.next: 618\n",
      "obs= [[[  2.68543225  -2.20308691  -0.25642264   0.72668878  -1.58150439\n",
      "     0.23600006]\n",
      "  [ -0.03710427   0.05589071  -0.1969912    0.23186261  -0.12554368\n",
      "     0.11209188]]\n",
      "\n",
      " [[ 10.39186481  -4.63393954  -7.59337893   2.23006693   4.27534006\n",
      "   -13.39051762]\n",
      "  [ -0.08879387   0.19891673  -0.15112472   0.06223168   0.09162942\n",
      "    -0.23525679]]] reward= -4370156.484654442 done= False\n",
      "Step 619\n",
      "Action:  [ 1.1226975   0.34127697 -0.9484938   1.3043886   2.6028461  -0.19351642]\n",
      "self.next: 619\n",
      "obs= [[[  2.68172182  -2.19749784  -0.27612176   0.74987504  -1.59405876\n",
      "     0.24720925]\n",
      "  [  0.13544756  -0.02353102   0.06576056  -0.28516082   0.13204463\n",
      "     0.04105379]]\n",
      "\n",
      " [[ 10.38298543  -4.61404786  -7.6084914    2.2362901    4.284503\n",
      "   -13.4140433 ]\n",
      "  [ -0.09075317   0.20171686  -0.15205968   0.06323836   0.09098032\n",
      "    -0.23595598]]] reward= -7416675.500582911 done= False\n",
      "Step 620\n",
      "Action:  [ 1.1064597   0.3419946  -0.9330129   1.2941109   2.548994   -0.18215069]\n",
      "self.next: 620\n",
      "obs= [[[  2.69526658  -2.19985094  -0.2695457    0.72135896  -1.5808543\n",
      "     0.25131462]\n",
      "  [ -0.06840325   0.02039027   0.04936608   0.05262818  -0.14946381\n",
      "     0.0247439 ]]\n",
      "\n",
      " [[ 10.37391011  -4.59387618  -7.62369736   2.24261394   4.29360103\n",
      "   -13.4376389 ]\n",
      "  [ -0.0926979    0.20450152  -0.1529889    0.06423816   0.09035268\n",
      "    -0.23668169]]] reward= -9621735.640529936 done= False\n",
      "Step 621\n",
      "Action:  [ 1.1077254   0.3415357  -0.93439525  1.29687     2.5589979  -0.18316837]\n",
      "self.next: 621\n",
      "obs= [[[ 2.68842625e+00 -2.19781192e+00 -2.64609092e-01  7.26621781e-01\n",
      "   -1.59580068e+00  2.53789014e-01]\n",
      "  [-8.61002387e-03 -6.73005626e-03  1.57698796e-02  2.93784353e-04\n",
      "   -1.22137876e-03  9.10809317e-02]]\n",
      "\n",
      " [[ 1.03646403e+01 -4.57342603e+00 -7.63899625e+00  2.24903776e+00\n",
      "    4.30263630e+00 -1.34613071e+01]\n",
      "  [-9.46272606e-02  2.07269023e-01 -1.53911837e-01  6.52311512e-02\n",
      "    8.97466739e-02 -2.37433752e-01]]] reward= -5059281.825958277 done= False\n",
      "Step 622\n",
      "Action:  [ 1.103119    0.3424423  -0.93037045  1.2941402   2.5419915  -0.18046325]\n",
      "self.next: 622\n",
      "obs= [[[ 2.68756525e+00 -2.19848492e+00 -2.63032104e-01  7.26651160e-01\n",
      "   -1.59592281e+00  2.62897107e-01]\n",
      "  [ 1.87070278e-02 -7.04337743e-02  9.31221644e-02  3.67768140e-02\n",
      "   -7.41494075e-03 -1.45761731e-01]]\n",
      "\n",
      " [[ 1.03551776e+01 -4.55269912e+00 -7.65438744e+00  2.25556087e+00\n",
      "    4.31161096e+00 -1.34850504e+01]\n",
      "  [-9.65404896e-02  2.10017660e-01 -1.54827933e-01  6.62173837e-02\n",
      "    8.91624222e-02 -2.38211968e-01]]] reward= -4445567.713302745 done= False\n",
      "Step 623\n",
      "Action:  [ 1.095917    0.3410706  -0.9232715   1.2894481   2.522905   -0.17515397]\n",
      "self.next: 623\n",
      "obs= [[[ 2.68943595e+00 -2.20552830e+00 -2.53719887e-01  7.30328841e-01\n",
      "   -1.59666431e+00  2.48320934e-01]\n",
      "  [-1.16882108e-01  5.06749631e-02 -8.35524899e-03  7.81232875e-02\n",
      "   -1.69484274e-01  3.04908703e-01]]\n",
      "\n",
      " [[ 1.03455235e+01 -4.53169736e+00 -7.66987023e+00  2.26218261e+00\n",
      "    4.32052721e+00 -1.35088716e+01]\n",
      "  [-9.84367891e-02  2.12745691e-01 -1.55736624e-01  6.71969102e-02\n",
      "    8.86000509e-02 -2.39016067e-01]]] reward= -4727201.94284002 done= False\n",
      "Step 624\n",
      "Action:  [ 1.1027566   0.34390417 -0.93045896  1.2960105   2.541636   -0.18106037]\n",
      "self.next: 624\n",
      "obs= [[[  2.67774774  -2.2004608   -0.25455541   0.73814117  -1.61361273\n",
      "     0.2788118 ]\n",
      "  [  0.13304957   0.01469979  -0.14608798  -0.05572922   0.14810355\n",
      "    -0.12540868]]\n",
      "\n",
      " [[ 10.33567987  -4.51042279  -7.68544389   2.2689023    4.32938721\n",
      "   -13.53277325]\n",
      "  [ -0.10031535   0.21545136  -0.15663736   0.06816977   0.08805968\n",
      "    -0.23984573]]] reward= -6628536.403564939 done= False\n",
      "Step 625\n",
      "Action:  [ 1.0900682   0.3429429  -0.9183166   1.2862219   2.497709   -0.17224523]\n",
      "self.next: 625\n",
      "obs= [[[  2.6910527   -2.19899083  -0.26916421   0.73256825  -1.59880238\n",
      "     0.26627094]\n",
      "  [ -0.06272041  -0.05946204   0.33470413  -0.1591042   -0.14721737\n",
      "     0.05067705]]\n",
      "\n",
      " [[ 10.32564833  -4.48887765  -7.70110763   2.27571928   4.33819318\n",
      "   -13.55675782]\n",
      "  [ -0.10217538   0.21813291  -0.15752958   0.069136     0.08754138\n",
      "    -0.24070058]]] reward= -6390054.060609773 done= False\n",
      "Step 626\n",
      "Action:  [ 1.0853009   0.3428899  -0.91354746  1.2858913   2.491793   -0.16846016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 626\n",
      "obs= [[[ 2.68478066e+00 -2.20493703e+00 -2.35693797e-01  7.16657828e-01\n",
      "   -1.61352412e+00  2.71338641e-01]\n",
      "  [ 9.11915848e-02  5.67314654e-03 -9.25645644e-02 -1.14565791e-01\n",
      "    2.03319317e-01 -9.73911604e-02]]\n",
      "\n",
      " [[ 1.03154308e+01 -4.46706436e+00 -7.71686059e+00  2.28263288e+00\n",
      "    4.34694732e+00 -1.35808279e+01]\n",
      "  [-1.04016049e-01  2.20788542e-01 -1.58412737e-01  7.00956108e-02\n",
      "    8.70452339e-02 -2.41580161e-01]]] reward= -6751564.479123084 done= False\n",
      "Step 627\n",
      "Action:  [ 1.0812781   0.34386468 -0.91048855  1.2818536   2.4700334  -0.16681822]\n",
      "self.next: 627\n",
      "obs= [[[  2.69389982  -2.20436971  -0.24495025   0.70520125  -1.59319219\n",
      "     0.26159953]\n",
      "  [ -0.04858209   0.04540399  -0.03958468   0.09587468  -0.14729402\n",
      "     0.0626704 ]]\n",
      "\n",
      " [[ 10.30502919  -4.44498551  -7.73270186   2.28964244   4.35565184\n",
      "   -13.6049859 ]\n",
      "  [ -0.10583654   0.22341649  -0.15928628   0.0710486    0.0865713\n",
      "    -0.24248398]]] reward= -6027613.479559881 done= False\n",
      "Step 628\n",
      "Action:  [ 1.0868518   0.34402913 -0.9158209   1.2875768   2.4927557  -0.1706707 ]\n",
      "self.next: 628\n",
      "obs= [[[  2.68904161  -2.19982932  -0.24890872   0.71478872  -1.60792159\n",
      "     0.26786656]\n",
      "  [ -0.04282388  -0.04841377   0.13087894   0.01579914  -0.05874667\n",
      "     0.03776842]]\n",
      "\n",
      " [[ 10.29444553  -4.42264386  -7.74863049   2.2967473    4.36430897\n",
      "   -13.62923429]\n",
      "  [ -0.10763603   0.22601496  -0.16014968   0.07199496   0.08611963\n",
      "    -0.24341146]]] reward= -5266685.679658879 done= False\n",
      "Step 629\n",
      "Action:  [ 1.0774947   0.34398806 -0.90694284  1.2820635   2.4652827  -0.16420564]\n",
      "self.next: 629\n",
      "obs= [[[ 2.68475922e+00 -2.20467069e+00 -2.35820828e-01  7.16368631e-01\n",
      "   -1.61379625e+00  2.71643407e-01]\n",
      "  [ 4.30951520e-02 -4.27491574e-02 -4.84744287e-04  7.91787022e-02\n",
      "   -7.92565815e-03 -4.41041378e-02]]\n",
      "\n",
      " [[ 1.02836819e+01 -4.40004236e+00 -7.76464546e+00  2.30394680e+00\n",
      "    4.37292093e+00 -1.36535754e+01]\n",
      "  [-1.09413692e-01  2.28582189e-01 -1.61002397e-01  7.29346581e-02\n",
      "    8.56902113e-02 -2.44361963e-01]]] reward= -4449262.443383432 done= False\n",
      "Step 630\n",
      "Action:  [ 1.0767545   0.34389347 -0.9063481   1.2813118   2.4617257  -0.16391596]\n",
      "self.next: 630\n",
      "obs= [[[ 2.68906874e+00 -2.20894561e+00 -2.35869302e-01  7.24286501e-01\n",
      "   -1.61458882e+00  2.67232993e-01]\n",
      "  [-3.73138580e-02  7.16116232e-03  3.38301857e-02 -5.72051623e-02\n",
      "   -1.53200441e-02  1.24161029e-01]]\n",
      "\n",
      " [[ 1.02727406e+01 -4.37718414e+00 -7.78074570e+00  2.31124026e+00\n",
      "    4.38148995e+00 -1.36780116e+01]\n",
      "  [-1.11168710e-01  2.31116397e-01 -1.61843902e-01  7.38676404e-02\n",
      "    8.52830592e-02 -2.45334790e-01]]] reward= -5101538.935320889 done= False\n",
      "Step 631\n",
      "Action:  [ 1.0717998   0.34567624 -0.9020863   1.279628    2.4439318  -0.16122574]\n",
      "self.next: 631\n",
      "obs= [[[ 2.68533735e+00 -2.20822949e+00 -2.32486283e-01  7.18565985e-01\n",
      "   -1.61612082e+00  2.79649096e-01]\n",
      "  [ 3.38083536e-02  3.11510858e-02 -6.52015268e-02 -1.43631263e-04\n",
      "    9.14132473e-02 -1.25916559e-01]]\n",
      "\n",
      " [[ 1.02616237e+01 -4.35407250e+00 -7.79693009e+00  2.31862702e+00\n",
      "    4.39001826e+00 -1.37025451e+01]\n",
      "  [-1.12900263e-01  2.33615833e-01 -1.62673677e-01  7.47938404e-02\n",
      "    8.48981377e-02 -2.46329165e-01]]] reward= -3942590.03500031 done= False\n",
      "Step 632\n",
      "Action:  [ 1.0664783   0.34510583 -0.89715326  1.2755637   2.4263675  -0.15769096]\n",
      "self.next: 632\n",
      "obs= [[[ 2.68871819e+00 -2.20511438e+00 -2.39006436e-01  7.18551622e-01\n",
      "   -1.60697950e+00  2.67057440e-01]\n",
      "  [-2.48254943e-03  1.50179782e-02 -5.40419293e-02  4.06797554e-02\n",
      "    1.17075911e-03  2.52091041e-04]]\n",
      "\n",
      " [[ 1.02503337e+01 -4.33071092e+00 -7.81319746e+00  2.32610641e+00\n",
      "    4.39850807e+00 -1.37271780e+01]\n",
      "  [-1.14607536e-01  2.36078758e-01 -1.63491211e-01  7.57131659e-02\n",
      "    8.45353955e-02 -2.47344244e-01]]] reward= -5264265.796893718 done= False\n",
      "Step 633\n",
      "Action:  [ 1.0660075   0.34573123 -0.8969125   1.2764316   2.425815   -0.15766984]\n",
      "self.next: 633\n",
      "obs= [[[ 2.68846993e+00 -2.20361259e+00 -2.44410629e-01  7.22619597e-01\n",
      "   -1.60686242e+00  2.67082649e-01]\n",
      "  [ 1.33223636e-02 -8.91356919e-03  3.72002303e-02 -4.20414507e-02\n",
      "    1.06477126e-03 -8.72709516e-02]]\n",
      "\n",
      " [[ 1.02388729e+01 -4.30710305e+00 -7.82954658e+00  2.33367773e+00\n",
      "    4.40696161e+00 -1.37519125e+01]\n",
      "  [-1.16289717e-01  2.38503458e-01 -1.64296007e-01  7.66255053e-02\n",
      "    8.41947597e-02 -2.48379119e-01]]] reward= -4518833.719883175 done= False\n",
      "Step 634\n",
      "Action:  [ 1.059487    0.3456307  -0.89068466  1.2726272   2.4065344  -0.15320046]\n",
      "self.next: 634\n",
      "obs= [[[  2.68980217  -2.20450394  -0.24069061   0.71841545  -1.60675595\n",
      "     0.25835555]\n",
      "  [  0.04132458   0.04108935  -0.08411263  -0.07931709   0.07996155\n",
      "     0.0450912 ]]\n",
      "\n",
      " [[ 10.22724394  -4.2832527   -7.84597618   2.34134028   4.41538109\n",
      "   -13.77675037]\n",
      "  [ -0.11794601   0.24088824  -0.16508757   0.07753072   0.08387612\n",
      "    -0.2494328 ]]] reward= -4491085.662884209 done= False\n",
      "Step 635\n",
      "Action:  [ 1.058386    0.3471553  -0.89017445  1.2725203   2.3992982  -0.15323879]\n",
      "self.next: 635\n",
      "obs= [[[  2.69393462  -2.20039501  -0.24910187   0.71048374  -1.59875979\n",
      "     0.26286467]\n",
      "  [ -0.07004494   0.05281071  -0.11436107   0.19380012  -0.13710101\n",
      "     0.0616183 ]]\n",
      "\n",
      " [[ 10.21544934  -4.25916388  -7.86248493   2.34909335   4.4237687\n",
      "   -13.80169365]\n",
      "  [ -0.1195756    0.24323145  -0.16586541   0.07842866   0.08357936\n",
      "    -0.25050425]]] reward= -5078075.080481339 done= False\n",
      "Step 636\n",
      "Action:  [ 1.0615427   0.34671256 -0.89322793  1.2754246   2.4126568  -0.15546995]\n",
      "self.next: 636\n",
      "obs= [[[ 2.68693013e+00 -2.19511394e+00 -2.60537975e-01  7.29863755e-01\n",
      "   -1.61246989e+00  2.69026504e-01]\n",
      "  [-1.48361104e-02 -9.39434486e-03  2.54361441e-02 -2.26508034e-03\n",
      "    1.18732804e-03  2.52227081e-02]]\n",
      "\n",
      " [[ 1.02034918e+01 -4.23484073e+00 -7.87907148e+00  2.35693621e+00\n",
      "    4.43212664e+00 -1.38267441e+01]\n",
      "  [-1.21177725e-01  2.45531441e-01 -1.66629077e-01  7.93191344e-02\n",
      "    8.33043179e-02 -2.51592325e-01]]] reward= -6991942.490415206 done= False\n",
      "Step 637\n",
      "Action:  [ 1.0503144   0.3472302  -0.8825947   1.2686108   2.377127   -0.14791557]\n",
      "self.next: 637\n",
      "obs= [[[ 2.68544652e+00 -2.19605337e+00 -2.57994361e-01  7.29637247e-01\n",
      "   -1.61235116e+00  2.71548775e-01]\n",
      "  [ 4.86099414e-04  7.92811752e-04  4.64973865e-04 -3.83968849e-03\n",
      "    9.37803794e-04  1.08052062e-03]]\n",
      "\n",
      " [[ 1.01913740e+01 -4.21028759e+00 -7.89573438e+00  2.36486813e+00\n",
      "    4.44045707e+00 -1.38519033e+01]\n",
      "  [-1.22751597e-01  2.47786633e-01 -1.67378087e-01  8.02019369e-02\n",
      "    8.30507974e-02 -2.52695842e-01]]] reward= -4147246.2595713604 done= False\n",
      "Step 638\n",
      "Action:  [ 1.0475019   0.34750533 -0.8800672   1.2671703   2.3680131  -0.14623539]\n",
      "self.next: 638\n",
      "obs= [[[ 2.68549513e+00 -2.19597409e+00 -2.57947863e-01  7.29253279e-01\n",
      "   -1.61225738e+00  2.71656827e-01]\n",
      "  [ 4.03050683e-02 -1.63732553e-02  1.06410197e-01 -1.85284748e-01\n",
      "    5.33462636e-02 -9.06376853e-03]]\n",
      "\n",
      " [[ 1.01790988e+01 -4.18550892e+00 -7.91247219e+00  2.37288832e+00\n",
      "    4.44876215e+00 -1.38771729e+01]\n",
      "  [-1.24296451e-01  2.49995463e-01 -1.68111996e-01  8.10768354e-02\n",
      "    8.28185884e-02 -2.53813536e-01]]] reward= -4090123.7087716465 done= False\n",
      "Step 639\n",
      "Action:  [ 1.0407628   0.34801492 -0.87372947  1.2632529   2.3466685  -0.1418182 ]\n",
      "self.next: 639\n",
      "obs= [[[  2.68952564  -2.19761142  -0.24730684   0.7107248   -1.60692275\n",
      "     0.27075045]\n",
      "  [  0.04029158   0.02077888  -0.01450228  -0.12715493   0.0828312\n",
      "    -0.01955346]]\n",
      "\n",
      " [[ 10.1666692   -4.16050938  -7.92928339   2.38099601   4.45704401\n",
      "   -13.90255424]\n",
      "  [ -0.12581153   0.25215641  -0.16883036   0.08194357   0.08260744\n",
      "    -0.25494407]]] reward= -6921058.957266351 done= False\n",
      "Step 640\n",
      "Action:  [ 1.039624    0.34852988 -0.8730497   1.2627716   2.3414674  -0.14152542]\n",
      "self.next: 640\n",
      "obs= [[[ 2.69355479e+00 -2.19553353e+00 -2.48757071e-01  6.98009311e-01\n",
      "   -1.59863963e+00  2.68795104e-01]\n",
      "  [ 8.09090243e-04 -2.37155072e-04  4.97778011e-04 -1.90896154e-03\n",
      "    5.82605409e-04  4.62087673e-05]]\n",
      "\n",
      " [[ 1.01540880e+01 -4.13529374e+00 -7.94616643e+00  2.38919036e+00\n",
      "    4.46530475e+00 -1.39280487e+01]\n",
      "  [-1.27296103e-01  2.54268010e-01 -1.69532758e-01  8.28018623e-02\n",
      "    8.24170767e-02 -2.56086058e-01]]] reward= -5550072.951211165 done= False\n",
      "Step 641\n",
      "Action:  [ 1.039053    0.34845617 -0.8726589   1.2630368   2.3415685  -0.14127837]\n",
      "self.next: 641\n",
      "obs= [[[ 2.69363570e+00 -2.19555724e+00 -2.48707294e-01  6.97818415e-01\n",
      "   -1.59858137e+00  2.68799724e-01]\n",
      "  [ 1.66169021e-02  8.73709443e-03 -2.40951559e-02 -1.63487044e-03\n",
      "    2.05760243e-03 -2.65472987e-02]]\n",
      "\n",
      " [[ 1.01413584e+01 -4.10986694e+00 -7.96311970e+00  2.39747055e+00\n",
      "    4.47354646e+00 -1.39536573e+01]\n",
      "  [-1.28749423e-01  2.56328818e-01 -1.70218765e-01  8.36513985e-02\n",
      "    8.22471858e-02 -2.57238020e-01]]] reward= -4093541.7816027687 done= False\n",
      "Step 642\n",
      "Action:  [ 1.0363936   0.34872472 -0.8702892   1.2616311   2.3329144  -0.13970537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 642\n",
      "obs= [[[ 2.69529739e+00 -2.19468353e+00 -2.51116809e-01  6.97654928e-01\n",
      "   -1.59837561e+00  2.66144995e-01]\n",
      "  [-1.43898976e-03 -3.06119472e-04  6.63281024e-04  2.74537526e-03\n",
      "   -5.06578793e-03  1.67233713e-03]]\n",
      "\n",
      " [[ 1.01284835e+01 -4.08423405e+00 -7.98014158e+00  2.40583569e+00\n",
      "    4.48177118e+00 -1.39793811e+01]\n",
      "  [-1.30170777e-01  2.58337451e-01 -1.70887972e-01  8.44918463e-02\n",
      "    8.20974188e-02 -2.58398430e-01]]] reward= -4235480.7720807195 done= False\n",
      "Step 643\n",
      "Action:  [ 1.0330399   0.34913945 -0.8672842   1.260031    2.3226125  -0.13770199]\n",
      "self.next: 643\n",
      "obs= [[[ 2.69515349e+00 -2.19471415e+00 -2.51050481e-01  6.97929465e-01\n",
      "   -1.59888219e+00  2.66312228e-01]\n",
      "  [ 1.54731139e-02  9.62799637e-03 -2.23819573e-02 -3.37481964e-03\n",
      "    2.19079413e-04 -2.53349808e-02]]\n",
      "\n",
      " [[ 1.01154664e+01 -4.05840031e+00 -7.99723038e+00  2.41428487e+00\n",
      "    4.48998092e+00 -1.40052209e+01]\n",
      "  [-1.31559458e-01  2.60292569e-01 -1.71539981e-01  8.53228471e-02\n",
      "    8.19673941e-02 -2.59565691e-01]]] reward= -4052984.796146388 done= False\n",
      "Step 644\n",
      "Action:  [ 1.0302781   0.34942982 -0.8648176   1.2585393   2.3135722  -0.13606249]\n",
      "self.next: 644\n",
      "obs= [[[ 2.69670081e+00 -2.19375135e+00 -2.53288677e-01  6.97591983e-01\n",
      "   -1.59886028e+00  2.63778730e-01]\n",
      "  [-3.13537379e-03 -4.88493559e-02  5.21399013e-02  7.78216170e-02\n",
      "   -8.04834344e-02  7.21571919e-02]]\n",
      "\n",
      " [[ 1.01023105e+01 -4.03237105e+00 -8.01438438e+00  2.42281716e+00\n",
      "    4.49817766e+00 -1.40311775e+01]\n",
      "  [-1.32914770e-01  2.62192880e-01 -1.72174404e-01  8.61440183e-02\n",
      "    8.18566952e-02 -2.60738148e-01]]] reward= -4236897.632444646 done= False\n",
      "Step 645\n",
      "Action:  [ 1.029399    0.3495072  -0.8640172   1.2587029   2.312974   -0.13563393]\n",
      "self.next: 645\n",
      "obs= [[[  2.69638727  -2.19863628  -0.24807469   0.70537414  -1.60690863\n",
      "     0.27099445]\n",
      "  [ -0.02054267  -0.03254149   0.27884781  -0.225175    -0.09425042\n",
      "     0.16616274]]\n",
      "\n",
      " [[ 10.08901899  -4.00615176  -8.03160182   2.43143156   4.50636333\n",
      "   -14.05725129]\n",
      "  [ -0.13423603   0.26403714  -0.17279087   0.08695495   0.08176487\n",
      "    -0.26191409]]] reward= -4481635.589164967 done= False\n",
      "Step 646\n",
      "Action:  [ 1.0208825   0.3506662  -0.85587305  1.2542756   2.2863579  -0.13015871]\n",
      "self.next: 646\n",
      "obs= [[[ 2.69433300e+00 -2.20189043e+00 -2.20189906e-01  6.82856645e-01\n",
      "   -1.61633367e+00  2.87610724e-01]\n",
      "  [-1.83391503e-03 -1.66740855e-03  1.43862565e-03  1.88054464e-03\n",
      "    2.16250029e-03 -1.76727422e-03]]\n",
      "\n",
      " [[ 1.00755954e+01 -3.97974805e+00 -8.04888090e+00  2.44012705e+00\n",
      "    4.51453982e+00 -1.40834427e+01]\n",
      "  [-1.35522564e-01  2.65824156e-01 -1.73388993e-01  8.77552261e-02\n",
      "    8.16914268e-02 -2.63091733e-01]]] reward= -8375541.153887514 done= False\n",
      "Step 647\n",
      "Action:  [ 1.0220104  0.3503042 -0.8573938  1.2543393  2.288005  -0.1311794]\n",
      "self.next: 647\n",
      "obs= [[[ 2.69414961e+00 -2.20205717e+00 -2.20046043e-01  6.83044700e-01\n",
      "   -1.61611742e+00  2.87433996e-01]\n",
      "  [ 5.46073474e-03  1.01466907e-02 -6.53866540e-02  1.31930403e-01\n",
      "   -8.68854704e-02 -5.42302420e-02]]\n",
      "\n",
      " [[ 1.00620431e+01 -3.95316563e+00 -8.06621980e+00  2.44890258e+00\n",
      "    4.52270896e+00 -1.41097519e+01]\n",
      "  [-1.36773713e-01  2.67552784e-01 -1.73968438e-01  8.85443862e-02\n",
      "    8.16358423e-02 -2.64269265e-01]]] reward= -4086622.5434604906 done= False\n",
      "Step 648\n",
      "Action:  [ 1.0235425   0.35001653 -0.85890937  1.2554675   2.2936635  -0.13229299]\n",
      "self.next: 648\n",
      "obs= [[[ 2.69469568e+00 -2.20104250e+00 -2.26584708e-01  6.96237740e-01\n",
      "   -1.62480597e+00  2.82010972e-01]\n",
      "  [ 5.12540555e-03  3.29479247e-02  1.06944913e-02 -1.25420253e-01\n",
      "    9.84720710e-02 -7.80815841e-03]]\n",
      "\n",
      " [[ 1.00483658e+01 -3.92641036e+00 -8.08361665e+00  2.45775702e+00\n",
      "    4.53087254e+00 -1.41361788e+01]\n",
      "  [-1.37988826e-01  2.69221930e-01 -1.74528855e-01  8.93219660e-02\n",
      "    8.15975542e-02 -2.65444810e-01]]] reward= -4878045.646277133 done= False\n",
      "Step 649\n",
      "Action:  [ 1.0125878   0.35159203 -0.84885615  1.2489339   2.2564025  -0.12547117]\n",
      "self.next: 649\n",
      "obs= [[[ 2.69520822e+00 -2.19774771e+00 -2.25515259e-01  6.83695715e-01\n",
      "   -1.61495876e+00  2.81230156e-01]\n",
      "  [-1.89436245e-02 -4.19293446e-02  1.40097339e-02  1.23710573e-01\n",
      "   -9.87351347e-02  3.29524779e-02]]\n",
      "\n",
      " [[ 1.00345669e+01 -3.89948816e+00 -8.10106953e+00  2.46668921e+00\n",
      "    4.53903230e+00 -1.41627233e+01]\n",
      "  [-1.39167269e-01  2.70830557e-01 -1.75069902e-01  9.00874782e-02\n",
      "    8.15759516e-02 -2.66616441e-01]]] reward= -5735520.840477846 done= False\n",
      "Step 650\n",
      "Action:  [ 1.0162174   0.35082933 -0.85223824  1.2517579   2.2713783  -0.12790997]\n",
      "self.next: 650\n",
      "obs= [[[ 2.69331386e+00 -2.20194064e+00 -2.24114286e-01  6.96066772e-01\n",
      "   -1.62483227e+00  2.84525404e-01]\n",
      "  [ 3.08263581e-02  5.10800097e-02 -8.02785489e-02 -1.50729419e-03\n",
      "    1.89319986e-02 -8.82205733e-02]]\n",
      "\n",
      " [[ 1.00206502e+01 -3.87240511e+00 -8.11857652e+00  2.47569796e+00\n",
      "    4.54718989e+00 -1.41893849e+01]\n",
      "  [-1.40308413e-01  2.72377676e-01 -1.75591266e-01  9.08404215e-02\n",
      "    8.15704060e-02 -2.67782201e-01]]] reward= -5334401.390013022 done= False\n",
      "Step 651\n",
      "Action:  [ 1.0113571   0.351612   -0.8479256   1.2485768   2.2530577  -0.12491579]\n",
      "self.next: 651\n",
      "obs= [[[ 2.69639650e+00 -2.19683264e+00 -2.32142141e-01  6.95916042e-01\n",
      "   -1.62293907e+00  2.75703347e-01]\n",
      "  [-2.06329484e-02 -1.28200734e-02  3.21564324e-02  1.07846486e-03\n",
      "    4.29911004e-03 -3.94714503e-02]]\n",
      "\n",
      " [[ 1.00066193e+01 -3.84516734e+00 -8.13613565e+00  2.48478200e+00\n",
      "    4.55534694e+00 -1.42161631e+01]\n",
      "  [-1.41411646e-01  2.73862353e-01 -1.76092631e-01  9.15802791e-02\n",
      "    8.15802327e-02 -2.68940083e-01]]] reward= -4849057.003468576 done= False\n",
      "Step 652\n",
      "Action:  [ 1.0059849   0.35186002 -0.8429068   1.2456154   2.2375808  -0.12151007]\n",
      "self.next: 652\n",
      "obs= [[[ 2.69433320e+00 -2.19811465e+00 -2.28926498e-01  6.96023889e-01\n",
      "   -1.62250916e+00  2.71756202e-01]\n",
      "  [ 1.22603208e-02  2.41570918e-02 -8.35060014e-02  4.83811305e-02\n",
      "    2.07324590e-03 -2.77856559e-02]]\n",
      "\n",
      " [[ 9.99247815e+00 -3.81778110e+00 -8.15374491e+00  2.49394003e+00\n",
      "    4.56350496e+00 -1.42430571e+01]\n",
      "  [-1.42476364e-01  2.75283709e-01 -1.76573698e-01  9.23065223e-02\n",
      "    8.16047168e-02 -2.70088051e-01]]] reward= -4133200.9254755094 done= False\n",
      "Step 653\n",
      "Action:  [ 1.0064124   0.3523253  -0.8435787   1.2461439   2.2375894  -0.12214623]\n",
      "self.next: 653\n",
      "obs= [[[ 2.69555924e+00 -2.19569894e+00 -2.37277098e-01  7.00862002e-01\n",
      "   -1.62230184e+00  2.68977636e-01]\n",
      "  [-1.91158022e-02  1.82578102e-02 -6.36478250e-04  5.46164460e-02\n",
      "   -1.53049189e-01  1.17751368e-01]]\n",
      "\n",
      " [[ 9.97823051e+00 -3.79025273e+00 -8.17140228e+00  2.50317068e+00\n",
      "    4.57166543e+00 -1.42700660e+01]\n",
      "  [-1.43501978e-01  2.76640922e-01 -1.77034188e-01  9.30186151e-02\n",
      "    8.16431088e-02 -2.71224044e-01]]] reward= -4348744.960813872 done= False\n",
      "Step 654\n",
      "Action:  [ 1.0049601   0.3528922  -0.84218556  1.2463152   2.2343738  -0.12153922]\n",
      "self.next: 654\n",
      "obs= [[[ 2.69364766e+00 -2.19387316e+00 -2.37340745e-01  7.06323647e-01\n",
      "   -1.63760676e+00  2.80752773e-01]\n",
      "  [-7.89089421e-03  3.22343280e-02  2.34810047e-02 -4.53038377e-02\n",
      "   -6.22304741e-02 -5.14945034e-02]]\n",
      "\n",
      " [[ 9.96388031e+00 -3.76258864e+00 -8.18910570e+00  2.51247254e+00\n",
      "    4.57982974e+00 -1.42971884e+01]\n",
      "  [-1.44487912e-01  2.77933226e-01 -1.77473829e-01  9.37160134e-02\n",
      "    8.16946181e-02 -2.72345973e-01]]] reward= -4555885.725006738 done= False\n",
      "Step 655\n",
      "Action:  [ 0.9981928   0.35298443 -0.835839    1.2416905   2.2125685  -0.11696389]\n",
      "self.next: 655\n",
      "obs= [[[ 2.69285857e+00 -2.19064973e+00 -2.34992645e-01  7.01793263e-01\n",
      "   -1.64382980e+00  2.75603323e-01]\n",
      "  [-6.20878295e-02  4.35274402e-02 -2.72328960e-02  9.97098748e-02\n",
      "   -1.54580575e-01  4.58947471e-03]]\n",
      "\n",
      " [[ 9.94943152e+00 -3.73479532e+00 -8.20685308e+00  2.52184415e+00\n",
      "    4.58799920e+00 -1.43244230e+01]\n",
      "  [-1.45433603e-01  2.79159913e-01 -1.77892360e-01  9.43981680e-02\n",
      "    8.17584149e-02 -2.73451729e-01]]] reward= -5036011.310046001 done= False\n",
      "Step 656\n",
      "Action:  [ 0.9989611   0.35316572 -0.83673996  1.2426306   2.2154095  -0.11779603]\n",
      "self.next: 656\n",
      "obs= [[[ 2.68664978e+00 -2.18629698e+00 -2.37715935e-01  7.11764250e-01\n",
      "   -1.65928786e+00  2.76062270e-01]\n",
      "  [ 5.53585336e-03 -1.64064720e-02  5.92050832e-02 -4.63269091e-02\n",
      "    3.53571845e-04 -1.02648316e-03]]\n",
      "\n",
      " [[ 9.93488816e+00 -3.70687933e+00 -8.22464232e+00  2.53128396e+00\n",
      "    4.59617504e+00 -1.43517681e+01]\n",
      "  [-1.46338505e-01  2.80320337e-01 -1.78289549e-01  9.50645324e-02\n",
      "    8.18336431e-02 -2.74539199e-01]]] reward= -5285979.424423596 done= False\n",
      "Step 657\n",
      "Action:  [ 0.9909562   0.35369816 -0.82919943  1.2373894   2.1897674  -0.11264177]\n",
      "self.next: 657\n",
      "obs= [[[ 2.68720337e+00 -2.18793763e+00 -2.31795426e-01  7.07131559e-01\n",
      "   -1.65925250e+00  2.75959622e-01]\n",
      "  [ 3.23132034e-03  2.17932309e-02 -7.12708647e-02  4.56842028e-02\n",
      "   -3.00201550e-03 -8.63836453e-02]]\n",
      "\n",
      " [[ 9.92025431e+00 -3.67884729e+00 -8.24247127e+00  2.54079042e+00\n",
      "    4.60435841e+00 -1.43792220e+01]\n",
      "  [-1.47202091e-01  2.81413916e-01 -1.78665168e-01  9.57145589e-02\n",
      "    8.19194019e-02 -2.75606258e-01]]] reward= -4974814.983844472 done= False\n",
      "Step 658\n",
      "Action:  [ 0.99158126  0.35371557 -0.83005923  1.2376894   2.1908054  -0.11320613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 658\n",
      "obs= [[[ 2.68752650e+00 -2.18575831e+00 -2.38922513e-01  7.11699980e-01\n",
      "   -1.65955270e+00  2.67321257e-01]\n",
      "  [-5.39447048e-04  7.75491645e-04 -3.14292204e-03  3.34630356e-03\n",
      "   -1.03823965e-03  2.20067920e-04]]\n",
      "\n",
      " [[ 9.90553410e+00 -3.65070590e+00 -8.26033779e+00  2.55036187e+00\n",
      "    4.61255035e+00 -1.44067827e+01]\n",
      "  [-1.48023848e-01  2.82440132e-01 -1.79019021e-01  9.63477095e-02\n",
      "    8.20147692e-02 -2.76650788e-01]]] reward= -4443751.117742014 done= False\n",
      "Step 659\n",
      "Action:  [ 0.9871115   0.3543756  -0.825932    1.235347    2.1768892  -0.11059204]\n",
      "self.next: 659\n",
      "obs= [[[  2.68747256  -2.18568076  -0.2392368    0.71203461  -1.65965653\n",
      "     0.26734326]\n",
      "  [ -0.04020277  -0.05320832   0.19187826   0.03817074  -0.2488993\n",
      "     0.2704325 ]]\n",
      "\n",
      " [[  9.89073172  -3.62246189  -8.27823969   2.55999664   4.62075183\n",
      "   -14.43444775]\n",
      "  [ -0.14880329   0.28339853  -0.17935092   0.09696345   0.08211878\n",
      "    -0.27767068]]] reward= -4092687.228827141 done= False\n",
      "Step 660\n",
      "Action:  [ 0.98625535  0.3547541  -0.82484055  1.2359993   2.1773849  -0.11059789]\n",
      "self.next: 660\n",
      "obs= [[[ 2.68345228e+00 -2.19100159e+00 -2.20048979e-01  7.15851684e-01\n",
      "   -1.68454646e+00  2.94386514e-01]\n",
      "  [ 3.36695422e-02 -3.13137851e-03 -7.66924125e-02 -8.63191557e-03\n",
      "    7.38124028e-02  7.22293197e-02]]\n",
      "\n",
      " [[ 9.87585139e+00 -3.59412203e+00 -8.29617478e+00  2.56969299e+00\n",
      "    4.62896370e+00 -1.44622148e+01]\n",
      "  [-1.49539950e-01  2.84288745e-01 -1.79660713e-01  9.75612715e-02\n",
      "    8.22304615e-02 -2.78663835e-01]]] reward= -6270682.24671188 done= False\n",
      "Step 661\n",
      "Action:  [ 0.9832062   0.35528815 -0.82250506  1.2330878   2.1629155  -0.10862822]\n",
      "self.next: 661\n",
      "obs= [[[  2.68681923  -2.19131473  -0.22771822   0.71498849  -1.67716522\n",
      "     0.30160945]\n",
      "  [  0.04817071   0.02493295  -0.07361324  -0.08222102   0.15867491\n",
      "    -0.15188794]]\n",
      "\n",
      " [[  9.86089739  -3.56569316  -8.31414086   2.57944911   4.63718675\n",
      "   -14.4900812 ]\n",
      "  [ -0.15023339   0.28511046  -0.17994826   0.09814066   0.08234879\n",
      "    -0.27962819]]] reward= -4836356.702307157 done= False\n",
      "Step 662\n",
      "Action:  [ 0.97842366  0.35517776 -0.81813836  1.2295893   2.1476667  -0.10528705]\n",
      "self.next: 662\n",
      "obs= [[[ 2.69163630e+00 -2.18882143e+00 -2.35079544e-01  7.06766391e-01\n",
      "   -1.66129773e+00  2.86420652e-01]\n",
      "  [-2.84162939e-02  4.59204941e-03  2.27782620e-02  1.42729830e-03\n",
      "   -7.94145284e-02  1.61903898e-01]]\n",
      "\n",
      " [[ 9.84587406e+00 -3.53718211e+00 -8.33213568e+00  2.58926318e+00\n",
      "    4.64542163e+00 -1.45180440e+01]\n",
      "  [-1.50883209e-01  2.85863448e-01 -1.80213439e-01  9.87011502e-02\n",
      "    8.24727241e-02 -2.80561709e-01]]] reward= -5413852.691884646 done= False\n",
      "Step 663\n",
      "Action:  [ 0.97795236  0.3560332  -0.81770533  1.2307478   2.1476495  -0.10572829]\n",
      "self.next: 663\n",
      "obs= [[[  2.68879467  -2.18836223  -0.23280172   0.70690912  -1.66923918\n",
      "     0.30261104]\n",
      "  [ -0.08789499   0.09831133  -0.18704545   0.23366073  -0.23185057\n",
      "     0.13579862]]\n",
      "\n",
      " [[  9.83078573  -3.50859577  -8.35015703   2.5991333    4.6536689\n",
      "   -14.54610019]\n",
      "  [ -0.15148903   0.28654757  -0.18045618   0.09924227   0.08260122\n",
      "    -0.2814624 ]]] reward= -4116651.185163871 done= False\n",
      "Step 664\n",
      "Action:  [ 0.98417205  0.35590464 -0.8238201   1.2349155   2.1664064  -0.11008041]\n",
      "self.next: 664\n",
      "obs= [[[ 2.68000517e+00 -2.17853110e+00 -2.51506263e-01  7.30275193e-01\n",
      "   -1.69242424e+00  3.16190904e-01]\n",
      "  [ 1.39308427e-02  9.18784157e-03 -2.11141723e-02 -1.27515284e-03\n",
      "   -3.28365443e-03 -2.49584339e-02]]\n",
      "\n",
      " [[ 9.81563683e+00 -3.47994101e+00 -8.36820264e+00  2.60905752e+00\n",
      "    4.66192902e+00 -1.45742464e+01]\n",
      "  [-1.52050505e-01  2.87162753e-01 -1.80676426e-01  9.97636046e-02\n",
      "    8.27332021e-02 -2.82328326e-01]]] reward= -7838541.689610553 done= False\n",
      "Step 665\n",
      "Action:  [ 0.97160476  0.35617697 -0.81177455  1.226361    2.1271157  -0.101511  ]\n",
      "self.next: 665\n",
      "obs= [[[  2.68139826  -2.17761231  -0.25361768   0.73014768  -1.6927526\n",
      "     0.31369506]\n",
      "  [  0.03374314  -0.0433076    0.23245685  -0.22122947  -0.08297036\n",
      "     0.08560042]]\n",
      "\n",
      " [[  9.80043178  -3.45122474  -8.38627029   2.61903388   4.67020234\n",
      "   -14.60247927]\n",
      "  [ -0.15256735   0.28770903  -0.18087414   0.10026474   0.08286758\n",
      "    -0.28315759]]] reward= -4340029.2036623275 done= False\n",
      "Step 666\n",
      "Action:  [ 0.96471375  0.35671175 -0.804957    1.222457    2.1073108  -0.09730222]\n",
      "self.next: 666\n",
      "obs= [[[  2.68477257  -2.18194307  -0.23037199   0.70802473  -1.70104964\n",
      "     0.3222551 ]\n",
      "  [ -0.04457959   0.04710333  -0.22468575   0.29814078  -0.0781469\n",
      "    -0.06867738]]\n",
      "\n",
      " [[  9.78517505  -3.42245383  -8.4043577    2.62906036   4.6784891\n",
      "   -14.63079502]\n",
      "  [ -0.15303932   0.28818652  -0.18104932   0.10074532   0.08300325\n",
      "    -0.28394839]]] reward= -9233920.668293027 done= False\n",
      "Step 667\n",
      "Action:  [ 0.97614104  0.35597122 -0.81653357  1.2291219   2.14081    -0.10486566]\n",
      "self.next: 667\n",
      "obs= [[[ 2.68031461e+00 -2.17723274e+00 -2.52840569e-01  7.37838809e-01\n",
      "   -1.70886433e+00  3.15387366e-01]\n",
      "  [ 2.94785580e-02 -5.21140840e-02  1.98419400e-01 -1.72566803e-01\n",
      "   -2.38769257e-03 -2.80528285e-02]]\n",
      "\n",
      " [[ 9.76987111e+00 -3.39363518e+00 -8.42246263e+00  2.63913489e+00\n",
      "    4.68678943e+00 -1.46591899e+01]\n",
      "  [-1.53466211e-01  2.88595436e-01 -1.81202036e-01  1.01205021e-01\n",
      "    8.31391266e-02 -2.84698988e-01]]] reward= -8716780.444781285 done= False\n",
      "Step 668\n",
      "Action:  [ 0.9594907   0.35695198 -0.80030936  1.2188798   2.0905128  -0.09404045]\n",
      "self.next: 668\n",
      "obs= [[[  2.68326247  -2.18244415  -0.23299863   0.72058213  -1.7091031\n",
      "     0.31258208]\n",
      "  [ -0.05274543  -0.0420508    0.09347254   0.1302429   -0.14275812\n",
      "     0.02244205]]\n",
      "\n",
      " [[  9.75452449  -3.36477564  -8.44058284   2.64925539   4.69510334\n",
      "   -14.68765976]\n",
      "  [ -0.15384788   0.28893609  -0.18133232   0.10164355   0.0832741\n",
      "    -0.28540773]]] reward= -7885779.757354844 done= False\n",
      "Step 669\n",
      "Action:  [ 0.9636301   0.3566724  -0.80445874  1.2218572   2.104393   -0.0970772 ]\n",
      "self.next: 669\n",
      "obs= [[[ 2.67798793e+00 -2.18664923e+00 -2.23651375e-01  7.33606419e-01\n",
      "   -1.72337891e+00  3.14826288e-01]\n",
      "  [ 1.55956417e-02  1.02587024e-02 -2.60708033e-02  2.03732818e-04\n",
      "    1.73022380e-04 -2.70448166e-02]]\n",
      "\n",
      " [[ 9.73913970e+00 -3.33588203e+00 -8.45871607e+00  2.65941975e+00\n",
      "    4.70343075e+00 -1.47162005e+01]\n",
      "  [-1.54184228e-01  2.89208890e-01 -1.81440301e-01  1.02060665e-01\n",
      "    8.34070746e-02 -2.86073055e-01]]] reward= -4818461.770046133 done= False\n",
      "Step 670\n",
      "Action:  [ 0.9608057   0.35750052 -0.80208004  1.2199694   2.0928001  -0.09538764]\n",
      "self.next: 670\n",
      "obs= [[[ 2.67954749e+00 -2.18562336e+00 -2.26258455e-01  7.33626792e-01\n",
      "   -1.72336161e+00  3.12121807e-01]\n",
      "  [ 4.25882481e-04 -2.61133915e-04  1.43586525e-03 -5.53764511e-04\n",
      "   -1.44196051e-03  1.53251871e-04]]\n",
      "\n",
      " [[ 9.72372128e+00 -3.30696114e+00 -8.47686010e+00  2.66962581e+00\n",
      "    4.71177146e+00 -1.47448078e+01]\n",
      "  [-1.54475249e-01  2.89414364e-01 -1.81526108e-01  1.02456173e-01\n",
      "    8.35369674e-02 -2.86693519e-01]]] reward= -4440244.602360225 done= False\n",
      "Step 671\n",
      "Action:  [ 0.9577852   0.35783175 -0.7993068   1.2181467   2.0833664  -0.09366094]\n",
      "self.next: 671\n",
      "obs= [[[  2.67959008  -2.18564947  -0.22611487   0.73357142  -1.7235058\n",
      "     0.31213713]\n",
      "  [ -0.06496835  -0.03619705   0.09937976   0.27357988  -0.3711367\n",
      "    -0.08922713]]\n",
      "\n",
      " [[  9.70827376  -3.2780197   -8.49501271   2.67987143   4.72012515\n",
      "   -14.77347719]\n",
      "  [ -0.15472099   0.28955314  -0.18158992   0.10282992   0.0836627\n",
      "    -0.28726778]]] reward= -4360678.627995366 done= False\n",
      "Step 672\n",
      "Action:  [ 0.96246046  0.35639638 -0.8033661   1.2213129   2.1027136  -0.0966375 ]\n",
      "self.next: 672\n",
      "obs= [[[ 2.67309324e+00 -2.18926917e+00 -2.16176893e-01  7.60929403e-01\n",
      "   -1.76061947e+00  3.03214418e-01]\n",
      "  [-5.33068719e-03  1.54737473e-02 -7.95445899e-03 -3.11109279e-03\n",
      "    8.83443396e-02 -2.87720430e-01]]\n",
      "\n",
      " [[ 9.69280166e+00 -3.24906439e+00 -8.51317170e+00  2.69015442e+00\n",
      "    4.72849142e+00 -1.48022040e+01]\n",
      "  [-1.54921555e-01  2.89625942e-01 -1.81631936e-01  1.03181810e-01\n",
      "    8.37832381e-02 -2.87794605e-01]]] reward= -6525307.412619665 done= False\n",
      "Step 673\n",
      "Action:  [ 0.9531005   0.3575743  -0.79506737  1.2144397   2.068721   -0.09026021]\n",
      "self.next: 673\n",
      "obs= [[[ 2.67256018e+00 -2.18772180e+00 -2.16972339e-01  7.60618294e-01\n",
      "   -1.75178504e+00  2.74442375e-01]\n",
      "  [ 8.79459014e-02 -9.28912692e-02  5.55359004e-03  3.48314988e-02\n",
      "    4.23969088e-02  1.16988398e-01]]\n",
      "\n",
      " [[ 9.67730950e+00 -3.22010180e+00 -8.53133489e+00  2.70047260e+00\n",
      "    4.73686975e+00 -1.48309834e+01]\n",
      "  [-1.55077157e-01  2.89633629e-01 -1.81652401e-01  1.03511786e-01\n",
      "    8.38975326e-02 -2.88272898e-01]]] reward= -4896279.667048298 done= False\n",
      "Step 674\n",
      "Action:  [ 0.95176965  0.3585591  -0.7937887   1.2142385   2.0644515  -0.09053313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 674\n",
      "obs= [[[ 2.68135477e+00 -2.19701093e+00 -2.16416980e-01  7.64101444e-01\n",
      "   -1.74754535e+00  2.86141215e-01]\n",
      "  [ 1.81234387e-02 -7.63697387e-03  3.90024791e-02 -4.86850196e-02\n",
      "    6.60974257e-04 -2.99566834e-02]]\n",
      "\n",
      " [[ 9.66180179e+00 -3.19113843e+00 -8.54950013e+00  2.71082378e+00\n",
      "    4.74525950e+00 -1.48598107e+01]\n",
      "  [-1.55188068e-01  2.89577158e-01 -1.81651591e-01  1.03819851e-01\n",
      "    8.40045979e-02 -2.88701690e-01]]] reward= -6077473.0085064005 done= False\n",
      "Step 675\n",
      "Action:  [ 0.9487194   0.35882646 -0.7910385   1.2125362   2.0547578  -0.08837533]\n",
      "self.next: 675\n",
      "obs= [[[ 2.68316711e+00 -2.19777462e+00 -2.12516732e-01  7.59232942e-01\n",
      "   -1.74747925e+00  2.83145547e-01]\n",
      "  [ 1.50039545e-03  1.99160214e-04 -2.71169744e-03  1.36422910e-03\n",
      "    4.54147198e-04 -4.54552554e-04]]\n",
      "\n",
      " [[ 9.64628298e+00 -3.16218072e+00 -8.56766529e+00  2.72120577e+00\n",
      "    4.75365996e+00 -1.48886809e+01]\n",
      "  [-1.55254649e-01  2.89457597e-01 -1.81629808e-01  1.04106055e-01\n",
      "    8.41034732e-02 -2.89080146e-01]]] reward= -5324107.834734639 done= False\n",
      "Step 676\n",
      "Action:  [ 0.94780403  0.35911965 -0.7903521   1.2120067   2.051412   -0.08806273]\n",
      "self.next: 676\n",
      "obs= [[[ 2.68331715e+00 -2.19775471e+00 -2.12787902e-01  7.59369365e-01\n",
      "   -1.74743384e+00  2.83100092e-01]\n",
      "  [-5.23032267e-02  1.52047369e-03  6.59005179e-04  1.79734847e-01\n",
      "   -2.15376985e-01  3.79853822e-02]]\n",
      "\n",
      " [[ 9.63075752e+00 -3.13323496e+00 -8.58582827e+00  2.73161637e+00\n",
      "    4.76207031e+00 -1.49175889e+01]\n",
      "  [-1.55277350e-01  2.89276129e-01 -1.81587389e-01  1.04370500e-01\n",
      "    8.41932417e-02 -2.89407574e-01]]] reward= -4453413.076147691 done= False\n",
      "Step 677\n",
      "Action:  [ 0.9500453   0.3587973  -0.79238844  1.2138017   2.0600674  -0.08977686]\n",
      "self.next: 677\n",
      "obs= [[[ 2.67808683e+00 -2.19760266e+00 -2.12722001e-01  7.77342850e-01\n",
      "   -1.76897154e+00  2.86898630e-01]\n",
      "  [-9.60831551e-05  2.15747917e-02 -1.74781429e-02 -4.56363321e-03\n",
      "    8.56036849e-02 -3.76587700e-01]]\n",
      "\n",
      " [[ 9.61522978e+00 -3.10430735e+00 -8.60398701e+00  2.74205342e+00\n",
      "    4.77048963e+00 -1.49465297e+01]\n",
      "  [-1.55256710e-01  2.89034047e-01 -1.81524696e-01  1.04613335e-01\n",
      "    8.42730339e-02 -2.89683424e-01]]] reward= -5616475.497212224 done= False\n",
      "Step 678\n",
      "Action:  [ 0.9439563   0.3586676  -0.78696805  1.2087241   2.0395584  -0.08500963]\n",
      "self.next: 678\n",
      "obs= [[[ 2.67807722e+00 -2.19544518e+00 -2.14469816e-01  7.76886486e-01\n",
      "   -1.76041117e+00  2.49239860e-01]\n",
      "  [ 1.02245080e-02 -5.60693912e-02  4.59462138e-02  8.45021903e-02\n",
      "   -9.59381821e-03 -1.47708703e-01]]\n",
      "\n",
      " [[ 9.59970411e+00 -3.07540394e+00 -8.62213948e+00  2.75251476e+00\n",
      "    4.77891693e+00 -1.49754980e+01]\n",
      "  [-1.55193362e-01  2.88732748e-01 -1.81442105e-01  1.04834755e-01\n",
      "    8.43420233e-02 -2.89907285e-01]]] reward= -5350611.072512993 done= False\n",
      "Step 679\n",
      "Action:  [ 0.9418579   0.35904685 -0.7849185   1.2078103   2.0341022  -0.08432831]\n",
      "self.next: 679\n",
      "obs= [[[ 2.67909967e+00 -2.20105212e+00 -2.09875194e-01  7.85336705e-01\n",
      "   -1.76137055e+00  2.34468989e-01]\n",
      "  [-4.23863691e-02  6.24441117e-03  3.46925218e-02  3.49557543e-03\n",
      "   -1.58865960e-01  2.58263686e-01]]\n",
      "\n",
      " [[ 9.58418477e+00 -3.04653067e+00 -8.64028369e+00  2.76299823e+00\n",
      "    4.78735114e+00 -1.50044887e+01]\n",
      "  [-1.55088032e-01  2.88373738e-01 -1.81340027e-01  1.05035004e-01\n",
      "    8.43994479e-02 -2.90078902e-01]]] reward= -4781514.493250148 done= False\n",
      "Step 680\n",
      "Action:  [ 0.9403258   0.36052853 -0.78338605  1.2077777   2.0277097  -0.08457223]\n",
      "self.next: 680\n",
      "obs= [[[  2.67486103  -2.20042768  -0.20640594   0.78568626  -1.77725714\n",
      "     0.26029536]\n",
      "  [ -0.05000625   0.08827021  -0.03713236   0.04786998  -0.21329692\n",
      "     0.15261022]]\n",
      "\n",
      " [[  9.56867597  -3.01769329  -8.6584177    2.77350173   4.79579108\n",
      "   -15.03349662]\n",
      "  [ -0.15494154   0.28795862  -0.18121888   0.10521437   0.0844446\n",
      "    -0.29019816]]] reward= -4590716.250121089 done= False\n",
      "Step 681\n",
      "Action:  [ 0.9411691   0.36060977 -0.78432494  1.2085243   2.030038   -0.08502853]\n",
      "self.next: 681\n",
      "obs= [[[ 2.66986041e+00 -2.19160066e+00 -2.10119178e-01  7.90473261e-01\n",
      "   -1.79858684e+00  2.75556380e-01]\n",
      "  [ 1.26756970e-02 -3.50643117e-02  2.14213393e-02  8.35165580e-02\n",
      "   -8.79133848e-02 -3.12960116e-02]]\n",
      "\n",
      " [[ 9.55318182e+00 -2.98889743e+00 -8.67653958e+00  2.78402317e+00\n",
      "    4.80423554e+00 -1.50625164e+01]\n",
      "  [-1.54754801e-01  2.87489105e-01 -1.81079113e-01  1.05373169e-01\n",
      "    8.44768448e-02 -2.90265103e-01]]] reward= -5435049.893397212 done= False\n",
      "Step 682\n",
      "Action:  [ 0.9369016   0.36004987 -0.7802597   1.2049949   2.0178404  -0.08189376]\n",
      "self.next: 682\n",
      "obs= [[[  2.67112798  -2.19510709  -0.20797704   0.79882492  -1.80737818\n",
      "     0.27242678]\n",
      "  [  0.058442    -0.05809537   0.17091487  -0.21647628   0.03435775\n",
      "    -0.0274002 ]]\n",
      "\n",
      " [[  9.53770634  -2.96014852  -8.6946475    2.79456049   4.81268323\n",
      "   -15.09154295]\n",
      "  [ -0.15452883   0.28696697  -0.18092115   0.10551177   0.0844956\n",
      "    -0.29027989]]] reward= -4436187.574982468 done= False\n",
      "Step 683\n",
      "Action:  [ 0.92906857  0.36079696 -0.7727924   1.1997627   1.9930619  -0.07700448]\n",
      "self.next: 683\n",
      "obs= [[[ 2.67697218e+00 -2.20091663e+00 -1.90885558e-01  7.77177288e-01\n",
      "   -1.80394240e+00  2.69686759e-01]\n",
      "  [-9.96284981e-03 -5.69993075e-03  6.65534048e-02 -4.91799843e-02\n",
      "   -8.48395187e-02  1.46637542e-01]]\n",
      "\n",
      " [[ 9.52225345e+00 -2.93145182e+00 -8.71273961e+00  2.80511166e+00\n",
      "    4.82113279e+00 -1.51205709e+01]\n",
      "  [-1.54264717e-01  2.86394109e-01 -1.80745449e-01  1.05630545e-01\n",
      "    8.45003525e-02 -2.90242847e-01]]] reward= -8154978.6711599175 done= False\n",
      "Step 684\n",
      "Action:  [ 0.93158805  0.3611869  -0.7753627   1.2018456   2.0002618  -0.07928858]\n",
      "self.next: 684\n",
      "obs= [[[  2.67597589  -2.20148662  -0.18423022   0.77225929  -1.81242635\n",
      "     0.28435051]\n",
      "  [ -0.01659715   0.13732837  -0.29389954   0.0926111    0.08910405\n",
      "    -0.15350421]]\n",
      "\n",
      " [[  9.50682698  -2.90281241  -8.73081416   2.81567472   4.82958282\n",
      "   -15.14959522]\n",
      "  [ -0.15396367   0.28577247  -0.18055246   0.10572993   0.08449068\n",
      "    -0.29015442]]] reward= -5386359.301801021 done= False\n",
      "Step 685\n",
      "Action:  [ 0.93728745  0.361206   -0.78157824  1.2049595   2.014487   -0.08252271]\n",
      "self.next: 685\n",
      "obs= [[[ 2.67431618e+00 -2.18775378e+00 -2.13620171e-01  7.81520399e-01\n",
      "   -1.80351595e+00  2.69000092e-01]\n",
      "  [ 1.29726421e-02 -5.71449940e-02  4.24557621e-02  8.35813912e-02\n",
      "   -7.92034603e-04 -1.49532761e-01]]\n",
      "\n",
      " [[ 9.49143061e+00 -2.87423516e+00 -8.74886940e+00  2.82624771e+00\n",
      "    4.83803189e+00 -1.51786107e+01]\n",
      "  [-1.53626967e-01  2.85104081e-01 -1.80342631e-01  1.05810356e-01\n",
      "    8.44662169e-02 -2.90015205e-01]]] reward= -6685427.306952505 done= False\n",
      "Step 686\n",
      "Action:  [ 0.92852217  0.36067337 -0.7727838   1.1991308   1.9913933  -0.07690951]\n",
      "self.next: 686\n",
      "obs= [[[ 2.67561344e+00 -2.19346828e+00 -2.09374595e-01  7.89878538e-01\n",
      "   -1.80359515e+00  2.54046815e-01]\n",
      "  [-1.29776379e-02  1.26893494e-02  1.28877023e-03 -1.73117484e-03\n",
      "   -8.24265301e-02  1.48406715e-01]]\n",
      "\n",
      " [[ 9.47606792e+00 -2.84572476e+00 -8.76690366e+00  2.83682875e+00\n",
      "    4.84647851e+00 -1.52076122e+01]\n",
      "  [-1.53255979e-01  2.84391035e-01 -1.80116383e-01  1.05872272e-01\n",
      "    8.44266692e-02 -2.89825888e-01]]] reward= -5009367.402781267 done= False\n",
      "Step 687\n",
      "Action:  [ 0.92710096  0.36189455 -0.7714304   1.1988658   1.9852427  -0.07692917]\n",
      "self.next: 687\n",
      "obs= [[[ 2.67431568e+00 -2.19219935e+00 -2.09245718e-01  7.89705421e-01\n",
      "   -1.81183780e+00  2.68887487e-01]\n",
      "  [ 2.25793428e-02 -2.09902963e-02 -2.45249683e-03  3.40298202e-03\n",
      "   -1.27614077e-02  3.71512687e-02]]\n",
      "\n",
      " [[ 9.46074232e+00 -2.81728565e+00 -8.78491530e+00  2.84741597e+00\n",
      "    4.85492118e+00 -1.52365948e+01]\n",
      "  [-1.52852158e-01  2.83635478e-01 -1.79874143e-01  1.05916147e-01\n",
      "    8.43718246e-02 -2.89587296e-01]]] reward= -4544072.304720362 done= False\n",
      "Step 688\n",
      "Action:  [ 0.9250154   0.36182308 -0.76956964  1.1972101   1.978867   -0.07545383]\n",
      "self.next: 688\n",
      "obs= [[[ 2.67657361e+00 -2.19429838e+00 -2.09490968e-01  7.90045719e-01\n",
      "   -1.81311394e+00  2.72602614e-01]\n",
      "  [ 6.89741784e-05  2.20788150e-02 -2.22391350e-02  9.40687345e-04\n",
      "   -8.33375415e-02  1.17662805e-01]]\n",
      "\n",
      " [[ 9.44545710e+00 -2.78892210e+00 -8.80290272e+00  2.85800759e+00\n",
      "    4.86335836e+00 -1.52655535e+01]\n",
      "  [-1.52417032e-01  2.82839605e-01 -1.79616309e-01  1.05942448e-01\n",
      "    8.43015415e-02 -2.89300359e-01]]] reward= -4705171.584536784 done= False\n",
      "Step 689\n",
      "Action:  [ 0.92452955  0.36224186 -0.7691408   1.1971514   1.9768667  -0.07552182]\n",
      "self.next: 689\n",
      "obs= [[[  2.67658051  -2.19209049  -0.21171488   0.79013979  -1.8214477\n",
      "     0.28436889]\n",
      "  [ -0.02400739  -0.01630879   0.03822453   0.13394979  -0.14073418\n",
      "    -0.13568606]]\n",
      "\n",
      " [[  9.4302154   -2.76063814  -8.82086435   2.86860183   4.87178851\n",
      "   -15.29448354]\n",
      "  [ -0.1519522    0.28200565  -0.17934326   0.10595164   0.08421575\n",
      "    -0.28896611]]] reward= -4715413.755323668 done= False\n",
      "Step 690\n",
      "Action:  [ 0.92409265  0.3614047  -0.76874757  1.196538    1.9775113  -0.07470971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 690\n",
      "obs= [[[ 2.67417977e+00 -2.19372137e+00 -2.07892429e-01  8.03534767e-01\n",
      "   -1.83552112e+00  2.70800289e-01]\n",
      "  [-5.96657657e-03  1.49932206e-02 -7.62254414e-03 -1.49181230e-03\n",
      "   -8.12915322e-02  5.93921259e-02]]\n",
      "\n",
      " [[ 9.41502018e+00 -2.73243758e+00 -8.83879867e+00  2.87919700e+00\n",
      "    4.88021009e+00 -1.53233802e+01]\n",
      "  [-1.51459339e-01  2.81135872e-01 -1.79055344e-01  1.05944197e-01\n",
      "    8.41144599e-02 -2.88585654e-01]]] reward= -4925942.962652101 done= False\n",
      "Step 691\n",
      "Action:  [ 0.92091393  0.3624827  -0.7657963   1.1946558   1.9656663  -0.07330643]\n",
      "self.next: 691\n",
      "obs= [[[  2.67358311  -2.19222205  -0.20865468   0.80338559  -1.84365027\n",
      "     0.2767395 ]\n",
      "  [ -0.01754862   0.07748055  -0.10862845   0.09960008  -0.14004239\n",
      "    -0.05480453]]\n",
      "\n",
      " [[  9.39987425  -2.70432399  -8.85670421   2.88979142   4.88862154\n",
      "   -15.35223872]\n",
      "  [ -0.15094017   0.28023256  -0.17875288   0.10592056   0.08399773\n",
      "    -0.2881602 ]]] reward= -4509809.563280089 done= False\n",
      "Step 692\n",
      "Action:  [ 0.92324215  0.36241344 -0.76822776  1.1962155   1.9725624  -0.07468794]\n",
      "self.next: 692\n",
      "obs= [[[ 2.67182825e+00 -2.18447400e+00 -2.19517528e-01  8.13345594e-01\n",
      "   -1.85765451e+00  2.71259048e-01]\n",
      "  [ 2.73974089e-03 -3.40401497e-02  8.15942376e-02 -4.92287895e-02\n",
      "   -8.95852217e-02  6.32244004e-02]]\n",
      "\n",
      " [[ 9.38478023e+00 -2.67630074e+00 -8.87457950e+00  2.90038347e+00\n",
      "    4.89702131e+00 -1.53810547e+01]\n",
      "  [-1.50396485e-01  2.79298009e-01 -1.78436145e-01  1.05881159e-01\n",
      "    8.38657172e-02 -2.87691030e-01]]] reward= -4866675.589471219 done= False\n",
      "Step 693\n",
      "Action:  [ 0.91535044  0.36275807 -0.7604339   1.1908367   1.9488928  -0.07000609]\n",
      "self.next: 693\n",
      "obs= [[[ 2.67210222e+00 -2.18787801e+00 -2.11358105e-01  8.08422715e-01\n",
      "   -1.86661303e+00  2.77581488e-01]\n",
      "  [-2.62873774e-04 -1.94165410e-03  2.57928081e-03  1.78573006e-03\n",
      "   -4.80330888e-04 -1.22488475e-03]]\n",
      "\n",
      " [[ 9.36974058e+00 -2.64837094e+00 -8.89242311e+00  2.91097159e+00\n",
      "    4.90540788e+00 -1.54098238e+01]\n",
      "  [-1.49830116e-01  2.78334521e-01 -1.78105383e-01  1.05826410e-01\n",
      "    8.37186056e-02 -2.87179457e-01]]] reward= -4958203.996700952 done= False\n",
      "Step 694\n",
      "Action:  [ 0.9152052   0.36292687 -0.7605984   1.1905123   1.9475478  -0.06991573]\n",
      "self.next: 694\n",
      "obs= [[[  2.67207594  -2.18807218  -0.21110018   0.80860129  -1.86666106\n",
      "     0.277459  ]\n",
      "  [ -0.06091214  -0.04778527   0.28372627  -0.13089697  -0.1283837\n",
      "     0.10464587]]\n",
      "\n",
      " [[  9.35475757  -2.62053748  -8.91023365   2.92155423   4.91377974\n",
      "   -15.43854179]\n",
      "  [ -0.14924294   0.2773444   -0.1777608    0.1057567    0.08355667\n",
      "    -0.28662688]]] reward= -4667163.013861827 done= False\n",
      "Step 695\n",
      "Action:  [ 0.9086932   0.36302975 -0.7539292   1.1864346   1.9295201  -0.06604798]\n",
      "self.next: 695\n",
      "obs= [[[  2.66598472  -2.1928507   -0.18272755   0.79551159  -1.87949943\n",
      "     0.28792359]\n",
      "  [  0.03101798   0.04787144  -0.43421137   0.43747678   0.17041648\n",
      "    -0.3091411 ]]\n",
      "\n",
      " [[  9.33983328  -2.59280304  -8.92800973   2.9321299    4.92213541\n",
      "   -15.46720447]\n",
      "  [ -0.14863687   0.27632992  -0.17740255   0.10567237   0.08338022\n",
      "    -0.28603471]]] reward= -6984140.159583591 done= False\n",
      "Step 696\n",
      "Action:  [ 0.92631453  0.36195663 -0.77202296  1.1963533   1.9798247  -0.07675351]\n",
      "self.next: 696\n",
      "obs= [[[  2.66908652  -2.18806356  -0.22614869   0.83925927  -1.86245779\n",
      "     0.25700948]\n",
      "  [ -0.04389885   0.0545934    0.11389733  -0.20465077  -0.09081471\n",
      "     0.15691079]]\n",
      "\n",
      " [[  9.32496959  -2.56517005  -8.94574998   2.94269714   4.93047343\n",
      "   -15.49580794]\n",
      "  [ -0.14801384   0.27529337  -0.17703078   0.10557376   0.08318964\n",
      "    -0.28540442]]] reward= -13318903.383116798 done= False\n",
      "Step 697\n",
      "Action:  [ 0.90745646  0.36408785 -0.7531189   1.1857877   1.9230171  -0.06568903]\n",
      "self.next: 697\n",
      "obs= [[[ 2.66469664e+00 -2.18260422e+00 -2.14758953e-01  8.18794191e-01\n",
      "   -1.87153926e+00  2.72700557e-01]\n",
      "  [ 6.40473674e-03 -4.27615812e-02  3.62286826e-02  7.96646786e-02\n",
      "   -7.69158440e-02  5.97914432e-02]]\n",
      "\n",
      " [[ 9.31016821e+00 -2.53764071e+00 -8.96345306e+00  2.95325451e+00\n",
      "    4.93879239e+00 -1.55243484e+01]\n",
      "  [-1.47375816e-01  2.74236986e-01 -1.76645513e-01  1.05461131e-01\n",
      "    8.29853338e-02 -2.84737475e-01]]] reward= -7830530.39125645 done= False\n",
      "Step 698\n",
      "Action:  [ 0.9097423   0.36334673 -0.7554683   1.1868968   1.9313219  -0.06708514]\n",
      "self.next: 698\n",
      "obs= [[[  2.66533711  -2.18688038  -0.21113608   0.82676066  -1.87923084\n",
      "     0.2786797 ]\n",
      "  [ -0.01944655   0.03551347  -0.1388957    0.16677851  -0.04529384\n",
      "    -0.11621189]]\n",
      "\n",
      " [[  9.29543062  -2.51021702  -8.98111761   2.96380063   4.94709093\n",
      "   -15.55282213]\n",
      "  [ -0.14672478   0.27316299  -0.1762468    0.10533473   0.08276778\n",
      "    -0.28403538]]] reward= -4934136.050778838 done= False\n",
      "Step 699\n",
      "Action:  [ 0.91267294  0.3633746  -0.75866055  1.1886227   1.93896    -0.06868007]\n",
      "self.next: 699\n",
      "obs= [[[ 2.66339245e+00 -2.18332903e+00 -2.25025655e-01  8.43438509e-01\n",
      "   -1.88376022e+00  2.67058512e-01]\n",
      "  [-1.46897187e-01  3.84271751e-03  1.42586270e-01  8.77797314e-02\n",
      "   -3.39000567e-01  2.68092711e-01]]\n",
      "\n",
      " [[ 9.28075815e+00 -2.48290072e+00 -8.99874229e+00  2.97433410e+00\n",
      "    4.95536770e+00 -1.55812257e+01]\n",
      "  [-1.46062714e-01  2.72073552e-01 -1.75834619e-01  1.05194743e-01\n",
      "    8.25374716e-02 -2.83299635e-01]]] reward= -6486783.544431246 done= False\n",
      "Step 700\n",
      "Action:  [ 0.90696144  0.36370885 -0.7524382   1.1856484   1.9236251  -0.06593893]\n",
      "self.next: 700\n",
      "obs= [[[ 2.64870274e+00 -2.18294476e+00 -2.10767028e-01  8.52216482e-01\n",
      "   -1.91766028e+00  2.93867784e-01]\n",
      "  [ 8.63075957e-02 -2.11216816e-03 -8.25866394e-02 -4.33195089e-02\n",
      "    1.24568541e-01 -1.39163962e-01]]\n",
      "\n",
      " [[ 9.26615187e+00 -2.45569336e+00 -9.01632576e+00  2.98485357e+00\n",
      "    4.96362145e+00 -1.56095556e+01]\n",
      "  [-1.45391608e-01  2.70970820e-01 -1.75408896e-01  1.05041323e-01\n",
      "    8.22949482e-02 -2.82531732e-01]]] reward= -6431072.078863447 done= False\n",
      "Step 701\n",
      "Action:  [ 0.9054591   0.36407417 -0.7518515   1.1835651   1.9160997  -0.06428123]\n",
      "self.next: 701\n",
      "obs= [[[ 2.65733350e+00 -2.18315598e+00 -2.19025692e-01  8.47884531e-01\n",
      "   -1.90520343e+00  2.79951387e-01]\n",
      "  [ 5.53713324e-02 -1.49590545e-02 -3.99194631e-02  8.08308768e-02\n",
      "   -1.43329361e-03 -2.00048430e-01]]\n",
      "\n",
      " [[ 9.25161271e+00 -2.42859628e+00 -9.03386664e+00  2.99535771e+00\n",
      "    4.97185095e+00 -1.56378088e+01]\n",
      "  [-1.44713444e-01  2.69856887e-01 -1.74969523e-01  1.04874572e-01\n",
      "    8.20407743e-02 -2.81733161e-01]]] reward= -5489800.874414855 done= False\n",
      "Step 702\n",
      "Action:  [ 0.90587807  0.3637419  -0.7522671   1.1839143   1.918585   -0.06452181]\n",
      "self.next: 702\n",
      "obs= [[[  2.66287063  -2.18465188  -0.22301764   0.85596762  -1.90534676\n",
      "     0.25994654]\n",
      "  [  0.03047016  -0.06766479   0.26114235  -0.26174972   0.03715725\n",
      "     0.02533248]]\n",
      "\n",
      " [[  9.23714137  -2.40161059  -9.0513636    3.00584516   4.98005502\n",
      "   -15.66598212]\n",
      "  [ -0.14403019   0.2687338   -0.17451635   0.10469454   0.08177554\n",
      "    -0.2809054 ]]] reward= -5143964.016741687 done= False\n",
      "Step 703\n",
      "Action:  [ 0.89615643  0.3645299  -0.74261516  1.1775484   1.8892342  -0.05889488]\n",
      "self.next: 703\n",
      "obs= [[[ 2.66591764e+00 -2.19141836e+00 -1.96903403e-01  8.29792647e-01\n",
      "   -1.90163103e+00  2.62479793e-01]\n",
      "  [-8.58068791e-03 -6.95295116e-03  1.61095082e-02 -1.04208060e-03\n",
      "    2.58968638e-03 -6.23767330e-02]]\n",
      "\n",
      " [[ 9.22273835e+00 -2.37473721e+00 -9.06881523e+00  3.01631462e+00\n",
      "    4.98823258e+00 -1.56940727e+01]\n",
      "  [-1.43343820e-01  2.67603546e-01 -1.74049177e-01  1.04501239e-01\n",
      "    8.14998552e-02 -2.80049881e-01]]] reward= -8893328.554178583 done= False\n",
      "Step 704\n",
      "Action:  [ 0.90173733  0.36436415 -0.74841523  1.1812851   1.905545   -0.06242597]\n",
      "self.next: 704\n",
      "obs= [[[ 2.66505958e+00 -2.19211366e+00 -1.95292452e-01  8.29688439e-01\n",
      "   -1.90137206e+00  2.56242119e-01]\n",
      "  [ 2.33881665e-02  2.37270856e-02 -4.64743283e-02 -5.74400495e-04\n",
      "   -3.48256471e-03 -7.13268289e-02]]\n",
      "\n",
      " [[ 9.20840397e+00 -2.34797686e+00 -9.08622015e+00  3.02676474e+00\n",
      "    4.99638256e+00 -1.57220777e+01]\n",
      "  [-1.42656251e-01  2.66468074e-01 -1.73567786e-01  1.04294623e-01\n",
      "    8.12143475e-02 -2.79168048e-01]]] reward= -4304549.105455618 done= False\n",
      "Step 705\n",
      "Action:  [ 0.9020617   0.36460713 -0.7488964   1.1815549   1.9060538  -0.06278174]\n",
      "self.next: 705\n",
      "obs= [[[  2.66739839  -2.18974095  -0.19993989   0.829631    -1.90172032\n",
      "     0.24910944]\n",
      "  [ -0.05834532   0.02271496   0.03802531   0.03900665  -0.12291114\n",
      "     0.06474841]]\n",
      "\n",
      " [[  9.19413834  -2.32133005  -9.10357693   3.0371942    5.004504\n",
      "   -15.74999446]\n",
      "  [ -0.1419694    0.26532927  -0.17307191   0.10407461   0.08091965\n",
      "    -0.27826129]]] reward= -4532338.125748035 done= False\n",
      "Step 706\n",
      "Action:  [ 0.90019095  0.36469927 -0.74689436  1.1805632   1.9010037  -0.06192333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 706\n",
      "obs= [[[ 2.66156386e+00 -2.18746945e+00 -1.96137354e-01  8.33531664e-01\n",
      "   -1.91401143e+00  2.55584278e-01]\n",
      "  [-5.74699195e-02 -3.47686526e-02  9.29600988e-02  4.60578463e-04\n",
      "   -8.34148603e-02  2.10344343e-01]]\n",
      "\n",
      " [[ 9.17994140e+00 -2.29479712e+00 -9.12088412e+00  3.04760166e+00\n",
      "    5.01259596e+00 -1.57778206e+01]\n",
      "  [-1.41285147e-01  2.64188949e-01 -1.72561252e-01  1.03841054e-01\n",
      "    8.06164095e-02 -2.77330949e-01]]] reward= -4411836.727632363 done= False\n",
      "Step 707\n",
      "Action:  [ 0.89684606  0.36490938 -0.74353075  1.1781956   1.8907428  -0.06018605]\n",
      "self.next: 707\n",
      "obs= [[[ 2.65581687e+00 -2.19094632e+00 -1.86841344e-01  8.33577722e-01\n",
      "   -1.92235292e+00  2.76618712e-01]\n",
      "  [ 6.10417202e-03  4.03715560e-02 -1.00250835e-01  1.35877644e-01\n",
      "   -8.50253841e-02 -2.08911176e-01]]\n",
      "\n",
      " [[ 9.16581289e+00 -2.26837823e+00 -9.13814025e+00  3.05798577e+00\n",
      "    5.02065760e+00 -1.58055537e+01]\n",
      "  [-1.40605334e-01  2.63048893e-01 -1.72035488e-01  1.03593787e-01\n",
      "    8.03052640e-02 -2.76378352e-01]]] reward= -5057683.9486792 done= False\n",
      "Step 708\n",
      "Action:  [ 0.90175605  0.36450568 -0.7487761   1.1812263   1.9055606  -0.062585  ]\n",
      "self.next: 708\n",
      "obs= [[[ 2.65642729e+00 -2.18690916e+00 -1.96866428e-01  8.47165486e-01\n",
      "   -1.93085546e+00  2.55727594e-01]\n",
      "  [-1.03766115e-01  6.94546123e-04  1.02736846e-01  4.23893351e-02\n",
      "   -2.12365036e-01  2.45528686e-01]]\n",
      "\n",
      " [[ 9.15175235e+00 -2.24207334e+00 -9.15534379e+00  3.06834515e+00\n",
      "    5.02868813e+00 -1.58331915e+01]\n",
      "  [-1.39931763e-01  2.61910809e-01 -1.71494281e-01  1.03332593e-01\n",
      "    7.99868628e-02 -2.75404777e-01]]] reward= -5372327.630413173 done= False\n",
      "Step 709\n",
      "Action:  [ 0.895956    0.36506587 -0.74261683  1.1778715   1.8883816  -0.05983049]\n",
      "self.next: 709\n",
      "obs= [[[  2.64605067  -2.18683971  -0.18659274   0.85140442  -1.95209196\n",
      "     0.28028046]\n",
      "  [  0.05149218   0.01963383  -0.25132508   0.1403495    0.04135252\n",
      "     0.04637058]]\n",
      "\n",
      " [[  9.13775918  -2.21588226  -9.17249322   3.07867841   5.03668682\n",
      "   -15.86073199]\n",
      "  [ -0.1392662    0.26077635  -0.17093726   0.10305721   0.07966184\n",
      "    -0.27441145]]] reward= -5283186.1702443855 done= False\n",
      "Step 710\n",
      "Action:  [ 0.9006907   0.36522776 -0.74785346  1.1801897   1.9000713  -0.06273367]\n",
      "self.next: 710\n",
      "obs= [[[ 2.65119989e+00 -2.18487632e+00 -2.11725252e-01  8.65439370e-01\n",
      "   -1.94795671e+00  2.84917521e-01]\n",
      "  [ 4.45909619e-03  4.65593113e-03 -8.28344989e-03  7.18657643e-04\n",
      "   -2.89685567e-03 -9.54461802e-02]]\n",
      "\n",
      " [[ 9.12383256e+00 -2.18980462e+00 -9.18958695e+00  3.08898413e+00\n",
      "    5.04465300e+00 -1.58881731e+01]\n",
      "  [-1.38610354e-01  2.59647112e-01 -1.70364048e-01  1.02767347e-01\n",
      "    7.93308243e-02 -2.73399560e-01]]] reward= -7139720.00242362 done= False\n",
      "Step 711\n",
      "Action:  [ 0.8938663   0.36530963 -0.74118304  1.1758375   1.8806527  -0.05805223]\n",
      "self.next: 711\n",
      "obs= [[[  2.6516458   -2.18441073  -0.2125536    0.86551124  -1.94824639\n",
      "     0.2753729 ]\n",
      "  [ -0.05859345  -0.03029351   0.26704433  -0.1364959   -0.20845476\n",
      "     0.22994434]]\n",
      "\n",
      " [[  9.10997152  -2.16383991  -9.20662335   3.09926086   5.05258608\n",
      "   -15.91551309]\n",
      "  [ -0.1379659    0.25852463  -0.16977425   0.10246268   0.07899443\n",
      "    -0.27237024]]] reward= -4271477.511326 done= False\n",
      "Step 712\n",
      "Action:  [ 0.88883394  0.36552346 -0.73567903  1.173081    1.8670055  -0.05550897]\n",
      "self.next: 712\n",
      "obs= [[[ 2.64578646e+00 -2.18744008e+00 -1.85849164e-01  8.51861646e-01\n",
      "   -1.96909187e+00  2.98367338e-01]\n",
      "  [-4.94403151e-04 -1.08176811e-03  3.11631683e-03 -6.83692487e-04\n",
      "   -2.41307340e-04 -5.37665045e-04]]\n",
      "\n",
      " [[ 9.09617493e+00 -2.13798745e+00 -9.22360078e+00  3.10950713e+00\n",
      "    5.06048553e+00 -1.59427501e+01]\n",
      "  [-1.37334445e-01  2.57410390e-01 -1.69167478e-01  1.02142846e-01\n",
      "    7.86532698e-02 -2.71324598e-01]]] reward= -7988580.9467343325 done= False\n",
      "Step 713\n",
      "Action:  [ 0.89184517  0.36556703 -0.7392544   1.1744784   1.874531   -0.05715529]\n",
      "self.next: 713\n",
      "obs= [[[ 2.64573702e+00 -2.18754826e+00 -1.85537532e-01  8.51793277e-01\n",
      "   -1.96911600e+00  2.98313571e-01]\n",
      "  [-7.32825966e-03 -5.47708841e-03  1.22537564e-02 -8.41014294e-04\n",
      "    1.10769895e-03 -5.87722499e-02]]\n",
      "\n",
      " [[ 9.08244149e+00 -2.11224641e+00 -9.24051753e+00  3.11972141e+00\n",
      "    5.06835085e+00 -1.59698826e+01]\n",
      "  [-1.36717556e-01  2.56305816e-01 -1.68543337e-01  1.01807480e-01\n",
      "    7.83079230e-02 -2.70263672e-01]]] reward= -4514618.814162714 done= False\n",
      "Step 714\n",
      "Action:  [ 0.89071786  0.36560234 -0.7382723   1.173663    1.8712158  -0.05641447]\n",
      "self.next: 714\n",
      "obs= [[[ 2.64500419e+00 -2.18809597e+00 -1.84312156e-01  8.51709175e-01\n",
      "   -1.96900523e+00  2.92436346e-01]\n",
      "  [ 7.72634708e-03  6.26769887e-03 -1.39879197e-02  1.44142202e-03\n",
      "   -1.30925460e-03  5.91319312e-02]]\n",
      "\n",
      " [[ 9.06876973e+00 -2.08661583e+00 -9.25737186e+00  3.12990216e+00\n",
      "    5.07618165e+00 -1.59969089e+01]\n",
      "  [-1.36116736e-01  2.55212281e-01 -1.67901434e-01  1.01456176e-01\n",
      "    7.79589576e-02 -2.69188466e-01]]] reward= -4096056.4865180505 done= False\n",
      "Step 715\n",
      "Action:  [ 0.89025915  0.36587614 -0.7378459   1.1734362   1.8694417  -0.05647642]\n",
      "self.next: 715\n",
      "obs= [[[  2.64577683  -2.1874692   -0.18571095   0.85185332  -1.96913616\n",
      "     0.29834954]\n",
      "  [ -0.02772743   0.07089     -0.22521924   0.18221493   0.07556493\n",
      "    -0.41661502]]\n",
      "\n",
      " [[  9.05515806  -2.0610946   -9.274162     3.14004778   5.08397754\n",
      "   -16.02382779]\n",
      "  [ -0.13553344   0.25413111  -0.16724138   0.10108852   0.07760692\n",
      "    -0.26809993]]] reward= -4926800.6395866275 done= False\n",
      "Step 716\n",
      "Action:  [ 0.8947832   0.36530223 -0.74284005  1.1756388   1.8824943  -0.05857673]\n",
      "self.next: 716\n",
      "obs= [[[ 2.64300408e+00 -2.18038020e+00 -2.08232872e-01  8.70074810e-01\n",
      "   -1.96157966e+00  2.56688038e-01]\n",
      "  [-7.80910100e-03  1.01860519e-02 -1.80310794e-03 -6.20244539e-04\n",
      "   -8.83523059e-02  7.46652500e-02]]\n",
      "\n",
      " [[ 9.04160472e+00 -2.03568149e+00 -9.29088614e+00  3.15015663e+00\n",
      "    5.09173823e+00 -1.60506378e+01]\n",
      "  [-1.34969046e-01  2.53063569e-01 -1.66562819e-01  1.00704075e-01\n",
      "    7.72523319e-02 -2.66998988e-01]]] reward= -8190161.990682029 done= False\n",
      "Step 717\n",
      "Action:  [ 0.88821787  0.36612862 -0.73594314  1.1722685   1.8633298  -0.05534895]\n",
      "self.next: 717\n",
      "obs= [[[ 2.64222317e+00 -2.17936159e+00 -2.08413183e-01  8.70012786e-01\n",
      "   -1.97041489e+00  2.64154563e-01]\n",
      "  [ 1.60088308e-02 -7.18281184e-02  5.47347357e-02  8.67434427e-02\n",
      "   -7.37743839e-02  1.96602354e-01]]\n",
      "\n",
      " [[ 9.02810781e+00 -2.01037513e+00 -9.30754242e+00  3.16022704e+00\n",
      "    5.09946347e+00 -1.60773377e+01]\n",
      "  [-1.34424901e-01  2.52010885e-01 -1.65865371e-01  1.00302402e-01\n",
      "    7.68956872e-02 -2.65886487e-01]]] reward= -4614229.433674063 done= False\n",
      "Step 718\n",
      "Action:  [ 0.88673407  0.3659592  -0.73436004  1.1711563   1.859629   -0.05470911]\n",
      "self.next: 718\n",
      "obs= [[[ 2.64382406e+00 -2.18654440e+00 -2.02939710e-01  8.78687130e-01\n",
      "   -1.97779233e+00  2.83814798e-01]\n",
      "  [-9.77068942e-03  6.54600244e-03  3.01235948e-03 -1.56132690e-04\n",
      "   -8.98690386e-02 -7.71103071e-02]]\n",
      "\n",
      " [[ 9.01466532e+00 -1.98517404e+00 -9.32412896e+00  3.17025728e+00\n",
      "    5.10715304e+00 -1.61039263e+01]\n",
      "  [-1.33902273e-01  2.50974234e-01 -1.65148707e-01  9.98830562e-02\n",
      "    7.65374584e-02 -2.64763258e-01]]] reward= -5874252.889855105 done= False\n",
      "Step 719\n",
      "Action:  [ 0.886858    0.3661571  -0.7347863   1.1712132   1.8593421  -0.05434788]\n",
      "self.next: 719\n",
      "obs= [[[ 2.64284699e+00 -2.18588980e+00 -2.02638474e-01  8.78671517e-01\n",
      "   -1.98677924e+00  2.76103768e-01]\n",
      "  [ 1.63291653e-02 -5.43849976e-02  2.20516095e-01 -1.83805542e-01\n",
      "   -3.68070718e-03 -9.01650884e-02]]\n",
      "\n",
      " [[ 9.00127509e+00 -1.96007662e+00 -9.34064383e+00  3.18024559e+00\n",
      "    5.11480678e+00 -1.61304027e+01]\n",
      "  [-1.33402373e-01  2.49954747e-01 -1.64412520e-01  9.94455919e-02\n",
      "    7.61780896e-02 -2.63630081e-01]]] reward= -4941003.726106019 done= False\n",
      "Step 720\n",
      "Action:  [ 0.8807469   0.36630395 -0.7288658   1.1668993   1.8416604  -0.05055939]\n",
      "self.next: 720\n",
      "obs= [[[  2.6444799   -2.1913283   -0.18058686   0.86029096  -1.98714731\n",
      "     0.26708726]\n",
      "  [  0.01650069   0.05320211  -0.20336993   0.05081246   0.08158091\n",
      "    -0.05135217]]\n",
      "\n",
      " [[  8.98793486  -1.93508115  -9.35708508   3.19019014   5.12242459\n",
      "   -16.15676567]\n",
      "  [ -0.13292636   0.24895351  -0.16365651   0.09898956   0.07581799\n",
      "    -0.26248769]]] reward= -7625696.209713659 done= False\n",
      "Step 721\n",
      "Action:  [ 0.8884309   0.3665493  -0.73683035  1.1717486   1.8623149  -0.05573571]\n",
      "self.next: 721\n",
      "obs= [[[ 2.64612997e+00 -2.18600809e+00 -2.00923857e-01  8.65372208e-01\n",
      "   -1.97898922e+00  2.61952041e-01]\n",
      "  [-2.53112202e-04 -1.20889540e-03 -3.97461202e-05  2.47072369e-03\n",
      "   -1.01376730e-03 -4.39716803e-04]]\n",
      "\n",
      " [[ 8.97464222e+00 -1.91018579e+00 -9.37345073e+00  3.20008910e+00\n",
      "    5.13000639e+00 -1.61830144e+01]\n",
      "  [-1.32475305e-01  2.47971584e-01 -1.62880456e-01  9.85145366e-02\n",
      "    7.54575614e-02 -2.61336804e-01]]] reward= -5602649.245505772 done= False\n",
      "Step 722\n",
      "Action:  [ 0.8835808   0.36656392 -0.7319183   1.1688178   1.8490463  -0.0527226 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 722\n",
      "obs= [[[ 2.64610466e+00 -2.18612898e+00 -2.00927832e-01  8.65619281e-01\n",
      "   -1.97909059e+00  2.61908070e-01]\n",
      "  [-1.37724772e-02  7.43073804e-03  6.15707461e-03 -4.84400113e-04\n",
      "   -8.82623851e-02  1.70060635e-01]]\n",
      "\n",
      " [[ 8.96139469e+00 -1.88538864e+00 -9.38973878e+00  3.20994055e+00\n",
      "    5.13755215e+00 -1.62091481e+01]\n",
      "  [-1.32050256e-01  2.47009965e-01 -1.62084111e-01  9.80200844e-02\n",
      "    7.50971458e-02 -2.60178073e-01]]] reward= -4352418.017128881 done= False\n",
      "Step 723\n",
      "Action:  [ 0.8834289   0.36674786 -0.73160034  1.1690142   1.8485543  -0.05299004]\n",
      "self.next: 723\n",
      "obs= [[[ 2.64472741e+00 -2.18538591e+00 -2.00312124e-01  8.65570841e-01\n",
      "   -1.98791683e+00  2.78914133e-01]\n",
      "  [ 1.25713946e-02  1.16392468e-02 -2.41632070e-02  4.19750959e-04\n",
      "    9.75888063e-04 -3.74443447e-02]]\n",
      "\n",
      " [[ 8.94818966e+00 -1.86068764e+00 -9.40594719e+00  3.21974256e+00\n",
      "    5.14506186e+00 -1.62351659e+01]\n",
      "  [-1.31652175e-01  2.46069630e-01 -1.61267305e-01  9.75057968e-02\n",
      "    7.47370755e-02 -2.59012132e-01]]] reward= -4755055.120859719 done= False\n",
      "Step 724\n",
      "Action:  [ 0.8824647   0.36676016 -0.7309824   1.1680257   1.8454778  -0.05212985]\n",
      "self.next: 724\n",
      "obs= [[[ 2.64598455e+00 -2.18422198e+00 -2.02728445e-01  8.65612816e-01\n",
      "   -1.98781924e+00  2.75169699e-01]\n",
      "  [ 1.10757566e-02  1.12069903e-02 -2.31461374e-02  2.54949016e-04\n",
      "    1.71756775e-04 -3.74740861e-02]]\n",
      "\n",
      " [[ 8.93502445e+00 -1.83608068e+00 -9.42207392e+00  3.22949314e+00\n",
      "    5.15253557e+00 -1.62610671e+01]\n",
      "  [-1.31281972e-01  2.45151516e-01 -1.60429896e-01  9.69712805e-02\n",
      "    7.43776468e-02 -2.57839576e-01]]] reward= -4417966.475930003 done= False\n",
      "Step 725\n",
      "Action:  [ 0.88162726  0.36685762 -0.73024505  1.1674551   1.8429247  -0.05168345]\n",
      "self.next: 725\n",
      "obs= [[[ 2.64709213e+00 -2.18310128e+00 -2.05043058e-01  8.65638311e-01\n",
      "   -1.98780207e+00  2.71422290e-01]\n",
      "  [ 2.22583368e-02 -4.67961705e-02  2.43531952e-02  8.61193492e-02\n",
      "    7.03445179e-04 -1.93362482e-01]]\n",
      "\n",
      " [[ 8.92189625e+00 -1.81156552e+00 -9.43811691e+00  3.23919027e+00\n",
      "    5.15997333e+00 -1.62868511e+01]\n",
      "  [-1.30940493e-01  2.44256526e-01 -1.59571791e-01  9.64161655e-02\n",
      "    7.40191265e-02 -2.56660969e-01]]] reward= -4381037.298208972 done= False\n",
      "Step 726\n",
      "Action:  [ 0.88076615  0.36649695 -0.729548    1.1666409   1.8414146  -0.0509533 ]\n",
      "self.next: 726\n",
      "obs= [[[  2.64931796  -2.1877809   -0.20260774   0.87425025  -1.98773172\n",
      "     0.25208604]\n",
      "  [ -0.07332941  -0.02148405   0.09559945   0.03755394  -0.18866433\n",
      "     0.08581432]]\n",
      "\n",
      " [[  8.9088022   -1.78713987  -9.45407409   3.24883189   5.16737525\n",
      "   -16.31251719]\n",
      "  [ -0.13062853   0.24338553  -0.15869294   0.09584011   0.07366175\n",
      "    -0.25547685]]] reward= -4851974.517318259 done= False\n",
      "Step 727\n",
      "Action:  [ 0.87986225  0.36681095 -0.72826946  1.1667364   1.838811   -0.05076672]\n",
      "self.next: 727\n",
      "obs= [[[  2.64198502  -2.18992931  -0.19304779   0.87800564  -2.00659815\n",
      "     0.26066747]\n",
      "  [  0.07916616   0.02134462  -0.09929541  -0.03820393   0.02199838\n",
      "    -0.09360349]]\n",
      "\n",
      " [[  8.89573935  -1.76280132  -9.46994338   3.2584159    5.17474142\n",
      "   -16.33806487]\n",
      "  [ -0.1303468    0.24253937  -0.15779334   0.09524279   0.07330573\n",
      "    -0.25428771]]] reward= -5451005.944215096 done= False\n",
      "Step 728\n",
      "Action:  [ 0.88077915  0.36721897 -0.729749    1.1667987   1.84       -0.05135545]\n",
      "self.next: 728\n",
      "obs= [[[  2.64990164  -2.18779484  -0.20297734   0.87418525  -2.00439832\n",
      "     0.25130713]\n",
      "  [ -0.04837722   0.02637669   0.02387742   0.03564315  -0.11392333\n",
      "    -0.13597561]]\n",
      "\n",
      " [[  8.88270467  -1.73854738  -9.48572272   3.26794018   5.18207199\n",
      "   -16.36349365]\n",
      "  [ -0.13009598   0.24171885  -0.15687304   0.09462393   0.07295123\n",
      "    -0.25309404]]] reward= -5731912.628309717 done= False\n",
      "Step 729\n",
      "Action:  [ 0.87939924  0.36699364 -0.7282797   1.1660619   1.8368256  -0.05032462]\n",
      "self.next: 729\n",
      "obs= [[[ 2.64506391e+00 -2.18515718e+00 -2.00589594e-01  8.77749562e-01\n",
      "   -2.01579065e+00  2.37709565e-01]\n",
      "  [-3.52190367e-02  3.68490784e-04 -1.05973170e-02  1.29626384e-01\n",
      "   -8.38944196e-02 -1.00886674e-01]]\n",
      "\n",
      " [[ 8.86969507e+00 -1.71437550e+00 -9.50141002e+00  3.27740257e+00\n",
      "    5.18936712e+00 -1.63888031e+01]\n",
      "  [-1.29876682e-01  2.40924767e-01 -1.55932157e-01  9.39832865e-02\n",
      "    7.25984139e-02 -2.51896297e-01]]] reward= -5177862.38189678 done= False\n",
      "Step 730\n",
      "Action:  [ 0.87947637  0.3669234  -0.72841746  1.1659739   1.8372102  -0.05049406]\n",
      "self.next: 730\n",
      "obs= [[[ 2.64154201e+00 -2.18512033e+00 -2.01649325e-01  8.90712200e-01\n",
      "   -2.02418009e+00  2.27620897e-01]\n",
      "  [ 3.81368151e-02  1.91772213e-03  5.84024742e-03 -1.29527093e-01\n",
      "    8.35977480e-02  4.28200310e-03]]\n",
      "\n",
      " [[ 8.85670740e+00 -1.69028302e+00 -9.51700324e+00  3.28680090e+00\n",
      "    5.19662696e+00 -1.64139927e+01]\n",
      "  [-1.29689449e-01  2.40157863e-01 -1.54970839e-01  9.33206438e-02\n",
      "    7.22473889e-02 -2.50694897e-01]]] reward= -5199714.617259156 done= False\n",
      "Step 731\n",
      "Action:  [ 0.87533945  0.3676395  -0.72457796  1.1630474   1.8235066  -0.04823485]\n",
      "self.next: 731\n",
      "obs= [[[ 2.64535569e+00 -2.18492855e+00 -2.01065301e-01  8.77759491e-01\n",
      "   -2.01582032e+00  2.28049097e-01]\n",
      "  [ 6.44977347e-03 -1.12194959e-01  2.37820050e-01 -8.36676251e-02\n",
      "    2.91021766e-02 -1.23733419e-01]]\n",
      "\n",
      " [[ 8.84373846e+00 -1.66626723e+00 -9.53250032e+00  3.29613296e+00\n",
      "    5.20385170e+00 -1.64390622e+01]\n",
      "  [-1.29534780e-01  2.39418872e-01 -1.53989302e-01  9.26358348e-02\n",
      "    7.18982454e-02 -2.49490250e-01]]] reward= -5901583.258373367 done= False\n",
      "Step 732\n",
      "Action:  [ 0.87171113  0.36711922 -0.7209768   1.1605109   1.814817   -0.04574824]\n",
      "self.next: 732\n",
      "obs= [[[ 2.64600067e+00 -2.19614805e+00 -1.77283296e-01  8.69392728e-01\n",
      "   -2.01291010e+00  2.15675755e-01]\n",
      "  [ 1.87785701e-02  2.21912905e-02 -3.84464864e-02 -2.44047603e-03\n",
      "   -1.68635418e-03 -8.20200318e-02]]\n",
      "\n",
      " [[ 8.83078498e+00 -1.64232535e+00 -9.54789925e+00  3.30539655e+00\n",
      "    5.21104152e+00 -1.64640112e+01]\n",
      "  [-1.29413107e-01  2.38708498e-01 -1.52987824e-01  9.19287382e-02\n",
      "    7.15510455e-02 -2.48282739e-01]]] reward= -5366260.911380102 done= False\n",
      "Step 733\n",
      "Action:  [ 0.8769651   0.3674935  -0.7263547   1.1642299   1.8290725  -0.04926427]\n",
      "self.next: 733\n",
      "obs= [[[ 2.64787853e+00 -2.19392892e+00 -1.81127944e-01  8.69148681e-01\n",
      "   -2.01307873e+00  2.07473752e-01]\n",
      "  [-6.69817861e-04  1.30056028e-03 -1.48358065e-03 -8.74551819e-04\n",
      "   -1.08348703e-04  1.10359068e-03]]\n",
      "\n",
      " [[ 8.81784367e+00 -1.61845450e+00 -9.56319803e+00  3.31458942e+00\n",
      "    5.21819663e+00 -1.64888395e+01]\n",
      "  [-1.29324797e-01  2.38027422e-01 -1.51966756e-01  9.11992899e-02\n",
      "    7.12058269e-02 -2.47072736e-01]]] reward= -4768211.814749497 done= False\n",
      "Step 734\n",
      "Action:  [ 0.87546134  0.367579   -0.72486085  1.1632553   1.8246262  -0.04848111]\n",
      "self.next: 734\n",
      "obs= [[[ 2.64781154e+00 -2.19379886e+00 -1.81276302e-01  8.69061225e-01\n",
      "   -2.01308957e+00  2.07584111e-01]\n",
      "  [ 3.90719463e-03 -1.59278457e-02  6.27225798e-02 -4.87665381e-02\n",
      "   -3.68650863e-03  1.02436845e-03]]\n",
      "\n",
      " [[ 8.80491119e+00 -1.59465175e+00 -9.57839471e+00  3.32370935e+00\n",
      "    5.22531721e+00 -1.65135467e+01]\n",
      "  [-1.29270174e-01  2.37376301e-01 -1.50926493e-01  9.04474611e-02\n",
      "    7.08625932e-02 -2.45860584e-01]]] reward= -4297614.910845363 done= False\n",
      "Step 735\n",
      "Action:  [ 0.8734137   0.36766914 -0.7228818   1.1619245   1.8187836  -0.04724139]\n",
      "self.next: 735\n",
      "obs= [[[  2.64820226  -2.19539165  -0.17500404   0.86418457  -2.01345822\n",
      "     0.20768655]\n",
      "  [ -0.05624403   0.02081699   0.03468517   0.04008624  -0.11309638\n",
      "    -0.04705507]]\n",
      "\n",
      " [[  8.79198417  -1.57091412  -9.59348736   3.3327541    5.23240347\n",
      "   -16.5381328 ]\n",
      "  [ -0.12924949   0.23675577  -0.1498675    0.08967328   0.07052132\n",
      "    -0.24464661]]] reward= -5115054.7078020945 done= False\n",
      "Step 736\n",
      "Action:  [ 0.87485904  0.36755896 -0.7242866   1.1630536   1.8234236  -0.04807972]\n",
      "self.next: 736\n",
      "obs= [[[ 2.64257786e+00 -2.19330995e+00 -1.71535527e-01  8.68193195e-01\n",
      "   -2.02476786e+00  2.02981041e-01]\n",
      "  [ 1.07946060e-02 -3.04020680e-02 -2.97781144e-02  1.34303631e-01\n",
      "   -2.60079601e-03 -9.62271658e-02]]\n",
      "\n",
      " [[ 8.77905922e+00 -1.54723855e+00 -9.60847411e+00  3.34172142e+00\n",
      "    5.23945560e+00 -1.65625975e+01]\n",
      "  [-1.29262953e-01  2.36166431e-01 -1.48790320e-01  8.88768479e-02\n",
      "    7.01819777e-02 -2.43431137e-01]]] reward= -4814405.72499904 done= False\n",
      "Step 737\n",
      "Action:  [ 0.87493813  0.36742526 -0.7245879   1.1627026   1.8237969  -0.04820364]\n",
      "self.next: 737\n",
      "obs= [[[ 2.64365732e+00 -2.19635016e+00 -1.74513339e-01  8.81623558e-01\n",
      "   -2.02502794e+00  1.93358324e-01]\n",
      "  [-1.36619560e-02  3.84201627e-02 -2.26549129e-02 -8.73034750e-02\n",
      "   -1.64433190e-01  1.80853697e-01]]\n",
      "\n",
      " [[ 8.76613293e+00 -1.52362190e+00 -9.62335314e+00  3.35060911e+00\n",
      "    5.24647380e+00 -1.65869406e+01]\n",
      "  [-1.29310692e-01  2.35608881e-01 -1.47695555e-01  8.80583030e-02\n",
      "    6.98444815e-02 -2.42214459e-01]]] reward= -5801999.926217549 done= False\n",
      "Step 738\n",
      "Action:  [ 0.8744645   0.36810064 -0.7238131   1.1631153   1.8213003  -0.04831653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 738\n",
      "obs= [[[ 2.64229113e+00 -2.19250814e+00 -1.76778830e-01  8.72893211e-01\n",
      "   -2.04147126e+00  2.11443694e-01]\n",
      "  [ 2.87446996e-02 -4.84578817e-02  7.10180776e-02  3.37837417e-02\n",
      "   -7.94383772e-04 -2.38558030e-01]]\n",
      "\n",
      " [[ 8.75320186e+00 -1.50006102e+00 -9.63812270e+00  3.35941494e+00\n",
      "    5.25345825e+00 -1.66111620e+01]\n",
      "  [-1.29392789e-01  2.35083683e-01 -1.46583881e-01  8.72178596e-02\n",
      "    6.95087409e-02 -2.40996864e-01]]] reward= -6553966.652438493 done= False\n",
      "Step 739\n",
      "Action:  [ 0.8714967   0.36755413 -0.7214079   1.1602911   1.8139235  -0.04598958]\n",
      "self.next: 739\n",
      "obs= [[[ 2.64516560e+00 -2.19735393e+00 -1.69677022e-01  8.76271585e-01\n",
      "   -2.04155069e+00  1.87587891e-01]\n",
      "  [-2.95996266e-02  2.83239942e-02  2.01796158e-03 -8.43436761e-02\n",
      "   -1.28220731e-02 -1.94184062e-01]]\n",
      "\n",
      " [[ 8.74026258e+00 -1.47655265e+00 -9.65278108e+00  3.36813672e+00\n",
      "    5.26040912e+00 -1.66352617e+01]\n",
      "  [-1.29509264e-01  2.34591380e-01 -1.45456043e-01  8.63557915e-02\n",
      "    6.91746372e-02 -2.39778627e-01]]] reward= -5209798.294068306 done= False\n",
      "Step 740\n",
      "Action:  [ 0.8715572   0.36802813 -0.7215796   1.1604549   1.8128968  -0.04612793]\n",
      "self.next: 740\n",
      "obs= [[[ 2.64220563e+00 -2.19452153e+00 -1.69475226e-01  8.67837217e-01\n",
      "   -2.04283290e+00  1.68169485e-01]\n",
      "  [-2.01361243e-02 -1.84069411e-02  3.88113984e-02 -7.40104494e-04\n",
      "   -8.78072130e-02  8.62097359e-02]]\n",
      "\n",
      " [[ 8.72731165e+00 -1.45309351e+00 -9.66732669e+00  3.37677230e+00\n",
      "    5.26732658e+00 -1.66592396e+01]\n",
      "  [-1.29660071e-01  2.34132493e-01 -1.44312871e-01  8.54724483e-02\n",
      "    6.88420307e-02 -2.38560015e-01]]] reward= -6034971.960361655 done= False\n",
      "Step 741\n",
      "Action:  [ 0.8712213   0.3680289  -0.7209684   1.1606185   1.8124077  -0.04630046]\n",
      "self.next: 741\n",
      "obs= [[[ 2.64019202e+00 -2.19636222e+00 -1.65594086e-01  8.67763207e-01\n",
      "   -2.05161362e+00  1.76790458e-01]\n",
      "  [ 4.25423792e-02  2.63989266e-02 -6.87969044e-02 -4.37721816e-04\n",
      "    1.89652999e-02  1.03148407e-01]]\n",
      "\n",
      " [[ 8.71434564e+00 -1.42968026e+00 -9.68175798e+00  3.38531955e+00\n",
      "    5.27421079e+00 -1.66830956e+01]\n",
      "  [-1.29845102e-01  2.33707518e-01 -1.43155266e-01  8.45682472e-02\n",
      "    6.85107589e-02 -2.37341284e-01]]] reward= -4725095.626884344 done= False\n",
      "Step 742\n",
      "Action:  [ 0.87200963  0.36826783 -0.72197014  1.160904    1.8139002  -0.04701235]\n",
      "self.next: 742\n",
      "obs= [[[ 2.64444626e+00 -2.19372233e+00 -1.72473777e-01  8.67719435e-01\n",
      "   -2.04971709e+00  1.87105299e-01]\n",
      "  [-1.35364120e-02  6.05310919e-02 -2.30901864e-01  1.82127887e-01\n",
      "   -1.82410880e-03  1.80785411e-03]]\n",
      "\n",
      " [[ 8.70136113e+00 -1.40630951e+00 -9.69607350e+00  3.39377637e+00\n",
      "    5.28106186e+00 -1.67068297e+01]\n",
      "  [-1.30064184e-01  2.33316930e-01 -1.41984213e-01  8.36436819e-02\n",
      "    6.81806387e-02 -2.36122684e-01]]] reward= -5720144.031064797 done= False\n",
      "Step 743\n",
      "Action:  [ 0.8757333   0.3680464  -0.7257654   1.1630994   1.8246137  -0.04930643]\n",
      "self.next: 743\n",
      "obs= [[[  2.64309262  -2.18766922  -0.19556396   0.88593222  -2.0498995\n",
      "     0.18728608]\n",
      "  [  0.09647774  -0.11479528   0.37841366  -0.39741178   0.11259397\n",
      "    -0.13588819]]\n",
      "\n",
      " [[  8.68835472  -1.38297782  -9.71027192   3.40214074   5.28787993\n",
      "   -16.73044197]\n",
      "  [ -0.13031708   0.23296118  -0.14080078   0.08269933   0.06785147\n",
      "    -0.23490446]]] reward= -7009462.00449859 done= False\n",
      "Step 744\n",
      "Action:  [ 0.86082107  0.36839464 -0.71124125  1.1530086   1.7824007  -0.03986844]\n",
      "self.next: 744\n",
      "obs= [[[  2.65274039  -2.19914875  -0.1577226    0.84619105  -2.03864011\n",
      "     0.17369727]\n",
      "  [ -0.10942673   0.02715721  -0.09658253   0.21337359  -0.198367\n",
      "     0.07246847]]\n",
      "\n",
      " [[  8.67532301  -1.3596817   -9.724352     3.41041067   5.29466507\n",
      "   -16.75393241]\n",
      "  [ -0.1306035    0.23264069  -0.13960607   0.08173581   0.06752301\n",
      "    -0.23368684]]] reward= -11505561.448875535 done= False\n",
      "Step 745\n",
      "Action:  [ 0.8741653   0.36792535 -0.72404474  1.1626037   1.8213912  -0.0483768 ]\n",
      "self.next: 745\n",
      "obs= [[[  2.64179772  -2.19643303  -0.16738085   0.8675284   -2.05847681\n",
      "     0.18094411]\n",
      "  [  0.01862388   0.07958163  -0.09973306  -0.08385637  -0.08029517\n",
      "     0.10099025]]\n",
      "\n",
      " [[  8.66226266  -1.33641763  -9.73831261   3.41858426   5.30141738\n",
      "   -16.7773011 ]\n",
      "  [ -0.13092304   0.23235585  -0.13840138   0.0807539    0.06719505\n",
      "    -0.23247007]]] reward= -7844658.235807612 done= False\n",
      "Step 746\n",
      "Action:  [ 0.8707497   0.36871177 -0.7208904   1.1603013   1.8097053  -0.0464274 ]\n",
      "self.next: 746\n",
      "obs= [[[ 2.64366011e+00 -2.18847487e+00 -1.77354157e-01  8.59142768e-01\n",
      "   -2.06650632e+00  1.91043137e-01]\n",
      "  [ 5.25232078e-02 -5.68206434e-02  7.35233323e-03 -4.26421793e-02\n",
      "   -1.29499704e-01  1.72952910e-01]]\n",
      "\n",
      " [[ 8.64917036e+00 -1.31318204e+00 -9.75215275e+00  3.42665965e+00\n",
      "    5.30813688e+00 -1.68005481e+01]\n",
      "  [-1.31275277e-01  2.32107048e-01 -1.37187992e-01  7.97543958e-02\n",
      "    6.68673131e-02 -2.31254371e-01]]] reward= -6882061.049796489 done= False\n",
      "Step 747\n",
      "Action:  [ 0.86843324  0.36849937 -0.7184548   1.1588926   1.8039303  -0.04508883]\n",
      "self.next: 747\n",
      "obs= [[[ 2.64891243e+00 -2.19415693e+00 -1.76618923e-01  8.54878550e-01\n",
      "   -2.07945629e+00  2.08338429e-01]\n",
      "  [-1.44087185e-02 -8.53440523e-03  2.38720622e-02 -3.34973547e-03\n",
      "   -9.53950173e-02  2.43316301e-01]]\n",
      "\n",
      " [[ 8.63604283e+00 -1.28997134e+00 -9.76587155e+00  3.43463508e+00\n",
      "    5.31482361e+00 -1.68236735e+01]\n",
      "  [-1.31659697e-01  2.31894618e-01 -1.35967308e-01  7.87382143e-02\n",
      "    6.65395255e-02 -2.30039982e-01]]] reward= -5637855.6766687855 done= False\n",
      "Step 748\n",
      "Action:  [ 0.86807936  0.36854896 -0.71806735  1.1585404   1.8024741  -0.04497178]\n",
      "self.next: 748\n",
      "obs= [[[  2.64747156  -2.19501037  -0.17423172   0.85454358  -2.0889958\n",
      "     0.23267006]\n",
      "  [  0.04364243   0.016893    -0.06146419  -0.1272907    0.03349724\n",
      "     0.05148111]]\n",
      "\n",
      " [[  8.62287686  -1.26678188  -9.77946828   3.44250891   5.32147756\n",
      "   -16.84667754]\n",
      "  [ -0.13207571   0.23171888  -0.13474083   0.07770636   0.0662114\n",
      "    -0.22882713]]] reward= -5223172.418865612 done= False\n",
      "Step 749\n",
      "Action:  [ 0.8672058   0.36887342 -0.71764064  1.157564    1.7990721  -0.04437511]\n",
      "self.next: 749\n",
      "obs= [[[ 2.65183580e+00 -2.19332107e+00 -1.80378136e-01  8.41814506e-01\n",
      "   -2.08564607e+00  2.37818170e-01]\n",
      "  [-7.05966634e-02 -1.00841388e-02  8.14239611e-02  4.01215828e-02\n",
      "   -1.09027158e-01  3.37868342e-02]]\n",
      "\n",
      " [[ 8.60966929e+00 -1.24360999e+00 -9.79294236e+00  3.45027954e+00\n",
      "    5.32809870e+00 -1.68695603e+01]\n",
      "  [-1.32522643e-01  2.31580104e-01 -1.33510144e-01  7.66599266e-02\n",
      "    6.58826380e-02 -2.27616057e-01]]] reward= -6203751.046139368 done= False\n",
      "Step 750\n",
      "Action:  [ 0.8660933   0.36846387 -0.7163206   1.1570412   1.7971425  -0.04351883]\n",
      "self.next: 750\n",
      "obs= [[[ 2.64477613e+00 -2.19432949e+00 -1.72235739e-01  8.45826664e-01\n",
      "   -2.09654879e+00  2.41196853e-01]\n",
      "  [ 6.71217300e-03  4.09266011e-02 -4.79276181e-02  1.74215077e-03\n",
      "    6.36985360e-02 -1.72128033e-01]]\n",
      "\n",
      " [[ 8.59641702e+00 -1.22045198e+00 -9.80629337e+00  3.45794553e+00\n",
      "    5.33468697e+00 -1.68923219e+01]\n",
      "  [-1.32999766e-01  2.31478554e-01 -1.32276926e-01  7.56001122e-02\n",
      "    6.55529221e-02 -2.26406992e-01]]] reward= -5286074.78844824 done= False\n",
      "Step 751\n",
      "Action:  [ 0.8662428   0.36866456 -0.7169937   1.1565711   1.796876   -0.0436062 ]\n",
      "self.next: 751\n",
      "obs= [[[ 2.64544735e+00 -2.19023683e+00 -1.77028501e-01  8.46000880e-01\n",
      "   -2.09017893e+00  2.23984050e-01]\n",
      "  [ 2.04115214e-02 -7.83773971e-03 -1.25737817e-02  1.64172033e-03\n",
      "    2.84078423e-02 -1.68712430e-01]]\n",
      "\n",
      " [[ 8.58311705e+00 -1.19730412e+00 -9.81952107e+00  3.46550555e+00\n",
      "    5.34124226e+00 -1.69149626e+01]\n",
      "  [-1.33506257e-01  2.31414441e-01 -1.31042951e-01  7.45282110e-02\n",
      "    6.52219290e-02 -2.25200180e-01]]] reward= -4871024.33219537 done= False\n",
      "Step 752\n",
      "Action:  [ 0.8650568   0.36865166 -0.71586996  1.1558793   1.7938468  -0.0429169 ]\n",
      "self.next: 752\n",
      "obs= [[[ 2.64748850e+00 -2.19102060e+00 -1.78285879e-01  8.46165052e-01\n",
      "   -2.08733815e+00  2.07112807e-01]\n",
      "  [-3.02635657e-03  1.62341314e-02 -6.42528424e-02  5.18782108e-02\n",
      "    6.83007810e-04 -6.07563536e-04]]\n",
      "\n",
      " [[ 8.56976642e+00 -1.17416268e+00 -9.83262536e+00  3.47295837e+00\n",
      "    5.34776445e+00 -1.69374826e+01]\n",
      "  [-1.34041220e-01  2.31387947e-01 -1.29810077e-01  7.34456158e-02\n",
      "    6.48893246e-02 -2.23995868e-01]]] reward= -4770905.163014953 done= False\n",
      "Step 753\n",
      "Action:  [ 0.8661105   0.3687716  -0.7168121   1.1567539   1.7965401  -0.04380164]\n",
      "self.next: 753\n",
      "obs= [[[ 2.64718587e+00 -2.18939719e+00 -1.84711164e-01  8.51352873e-01\n",
      "   -2.08726985e+00  2.07052051e-01]\n",
      "  [ 1.69551282e-02 -7.38014392e-02  1.04361637e-01  3.59196797e-02\n",
      "    1.05900092e-02 -5.75148421e-02]]\n",
      "\n",
      " [[ 8.55636230e+00 -1.15102389e+00 -9.84560637e+00  3.48030293e+00\n",
      "    5.35425339e+00 -1.69598822e+01]\n",
      "  [-1.34603676e-01  2.31399216e-01 -1.28580262e-01  7.23538259e-02\n",
      "    6.45547686e-02 -2.22794313e-01]]] reward= -5168153.011965069 done= False\n",
      "Step 754\n",
      "Action:  [ 0.8622085   0.36862203 -0.7130027   1.1540968   1.78617    -0.04131694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 754\n",
      "obs= [[[ 2.64888138e+00 -2.19677733e+00 -1.74275000e-01  8.54944841e-01\n",
      "   -2.08621085e+00  2.01300566e-01]\n",
      "  [-3.05677951e-02  1.35756210e-01 -3.36305710e-01  1.46549354e-01\n",
      "   -1.07682166e-02  5.81305378e-02]]\n",
      "\n",
      " [[ 8.54290193e+00 -1.12788396e+00 -9.85846440e+00  3.48753831e+00\n",
      "    5.36070886e+00 -1.69821616e+01]\n",
      "  [-1.35192576e-01  2.31448355e-01 -1.27355543e-01  7.12544336e-02\n",
      "    6.42179120e-02 -2.21595775e-01]]] reward= -5286007.051673255 done= False\n",
      "Step 755\n",
      "Action:  [ 0.87179536  0.3689438  -0.7225348   1.1603329   1.8118511  -0.04767066]\n",
      "self.next: 755\n",
      "obs= [[[ 2.64582460e+00 -2.18320171e+00 -2.07905571e-01  8.69599776e-01\n",
      "   -2.08728767e+00  2.07113620e-01]\n",
      "  [ 2.29492241e-02 -6.61344937e-02  2.78430976e-01 -2.35909565e-01\n",
      "    2.03055525e-03 -4.96230818e-02]]\n",
      "\n",
      " [[ 8.52938267e+00 -1.10473913e+00 -9.87119995e+00  3.49466375e+00\n",
      "    5.36713065e+00 -1.70043212e+01]\n",
      "  [-1.35806770e-01  2.31535426e-01 -1.26138077e-01  7.01491579e-02\n",
      "    6.38784099e-02 -2.20400537e-01]]] reward= -7748599.682172321 done= False\n",
      "Step 756\n",
      "Action:  [ 0.85702735  0.3690822  -0.7079658   1.1507341   1.7706609  -0.03818747]\n",
      "self.next: 756\n",
      "obs= [[[  2.64811952  -2.18981516  -0.18006247   0.84600882  -2.08708461\n",
      "     0.20215131]\n",
      "  [ -0.04619393  -0.01867608   0.06769653   0.03982387  -0.08066847\n",
      "     0.06008049]]\n",
      "\n",
      " [[  8.515802    -1.08158559  -9.88381376   3.50167867   5.37351849\n",
      "   -17.02636123]\n",
      "  [ -0.13644507   0.23166046  -0.12493004   0.06903977   0.0635359\n",
      "    -0.21920887]]] reward= -9037712.44923785 done= False\n",
      "Step 757\n",
      "Action:  [ 0.8622563   0.36889037 -0.7130136   1.1544166   1.7858503  -0.04156529]\n",
      "self.next: 757\n",
      "obs= [[[ 2.64350013e+00 -2.19168277e+00 -1.73292821e-01  8.49991207e-01\n",
      "   -2.09515146e+00  2.08159361e-01]\n",
      "  [-2.82141018e-03 -4.05852079e-02  2.21805276e-01 -1.79348959e-01\n",
      "   -2.55803548e-02  2.19857095e-02]]\n",
      "\n",
      " [[ 8.50215749e+00 -1.05841954e+00 -9.89630676e+00  3.50858265e+00\n",
      "    5.37987208e+00 -1.70482821e+01]\n",
      "  [-1.37106165e-01  2.31823434e-01 -1.23733771e-01  6.79282036e-02\n",
      "    6.31900333e-02 -2.18021069e-01]]] reward= -5130338.10320366 done= False\n",
      "Step 758\n",
      "Action:  [ 0.85788643  0.36914837 -0.7088121   1.1514139   1.7731415  -0.03887254]\n",
      "self.next: 758\n",
      "obs= [[[ 2.64321799e+00 -2.19574129e+00 -1.51112293e-01  8.32056311e-01\n",
      "   -2.09770950e+00  2.10357931e-01]\n",
      "  [-2.10771338e-02  4.56446059e-02 -2.45358263e-02 -8.42279307e-02\n",
      "   -1.18118103e-02  1.08343178e-01]]\n",
      "\n",
      " [[ 8.48844687e+00 -1.03523720e+00 -9.90868014e+00  3.51537547e+00\n",
      "    5.38619109e+00 -1.70700842e+01]\n",
      "  [-1.37788697e-01  2.32024287e-01 -1.22551634e-01  6.68164462e-02\n",
      "    6.28404598e-02 -2.16837447e-01]]] reward= -7891895.121488795 done= False\n",
      "Step 759\n",
      "Action:  [ 0.8623131   0.36931077 -0.7132721   1.1543453   1.7850107  -0.04185462]\n",
      "self.next: 759\n",
      "obs= [[[ 2.64111027e+00 -2.19117683e+00 -1.53565876e-01  8.23633518e-01\n",
      "   -2.09889068e+00  2.21192249e-01]\n",
      "  [ 2.96876591e-03  3.07981060e-03 -1.83632589e-01  2.58735402e-01\n",
      "    1.15720559e-02 -1.58347095e-01]]\n",
      "\n",
      " [[ 8.47466800e+00 -1.01203477e+00 -9.92093530e+00  3.52205711e+00\n",
      "    5.39247513e+00 -1.70917680e+01]\n",
      "  [-1.38491217e-01  2.32262913e-01 -1.21386101e-01  6.57066100e-02\n",
      "    6.24868350e-02 -2.15658326e-01]]] reward= -5577929.426865382 done= False\n",
      "Step 760\n",
      "Action:  [ 0.86589974  0.36867148 -0.7171089   1.1562076   1.7967291  -0.04396404]\n",
      "self.next: 760\n",
      "obs= [[[ 2.64140715e+00 -2.19086885e+00 -1.71929135e-01  8.49507058e-01\n",
      "   -2.09773347e+00  2.05357540e-01]\n",
      "  [-1.70771389e-03 -1.67677277e-03  2.72470120e-03  2.96257687e-03\n",
      "   -2.73500448e-03 -2.20600140e-04]]\n",
      "\n",
      " [[ 8.46081888e+00 -9.88808477e-01 -9.93307391e+00  3.52862777e+00\n",
      "    5.39872382e+00 -1.71133338e+01]\n",
      "  [-1.39212216e-01  2.32539158e-01 -1.20239693e-01  6.46008846e-02\n",
      "    6.21288185e-02 -2.14484038e-01]]] reward= -8257685.630381855 done= False\n",
      "Step 761\n",
      "Action:  [ 0.86051685  0.36920413 -0.7116936   1.15302     1.7804161  -0.04071297]\n",
      "self.next: 761\n",
      "obs= [[[ 2.64123638e+00 -2.19103652e+00 -1.71656665e-01  8.49803316e-01\n",
      "   -2.09800697e+00  2.05335480e-01]\n",
      "  [-1.30189905e-02  5.82122998e-02 -4.46776269e-02 -8.40268890e-02\n",
      "   -9.38966743e-03  5.69050907e-02]]\n",
      "\n",
      " [[ 8.44689766e+00 -9.65554561e-01 -9.94509788e+00  3.53508786e+00\n",
      "    5.40493670e+00 -1.71347822e+01]\n",
      "  [-1.39950133e-01  2.32852832e-01 -1.19114976e-01  6.35015367e-02\n",
      "    6.17660735e-02 -2.13314919e-01]]] reward= -4662062.827534715 done= False\n",
      "Step 762\n",
      "Action:  [ 0.8607347   0.36949888 -0.7119416   1.1532446   1.7802702  -0.04097103]\n",
      "self.next: 762\n",
      "obs= [[[ 2.63993448e+00 -2.18521529e+00 -1.76124427e-01  8.41400627e-01\n",
      "   -2.09894594e+00  2.11025989e-01]\n",
      "  [ 2.00754518e-03 -4.09580866e-02  3.91359578e-02 -1.61529908e-03\n",
      "    3.16850446e-02 -2.80094588e-02]]\n",
      "\n",
      " [[ 8.43290265e+00 -9.42269278e-01 -9.95700938e+00  3.54143802e+00\n",
      "    5.41111331e+00 -1.71561137e+01]\n",
      "  [-1.40703328e-01  2.33203691e-01 -1.18014595e-01  6.24109324e-02\n",
      "    6.13982814e-02 -2.12151333e-01]]] reward= -5836332.612852355 done= False\n",
      "Step 763\n",
      "Action:  [ 0.85825115  0.3692393  -0.70962125  1.1513726   1.7740146  -0.03941116]\n",
      "self.next: 763\n",
      "obs= [[[ 2.64013523e+00 -2.18931110e+00 -1.72210832e-01  8.41239097e-01\n",
      "   -2.09577744e+00  2.08225043e-01]\n",
      "  [-3.63131537e-03  4.04074044e-02 -3.54758081e-02 -5.98731037e-05\n",
      "   -3.34213244e-02  2.88910159e-02]]\n",
      "\n",
      " [[ 8.41883231e+00 -9.18948909e-01 -9.96881084e+00  3.54767911e+00\n",
      "    5.41725313e+00 -1.71773288e+01]\n",
      "  [-1.41470119e-01  2.33591452e-01 -1.16941222e-01  6.13315006e-02\n",
      "    6.10251331e-02 -2.10993648e-01]]] reward= -4750979.083717254 done= False\n",
      "Step 764\n",
      "Action:  [ 0.86001486  0.3694229  -0.7113249   1.1527721   1.7787032  -0.04060418]\n",
      "self.next: 764\n",
      "obs= [[[ 2.63977210e+00 -2.18527036e+00 -1.75758412e-01  8.41233110e-01\n",
      "   -2.09911957e+00  2.11114145e-01]\n",
      "  [-6.72630915e-03 -9.05533168e-03  1.26448537e-02  3.67667419e-03\n",
      "    4.31445664e-04  4.96967022e-02]]\n",
      "\n",
      " [[ 8.40468530e+00 -8.95589763e-01 -9.98050496e+00  3.55381226e+00\n",
      "    5.42335565e+00 -1.71984282e+01]\n",
      "  [-1.42248768e-01  2.34015786e-01 -1.15897577e-01  6.02657454e-02\n",
      "    6.06463371e-02 -2.09842246e-01]]] reward= -5166495.14711617 done= False\n",
      "Step 765\n",
      "Action:  [ 0.858207    0.36939698 -0.7095779   1.1514697   1.7736158  -0.03955135]\n",
      "self.next: 765\n",
      "obs= [[[ 2.63909947e+00 -2.18617590e+00 -1.74493927e-01  8.41600777e-01\n",
      "   -2.09907642e+00  2.16083815e-01]\n",
      "  [-2.15352600e-04 -4.41789260e-04  1.02857838e-03  5.68887049e-04\n",
      "   -5.87957805e-04 -1.52290445e-04]]\n",
      "\n",
      " [[ 8.39046043e+00 -8.72188185e-01 -9.99209472e+00  3.55983883e+00\n",
      "    5.42942028e+00 -1.72194124e+01]\n",
      "  [-1.43037513e-01  2.34476327e-01 -1.14886381e-01  5.92162159e-02\n",
      "    6.02616156e-02 -2.08697519e-01]]] reward= -4883905.451986826 done= False\n",
      "Step 766\n",
      "Action:  [ 0.85788596  0.36944577 -0.70936185  1.1512201   1.7727293  -0.03936776]\n",
      "self.next: 766\n",
      "obs= [[[ 2.63907794e+00 -2.18622007e+00 -1.74391069e-01  8.41657666e-01\n",
      "   -2.09913522e+00  2.16068586e-01]\n",
      "  [-2.78426024e-02 -1.76665826e-02  4.47252425e-02  3.81303657e-04\n",
      "    6.38068925e-02 -3.24442536e-01]]\n",
      "\n",
      " [[ 8.37615667e+00 -8.48740552e-01 -1.00035834e+01  3.56576045e+00\n",
      "    5.43544644e+00 -1.72402822e+01]\n",
      "  [-1.43834553e-01  2.34972666e-01 -1.13910379e-01  5.81855139e-02\n",
      "    5.98707127e-02 -2.07559869e-01]]] reward= -4743003.228534903 done= False\n",
      "Step 767\n",
      "Action:  [ 0.855938    0.36926436 -0.7078615   1.1493843   1.7677094  -0.03798147]\n",
      "self.next: 767\n",
      "obs= [[[  2.63629368  -2.18798673  -0.16991854   0.8416958   -2.09275453\n",
      "     0.18362433]\n",
      "  [  0.04396081  -0.04287162   0.17993313  -0.17962441   0.02846053\n",
      "     0.01947354]]\n",
      "\n",
      " [[  8.36177322  -0.82524329 -10.0149744    3.57157901   5.44143351\n",
      "   -17.26103815]\n",
      "  [ -0.14463808   0.23550436  -0.1129723    0.05717627   0.05947339\n",
      "    -0.2064297 ]]] reward= -5760453.51788075 done= False\n",
      "Step 768\n",
      "Action:  [ 0.852936    0.3696596  -0.70464504  1.1479374   1.7588143  -0.03645014]\n",
      "self.next: 768\n",
      "obs= [[[ 2.64068976e+00 -2.19227390e+00 -1.51925232e-01  8.23733355e-01\n",
      "   -2.08990848e+00  1.85571687e-01]\n",
      "  [ 5.83238723e-03  1.34639730e-02 -2.09437076e-02  1.41816958e-04\n",
      "    8.92840462e-04 -5.10973858e-02]]\n",
      "\n",
      " [[ 8.34730941e+00 -8.01692849e-01 -1.00262716e+01  3.57729663e+00\n",
      "    5.44738085e+00 -1.72816811e+01]\n",
      "  [-1.45446264e-01  2.36070942e-01 -1.12074859e-01  5.61911413e-02\n",
      "    5.90694388e-02 -2.05307437e-01]]] reward= -8350092.652199213 done= False\n",
      "Step 769\n",
      "Action:  [ 0.857166    0.369552   -0.7089512   1.1506766   1.7709618  -0.03909121]\n",
      "self.next: 769\n",
      "obs= [[[ 2.64127300e+00 -2.19092750e+00 -1.54019603e-01  8.23747537e-01\n",
      "   -2.08981919e+00  1.80461948e-01]\n",
      "  [-2.61025701e-02 -3.53304323e-02  6.28064751e-02 -2.93110378e-03\n",
      "   -9.59832012e-02  1.56213002e-01]]\n",
      "\n",
      " [[ 8.33276478e+00 -7.78085755e-01 -1.00374791e+01  3.58291575e+00\n",
      "    5.45328780e+00 -1.73022119e+01]\n",
      "  [-1.46257288e-01  2.36671897e-01 -1.11220753e-01  5.52327988e-02\n",
      "    5.86586691e-02 -2.04193496e-01]]] reward= -4974176.787358551 done= False\n",
      "Step 770\n",
      "Action:  [ 0.8562295   0.36954206 -0.7077078   1.1504052   1.7683499  -0.03865417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 770\n",
      "obs= [[[ 2.63866274e+00 -2.19446054e+00 -1.47738955e-01  8.23454427e-01\n",
      "   -2.09941751e+00  1.96083248e-01]\n",
      "  [ 9.11188132e-03 -1.53817023e-02  8.73908941e-03 -5.14500925e-03\n",
      "   -6.14561449e-02  7.31738332e-02]]\n",
      "\n",
      " [[ 8.31813906e+00 -7.54418566e-01 -1.00486012e+01  3.58843903e+00\n",
      "    5.45915366e+00 -1.73226312e+01]\n",
      "  [-1.47069357e-01  2.37306703e-01 -1.10412607e-01  5.43038942e-02\n",
      "    5.82409167e-02 -2.03088296e-01]]] reward= -5593500.263432554 done= False\n",
      "Step 771\n",
      "Action:  [ 0.85643864  0.3696225  -0.7080893   1.1504129   1.768899   -0.03881111]\n",
      "self.next: 771\n",
      "obs= [[[  2.63957393  -2.19599871  -0.14686505   0.82293993  -2.10556313\n",
      "     0.20340063]\n",
      "  [  0.02649152   0.0308833   -0.05824421  -0.12225312   0.08710002\n",
      "    -0.3218848 ]]\n",
      "\n",
      " [[  8.30343212  -0.7306879  -10.05964245   3.59386942   5.46497776\n",
      "   -17.34294005]\n",
      "  [ -0.1478807    0.23797481  -0.109653     0.05340707   0.05781605\n",
      "    -0.20199226]]] reward= -5156616.8743095 done= False\n",
      "Step 772\n",
      "Action:  [ 0.85506094  0.3697613  -0.7074175   1.1487833   1.7648046  -0.03785418]\n",
      "self.next: 772\n",
      "obs= [[[  2.64222308  -2.19291038  -0.15268947   0.81071461  -2.09685313\n",
      "     0.17121215]\n",
      "  [  0.03297959  -0.07446021   0.03914992  -0.04422194  -0.0498727\n",
      "     0.25273319]]\n",
      "\n",
      " [[  8.28864405  -0.70689041 -10.07060775   3.59921012   5.47075936\n",
      "   -17.36313927]\n",
      "  [ -0.14868959   0.23867567  -0.10894441   0.05254492   0.05738395\n",
      "    -0.2009058 ]]] reward= -7466370.47760238 done= False\n",
      "Step 773\n",
      "Action:  [ 0.85491043  0.36972895 -0.7065857   1.1494553   1.7643254  -0.03819312]\n",
      "self.next: 773\n",
      "obs= [[[ 2.64552104e+00 -2.20035640e+00 -1.48774475e-01  8.06292420e-01\n",
      "   -2.10184039e+00  1.96485471e-01]\n",
      "  [-1.25632624e-02  5.29895542e-02 -4.16962826e-02 -8.01844956e-02\n",
      "    8.04459446e-02 -1.47138373e-01]]\n",
      "\n",
      " [[ 8.27377509e+00 -6.83022847e-01 -1.00815022e+01  3.60446462e+00\n",
      "    5.47649776e+00 -1.73832299e+01]\n",
      "  [-1.49494358e-01  2.39408711e-01 -1.08289257e-01  5.17199973e-02\n",
      "    5.69445354e-02 -1.99829329e-01]]] reward= -5663750.979927838 done= False\n",
      "Step 774\n",
      "Action:  [ 0.85460424  0.3698744  -0.7068747   1.1486241   1.7631655  -0.03777951]\n",
      "self.next: 774\n",
      "obs= [[[ 2.64426471e+00 -2.19505745e+00 -1.52944103e-01  7.98273971e-01\n",
      "   -2.09379580e+00  1.81771633e-01]\n",
      "  [ 5.51798540e-02 -9.38835401e-03 -4.65302879e-02 -4.38854589e-02\n",
      "    1.09340452e-01 -1.26247437e-01]]\n",
      "\n",
      " [[ 8.25882566e+00 -6.59081976e-01 -1.00923311e+01  3.60963661e+00\n",
      "    5.48219221e+00 -1.74032128e+01]\n",
      "  [-1.50293405e-01  2.40173367e-01 -1.07689824e-01  5.09347949e-02\n",
      "    5.64977619e-02 -1.98763250e-01]]] reward= -5681270.51981007 done= False\n",
      "Step 775\n",
      "Action:  [ 0.8536242   0.36982137 -0.70606184  1.1479317   1.7608256  -0.03735685]\n",
      "self.next: 775\n",
      "obs= [[[ 2.64978270e+00 -2.19599628e+00 -1.57597132e-01  7.93885425e-01\n",
      "   -2.08286176e+00  1.69146890e-01]\n",
      "  [-6.82384547e-02 -1.65092471e-02  8.45805840e-02  4.34352629e-02\n",
      "   -1.11280155e-01  3.33832056e-02]]\n",
      "\n",
      " [[ 8.24379631e+00 -6.35064639e-01 -1.01031001e+01  3.61473009e+00\n",
      "    5.48784198e+00 -1.74230891e+01]\n",
      "  [-1.51085215e-01  2.40969081e-01 -1.07148286e-01  5.01917145e-02\n",
      "    5.60435984e-02 -1.97707948e-01]]] reward= -5140390.594725202 done= False\n",
      "Step 776\n",
      "Action:  [ 0.8535636   0.36966372 -0.7055175   1.1484536   1.7610489  -0.03725106]\n",
      "self.next: 776\n",
      "obs= [[[  2.64295885  -2.19764721  -0.14913907   0.79822895  -2.09398977\n",
      "     0.17248521]\n",
      "  [  0.04817009  -0.0240567   -0.02464889  -0.04288956   0.10634222\n",
      "    -0.1702285 ]]\n",
      "\n",
      " [[  8.22868779  -0.61096773 -10.11381492   3.61974927   5.49344634\n",
      "   -17.44285991]\n",
      "  [ -0.15186837   0.24179531  -0.10666668   0.04949307   0.05558205\n",
      "    -0.1966638 ]]] reward= -5866003.891752144 done= False\n",
      "Step 777\n",
      "Action:  [ 0.852322    0.3698322  -0.70491815  1.1469882   1.757374   -0.03663419]\n",
      "self.next: 777\n",
      "obs= [[[ 2.64777586e+00 -2.20005288e+00 -1.51603963e-01  7.93939995e-01\n",
      "   -2.08335555e+00  1.55462360e-01]\n",
      "  [-1.05910472e-02 -2.60655962e-02  3.64143629e-02  5.80834589e-04\n",
      "    9.27521420e-04  4.54547255e-03]]\n",
      "\n",
      " [[ 8.21350096e+00 -5.86788200e-01 -1.01244816e+01  3.62469857e+00\n",
      "    5.49900455e+00 -1.74625263e+01]\n",
      "  [-1.52641549e-01  2.42651522e-01 -1.06246897e-01  4.88410568e-02\n",
      "    5.51131334e-02 -1.95631152e-01]]] reward= -5044796.109628442 done= False\n",
      "Step 778\n",
      "Action:  [ 0.8523517   0.36982217 -0.70466024  1.1473615   1.7574202  -0.03671489]\n",
      "self.next: 778\n",
      "obs= [[[ 2.64671676e+00 -2.20265944e+00 -1.47962526e-01  7.93998079e-01\n",
      "   -2.08326280e+00  1.55916908e-01]\n",
      "  [-3.33596681e-02  6.26027298e-02 -3.09341060e-02  4.54763061e-02\n",
      "   -1.07985216e-01  1.61596616e-02]]\n",
      "\n",
      " [[ 8.19823680e+00 -5.62523048e-01 -1.01351063e+01  3.62958268e+00\n",
      "    5.50451586e+00 -1.74820894e+01]\n",
      "  [-1.53403566e-01  2.43537230e-01 -1.05890674e-01  4.82377638e-02\n",
      "    5.46369114e-02 -1.94610345e-01]]] reward= -5088002.021402947 done= False\n",
      "Step 779\n",
      "Action:  [ 0.8545298   0.36989146 -0.7067169   1.1490716   1.7635628  -0.03805888]\n",
      "self.next: 779\n",
      "obs= [[[ 2.64338079e+00 -2.19639916e+00 -1.51055937e-01  7.98545709e-01\n",
      "   -2.09406132e+00  1.57532874e-01]\n",
      "  [-9.66800768e-04 -2.52502178e-02 -1.52333730e-01  1.76391158e-01\n",
      "    6.78952514e-02 -1.06292525e-01]]\n",
      "\n",
      " [[ 8.18289644e+00 -5.38169325e-01 -1.01456953e+01  3.63440645e+00\n",
      "    5.50997955e+00 -1.75015504e+01]\n",
      "  [-1.54153351e-01  2.44451969e-01 -1.05599585e-01  4.76851408e-02\n",
      "    5.41534578e-02 -1.93601687e-01]]] reward= -5598037.532338831 done= False\n",
      "Step 780\n",
      "Action:  [ 0.85486084  0.3696409  -0.70742935  1.148595    1.7648829  -0.03841187]\n",
      "self.next: 780\n",
      "obs= [[[ 2.64328411e+00 -2.19892418e+00 -1.66289310e-01  8.16184825e-01\n",
      "   -2.08727179e+00  1.46903621e-01]\n",
      "  [ 5.68643141e-02 -1.25195489e-02 -4.05473154e-02 -5.05720340e-02\n",
      "    1.08871433e-01 -1.20861881e-01]]\n",
      "\n",
      " [[ 8.16748111e+00 -5.13724128e-01 -1.01562553e+01  3.63917497e+00\n",
      "    5.51539490e+00 -1.75209106e+01]\n",
      "  [-1.54889978e-01  2.45395322e-01 -1.05375024e-01  4.71849912e-02\n",
      "    5.36628691e-02 -1.92605457e-01]]] reward= -8742492.074267488 done= False\n",
      "Step 781\n",
      "Action:  [ 0.8505838   0.3700352  -0.70341605  1.1458186   1.7522663  -0.03585611]\n",
      "self.next: 781\n",
      "obs= [[[  2.64897054  -2.20017614  -0.17034404   0.81112762  -2.07638465\n",
      "     0.13481743]\n",
      "  [  0.08647307  -0.05630249   0.14667358  -0.26523647   0.15400014\n",
      "    -0.07647388]]\n",
      "\n",
      " [[  8.15199211  -0.4891846  -10.16679281   3.64389347   5.52076119\n",
      "   -17.54017115]\n",
      "  [ -0.15561267   0.24636692  -0.1052182    0.04673896   0.05316526\n",
      "    -0.19162191]]] reward= -5274117.89699794 done= False\n",
      "Step 782\n",
      "Action:  [ 0.8458358   0.37022877 -0.6988491   1.1426157   1.7387632  -0.03309229]\n",
      "self.next: 782\n",
      "obs= [[[  2.65761785  -2.20580639  -0.15567668   0.78460398  -2.06098464\n",
      "     0.12717004]\n",
      "  [ -0.07416666   0.04828481   0.02664783  -0.03891616  -0.19160607\n",
      "     0.1510502 ]]\n",
      "\n",
      " [[  8.13643085  -0.4645479  -10.17731463   3.64856736   5.52607771\n",
      "   -17.55933334]\n",
      "  [ -0.1563208    0.24736645  -0.10513015   0.04634855   0.05266076\n",
      "    -0.19065125]]] reward= -9066150.598682685 done= False\n",
      "Step 783\n",
      "Action:  [ 0.85249674  0.37011153 -0.7047368   1.1479427   1.7574948  -0.03710309]\n",
      "self.next: 783\n",
      "obs= [[[ 2.65020118e+00 -2.20097791e+00 -1.53011901e-01  7.80712359e-01\n",
      "   -2.08014524e+00  1.42275065e-01]\n",
      "  [-1.81486828e-02 -6.66476392e-02  8.31023350e-02  1.56334089e-03\n",
      "   -6.64021919e-02  7.92019849e-02]]\n",
      "\n",
      " [[ 8.12079876e+00 -4.39811258e-01 -1.01878276e+01  3.65320222e+00\n",
      "    5.53134379e+00 -1.75783985e+01]\n",
      "  [-1.57013882e-01  2.48393655e-01 -1.05111751e-01  4.60151124e-02\n",
      "    5.21495349e-02 -1.89693698e-01]]] reward= -6777869.402173948 done= False\n",
      "Step 784\n",
      "Action:  [ 0.8495399   0.36994734 -0.70204437  1.1455588   1.74965    -0.03538788]\n",
      "self.next: 784\n",
      "obs= [[[ 2.64838631e+00 -2.20764267e+00 -1.44701667e-01  7.80868693e-01\n",
      "   -2.08678546e+00  1.50195263e-01]\n",
      "  [ 6.14963668e-02  3.74260522e-03 -6.63756646e-02 -4.69787868e-02\n",
      "    1.08547664e-01 -1.68319941e-01]]\n",
      "\n",
      " [[ 8.10509738e+00 -4.14971893e-01 -1.01983388e+01  3.65780373e+00\n",
      "    5.53655874e+00 -1.75973678e+01]\n",
      "  [-1.57691607e-01  2.49448346e-01 -1.05163653e-01  4.57397904e-02\n",
      "    5.16317303e-02 -1.88749387e-01]]] reward= -5877558.777419678 done= False\n",
      "Step 785\n",
      "Action:  [ 0.8497405   0.37011296 -0.7028555   1.145123    1.7501605  -0.0356166 ]\n",
      "self.next: 785\n",
      "obs= [[[  2.65453595  -2.20726841  -0.15133923   0.77617081  -2.0759307\n",
      "     0.13336327]\n",
      "  [ -0.02656948   0.04643258  -0.01939054  -0.08383523  -0.01780986\n",
      "     0.11157091]]\n",
      "\n",
      " [[  8.08932822  -0.39002706 -10.20885519   3.66237771   5.54172192\n",
      "   -17.61624277]\n",
      "  [ -0.15835382   0.25053041  -0.10528635   0.04552359   0.05110752\n",
      "    -0.18781844]]] reward= -5710440.094989903 done= False\n",
      "Step 786\n",
      "Action:  [ 0.850423    0.3702911  -0.7031107   1.1460655   1.7512196  -0.03610899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 786\n",
      "obs= [[[ 2.65187900e+00 -2.20262515e+00 -1.53278288e-01  7.67787291e-01\n",
      "   -2.07771168e+00  1.44520360e-01]\n",
      "  [-6.68037682e-03  5.54757403e-04  5.49786810e-03  4.97689004e-04\n",
      "   -1.01248851e-01  1.17472256e-01]]\n",
      "\n",
      " [[ 8.07349283e+00 -3.64974018e-01 -1.02193838e+01  3.66693007e+00\n",
      "    5.54683267e+00 -1.76350246e+01]\n",
      "  [-1.59000517e-01  2.51639788e-01 -1.05480166e-01  4.53673465e-02\n",
      "    5.05770840e-02 -1.86900948e-01]]] reward= -5836915.094872808 done= False\n",
      "Step 787\n",
      "Action:  [ 0.8501686   0.37013963 -0.70278     1.1460565   1.7511088  -0.03600534]\n",
      "self.next: 787\n",
      "obs= [[[ 2.65121096e+00 -2.20256968e+00 -1.52728501e-01  7.67837060e-01\n",
      "   -2.08783657e+00  1.56267585e-01]\n",
      "  [ 3.55100193e-02  3.50247222e-02 -2.44518904e-01  1.72112447e-01\n",
      "    2.70281231e-03  3.48342642e-02]]\n",
      "\n",
      " [[ 8.05759278e+00 -3.39810039e-01 -1.02299318e+01  3.67146680e+00\n",
      "    5.55189038e+00 -1.76537147e+01]\n",
      "  [-1.59631867e-01  2.52776526e-01 -1.05745231e-01  4.52717198e-02\n",
      "    5.00405982e-02 -1.85996952e-01]]] reward= -5685753.673152285 done= False\n",
      "Step 788\n",
      "Action:  [ 0.85435575  0.37000626 -0.7072018   1.1483748   1.7630942  -0.03878085]\n",
      "self.next: 788\n",
      "obs= [[[ 2.65476197e+00 -2.19906721e+00 -1.77180392e-01  7.85048305e-01\n",
      "   -2.08756629e+00  1.59751012e-01]\n",
      "  [ 9.08247519e-04 -1.35603627e-03  1.38012084e-04  3.96270773e-04\n",
      "   -2.73125507e-04 -1.39272284e-04]]\n",
      "\n",
      " [[ 8.04162960e+00 -3.14532386e-01 -1.02405064e+01  3.67599398e+00\n",
      "    5.55689444e+00 -1.76723144e+01]\n",
      "  [-1.60248176e-01  2.53940725e-01 -1.06081534e-01  4.52372200e-02\n",
      "    4.94982469e-02 -1.85106472e-01]]] reward= -8025968.510941563 done= False\n",
      "Step 789\n",
      "Action:  [ 0.8480518   0.37019488 -0.7010056   1.1442636   1.745034   -0.03480658]\n",
      "self.next: 789\n",
      "obs= [[[ 2.65485279e+00 -2.19920281e+00 -1.77166590e-01  7.85087932e-01\n",
      "   -2.08759360e+00  1.59737084e-01]\n",
      "  [ 8.62438584e-04 -4.77633098e-02  4.53938406e-02  1.86844612e-03\n",
      "    3.92613233e-02 -1.44073121e-01]]\n",
      "\n",
      " [[ 8.02560478e+00 -2.89138314e-01 -1.02511145e+01  3.68051770e+00\n",
      "    5.56184426e+00 -1.76908251e+01]\n",
      "  [-1.60849922e-01  2.55132582e-01 -1.06488881e-01  4.52641807e-02\n",
      "    4.89502024e-02 -1.84229479e-01]]] reward= -5172834.008792292 done= False\n",
      "Step 790\n",
      "Action:  [ 0.84605163  0.37009192 -0.6992684   1.1426516   1.73991    -0.03360547]\n",
      "self.next: 790\n",
      "obs= [[[ 2.65493903e+00 -2.20397914e+00 -1.72627206e-01  7.85274776e-01\n",
      "   -2.08366747e+00  1.45329772e-01]\n",
      "  [ 5.19300120e-03 -1.60273181e-02  1.09581472e-02  2.44872257e-04\n",
      "   -6.06737882e-02  1.55027877e-01]]\n",
      "\n",
      " [[ 8.00951979e+00 -2.63625055e-01 -1.02617634e+01  3.68504412e+00\n",
      "    5.56673928e+00 -1.77092480e+01]\n",
      "  [-1.61437703e-01  2.56352363e-01 -1.06966955e-01  4.53528053e-02\n",
      "    4.83966411e-02 -1.83365920e-01]]] reward= -5328252.709082192 done= False\n",
      "Step 791\n",
      "Action:  [ 0.8480607   0.37022933 -0.7008947   1.1444569   1.7449973  -0.0350237 ]\n",
      "self.next: 791\n",
      "obs= [[[ 2.65545834e+00 -2.20558187e+00 -1.71531392e-01  7.85299264e-01\n",
      "   -2.08973484e+00  1.60832560e-01]\n",
      "  [-7.54294459e-02  1.09492423e-02  6.59867099e-02  4.75710482e-02\n",
      "    1.21398631e-02 -2.78493501e-01]]\n",
      "\n",
      " [[ 7.99337602e+00 -2.37989819e-01 -1.02724601e+01  3.68957940e+00\n",
      "    5.57157894e+00 -1.77275846e+01]\n",
      "  [-1.62012257e-01  2.57600415e-01 -1.07515307e-01  4.55031557e-02\n",
      "    4.78377314e-02 -1.82515712e-01]]] reward= -5383734.624732709 done= False\n",
      "Step 792\n",
      "Action:  [ 0.8456505   0.37003338 -0.6989742   1.1422126   1.7390124  -0.03332833]\n",
      "self.next: 792\n",
      "obs= [[[  2.64791539  -2.20448695  -0.16493272   0.79005637  -2.08852086\n",
      "     0.13298321]\n",
      "  [  0.05460812  -0.03547241  -0.0191143   -0.04943863   0.0470314\n",
      "     0.08995088]]\n",
      "\n",
      " [[  7.97717479  -0.21222978 -10.28321163   3.69412971   5.57636272\n",
      "   -17.74583617]\n",
      "  [ -0.16257446   0.25887717  -0.10813335   0.04571515   0.04727363\n",
      "    -0.18167873]]] reward= -6274875.098971831 done= False\n",
      "Step 793\n",
      "Action:  [ 0.8462601   0.3703134  -0.69948184  1.1429105   1.7400221  -0.03412542]\n",
      "self.next: 793\n",
      "obs= [[[ 2.65337620e+00 -2.20803419e+00 -1.66844150e-01  7.85112506e-01\n",
      "   -2.08381772e+00  1.41978298e-01]\n",
      "  [-4.27494291e-02 -1.55568596e-03  4.49036917e-02  4.26607949e-02\n",
      "   -7.02299706e-02 -1.85808044e-01]]\n",
      "\n",
      " [[ 7.96091734e+00 -1.86342061e-01 -1.02940250e+01  3.69870123e+00\n",
      "    5.58109008e+00 -1.77640040e+01]\n",
      "  [-1.63125281e-01  2.60183120e-01 -1.08820392e-01  4.59885965e-02\n",
      "    4.67044778e-02 -1.80854840e-01]]] reward= -5215658.176858749 done= False\n",
      "Step 794\n",
      "Action:  [ 0.8458221   0.37012094 -0.69911367  1.1425903   1.7396183  -0.0336026 ]\n",
      "self.next: 794\n",
      "obs= [[[ 2.64910126e+00 -2.20818976e+00 -1.62353781e-01  7.89378585e-01\n",
      "   -2.09084072e+00  1.23397494e-01]\n",
      "  [-9.02494301e-03  6.93268169e-02 -6.04261188e-02 -8.21762371e-02\n",
      "   -1.72524627e-01  4.15018030e-01]]\n",
      "\n",
      " [[ 7.94460482e+00 -1.60323749e-01 -1.03049070e+01  3.70330009e+00\n",
      "    5.58576053e+00 -1.77820895e+01]\n",
      "  [-1.63665824e-01  2.61518852e-01 -1.09575645e-01  4.63231843e-02\n",
      "    4.61304120e-02 -1.80043860e-01]]] reward= -6436002.795589912 done= False\n",
      "Step 795\n",
      "Action:  [ 0.84978896  0.37048352 -0.7024298   1.1458805   1.749004   -0.03646404]\n",
      "self.next: 795\n",
      "obs= [[[  2.64819876  -2.20125708  -0.16839639   0.78116096  -2.10809318\n",
      "     0.1648993 ]\n",
      "  [  0.02787469  -0.07803862   0.05057749  -0.04718931   0.10220916\n",
      "    -0.13751506]]\n",
      "\n",
      " [[  7.92823823  -0.13417186 -10.31586457   3.70793241   5.59037357\n",
      "   -17.80009391]\n",
      "  [ -0.16419727   0.262885    -0.11039824   0.04671851   0.04555155\n",
      "    -0.1792456 ]]] reward= -7232664.899529426 done= False\n",
      "Step 796\n",
      "Action:  [ 0.84268004  0.37020805 -0.6963143   1.140034    1.7305539  -0.0320547 ]\n",
      "self.next: 796\n",
      "obs= [[[ 2.65098623e+00 -2.20906094e+00 -1.63338644e-01  7.76442031e-01\n",
      "   -2.09787226e+00  1.51147791e-01]\n",
      "  [ 9.47043167e-03  5.68189303e-02 -1.40984774e-02 -2.15077311e-01\n",
      "    5.95208226e-02 -3.11734596e-02]]\n",
      "\n",
      " [[ 7.91181851e+00 -1.07883363e-01 -1.03269044e+01  3.71260426e+00\n",
      "    5.59492872e+00 -1.78180185e+01]\n",
      "  [-1.64720909e-01  2.64282294e-01 -1.11287194e-01  4.71740670e-02\n",
      "    4.49679841e-02 -1.78459833e-01]]] reward= -5214106.298558401 done= False\n",
      "Step 797\n",
      "Action:  [ 0.8441423   0.3706503  -0.6976997   1.1413003   1.7335343  -0.03296638]\n",
      "self.next: 797\n",
      "obs= [[[  2.65193328  -2.20337904  -0.16474849   0.7549343   -2.09192018\n",
      "     0.14803045]\n",
      "  [ -0.03688359  -0.04539997   0.0323844    0.12746017  -0.13444615\n",
      "     0.06058899]]\n",
      "\n",
      " [[  7.89534642  -0.08145513 -10.33803311   3.71732166   5.59942552\n",
      "   -17.83586445]\n",
      "  [ -0.16523808   0.26571149  -0.11224152   0.04768929   0.0443798\n",
      "    -0.17768633]]] reward= -8385000.627470285 done= False\n",
      "Step 798\n",
      "Action:  [ 0.84566677  0.37006855 -0.6988239   1.1426209   1.7391908  -0.03395826]\n",
      "self.next: 798\n",
      "obs= [[[  2.64824492  -2.20791904  -0.16151005   0.76768032  -2.10536479\n",
      "     0.15408934]\n",
      "  [  0.06290512   0.03343796  -0.09836661  -0.04543823   0.10492837\n",
      "    -0.17772766]]\n",
      "\n",
      " [[  7.87882261  -0.05488398 -10.34925726   3.72209059   5.6038635\n",
      "   -17.85363309]\n",
      "  [ -0.16575019   0.26717342  -0.11326013   0.04826354   0.04378707\n",
      "    -0.17692485]]] reward= -7117770.24984776 done= False\n",
      "Step 799\n",
      "Action:  [ 0.84421146  0.3704023  -0.69810295  1.140987    1.734722   -0.03323321]\n",
      "self.next: 799\n",
      "obs= [[[ 2.65453543e+00 -2.20457525e+00 -1.71346712e-01  7.63136494e-01\n",
      "   -2.09487196e+00  1.36316578e-01]\n",
      "  [ 3.62970758e-03  6.34452007e-02 -6.76321366e-02 -1.59453414e-01\n",
      "    1.57406465e-01 -1.02488916e-01]]\n",
      "\n",
      " [[ 7.86224759e+00 -2.81666431e-02 -1.03605833e+01  3.72691695e+00\n",
      "    5.60824221e+00 -1.78713256e+01]\n",
      "  [-1.66258728e-01  2.68668956e-01 -1.14341928e-01  4.88961256e-02\n",
      "    4.31898276e-02 -1.76175109e-01]]] reward= -6571871.675025022 done= False\n",
      "Step 800\n",
      "Action:  [ 0.8429334   0.3705972  -0.69690263  1.1400537   1.730377   -0.03253684]\n",
      "self.next: 800\n",
      "obs= [[[ 2.65489840e+00 -2.19823073e+00 -1.78109926e-01  7.47191152e-01\n",
      "   -2.07913131e+00  1.26067686e-01]\n",
      "  [ 6.80897606e-04 -1.02245940e-03 -8.35062234e-04  2.21156521e-04\n",
      "    2.27606391e-03 -7.07647768e-04]]\n",
      "\n",
      " [[ 7.84562172e+00 -1.29974748e-03 -1.03720175e+01  3.73180656e+00\n",
      "    5.61256119e+00 -1.78889431e+01]\n",
      "  [-1.66765191e-01  2.70199025e-01 -1.15485759e-01  4.95863080e-02\n",
      "    4.25881011e-02 -1.75436849e-01]]] reward= -6525611.041836655 done= False\n",
      "Step 801\n",
      "Action:  [ 0.8428806   0.37033805 -0.69659173  1.1403588   1.7308754  -0.03257585]\n",
      "self.next: 801\n",
      "obs= [[[ 2.65496649e+00 -2.19833297e+00 -1.78193432e-01  7.47213268e-01\n",
      "   -2.07890370e+00  1.25996922e-01]\n",
      "  [-9.50051151e-03 -3.26023754e-02  4.12562390e-02  1.67678650e-03\n",
      "   -2.29387362e-03 -8.17077895e-02]]\n",
      "\n",
      " [[ 7.82894520e+00  2.57201550e-02 -1.03835660e+01  3.73676519e+00\n",
      "    5.61682000e+00 -1.79064868e+01]\n",
      "  [-1.67271126e-01  2.71764578e-01 -1.16690459e-01  5.03333216e-02\n",
      "    4.19818966e-02 -1.74709787e-01]]] reward= -5348627.966319957 done= False\n",
      "Step 802\n",
      "Action:  [ 0.84145784  0.370267   -0.6953008   1.1392809   1.7272464  -0.03174935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 802\n",
      "obs= [[[ 2.65401644e+00 -2.20159321e+00 -1.74067808e-01  7.47380947e-01\n",
      "   -2.07913309e+00  1.17826143e-01]\n",
      "  [-2.00036431e-02 -6.26405038e-02  8.23343669e-02 -9.46569996e-04\n",
      "   -1.02097860e-01  6.06294132e-02]]\n",
      "\n",
      " [[ 7.81221808e+00  5.28966128e-02 -1.03952351e+01  3.74179852e+00\n",
      "    5.62101819e+00 -1.79239577e+01]\n",
      "  [-1.67778099e-01  2.73366602e-01 -1.17954842e-01  5.11363730e-02\n",
      "    4.13711992e-02 -1.73993640e-01]]] reward= -5622418.2261755075 done= False\n",
      "Step 803\n",
      "Action:  [ 0.8416489   0.37025368 -0.69525254  1.139672    1.727742   -0.03194872]\n",
      "self.next: 803\n",
      "obs= [[[ 2.65201608e+00 -2.20785726e+00 -1.65834372e-01  7.47286290e-01\n",
      "   -2.08934288e+00  1.23889084e-01]\n",
      "  [-3.03971458e-02  1.01791170e-02  1.93539684e-01 -1.71346718e-01\n",
      "   -1.60692215e-01  2.25775134e-01]]\n",
      "\n",
      " [[ 7.79544027e+00  8.02332731e-02 -1.04070306e+01  3.74691216e+00\n",
      "    5.62515531e+00 -1.79413571e+01]\n",
      "  [-1.68287688e-01  2.75006103e-01 -1.19277715e-01  5.19946575e-02\n",
      "    4.07559764e-02 -1.73288124e-01]]] reward= -6466362.420255263 done= False\n",
      "Step 804\n",
      "Action:  [ 0.8403635   0.37049073 -0.6937233   1.1390437   1.7233382  -0.03121207]\n",
      "self.next: 804\n",
      "obs= [[[  2.64897636  -2.20683935  -0.1464804    0.73015162  -2.1054121\n",
      "     0.1464666 ]\n",
      "  [  0.03880477  -0.06794944   0.02920632  -0.05041009   0.20259981\n",
      "    -0.38986476]]\n",
      "\n",
      " [[  7.77861151   0.10773388 -10.41895835   3.75211162   5.62923091\n",
      "   -17.95868592]\n",
      "  [ -0.16880148   0.2766841   -0.12065787   0.05290736   0.04013618\n",
      "    -0.17259296]]] reward= -9462104.14157703 done= False\n",
      "Step 805\n",
      "Action:  [ 0.8380273   0.3700882  -0.6926491   1.1359797   1.7187003  -0.03006594]\n",
      "self.next: 805\n",
      "obs= [[[  2.65285684  -2.21363429  -0.14355977   0.72511061  -2.08515212\n",
      "     0.10748012]\n",
      "  [ -0.04726658   0.09178597  -0.22085389   0.09609512  -0.12724454\n",
      "     0.15100428]]\n",
      "\n",
      " [[  7.76173136   0.13540229 -10.43102413   3.75740236   5.63324453\n",
      "   -17.97594522]\n",
      "  [ -0.16932104   0.27840162  -0.12209411   0.05387367   0.03951173\n",
      "    -0.17190787]]] reward= -5968652.336968636 done= False\n",
      "Step 806\n",
      "Action:  [ 0.84843725  0.37036175 -0.7019807   1.1441565   1.746357   -0.03634332]\n",
      "self.next: 806\n",
      "obs= [[[ 2.64813018e+00 -2.20445569e+00 -1.65645160e-01  7.34720121e-01\n",
      "   -2.09787657e+00  1.22580549e-01]\n",
      "  [-3.96813848e-03 -2.83387889e-02 -1.62785174e-02  4.50328956e-02\n",
      "   -5.16883604e-02  6.13572554e-02]]\n",
      "\n",
      " [[ 7.74479925e+00  1.63242455e-01 -1.04432335e+01  3.76278973e+00\n",
      "    5.63719570e+00 -1.79931360e+01]\n",
      "  [-1.69847928e-01  2.80159677e-01 -1.23585249e-01  5.48927806e-02\n",
      "    3.88825514e-02 -1.71232584e-01]]] reward= -9226462.193374561 done= False\n",
      "Step 807\n",
      "Action:  [ 0.8417834   0.37026507 -0.69563824  1.139441    1.7281687  -0.03239459]\n",
      "self.next: 807\n",
      "obs= [[[ 2.64773337e+00 -2.20728957e+00 -1.67273012e-01  7.39223411e-01\n",
      "   -2.10304541e+00  1.28716274e-01]\n",
      "  [ 1.90694932e-03 -3.96613407e-02  3.65032181e-02 -3.56873295e-03\n",
      "   -5.39080574e-02 -8.49760103e-02]]\n",
      "\n",
      " [[ 7.72781446e+00  1.91258423e-01 -1.04555921e+01  3.76827901e+00\n",
      "    5.64108396e+00 -1.80102593e+01]\n",
      "  [-1.70383698e-01  2.81959285e-01 -1.25130052e-01  5.59638900e-02\n",
      "    3.82485374e-02 -1.70566846e-01]]] reward= -6439094.7542399205 done= False\n",
      "Step 808\n",
      "Action:  [ 0.839755    0.37027314 -0.6938258   1.1379418   1.7228216  -0.03117044]\n",
      "self.next: 808\n",
      "obs= [[[ 2.64792406e+00 -2.21125571e+00 -1.63622690e-01  7.38866538e-01\n",
      "   -2.10843621e+00  1.20218673e-01]\n",
      "  [-1.40241289e-02  7.29668895e-02 -5.89882206e-02 -7.86139714e-02\n",
      "   -7.57033894e-02  2.70450374e-01]]\n",
      "\n",
      " [[ 7.71077609e+00  2.19454352e-01 -1.04681051e+01  3.77387539e+00\n",
      "    5.64490881e+00 -1.80273159e+01]\n",
      "  [-1.70929855e-01  2.83801426e-01 -1.26727328e-01  5.70862167e-02\n",
      "    3.76095721e-02 -1.69910408e-01]]] reward= -6261711.793338043 done= False\n",
      "Step 809\n",
      "Action:  [ 0.8431189   0.37055367 -0.6967939   1.140475    1.7307684  -0.03338489]\n",
      "self.next: 809\n",
      "obs= [[[  2.64652165  -2.20395902  -0.16952151   0.73100514  -2.11600655\n",
      "     0.14726371]\n",
      "  [  0.05884962  -0.03331722   0.02503008  -0.10357278   0.04820631\n",
      "     0.03627307]]\n",
      "\n",
      " [[  7.69368311   0.24783449 -10.48077781   3.77958402   5.64866977\n",
      "   -18.04430699]\n",
      "  [ -0.17148787   0.28568705  -0.12837588   0.058259     0.03696553\n",
      "    -0.16926304]]] reward= -6642458.687813564 done= False\n",
      "Step 810\n",
      "Action:  [ 0.83814204  0.370414   -0.69237494  1.1366265   1.7177917  -0.03053857]\n",
      "self.next: 810\n",
      "obs= [[[  2.65240661  -2.20729074  -0.1670185    0.72064786  -2.11118592\n",
      "     0.15089102]\n",
      "  [  0.04411513  -0.08677338   0.21609918  -0.22642309   0.15833331\n",
      "    -0.25746642]]\n",
      "\n",
      " [[  7.67653432   0.2764032  -10.49361539   3.78540992   5.65236632\n",
      "   -18.06123329]\n",
      "  [ -0.17205917   0.28761706  -0.13007449   0.05948149   0.03631627\n",
      "    -0.16862454]]] reward= -6804992.642819501 done= False\n",
      "Step 811\n",
      "Action:  [ 0.83234084  0.37022725 -0.6871614   1.1319895   1.7025323  -0.02722386]\n",
      "self.next: 811\n",
      "obs= [[[ 2.65681812e+00 -2.21596808e+00 -1.45408586e-01  6.98005554e-01\n",
      "   -2.09535259e+00  1.25144376e-01]\n",
      "  [ 7.09260605e-02 -9.99920875e-04 -6.89686637e-02 -5.41667294e-02\n",
      "    1.35786683e-03  2.42876996e-01]]\n",
      "\n",
      " [[ 7.65932840e+00  3.05164906e-01 -1.05066228e+01  3.79135806e+00\n",
      "    5.65599795e+00 -1.80780957e+01]\n",
      "  [-1.72645145e-01  2.89592320e-01 -1.31821930e-01  6.07529537e-02\n",
      "    3.56616376e-02 -1.67994693e-01]]] reward= -9600600.12798158 done= False\n",
      "Step 812\n",
      "Action:  [ 0.84130514  0.37039056 -0.6953712   1.1388425   1.7264501  -0.03277163]\n",
      "self.next: 812\n",
      "obs= [[[ 2.66391073e+00 -2.21606807e+00 -1.52305452e-01  6.92588881e-01\n",
      "   -2.09521680e+00  1.49432076e-01]\n",
      "  [-1.49043839e-02 -1.65995898e-02  3.09755103e-02  1.85763550e-03\n",
      "    4.98821250e-02 -2.10370983e-01]]\n",
      "\n",
      " [[ 7.64206389e+00  3.34124138e-01 -1.05198050e+01  3.79743336e+00\n",
      "    5.65956411e+00 -1.80948952e+01]\n",
      "  [-1.73247098e-01  2.91613594e-01 -1.33616994e-01  6.20727014e-02\n",
      "    3.50014933e-02 -1.67373349e-01]]] reward= -6078043.311359151 done= False\n",
      "Step 813\n",
      "Action:  [ 0.8374891   0.37017137 -0.6920569   1.1357533   1.7169602  -0.03030163]\n",
      "self.next: 813\n",
      "obs= [[[ 2.66242029e+00 -2.21772803e+00 -1.49207901e-01  6.92774645e-01\n",
      "   -2.09022859e+00  1.28394978e-01]\n",
      "  [-2.07742267e-04 -2.01288142e-03  2.06519874e-03  6.30658489e-04\n",
      "    4.30191378e-04 -4.32476101e-04]]\n",
      "\n",
      " [[ 7.62473918e+00  3.63285497e-01 -1.05331667e+01  3.80364063e+00\n",
      "    5.66306426e+00 -1.81116326e+01]\n",
      "  [-1.73866298e-01  2.93681591e-01 -1.35458405e-01  6.34400292e-02\n",
      "    3.43356692e-02 -1.66760351e-01]]] reward= -6003644.114872303 done= False\n",
      "Step 814\n",
      "Action:  [ 0.83874923  0.37023965 -0.69311184  1.136824    1.72009    -0.03121081]\n",
      "self.next: 814\n",
      "obs= [[[ 2.66239952e+00 -2.21792932e+00 -1.49001381e-01  6.92837711e-01\n",
      "   -2.09018557e+00  1.28351730e-01]\n",
      "  [ 4.86987396e-04  9.73753905e-04 -9.69442635e-04 -2.51138628e-03\n",
      "    1.52678297e-03  2.41106873e-04]]\n",
      "\n",
      " [[ 7.60735255e+00  3.92653656e-01 -1.05467126e+01  3.80998463e+00\n",
      "    5.66649783e+00 -1.81283086e+01]\n",
      "  [-1.74503928e-01  2.95796916e-01 -1.37344882e-01  6.48542660e-02\n",
      "    3.36640078e-02 -1.66155580e-01]]] reward= -5557415.81035836 done= False\n",
      "Step 815\n",
      "Action:  [ 0.83842844  0.37023196 -0.6928435   1.136538    1.7192334  -0.03111048]\n",
      "self.next: 815\n",
      "obs= [[[  2.66244822  -2.21783194  -0.14909833   0.69258657  -2.09003289\n",
      "     0.12837584]\n",
      "  [ -0.0196317    0.0907497   -0.29614221   0.22493565   0.05204934\n",
      "    -0.13189976]]\n",
      "\n",
      " [[  7.58990216   0.42223335 -10.56044706   3.81647006   5.66986423\n",
      "   -18.14492414]\n",
      "  [ -0.1751611    0.29796007  -0.13927509   0.06631474   0.03298635\n",
      "    -0.16555894]]] reward= -5595351.893452821 done= False\n",
      "Step 816\n",
      "Action:  [ 0.84453183  0.37004456 -0.6990613   1.1402878   1.7368197  -0.03488141]\n",
      "self.next: 816\n",
      "obs= [[[  2.66048505  -2.20875697  -0.17871255   0.71508014  -2.08482796\n",
      "     0.11518586]\n",
      "  [ -0.0727227   -0.05006642   0.29460831  -0.19755249  -0.1864117\n",
      "     0.22091357]]\n",
      "\n",
      " [[  7.57238605   0.45202935 -10.57437457   3.82310153   5.67316286\n",
      "   -18.16148004]\n",
      "  [ -0.17583884   0.30017142  -0.14124766   0.06782081   0.03230254\n",
      "    -0.16497037]]] reward= -9198928.052878521 done= False\n",
      "Step 817\n",
      "Action:  [ 0.83389     0.3702618  -0.68793255  1.1337488   1.7059184  -0.02850512]\n",
      "self.next: 817\n",
      "obs= [[[ 2.65321278e+00 -2.21376362e+00 -1.49251716e-01  6.95324888e-01\n",
      "   -2.10346913e+00  1.37277222e-01]\n",
      "  [ 5.37554077e-02  1.66268418e-02 -7.03382885e-02 -5.44405055e-02\n",
      "    1.06642968e-01 -6.28115895e-02]]\n",
      "\n",
      " [[ 7.55480216e+00  4.82046496e-01 -1.05884993e+01  3.82988362e+00\n",
      "    5.67639312e+00 -1.81779771e+01]\n",
      "  [-1.76538101e-01  3.02431208e-01 -1.43261126e-01  6.93717847e-02\n",
      "    3.16124256e-02 -1.64389832e-01]]] reward= -9162946.726307096 done= False\n",
      "Step 818\n",
      "Action:  [ 0.8368466   0.37025687 -0.6916784   1.134996    1.7149501  -0.0305345 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.next: 818\n",
      "obs= [[[  2.65858832  -2.21210093  -0.15628555   0.68988084  -2.09280483\n",
      "     0.13099606]\n",
      "  [  0.11052062  -0.06761191  -0.04317553  -0.11129851   0.21618687\n",
      "    -0.08550436]]\n",
      "\n",
      " [[  7.53714835   0.51228962 -10.60282545   3.83682079   5.67955436\n",
      "   -18.19441606]\n",
      "  [ -0.17725972   0.30473951  -0.14531398   0.07096701   0.03091587\n",
      "    -0.16381732]]] reward= -6425798.988173389 done= False\n",
      "Step 819\n",
      "Action:  [ 0.83400345  0.37012085 -0.6892157   1.1326298   1.7075052  -0.02920379]\n",
      "self.next: 819\n",
      "obs= [[[  2.66964038  -2.21886212  -0.1606031    0.67875099  -2.07118615\n",
      "     0.12244563]\n",
      "  [  0.02227966   0.04054175  -0.06295145  -0.13472243   0.03025849\n",
      "     0.09290838]]\n",
      "\n",
      " [[  7.51942238   0.54276357 -10.61735685   3.8439175    5.68264595\n",
      "   -18.21079779]\n",
      "  [ -0.17800443   0.30709623  -0.14740459   0.07260581   0.03021275\n",
      "    -0.16325288]]] reward= -6247109.620329563 done= False\n",
      "Step 820\n",
      "Action:  [ 0.8374538   0.37038946 -0.692148    1.1355838   1.7159836  -0.0310717 ]\n",
      "self.next: 820\n",
      "obs= [[[ 2.67186835e+00 -2.21480795e+00 -1.66898243e-01  6.65278744e-01\n",
      "   -2.06816030e+00  1.31736464e-01]\n",
      "  [ 1.18776413e-03  8.88448866e-02 -2.14702870e-01 -1.05474962e-02\n",
      "    7.86009397e-02  1.97714037e-02]]\n",
      "\n",
      " [[ 7.50162194e+00  5.73473191e-01 -1.06320973e+01  3.85117808e+00\n",
      "    5.68566722e+00 -1.82271231e+01]\n",
      "  [-1.78772877e-01  3.09501070e-01 -1.49531241e-01  7.42874538e-02\n",
      "    2.95029669e-02 -1.62696565e-01]]] reward= -7220191.458188275 done= False\n",
      "Step 821\n",
      "Action:  [ 0.8400992   0.37030149 -0.69491005  1.1371186   1.7235284  -0.03276895]\n",
      "self.next: 821\n",
      "obs= [[[ 2.67198712e+00 -2.20592346e+00 -1.88368530e-01  6.64223995e-01\n",
      "   -2.06030020e+00  1.33713604e-01]\n",
      "  [-1.82967533e-03  2.61570963e-02 -7.54388759e-02  4.84207219e-02\n",
      "   -1.39480685e-04 -5.40241576e-02]]\n",
      "\n",
      " [[ 7.48374465e+00  6.04423298e-01 -1.06470504e+01  3.85860682e+00\n",
      "    5.68861752e+00 -1.82433927e+01]\n",
      "  [-1.79565575e-01  3.11953536e-01 -1.51692094e-01  7.60112117e-02\n",
      "    2.87864261e-02 -1.62148484e-01]]] reward= -7293559.626962512 done= False\n",
      "Step 822\n",
      "Action:  [ 0.83654004  0.37009454 -0.69143045  1.1347446   1.7142661  -0.03069647]\n",
      "self.next: 822\n",
      "obs= [[[ 2.67180415e+00 -2.20330775e+00 -1.95912418e-01  6.69066067e-01\n",
      "   -2.06031415e+00  1.28311189e-01]\n",
      "  [-4.03440704e-02 -4.90224890e-03  4.48843003e-02 -7.63415632e-02\n",
      "   -8.60166822e-02  1.77729335e-01]]\n",
      "\n",
      " [[ 7.46578809e+00  6.35618651e-01 -1.06622196e+01  3.86620794e+00\n",
      "    5.69149616e+00 -1.82596076e+01]\n",
      "  [-1.80382923e-01  3.14452895e-01 -1.53885147e-01  7.77762801e-02\n",
      "    2.80630689e-02 -1.61608771e-01]]] reward= -5985403.42696944 done= False\n",
      "Step 823\n",
      "Action:  [ 0.83520347  0.37018383 -0.6897912   1.1340476   1.7097493  -0.02999232]\n",
      "self.next: 823\n",
      "obs= [[[ 2.66776975e+00 -2.20379797e+00 -1.91423988e-01  6.61431910e-01\n",
      "   -2.06891582e+00  1.46084122e-01]\n",
      "  [-1.89819578e-02 -3.25095049e-02  5.07099214e-02  5.40749272e-02\n",
      "   -5.24099443e-02  4.96720593e-03]]\n",
      "\n",
      " [[ 7.44774980e+00  6.67063941e-01 -1.06776082e+01  3.87398557e+00\n",
      "    5.69430247e+00 -1.82757685e+01]\n",
      "  [-1.81225187e-01  3.16998161e-01 -1.56108260e-01  7.95818081e-02\n",
      "    2.73328677e-02 -1.61077603e-01]]] reward= -6853566.397409074 done= False\n",
      "Step 824\n",
      "Action:  [ 0.83386993  0.36991024 -0.68871176  1.1328154   1.7070693  -0.02933513]\n",
      "self.next: 824\n",
      "obs= [[[ 2.66587155e+00 -2.20704892e+00 -1.86352996e-01  6.66839403e-01\n",
      "   -2.07415681e+00  1.46580843e-01]\n",
      "  [-1.46089430e-02  4.04009583e-02 -2.00579525e-01  1.72074124e-01\n",
      "    8.86213562e-04 -3.60528010e-02]]\n",
      "\n",
      " [[ 7.42962728e+00  6.98763757e-01 -1.06932190e+01  3.88194375e+00\n",
      "    5.69703575e+00 -1.82918762e+01]\n",
      "  [-1.82092495e-01  3.19588075e-01 -1.58359111e-01  8.14268704e-02\n",
      "    2.65958295e-02 -1.60555194e-01]]] reward= -5866613.192052669 done= False\n",
      "Step 825\n",
      "Action:  [ 0.8388551   0.36990064 -0.693763    1.1359892   1.7210734  -0.03240582]\n",
      "self.next: 825\n",
      "obs= [[[ 2.66441066e+00 -2.20300883e+00 -2.06410948e-01  6.84046815e-01\n",
      "   -2.07406819e+00  1.42975562e-01]\n",
      "  [-2.37908488e-02  1.45914947e-02  1.81737844e-01 -2.49530239e-01\n",
      "   -3.31412179e-02  1.02806851e-01]]\n",
      "\n",
      " [[ 7.41141803e+00  7.30722565e-01 -1.07090549e+01  3.89008644e+00\n",
      "    5.69969534e+00 -1.83079317e+01]\n",
      "  [-1.82984827e-01  3.22221083e-01 -1.60635195e-01  8.33104609e-02\n",
      "    2.58520046e-02 -1.60041798e-01]]] reward= -8675500.803279083 done= False\n",
      "Step 826\n",
      "Action:  [ 0.83016187  0.37021634 -0.6850817   1.1301885   1.695689   -0.02726331]\n",
      "self.next: 826\n",
      "obs= [[[ 2.66203157e+00 -2.20154968e+00 -1.88237164e-01  6.59093792e-01\n",
      "   -2.07738231e+00  1.53256248e-01]\n",
      "  [-1.81738447e-03 -1.62060528e-02  1.80068500e-02 -1.73339304e-03\n",
      "    1.46153224e-03 -3.65548694e-02]]\n",
      "\n",
      " [[ 7.39311955e+00  7.62944673e-01 -1.07251184e+01  3.89841748e+00\n",
      "    5.70228054e+00 -1.83239359e+01]\n",
      "  [-1.83902025e-01  3.24895323e-01 -1.62933771e-01  8.52314588e-02\n",
      "    2.51014761e-02 -1.59537697e-01]]] reward= -10203510.109966265 done= False\n",
      "Step 827\n",
      "Action:  [ 0.83248854  0.36990342 -0.6876156   1.1314814   1.7032934  -0.02883997]\n",
      "self.next: 827\n",
      "obs= [[[ 2.66184983e+00 -2.20317028e+00 -1.86436479e-01  6.58920452e-01\n",
      "   -2.07723616e+00  1.49600761e-01]\n",
      "  [-1.81738447e-03 -1.62060528e-02  1.80068500e-02 -1.73339304e-03\n",
      "    1.46153224e-03 -3.65548694e-02]]\n",
      "\n",
      " [[ 7.37472935e+00  7.95434205e-01 -1.07414118e+01  3.90694063e+00\n",
      "    5.70479069e+00 -1.83398897e+01]\n",
      "  [-1.84843753e-01  3.27608591e-01 -1.65251903e-01  8.71886460e-02\n",
      "    2.43443936e-02 -1.59043223e-01]]] reward= -5812349.299483713 done= True\n",
      "Goal reached! reward= -5812349.299483713\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "n_steps = 1000\n",
    "stat = np.empty((0,2,2,6))\n",
    "for step in range(n_steps):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    print(\"Step {}\".format(step + 1))\n",
    "    print(\"Action: \", action)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print('obs=', obs, 'reward=', reward, 'done=', done)\n",
    "    env.render(mode='console')\n",
    "    stat=np.append(stat,[obs],axis=0)\n",
    "    if done:\n",
    "        # Note that the VecEnv resets automatically\n",
    "        # when a done signal is encountered\n",
    "        print(\"Goal reached!\", \"reward=\", reward)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c204854a70f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mteacher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteacher_pose\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlearner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlearner_pose\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0manimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-da840f0356e5>\u001b[0m in \u001b[0;36manimate\u001b[0;34m(teacher_pose, learner_pose, r)\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mwin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_pose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "teacher=np.empty((0,7,2))#7 = number of points (L+1)\n",
    "learner=np.empty((0,7,2))\n",
    "for i in range(len(stat)):\n",
    "    teacher_theta=stat[i,0,0,:]\n",
    "    learner_theta=stat[i,1,0,:]\n",
    "    teacher_pose=position_from_angle(teacher_theta,env.L_list,[1000,500])\n",
    "    learner_pose=position_from_angle(learner_theta,env.L_list,[500,500])\n",
    "    teacher=np.append(teacher,[teacher_pose],axis=0)\n",
    "    learner=np.append(learner,[learner_pose],axis=0)\n",
    "animate(teacher,learner,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
